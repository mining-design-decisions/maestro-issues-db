[
    {
        "_id": "61d62e56f4d395ee222705d4",
        "key": "AMBARI-9708",
        "id": "12776186",
        "description": "Ran into a rat check failure that was not encountered when testing locally or on a local Jenkins job: https://builds.apache.org/view/All/job/Ambari-contrib-views/ws/contrib/views/target/rat.txt\nThis is because the one on https://builds.apache.org/view/All/job/Ambari-contrib-views installs node.js in workspace.\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.015596241690218449
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008781005628407001
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004945599008351564
                }
            }
        },
        "comments": [
            {
                "author_name": "hadoopqa",
                "id": "14327627",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12699688/AMBARI-9708.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in .\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/1740//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/1740//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "mahadev",
                "id": "14327664",
                "body": "\n+1"
            },
            {
                "author_name": "u39kun",
                "id": "14327667",
                "body": "Committed to trunk."
            },
            {
                "author_name": "hudson",
                "id": "14327737",
                "body": "SUCCESS: Integrated in Ambari-view #9 (See [https://builds.apache.org/job/Ambari-view/9/])\nAMBARI-9708. Ignore \"target\" directories to avoid rat check errors when compiling contrib/views directly from Jenkins. (yusaku) (yusaku: http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=53922274bb3b977686b626e4864f9227934f3a88)\n* contrib/views/pom.xml\n"
            },
            {
                "author_name": "hudson",
                "id": "14327830",
                "body": "SUCCESS: Integrated in Ambari-trunk-Commit #1812 (See [https://builds.apache.org/job/Ambari-trunk-Commit/1812/])\nAMBARI-9708. Ignore \"target\" directories to avoid rat check errors when compiling contrib/views directly from Jenkins. (yusaku) (yusaku: http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=53922274bb3b977686b626e4864f9227934f3a88)\n* contrib/views/pom.xml\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d61afbf4d395ee22245768",
        "key": "CONTINUUM-1732",
        "id": "12791994",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.011837158352136612
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0069313934072852135
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005594140850007534
                }
            }
        },
        "comments": [
            {
                "author_name": "ctan",
                "id": "14403861",
                "body": "submitted patch for this issue.\n\n* changed role-hint value of ContinuumUrlValidator from \"continuumUrl\" to \"url\""
            },
            {
                "author_name": "olamy",
                "id": "14404128",
                "body": "I don't really understand where do you have issue ?\nIn application.xml in the webapp we have \n{code:xml}\n    <component>\n      <role>org.codehaus.plexus.formica.validation.Validator</role>\n      <role-hint>url</role-hint>\n      <implementation>org.apache.maven.continuum.utils.ContinuumUrlValidator</implementation>\n      <configuration>\n        <allowedSchemes>\n          <allowedScheme>http</allowedScheme>\n          <allowedScheme>https</allowedScheme>\n          <allowedScheme>ftp</allowedScheme>\n          <!-- <allowedScheme>file</allowedScheme> -->\n        </allowedSchemes>\n      </configuration>\n    </component>\n{code}\nThe implementation value is correct.\nCan you explain in which case you have this  \"ClassNotFoundException during bean creation\" ?\nThanks."
            },
            {
                "author_name": "ctan",
                "id": "14404176",
                "body": "I was getting the ClassNotFoundException during bean creation when trying to add a Maven2 Project.\n\nI tried reproducing this again but now I'm not getting it anymore :( sorry..."
            }
        ],
        "comments_predictions": [
            [
                3299353,
                "CONTINUUM-1732",
                "I don't really understand where do you have issue ?\nIn application.xml in the webapp we have \n{code:xml}\n    <component>\n      <role>org.codehaus.plexus.formica.validation.Validator</role>\n      <role-hint>url</role-hint>\n      <implementation>org.apache.maven.continuum.utils.ContinuumUrlValidator</implementation>\n      <configuration>\n        <allowedSchemes>\n          <allowedScheme>http</allowedScheme>\n          <allowedScheme>https</allowedScheme>\n          <allowedScheme>ftp</allowedScheme>\n          <!-- <allowedScheme>file</allowedScheme> -->\n        </allowedSchemes>\n      </configuration>\n    </component>\n{code}\nThe implementation value is correct.\nCan you explain in which case you have this  \"ClassNotFoundException during bean creation\" ?\nThanks.",
                {
                    "property": {
                        "confidence": 0.005521600134670734,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006322534754872322,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01406859327107668,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5fe83f4d395ee22205ade",
        "key": "HIVE-23913",
        "id": "13318999",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008443865925073624
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.014594237320125103
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004318085499107838
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f655f4d395ee221f3ba9",
        "key": "JCR-2963",
        "id": "12506307",
        "description": "this issue is known (at least) since the early days of jsr 283 implementation but unfortunately never made it into jira...\n\njsr 283 defines that \"jcr:versionManagement: The privilege to perform versioning operations on a node\" which - as far as i know is consistently enforced in jackrabbit-core. similarly the specification mandates that \"If a repository supports full versioning, then it must expose the version storage at \n/jcr:system/jcr:versionStorage\", which is defined to be a write protected area that is shared between all workspaces of a repository. however, the specification doesn't define the accessibility of the version storage by means of reading.\n\naccessibility of the version storage:\nin jackrabbit-core the accessibility of the tree present underneath jcr:system is controlled by regular read permissions such as defined on other nodes based on the security configuration of the repository and the workspace.\n\nexecution of versioning operations:\ncurrently successful execution of versioning API operations (both reading and writing) depends on the accessibility of the version storage. from my point of view this is problematic it is not feasible to limit read permissions to those parts of the version storage that are - outside of the version storage - accessible to the reading/editing session. this basically implies that some being allowed to execute version operations and read versions must be allowed to read the complete version store. this will allow that session to be informed about versions of nodes that he/she might not be allowed to access otherwise.\n\nin order to address this issue, we should consider/evaluate the following:\n- execution of API operations should be separated from read-access to the version storage\n- access to jcr:system should be restricted\n- alternatively we might find a way to evaluate the readability of version content based on the accessibility of the corresponding node.\n- traversing the node hierarchy starting from a version/versionhistory node and any other item located in the version storage should be restricted accordingly.\n\n\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.023349812254309654
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.9313467741012573
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.14012525975704193
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d622d1f4d395ee222574ca",
        "key": "CALCITE-2406",
        "id": "13170820",
        "description": "I have some case of incompatibility between MySQL (actually on HerdDB which is a replacement for MySQL) and Calcite around timestamp syntax.\r\n\r\nIn MySQL it is legal to write timestamp literals in this form:\r\n\r\nINSERT INTO table(tscolum) values('2018-12-22 22:33:00.333')\r\n\r\nThis is currently not possible for standard Calcite SQL Parser/Validator.\r\n\r\n\u00a0\r\n\r\nIt is not a requirement that the Validator converts the literal directly, a string will be fine, so that downstream the string will be parsed according to the Database/User/Session settings\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.042234230786561966
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.012616891413927078
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0032008930575102568
                }
            }
        },
        "comments": [
            {
                "author_name": "julianhyde",
                "id": "16672501",
                "body": "This is an issue with the validator rather than the parser. Babel would not be the place to fix it."
            },
            {
                "author_name": "eolivelli",
                "id": "16672679",
                "body": "[~julianhyde] I have updated the title and description, thanks.\r\n\r\nWhen I will have cycles I can work on this"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d608b7f4d395ee2221b2f1",
        "key": "HADOOP-12945",
        "id": "12951560",
        "description": "The current LDAP group name resolution supports LDAP over SSL (LDAPS) encryption. However, LDAPS is considered deprecated. A better encryption protocol is LDAP Start TLS extension (RFC-2830).\n\nI added the StartTLS support using JNDI API, and have verified that it works against my Apache Directory Service.\n\nTo enable LDAPS, set hadoop.security.group.mapping.ldap.ssl to true. To enable StartTLS, set hadoop.security.group.mapping.ldap.starttls to true. If both properties are true, this implementation will choose StartTLS over LDAPS, as the latter is considered deprecated.\n\nIf StartTLS is chosen, no alternative port is necessary; otherwise, LDAPS often uses a different port (normally 636) than LDAP port (normally 389). By default, StartTLS performs DEFAULT host name verification. But this can be changed via hadoop.security.group.mapping.ldap.starttls.hostnameverifier. To disable host name verifier, set this value to ALLOW_ALL. Other valid values are: STRICT, STRICT_IE6, and DEFAULT_AND_LOCALHOST. (See {{SSLHostnameVerifier.java}} for more details)\n\nThis patch will conflict with HADOOP-12862 (LDAP Group Mapping over SSL can not specify trust store) (status: patch available) because of the code proximity.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.31572234630584717
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.263622522354126
                },
                "property": {
                    "prediction": true,
                    "confidence": 0.7437919974327087
                }
            }
        },
        "comments": [
            {
                "author_name": "weichiu",
                "id": "15201805",
                "body": "Rev01: Added code, docs and configs.\nNo test is included, as this new feature interacts with an external LDAP server, so it will be hard to unit test. However, I have built and tested it locally against my Active Directory server.\n\nThe feature is backward compatible. It continues to support LDAP over SSL through `hadoop.security.group.mapping.ldap.ssl`. It continues to support plain LDAP with no encryption, if both `hadoop.security.group.mapping.ldap.ssl` and `hadoop.security.group.mapping.ldap.starttls` are false."
            },
            {
                "author_name": "hadoopqa",
                "id": "15202336",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 11m 33s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 56s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 34s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 11s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 21s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 0s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 32s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 54s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 4s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 41s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 48s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 44s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 44s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 20s {color} | {color:red} hadoop-common-project/hadoop-common: patch generated 3 new + 34 unchanged - 0 fixed = 37 total (was 34) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 0s {color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 48s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 55s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 32s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 35s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 24s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 70m 25s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12794218/HADOOP-12945.001.patch |\n| JIRA Issue | HADOOP-12945 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 598a818968ca 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / fbe3e86 |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/8873/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-common.txt |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8873/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8873/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8873/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8873/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8873/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/8873/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8873/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "weichiu",
                "id": "15210588",
                "body": "Rev02: fixed checkstyle warning."
            },
            {
                "author_name": "hadoopqa",
                "id": "15210893",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 28s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 47s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 30s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 7s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 6s {color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 10s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 16s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 49s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 14s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 14s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 33s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 33s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 21s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 0s {color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 51s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 51s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 42s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 41s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 23s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 62m 1s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_74 Failed junit tests | hadoop.ha.TestZKFailoverController |\n|   | hadoop.net.TestDNS |\n| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:fbe3e86 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12795247/HADOOP-12945.002.patch |\n| JIRA Issue | HADOOP-12945 |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 97eef5bd0636 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 2e1d0ff |\n| Default Java | 1.7.0_95 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8917/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |\n| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8917/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8917/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8917/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |\n| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8917/testReport/ |\n| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/8917/artifact/patchprocess/patch-asflicense-problems.txt |\n| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8917/console |\n| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            }
        ],
        "comments_predictions": [
            [
                2568156,
                "HADOOP-12945",
                "Rev01: Added code, docs and configs.\nNo test is included, as this new feature interacts with an external LDAP server, so it will be hard to unit test. However, I have built and tested it locally against my Active Directory server.\n\nThe feature is backward compatible. It continues to support LDAP over SSL through `hadoop.security.group.mapping.ldap.ssl`. It continues to support plain LDAP with no encryption, if both `hadoop.security.group.mapping.ldap.ssl` and `hadoop.security.group.mapping.ldap.starttls` are false.",
                {
                    "property": {
                        "confidence": 0.004792762920260429,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006667854264378548,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016847796738147736,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5e26af4d395ee221bcbc1",
        "key": "RANGER-370",
        "id": "12788059",
        "description": "The default policy created for a new HDFS service should have isRecursive set to 'true', so that access to any path will be audited - similar to accesses to resources in other services (Hive/HBase/..).",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0069954232312738895
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01214065495878458
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0049532754346728325
                }
            }
        },
        "comments": [
            {
                "author_name": "madhan",
                "id": "14394940",
                "body": "Patch is available at the review site: https://reviews.apache.org/r/32829/"
            },
            {
                "author_name": "madhan",
                "id": "14395270",
                "body": "Fix committed. http://git-wip-us.apache.org/repos/asf/incubator-ranger/commit/f5317ec9"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "64074464d69a44c13533b25d",
        "key": "SPARK-32888",
        "id": "13327636",
        "description": "* Imagine a two-row csv file like so (where the header and first record are duplicate rows):\r\n\r\naaa,bbb\r\n\r\naaa,bbb\r\n * The following is pyspark code\r\n * create a parallelized rdd like: {color:#FF0000}prdd = spark.read.text(\"test.csv\").rdd.flatMap(lambda x : x){color}\r\n * {color:#172b4d}create a df like so:\u00a0{color:#de350b}mydf = spark.read.csv(prdd, header=True){color}{color}\r\n * {color:#172b4d}{color:#de350b}df.count(){color:#172b4d} will result in a record count of zero (when it should be 1){color}{color}{color}",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640753d518228aa73892e123",
        "key": "COUCHDB-1856",
        "id": "12659048",
        "description": "When I remotely replicate a database that has doc > 10M, with 600kb/s network speed, in a win7 64bit platform with couchdb 1.3.1, the couchdb server will launch the replication, but erl.exe soon reach up to commiting > 2GB memory, then\ncouchdb server hangs until a restart.\n\nTwo things that might helpful:\n1) It's fine for me to replicate the database in the same couchdb server (in the same machine);  \n2) My web browers, IE9/10, chrome, firefox, also hang or without response, at sometimes,  when I open the documents in the database with URL; ",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d640f4d395ee22194140",
        "key": "TORQUE-356",
        "id": "13203268",
        "description": "HSQLDB Tests fail with HSQLDB 2.4.1. The following changes need to be made:\r\n* Remove special handling for ignoreCaseInOrderBy()\r\n* Add native limit/offset-support\r\n* Handle CURRENT_TIME returning timezone information",
        "predictions": {},
        "comments": [
            {
                "author_name": "gk",
                "id": "17159803",
                "body": "- hsqldb version is now 2.5.1 and profile hsqldb does not fail anymore."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d2edf4d395ee22181e52",
        "key": "ZOOKEEPER-1422",
        "id": "12546706",
        "description": "At the moment a JAAS configuration file needs to be created with the Kerberos principal specified as user/host. It would be much easier for deployment automation if the host portion could be resolved at startup time, as supported in Hadoop (something like user/_HOST instead of user/hostname). A configuration alternative to global JAAS conf would be even better (via direct properties in zoo.cfg?).\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02551012486219406
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.014670345932245255
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006023582071065903
                }
            }
        },
        "comments": [
            {
                "author_name": "phunt",
                "id": "13573065",
                "body": "[~thw] are you talking about HADOOP-8381 ?"
            },
            {
                "author_name": "stevenwillis",
                "id": "13931873",
                "body": "[~phunt], I believe the functionality in HADOOP-8381 was what [~thw] was referencing. However, last time I checked, (which was a while ago) this functionality was not available in the zookeeper jaas configuration, only in the hadoop '*-site.xml' configuration files. Did the change introduced in HADOOP-8381 make the _HOST substitution more widely available?"
            },
            {
                "author_name": "phunt",
                "id": "13936437",
                "body": "Thanks [~stevenwillis]. I suspect more widely available in the hadoop ecosystem, however in our case we don't use the hadoop, xml based config parsers. We have our own properties based on. Likely we'd have to replicate that functionality ourselves (I'm no expert on this subject though...)"
            },
            {
                "author_name": "mfenes",
                "id": "16330762",
                "body": "This functionality is already implemented in master and branch 3.5 in org.apache.zookeeper.util.SecurityUtils:\r\n{code:java}\r\n/**\r\n * Convert Kerberos principal name pattern to valid Kerberos principal name.\r\n * If the principal name contains hostname pattern \"_HOST\" then it replaces\r\n * with the given hostname, which should be fully-qualified domain name.\r\n *\r\n * @param principalConfig\r\n *            the Kerberos principal name conf value to convert\r\n * @param hostname\r\n *            the fully-qualified domain name used for substitution\r\n * @return converted Kerberos principal name\r\n */\r\npublic static String getServerPrincipal(String principalConfig,\r\n        String hostname) {\r\n    String[] components = getComponents(principalConfig);\r\n    if (components == null || components.length != 2\r\n            || !components[1].equals(QUORUM_HOSTNAME_PATTERN)) {\r\n        return principalConfig;\r\n    } else {\r\n        return replacePattern(components, hostname);\r\n    }\r\n}{code}\r\nTherefore I'm setting the status of this Jira to Implemented."
            }
        ],
        "comments_predictions": [
            [
                19760,
                "ZOOKEEPER-1422",
                "[~phunt], I believe the functionality in HADOOP-8381 was what [~thw] was referencing. However, last time I checked, (which was a while ago) this functionality was not available in the zookeeper jaas configuration, only in the hadoop '*-site.xml' configuration files. Did the change introduced in HADOOP-8381 make the _HOST substitution more widely available?",
                {
                    "property": {
                        "confidence": 0.004159456118941307,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008486530743539333,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014287687838077545,
                        "prediction": false
                    }
                }
            ],
            [
                19761,
                "ZOOKEEPER-1422",
                "Thanks [~stevenwillis]. I suspect more widely available in the hadoop ecosystem, however in our case we don't use the hadoop, xml based config parsers. We have our own properties based on. Likely we'd have to replicate that functionality ourselves (I'm no expert on this subject though...)",
                {
                    "property": {
                        "confidence": 0.008940117433667183,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.7574127912521362,
                        "prediction": true
                    },
                    "existence": {
                        "confidence": 0.06003974378108978,
                        "prediction": false
                    }
                }
            ],
            [
                19762,
                "ZOOKEEPER-1422",
                "This functionality is already implemented in master and branch 3.5 in org.apache.zookeeper.util.SecurityUtils:\r\n{code:java}\r\n/**\r\n * Convert Kerberos principal name pattern to valid Kerberos principal name.\r\n * If the principal name contains hostname pattern \"_HOST\" then it replaces\r\n * with the given hostname, which should be fully-qualified domain name.\r\n *\r\n * @param principalConfig\r\n *            the Kerberos principal name conf value to convert\r\n * @param hostname\r\n *            the fully-qualified domain name used for substitution\r\n * @return converted Kerberos principal name\r\n */\r\npublic static String getServerPrincipal(String principalConfig,\r\n        String hostname) {\r\n    String[] components = getComponents(principalConfig);\r\n    if (components == null || components.length != 2\r\n            || !components[1].equals(QUORUM_HOSTNAME_PATTERN)) {\r\n        return principalConfig;\r\n    } else {\r\n        return replacePattern(components, hostname);\r\n    }\r\n}{code}\r\nTherefore I'm setting the status of this Jira to Implemented.",
                {
                    "property": {
                        "confidence": 0.005211743526160717,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00638179574161768,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014651844277977943,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d628acf4d395ee22264285",
        "key": "ARTEMIS-3343",
        "id": "13383519",
        "description": "In setting file {{broker.xml}}, it is possible to register multiple {{address-setting}} blocks for the same {{match}}. But because these blocks are put in a {{Map}} (in {{org.apache.activemq.artemis.core.deployers.impl.parseAddressSettings()}}), any previous block with the same {{match}} will be effectively ignored.\r\n\r\nThis may also happen for some of the other named blocks.\r\n\r\nMy suggestion is to raise an error when configuration information is lost.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.005148632451891899
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01525870617479086
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006258518900722265
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "17375952",
                "body": "Commit 47d4b8fff441b936cee2a63be27944b93b27e858 in activemq-artemis's branch refs/heads/main from Justin Bertram\n[ https://gitbox.apache.org/repos/asf?p=activemq-artemis.git;h=47d4b8f ]\n\nARTEMIS-3343 log WARN & ignore duplicate address-setting match\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d63154f4d395ee22275961",
        "key": "ACCUMULO-4597",
        "id": "13048192",
        "description": "Ran continuous ingest on a 4 node cluster. Tried running rfile-info on a resulting RFile.\n\n{noformat}\n/opt/accumulo-1.8.1/bin/accumulo rfile-info -d hdfs://localhost:8020/accumulo/tables/2/t-00000bq/C0005ct2.rf\nReading file: hdfs://localhost:8020/accumulo/tables/2/t-00000bq/C0005ct2.rf\nRFile Version            : 8\n\nLocality group           : <DEFAULT>\n    Num   blocks           : 2,868\n    Index level 0          : 92,114 bytes  1 blocks\n    First key              : 1666667494e6a12f 3156:10ea [] 1488561068054 false\n    Last key               : 1777776d22e8074a 711e:4443 [] 1488560945783 false\n    Num entries            : 2,672,521\n    Column families        : <UNKNOWN>\n\nMeta block     : BCFile.index\n      Raw size             : 4 bytes\n      Compressed size      : 12 bytes\n      Compression type     : gz\n\nMeta block     : RFile.index\n      Raw size             : 92,190 bytes\n      Compressed size      : 44,822 bytes\n      Compression type     : gz\n\n2017-03-03 11:43:10,451 [start.Main] ERROR: Thread 'rfile-info' died.\njava.lang.NullPointerException\n    at org.apache.accumulo.core.file.rfile.RFile$Reader.getLocalityGroupCF(RFile.java:1300)\n    at org.apache.accumulo.core.file.rfile.PrintInfo.execute(PrintInfo.java:165)\n    at org.apache.accumulo.start.Main$1.run(Main.java:120)\n    at java.lang.Thread.run(Thread.java:745)\n\n{noformat}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.025617919862270355
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009327850304543972
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.003853042144328356
                }
            }
        },
        "comments": [
            {
                "author_name": "kturner",
                "id": "15895806",
                "body": "[~dlmarion] do you know if this happened with other files?"
            },
            {
                "author_name": "dlmarion",
                "id": "15895882",
                "body": "We restarted CI yesterday. I checked an A and C type files, both exhibit the same symptoms when `-d` is specified. Without `-d`, it works without error."
            },
            {
                "author_name": "kturner",
                "id": "15897731",
                "body": "I tracked down the cause of this.  When an RFile has more than 1000 column families in the default locality group, it stops tracking it.  Code added in ACCUMULO-3420 does not handle this case properly.  This code is activated when trying to dump a rfile.  Continuous ingest creates more than 1000 families."
            },
            {
                "author_name": "etcoleman",
                "id": "15900653",
                "body": "Because of 1.7.3-rc1 failing the vote due to ACCUMULO-4600, moving the fix version from 1.7.4 to 1.7.3 so that it can be included in 1.7.3-rc2"
            }
        ],
        "comments_predictions": [
            [
                3941396,
                "ACCUMULO-4597",
                "I tracked down the cause of this.  When an RFile has more than 1000 column families in the default locality group, it stops tracking it.  Code added in ACCUMULO-3420 does not handle this case properly.  This code is activated when trying to dump a rfile.  Continuous ingest creates more than 1000 families.",
                {
                    "property": {
                        "confidence": 0.006160803139209747,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0051641021855175495,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.05695794150233269,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d61297f4d395ee22231ab4",
        "key": "FLEX-15971",
        "id": "12576836",
        "description": "Steps to reproduce:\n1. Compile and run attached MXML file (or run SWF)\n2. Select an item from the List control.\n3. Click the \"selectedIndices=null\" button. RTE!\n4. Select an item from the List control.\n5. Click the \"selectedItems=null\" button. RTE!\n\n \nActual Results:\nRTE when setting selectedIndices and/or selectedItems to null. \nRTE from step 3) TypeError: Error #1009: Cannot access a property or method of a null object reference.\n\tat mx.controls.listClasses::ListBase/setSelectionIndicesLoop()[E:\\dev\\3.1.0\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:6199]\n\tat mx.controls.listClasses::ListBase/http://www.adobe.com/2006/flex/mx/internal::commitSelectedIndices()[E:\\dev\\3.1.0\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:6191]\n\tat mx.controls.listClasses::ListBase/set selectedIndices()[E:\\dev\\3.1.0\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:2841]\n\tat List_selectedIndex_test/___List_selectedIndex_test_Button4_click()[C:\\Documents and Settings\\pdehaan\\...\\List_selectedIndex_test\\src\\List_selectedIndex_test.mxml:22]\n\n\nRTE from step 5) TypeError: Error #1009: Cannot access a property or method of a null object reference.\n\tat mx.controls.listClasses::ListBase/setSelectionDataLoop()[E:\\dev\\3.1.0\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:6338]\n\tat mx.controls.listClasses::ListBase/commitSelectedItems()[E:\\dev\\3.1.0\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:6275]\n\tat mx.controls.listClasses::ListBase/set selectedItems()[E:\\dev\\3.1.0\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:2921]\n\tat List_selectedIndex_test/___List_selectedIndex_test_Button8_click()[C:\\Documents and Settings\\pdehaan\\...\\List_selectedIndex_test\\src\\List_selectedIndex_test.mxml:29]\n\n\nExpected Results:\nThe opposite RTE.\n\n\nWorkaround (if any):\n(a) Set selectedIndices and/or selectedItems to an empty array '[ ]' instead of null.\n(b) use try/catch blocks to catch errors:\n\nprivate function clickHandler1(evt:MouseEvent):void {\n    try {\n        list.selectedIndices = null;\n    } catch (err:TypeError) {\n        Alert.show(err.toString(), 'caught A');\n    }\n}\n\nprivate function clickHandler2(evt:MouseEvent):void {\n    try {\n        list.selectedItems = null;\n    } catch (err:TypeError) {\n        Alert.show(err.toString(), 'caught B');\n    }\n}",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13343691",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-17171\nOriginal Reporter: pdehaan\nOriginal Resolution: Not a Bug\nDiscoverability: Medium\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nResolved by: laupark\nSeverity: Runtime Error\nreporter: pdehaan"
            },
            {
                "author_name": "adobejira",
                "id": "13343692",
                "body": "created: 2008-10-03 11:41:00.000\nresolved: 2009-06-03 20:05:20.262\nupdated: 2009-06-08 15:03:48.000"
            },
            {
                "author_name": "adobejira",
                "id": "13343693",
                "body": "On 2008-10-03 13:13:40.870 mitelman commented:\nDeferrable in my opinion\nOn 2008-10-08 07:20:40.026 laupark commented:\nDeepa -\nOn 2009-02-24 16:52:48.318 dsubrama commented:\nDeferring - I'll ensure this works in the Spark list.\nOn 2009-05-14 13:21:02.387 rfrishbe commented:\nSeems to be fixed.  Not sure when.\nOn 2009-05-19 17:03:18.882 pdehaan commented:\nSending back to IRB. Recommend defer or retire. It probably falls under the \"garbage in, garbage out\" rule.\nI can still repro the selectedIndices=null and selectedItems=null cases using 3.4 and trunk:\n\nTypeError: Error #1009: Cannot access a property or method of a null object reference.\n        at mx.controls.listClasses::ListBase/setSelectionIndicesLoop()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:7163]\n        at mx.controls.listClasses::ListBase/http://www.adobe.com/2006/flex/mx/internal::commitSelectedIndices()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:7155]\n        at mx.controls.listClasses::ListBase/set selectedIndices()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:3427]\n        at main/___main_Button4_click()[C:\\Documents and Settings\\pdehaan\\My Documents\\Adobe Gumbo Preview\\3.4b\\src\\main.mxml:22]\n\n\nTypeError: Error #1009: Cannot access a property or method of a null object reference.\n        at mx.controls.listClasses::ListBase/commitSelectedItems()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:7226]\n        at mx.controls.listClasses::ListBase/set selectedItems()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:3517]\n        at main/___main_Button8_click()[C:\\Documents and Settings\\pdehaan\\My Documents\\Adobe Gumbo Preview\\3.4b\\src\\main.mxml:29]\n\n\nAlso, I can also repro similar cases using the Spark List control using selectedIndices=null and selectedItems=null.\nOn 2009-06-03 20:05:20.418 laupark commented:\nRetired.\nOn 2009-06-05 17:14:12.490 pdehaan commented:\nclosing.\nOn 2009-06-08 15:03:48.468 pdehaan commented:\nThis isnt working on the Spark List control (as of build 4.0.0.7584). Filed a new bug for the Spark control: http://bugs.adobe.com/jira/browse/SDK-21677"
            }
        ],
        "comments_predictions": [
            [
                3014195,
                "FLEX-15971",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-17171\nOriginal Reporter: pdehaan\nOriginal Resolution: Not a Bug\nDiscoverability: Medium\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nResolved by: laupark\nSeverity: Runtime Error\nreporter: pdehaan",
                {
                    "property": {
                        "confidence": 0.0038284261245280504,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.037751201540231705,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009928442537784576,
                        "prediction": false
                    }
                }
            ],
            [
                3014197,
                "FLEX-15971",
                "On 2008-10-03 13:13:40.870 mitelman commented:\nDeferrable in my opinion\nOn 2008-10-08 07:20:40.026 laupark commented:\nDeepa -\nOn 2009-02-24 16:52:48.318 dsubrama commented:\nDeferring - I'll ensure this works in the Spark list.\nOn 2009-05-14 13:21:02.387 rfrishbe commented:\nSeems to be fixed.  Not sure when.\nOn 2009-05-19 17:03:18.882 pdehaan commented:\nSending back to IRB. Recommend defer or retire. It probably falls under the \"garbage in, garbage out\" rule.\nI can still repro the selectedIndices=null and selectedItems=null cases using 3.4 and trunk:\n\nTypeError: Error #1009: Cannot access a property or method of a null object reference.\n        at mx.controls.listClasses::ListBase/setSelectionIndicesLoop()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:7163]\n        at mx.controls.listClasses::ListBase/http://www.adobe.com/2006/flex/mx/internal::commitSelectedIndices()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:7155]\n        at mx.controls.listClasses::ListBase/set selectedIndices()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:3427]\n        at main/___main_Button4_click()[C:\\Documents and Settings\\pdehaan\\My Documents\\Adobe Gumbo Preview\\3.4b\\src\\main.mxml:22]\n\n\nTypeError: Error #1009: Cannot access a property or method of a null object reference.\n        at mx.controls.listClasses::ListBase/commitSelectedItems()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:7226]\n        at mx.controls.listClasses::ListBase/set selectedItems()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\controls\\listClasses\\ListBase.as:3517]\n        at main/___main_Button8_click()[C:\\Documents and Settings\\pdehaan\\My Documents\\Adobe Gumbo Preview\\3.4b\\src\\main.mxml:29]\n\n\nAlso, I can also repro similar cases using the Spark List control using selectedIndices=null and selectedItems=null.\nOn 2009-06-03 20:05:20.418 laupark commented:\nRetired.\nOn 2009-06-05 17:14:12.490 pdehaan commented:\nclosing.\nOn 2009-06-08 15:03:48.468 pdehaan commented:\nThis isnt working on the Spark List control (as of build 4.0.0.7584). Filed a new bug for the Spark control: http://bugs.adobe.com/jira/browse/SDK-21677",
                {
                    "property": {
                        "confidence": 0.004681957885622978,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008996114134788513,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.020076263695955276,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d601cbf4d395ee2220cbe4",
        "key": "HDFS-12174",
        "id": "13088903",
        "description": "The DN's attempt to send a successful commit block synchronization to the NN is fire and forget.  There are no retries.  The file will linger open until the hard lease timeout.  Ideally this would be a queued item for guaranteed delivery similar to IBRs.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0026751295663416386
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.8667561411857605
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.2877764105796814
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "6407469b6dae30aca681df65",
        "key": "DAFFODIL-2767",
        "id": "13517043",
        "description": "When unparsing with the SAX API, we spawn a new thread and run the unparse() call in that using our custom coroutine implementation. The main SAX thread and the coroutine unparse thread() using an ArrayBlockingQueue to suspend execution of one subroutine while the other executes.\r\n\r\nHowever, if the main thread throws an exception then it leaves the corutine unparse() thread hung, blocked on the ArrayBlockingQueue.\r\n\r\nThis is exactly what happens if there is mixed content in the infoset we are unparsing. If mixed content is detected in the DaffodilUnparseContentHander startElement function then, then we throw an exception that can be caught by the SAX API, but the unparse thread is still running and blocked.\r\n\r\nOne option is to modify the startElement() function in the main thread to add state to a SAXEvent when it detects mixed content. When the unparse thread sees this state it can cause the unparse() thread to finish by throwing an exception. This will create an UnparseResult that eventually is passed back to the main thread and coroutine logic can finish.",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640743b5342d895c2bd2ae81",
        "key": "LUCENE-6928",
        "id": "12921682",
        "description": "Now that norms are disk-based (since 5.3) we're seeing similar issues as we were having with doc values in case of sparse fields. We could implement a similar approach to what was done in LUCENE-6863 in order to keep things fast in the dense case yet reduce disk requirements in the sparse case.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.015155518427491188
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.04577735811471939
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.34671446681022644
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e26af4d395ee221bc64f",
        "key": "RANGER-1767",
        "id": "13100201",
        "description": "The Hive tests fail if Hive is already running on the machine. The problem is that there is a clash with the web UI ports. The fix is just not to enable the Web UI for the tests.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02572992816567421
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007890976965427399
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004454194568097591
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f374f4d395ee221eb94a",
        "key": "KNOX-1918",
        "id": "13243884",
        "description": "When Atlas is ingesting metadata, the global HDFS rules need to be avoided. ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.013280991464853287
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.057535357773303986
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004522393457591534
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "16881234",
                "body": "Commit 082cb1e14d757390e3fba73dbab04b904a8af187 in knox's branch refs/heads/master from Kevin Risden\n[ https://gitbox.apache.org/repos/asf?p=knox.git;h=082cb1e ]\n\nKNOX-1918 - Atlas API - prevent global HDFS rules from triggering (#111)\n\nSigned-off-by: Kevin Risden <krisden@apache.org>"
            },
            {
                "author_name": "jira-bot",
                "id": "16881235",
                "body": "Commit ff61dae4d30c0cb828eaaa73ff01e7e9f6128d61 in knox's branch refs/heads/v1.3.0 from Kevin Risden\n[ https://gitbox.apache.org/repos/asf?p=knox.git;h=ff61dae ]\n\nKNOX-1918 - Atlas API - prevent global HDFS rules from triggering (#111)\n\nSigned-off-by: Kevin Risden <krisden@apache.org>"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5ebd9f4d395ee221d7139",
        "key": "MTOMCAT-47",
        "id": "12521773",
        "description": "For integration tests we want to deploy an exploded webapp into tomcat. But this fails if we deployed the webapp in a previous run as the deployment seems to start before the undeployment is actually done.\n\nThis is the code snippet we use for deployment. Mind the \"update=true\" which should do the undeployment:\n\n{code:xml}\n      <plugin>\n        <groupId>org.codehaus.mojo</groupId>\n        <artifactId>tomcat-maven-plugin</artifactId>\n        <version>1.0-beta-1</version>\n        <executions>\n          <execution>\n            <id>deploy</id>\n            <goals>\n              <goal>exploded</goal>\n            </goals>\n            <phase>compile</phase>\n            <configuration>\n              <url>http://localhost:8001/manager</url>\n              <username>some</username>\n              <password>someother</password>\n              <warDirectory>/webapp</warDirectory>\n              <path>/</path>\n              <update>true</update>\n            </configuration>\n          </execution>\n        </executions>\n      </plugin>\n{code}\n\nFrom the log:\n{noformat}\n[INFO] --- tomcat-maven-plugin:1.0-beta-1:exploded (deploy) @ tomcat-deployment ---\n[DEBUG] Created new class realm plugin>org.codehaus.mojo:tomcat-maven-plugin:1.0-beta-1\n[DEBUG] Populating plugin realm for org.codehaus.mojo:tomcat-maven-plugin:1.0-beta-1\n[DEBUG]   Included: org.codehaus.mojo:tomcat-maven-plugin:maven-plugin:1.0-beta-1\n[DEBUG]   Excluded: org.apache.maven:maven-plugin-api:jar:2.0\n[DEBUG]   Excluded: org.apache.maven:maven-artifact-manager:jar:2.0\n[DEBUG]   Excluded: org.apache.maven:maven-repository-metadata:jar:2.0\n[DEBUG]   Included: org.codehaus.plexus:plexus-utils:jar:1.0.4\n[DEBUG]   Excluded: org.apache.maven:maven-artifact:jar:2.0\n[DEBUG]   Excluded: org.codehaus.plexus:plexus-container-default:jar:1.0-alpha-8\n[DEBUG]   Excluded: classworlds:classworlds:jar:1.1-alpha-2\n[DEBUG]   Excluded: org.apache.maven.wagon:wagon-provider-api:jar:1.0-alpha-5\n[DEBUG]   Included: commons-codec:commons-codec:jar:1.3\n[DEBUG]   Included: org.apache.tomcat:catalina:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:servlet-api:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:juli:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:annotations-api:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:catalina-ha:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:coyote:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:tribes:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:el-api:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:jasper:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:jsp-api:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:jasper-jdt:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:jasper-el:jar:6.0.16\n[DEBUG]   Included: org.apache.tomcat:dbcp:jar:6.0.16\n[DEBUG] Configuring mojo 'org.codehaus.mojo:tomcat-maven-plugin:1.0-beta-1:exploded' with basic configurator -->\n[DEBUG]   (f) charset = ISO-8859-1\n[DEBUG]   (f) contextFile = ...\\META-INF\\context.xml\n[DEBUG]   (f) mode = war\n[DEBUG]   (f) packaging = war\n[DEBUG]   (f) password = ...\n[DEBUG]   (f) path = /editor\n[DEBUG]   (f) update = true\n[DEBUG]   (f) url = http://localhost:8001/manager\n[DEBUG]   (f) username = ...\n[DEBUG]   (f) version = 1.0-beta-1\n[DEBUG]   (f) warDirectory = ...\\webapp\n[DEBUG] -- end configuration --\n[INFO] Deploying war to http://localhost:8001/editor\n[DEBUG] No server specified for authentication - using defaults\n[INFO] OK - Undeployed application at context path /editor\n[INFO] FAIL - Application already exists at path /editor\n{noformat}\n\nThus the deployment fails because undeployment is still incomplete.\n\n*Workarounds:*\n\n* Manually clean before doing the deployment.\n",
        "predictions": {},
        "comments": [
            {
                "author_name": "markt",
                "id": "13099493",
                "body": "so as we are only using the tomcat manager (through a kind of wget call) I'm not really sure it's a mojo issue.\nAre you using an old tomcat version ?"
            },
            {
                "author_name": "olamy",
                "id": "13551186",
                "body": "must not be a problem with recent version."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e0ecf4d395ee221b8fbf",
        "key": "SAMZA-2659",
        "id": "13384427",
        "description": "The current version is a version back to 2018. We would like to update it a newer stable version.",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "64074392c81e49582cd2ab61",
        "key": "HBASE-8095",
        "id": "12636879",
        "description": "Failed for me while my machine was under load: Failed tests:   testBackoffLogic(org.apache.hadoop.hbase.client.TestSnapshotFromAdmin): Elapsed time:4119 is more than expected max:4050\n\nLooks like it uses system time.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.016672004014253616
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0054281349293887615
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006452756468206644
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5edc6f4d395ee221ddb73",
        "key": "MESOS-5852",
        "id": "12989883",
        "description": "The existing CMake lists place protobufs at the same level as other Mesos sources:\nhttps://github.com/apache/mesos/blob/c4cecf9c279c5206faaf996fef0b1810b490b329/src/CMakeLists.txt#L415\n\nThis is incorrect, as protobuf changes need to be regenerated before we can build against them.\n\nNote: in the autotools build, this is done by compiling protobufs into {{libmesos}}, which then builds {{libmesos_no_3rdparty}}:\nhttps://github.com/apache/mesos/blob/c4cecf9c279c5206faaf996fef0b1810b490b329/src/Makefile.am#L1304-L1305",
        "predictions": {},
        "comments": [
            {
                "author_name": "kaysoky",
                "id": "15392928",
                "body": "Srini's review: https://reviews.apache.org/r/50088/"
            },
            {
                "author_name": "kaysoky",
                "id": "15392941",
                "body": "{code}\ncommit d7269f78a3b179355053369085893854a0dcef41\nAuthor: Srinivas Brahmaroutu <srbrahma@us.ibm.com>\nDate:   Tue Jul 19 11:22:59 2016 -0700\n\n    CMake: Added mesos-protobuf target to build protobuf libraries.\n    \n    Protobufs need to be (re)generated before building other Mesos sources.\n    To enforce this build order, we introduce a seperate build target\n    that produces a shared library of protobufs.  The `libmesos` build\n    target depends and links against this protobuf target.\n    \n    Review: https://reviews.apache.org/r/50088/\n{code}"
            }
        ],
        "comments_predictions": [
            [
                1382270,
                "MESOS-5852",
                "{code}\ncommit d7269f78a3b179355053369085893854a0dcef41\nAuthor: Srinivas Brahmaroutu <srbrahma@us.ibm.com>\nDate:   Tue Jul 19 11:22:59 2016 -0700\n\n    CMake: Added mesos-protobuf target to build protobuf libraries.\n    \n    Protobufs need to be (re)generated before building other Mesos sources.\n    To enforce this build order, we introduce a seperate build target\n    that produces a shared library of protobufs.  The `libmesos` build\n    target depends and links against this protobuf target.\n    \n    Review: https://reviews.apache.org/r/50088/\n{code}",
                {
                    "property": {
                        "confidence": 0.005593759007751942,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008319880813360214,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010887970216572285,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d61395f4d395ee222350e9",
        "key": "FLEX-2093",
        "id": "12562966",
        "description": "This bug was imported from another system and requires review from a project committer before some of the details can be marked public. For more information about historical bugs, please read: [Why are some bugs missing information?|https://bugs.adobe.com/confluence/display/ADOBE/Why+are+some+bugs+missing+information]\n\nYou can request a review of this bug report by sending an e-mail to: [Request Public Review for This Bug|mailto:jira_support@adobe.com?subject=Bug%20Review%20Request%20-%20SDK-2134&amp;body=Please%20review%20this%20historical%20bug%20report%20and%20consider%20making%20additional%20information%20public.%20%20I%20understand%20that%20my%20request%20(including%20this%20e-mail)%20may%20be%20included%20as%20part%20of%20the%20public%20history%20in%20the%20bug%20comments.%0D%0A%0D%0AAdditional Information: ]\n\nPlease be sure to include the bug number in your request.",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13302463",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-2134\nOriginal Reporter: gauravj\nOriginal Resolution: Fixed\nNeeds Release Note: No\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nResolved by: jspiro\nSeverity: Incorrectly Functioning\nreporter: gauravj"
            },
            {
                "author_name": "adobejira",
                "id": "13302464",
                "body": "created: 2007-02-28 10:35:45.000\nresolved: 2007-06-04 10:07:10.369\nupdated: 2011-04-29 10:40:37.000"
            },
            {
                "author_name": "adobejira",
                "id": "13302465",
                "body": "On 2007-05-12 14:24:07.531 customware commented:\nMilestone ID = 1513\nMilestone = Feature_Complete_Moxie\nBuild ID = 24863\nBuild = 163038_flex\nFix Build ID = 24863\nFix Build = 163038_flex\nOn 2007-05-12 14:24:07.531 customware commented:\nMove from BugDB issue number 199923"
            }
        ],
        "comments_predictions": [
            [
                3055550,
                "FLEX-2093",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-2134\nOriginal Reporter: gauravj\nOriginal Resolution: Fixed\nNeeds Release Note: No\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nResolved by: jspiro\nSeverity: Incorrectly Functioning\nreporter: gauravj",
                {
                    "property": {
                        "confidence": 0.003380771027877927,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.08096443116664886,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013135734014213085,
                        "prediction": false
                    }
                }
            ],
            [
                3055552,
                "FLEX-2093",
                "On 2007-05-12 14:24:07.531 customware commented:\nMilestone ID = 1513\nMilestone = Feature_Complete_Moxie\nBuild ID = 24863\nBuild = 163038_flex\nFix Build ID = 24863\nFix Build = 163038_flex\nOn 2007-05-12 14:24:07.531 customware commented:\nMove from BugDB issue number 199923",
                {
                    "property": {
                        "confidence": 0.003432284342125058,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01576054096221924,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01387789286673069,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5edc6f4d395ee221dc327",
        "key": "METRON-1461",
        "id": "13140590",
        "description": "Currently the MIN and MAX stellar function accepts only the list\u00a0 as input and the list may only contain objects that are mutually comparable / ordinal. Modify the method to\u00a0take a stats or list object and return min/max.\r\n * [|https://hortonworks.jira.com/secure/AddComment!default.jspa?id=163485]",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.011593755334615707
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.06864038109779358
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.003066091798245907
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16374917",
                "body": "GitHub user MohanDV opened a pull request:\n\n    https://github.com/apache/metron/pull/942\n\n    METRON-1461: Modify the MIN, MAX Stellar methods to take a stats or list object and return min and max\n\n    \r\n    ## Contributor Comments\r\n    Presently the MIN and MAX stellar function accepts only the list  as input and the list may only contain objects that are mutually comparable / ordinal. Modify the method to take a stats or list object and return min/max.\r\n    \r\n    ## Pull Request Checklist\r\n    \r\n    Thank you for submitting a contribution to Apache Metron.  \r\n    Please refer to our [Development Guidelines](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=61332235) for the complete guide to follow for contributions.  \r\n    Please refer also to our [Build Verification Guidelines](https://cwiki.apache.org/confluence/display/METRON/Verifying+Builds?show-miniview) for complete smoke testing guides.  \r\n    \r\n    \r\n    In order to streamline the review of the contribution we ask you follow these guidelines and ask you to double check the following:\r\n    \r\n    ### For all changes:\r\n    - [x] Is there a JIRA ticket associated with this PR? If not one needs to be created at [Metron Jira](https://issues.apache.org/jira/browse/METRON/?selectedTab=com.atlassian.jira.jira-projects-plugin:summary-panel).\r\n    - [x] Does your PR title start with METRON-XXXX where XXXX is the JIRA number you are trying to resolve? Pay particular attention to the hyphen \"-\" character.\r\n    - [x] Has your PR been rebased against the latest commit within the target branch (typically master)?\r\n    \r\n    \r\n    ### For code changes:\r\n    - [ ] Have you included steps to reproduce the behavior or problem that is being changed or addressed?\r\n    - [ ] Have you included steps or a guide to how the change may be verified and tested manually?\r\n    - [ ] Have you ensured that the full suite of tests and checks have been executed in the root metron folder via:\r\n      ```\r\n      mvn -q clean integration-test install && dev-utilities/build-utils/verify_licenses.sh \r\n      ```\r\n    \r\n    - [x] Have you written or updated unit tests and or integration tests to verify your changes?\r\n    - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?\r\n    - [ ] Have you verified the basic functionality of the build by building and running locally with Vagrant full-dev environment or the equivalent?\r\n    \r\n    ### For documentation related changes:\r\n    - [ ] Have you ensured that format looks appropriate for the output in which it is rendered by building and verifying the site-book? If not then run the following commands and the verify changes via `site-book/target/site/index.html`:\r\n    \r\n      ```\r\n      cd site-book\r\n      mvn site\r\n      ```\r\n    \r\n    #### Note:\r\n    Please ensure that once the PR is submitted, you check travis-ci for build issues and submit an update to your PR as soon as possible.\r\n    It is also recommended that [travis-ci](https://travis-ci.org) is set up for your personal repository such that your branches are built there before submitting a pull request.\r\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/MohanDV/metron METRON-1461\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/metron/pull/942.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #942\n    \n----\ncommit 5cb3a9354efbba6c8f9b85382848152839407d68\nAuthor: Mohan Venkateshaiah <mohan.dv@...>\nDate:   2018-02-23T19:59:07Z\n\n    Modify the MIN, MAX Stellar methods to take a stats or list object and return min/max.\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "16376899",
                "body": "Github user nickwallen commented on a diff in the pull request:\n\n    https://github.com/apache/metron/pull/942#discussion_r170595688\n  \n    --- Diff: metron-stellar/stellar-common/src/main/java/org/apache/metron/stellar/dsl/functions/OrdinalFunctions.java ---\n    @@ -37,17 +35,23 @@\n        * Return the maximum value of a list of input values in a Stellar list\n        */\n       @Stellar(name = \"MAX\"\n    -          , description = \"Returns the maximum value of a list of input values\"\n    -          , params = {\"list - List of arguments. The list may only contain objects that are mutually comparable / ordinal (implement java.lang.Comparable interface)\" +\n    +          , description = \"Returns the maximum value of a list of input values or from a statistics object\"\n    +          , params = {\"stats - The Stellar statistics object\"\n    +          ,\"list - List of arguments. The list may only contain objects that are mutually comparable / ordinal (implement java.lang.Comparable interface)\" +\n               \" Multi type numeric comparisons are supported: MAX([10,15L,15.3]) would return 15.3, but MAX(['23',25]) will fail and return null as strings and numbers can't be compared.\"}\n    -          , returns = \"The maximum value in the list, or null if the list is empty or the input values were not comparable.\")\n    +          , returns = \"The maximum value in the list or from stats, or null if the list is empty or the input values were not comparable.\")\n       public static class Max extends BaseStellarFunction {\n     \n         @Override\n         public Object apply(List<Object> args) {\n           if (args.size() < 1 || args.get(0) == null) {\n             throw new IllegalStateException(\"MAX function requires at least a Stellar list of values\");\n    --- End diff --\n    \n    With your changes, this error message is now incorrect.  Can you update this? \r\n    \r\n    This only checks the number of args, so the error message should probably just say that we expect one argument or something to that effect.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16376900",
                "body": "Github user nickwallen commented on a diff in the pull request:\n\n    https://github.com/apache/metron/pull/942#discussion_r170598354\n  \n    --- Diff: metron-stellar/stellar-common/src/main/java/org/apache/metron/stellar/dsl/functions/Ordinal.java ---\n    @@ -0,0 +1,24 @@\n    +/**\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + * or more contributor license agreements.  See the NOTICE file\n    + * distributed with this work for additional information\n    + * regarding copyright ownership.  The ASF licenses this file\n    + * to you under the Apache License, Version 2.0 (the\n    + * \"License\"); you may not use this file except in compliance\n    + * with the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.metron.stellar.dsl.functions;\n    +\n    +public interface Ordinal {\n    --- End diff --\n    \n    Can you add javadocs for the class and each method?\n"
            },
            {
                "author_name": "githubbot",
                "id": "16376901",
                "body": "Github user nickwallen commented on a diff in the pull request:\n\n    https://github.com/apache/metron/pull/942#discussion_r170597762\n  \n    --- Diff: metron-stellar/stellar-common/src/main/java/org/apache/metron/stellar/dsl/functions/OrdinalFunctions.java ---\n    @@ -37,17 +35,23 @@\n        * Return the maximum value of a list of input values in a Stellar list\n        */\n       @Stellar(name = \"MAX\"\n    -          , description = \"Returns the maximum value of a list of input values\"\n    -          , params = {\"list - List of arguments. The list may only contain objects that are mutually comparable / ordinal (implement java.lang.Comparable interface)\" +\n    +          , description = \"Returns the maximum value of a list of input values or from a statistics object\"\n    +          , params = {\"stats - The Stellar statistics object\"\n    +          ,\"list - List of arguments. The list may only contain objects that are mutually comparable / ordinal (implement java.lang.Comparable interface)\" +\n               \" Multi type numeric comparisons are supported: MAX([10,15L,15.3]) would return 15.3, but MAX(['23',25]) will fail and return null as strings and numbers can't be compared.\"}\n    -          , returns = \"The maximum value in the list, or null if the list is empty or the input values were not comparable.\")\n    +          , returns = \"The maximum value in the list or from stats, or null if the list is empty or the input values were not comparable.\")\n       public static class Max extends BaseStellarFunction {\n     \n         @Override\n         public Object apply(List<Object> args) {\n           if (args.size() < 1 || args.get(0) == null) {\n             throw new IllegalStateException(\"MAX function requires at least a Stellar list of values\");\n           }\n    +      Object firstArg = args.get(0);\n    +      if(firstArg instanceof Ordinal) {\n    +        Ordinal stats = convert(firstArg, Ordinal.class);\n    +        return stats.getMax();\n    +      }\n           Iterable list = (Iterable<Object>) args.get(0);\n    --- End diff --\n    \n    It would make sense to wrap the existing \"iterable\" handling code in an \"else if\".  And also handle the possibility that the argument is not an Iterable nor an Ordinal. Perhaps like so...\r\n    \r\n    ```\r\n    Object firstArg = args.get(0);\r\n    if(firstArg instanceof Ordinal) {\r\n      <your new code>\r\n    \r\n    } else if(firstArg instanceof Iterable) {\r\n      <existing code>\r\n    \r\n    } else {\r\n       throw new IllegalStateException(\"MAX function expects either .... \");\r\n    \r\n    }\r\n    ```\n"
            },
            {
                "author_name": "githubbot",
                "id": "16377298",
                "body": "Github user MohanDV commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    @nickwallen Thanks for the review, I have incorporated your comments. \n"
            },
            {
                "author_name": "githubbot",
                "id": "16387902",
                "body": "Github user nickwallen commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    @MohanDV - It looks like some care was taken previously so that getting the max of a list of mixed elements will just work.  For example `MAX([1, 2d, 3f]) == 3f`.  \r\n    \r\n    Did you consider an implementation such that this would continue to work with STATS objects?  I imagine that something like the following could be made to work; `MAX[1, 2d, 3f, stats]`?  \r\n    \r\n    What do you think?\r\n    \r\n\n"
            },
            {
                "author_name": "githubbot",
                "id": "16387979",
                "body": "Github user MohanDV commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    @nickwallen I dint consider implementation where STATS object can be passed in list of mixed object . That requires to change the STATS object to be 'Comparable' type . Do you think it should be addressed in this pull request ?\n"
            },
            {
                "author_name": "githubbot",
                "id": "16388032",
                "body": "Github user nickwallen commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    I would like to address the issue somehow or at least garner more community feedback on this change.\r\n    \r\n    As it stands, usage of the function is not very consistent.  For example, I can pass a list of numbers, but I can't pass a list of Stat objects.  I can have a list of mixed numeric types, but I can't have a Stats object in a mixed list.  That is inconsistent IMO.\r\n    \r\n    \r\n    \r\n\n"
            },
            {
                "author_name": "githubbot",
                "id": "16388053",
                "body": "Github user nickwallen commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    The first point here is around semantics.  I am assuming the semantics of this would be a \"max of maxes\".  So if I have a list of stats objects, I compare the max of each one.  Whichever max is the greatest, that stats object gets returned.  The MIN function would just be a \"min of mins\".\r\n    \r\n    Does that match your use case?  Is this the right approach?\r\n    \r\n    Given those semantics, I think the 'Comparable' approach could work, but with a twist.  You can't just make the Stats objects Comparable.  Because how do you compare them?  By the average, median, min or max?  There is not one way to do it that is broadly applicable.\r\n    \r\n    The means of comparison for the MAX function should use the max of a stats object.  The means of comparison for the MIN function should use the min of the stats object. \r\n    \r\n    One way is to create a class that wraps a Stats object and implements the Comparable interface.  In the case of MAX, the wrapper will compare using the max of the underlying stats object.  In the case of MIN function, the wrapper will compare using the min of the underlying stats object. \r\n    \r\n    \r\n\n"
            },
            {
                "author_name": "githubbot",
                "id": "16388080",
                "body": "Github user ottobackwards commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    Maybe making this function so generic is going to necessitate it being so complicated that it is harder to maintain etc.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16388091",
                "body": "Github user simonellistonball commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    I would say performance trumps complexity of functionality here.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16397430",
                "body": "Github user cestella commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    So, I would suggest rather than accepting a list of stats objects, `MAX` and `MIN` accept one of the following:\r\n    * A StatisticsProvider object\r\n    * A list of comparables\r\n    \r\n    Essentially, these two would both function:\r\n    * `MAX(STATS_ADD(null, 1, 2, 3))`\r\n    * `MAX([1, 2, 3])`\n"
            },
            {
                "author_name": "githubbot",
                "id": "16427404",
                "body": "Github user nickwallen commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    That works for me.  I just wanted to get some community discussion around this.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16445739",
                "body": "Github user simonellistonball commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    Do we think we've reached consensus on this? It seems like avoiding the mixed scenarios is a good thing from a performance perspective, which is key to something like this which will be used a lot in baselining use cases. Any one else have any open thoughts on this?\n"
            },
            {
                "author_name": "githubbot",
                "id": "16446199",
                "body": "Github user cestella commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    I think so.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16449693",
                "body": "Github user MohanDV commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    If we've reached consensus can I get +1 for this ?\n"
            },
            {
                "author_name": "githubbot",
                "id": "16467472",
                "body": "Github user cestella commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    +1 by inspection, lgtm\n"
            },
            {
                "author_name": "githubbot",
                "id": "16468400",
                "body": "Github user MohanDV commented on the issue:\n\n    https://github.com/apache/metron/pull/942\n  \n    Thanks @cestella . Can you please merge this pull request.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16469445",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/metron/pull/942\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "64074492016d21d91d33b54e",
        "key": "ARROW-14881",
        "id": "13413856",
        "description": "When building the doxygen apidoc for C++ I get a few warnings that forced me to disable {{WARN_AS_ERROR}} option to be able to proceed with building the docs.\r\n\r\nIs it an actual issue or something stray in my local environment?\r\n\r\nHere is a preview of the warnings\r\n{code:java}\r\n$ doxygen\r\nwarning: Tag 'COLS_IN_ALPHA_INDEX' at line 1118 of file 'Doxyfile' has become obsolete.\r\n\u00a0\u00a0 \u00a0 \u00a0 \u00a0 To avoid this warning please remove this line from your configuration file or upgrade it using \"doxygen -u\"\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2741: warning: no uniquely matching class member found for \r\n\u00a0 void arrow::flight::protocol::HandshakeRequest::clear_protocol_version()\r\n\r\n\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2744: warning: no uniquely matching class member found for \r\n\u00a0 PROTOBUF_NAMESPACE_ID::uint64 arrow::flight::protocol::HandshakeRequest::_internal_protocol_version() const\r\n\r\n\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2747: warning: no uniquely matching class member found for \r\n\u00a0 PROTOBUF_NAMESPACE_ID::uint64 arrow::flight::protocol::HandshakeRequest::protocol_version() const\r\n\r\n\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2751: warning: no uniquely matching class member found for \r\n\u00a0 void arrow::flight::protocol::HandshakeRequest::_internal_set_protocol_version(::PROTOBUF_NAMESPACE_ID::uint64 value)\r\n\r\n\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2755: warning: no uniquely matching class member found for \r\n\u00a0 void arrow::flight::protocol::HandshakeRequest::set_protocol_version(::PROTOBUF_NAMESPACE_ID::uint64 value)\r\n\r\n\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2761: warning: no uniquely matching class member found for \r\n\u00a0 void arrow::flight::protocol::HandshakeRequest::clear_payload()\r\n\r\n\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2764: warning: no uniquely matching class member found for \r\n\u00a0 const std::string & arrow::flight::protocol::HandshakeRequest::payload() const\r\n\r\n\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2768: warning: no uniquely matching class member found for \r\n\u00a0 void arrow::flight::protocol::HandshakeRequest::set_payload(const std::string &value)\r\n\r\n\r\n/Users/amol/ARROW/arrow/cpp/src/arrow/flight/Flight.pb.h:2772: warning: no uniquely matching class member found for \r\n\u00a0 std::string * arrow::flight::protocol::HandshakeRequest::mutable_payload() {code}",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640753ce69df6fb34192dec9",
        "key": "COUCHDB-3264",
        "id": "13031418",
        "description": "In CouchDB 2.0, POST to _all_docs with ids specified in the keys field does not respect the conflicts=true parameter.\n\nIn CouchDB 1.6.1:\n\n{code}\n$ curl -X PUT http://127.0.0.1:5984/test\n{\"ok\":true}\n\n$ curl -X POST http://127.0.0.1:5984/test/_bulk_docs -H 'Content-type:application/json' -d '{ \"docs\":[{\"_id\":\"foo\",\"_rev\": \"1-a1\"},{\"_id\":\"foo\",\"_rev\": \"1-a2\"}], \"new_edits\":false}'\n[]\n\n$ curl -X GET 'http://127.0.0.1:5984/test/_all_docs?include_docs=true&conflicts=true'\n{\"total_rows\":1,\"offset\":0,\"rows\":[\n{\"id\":\"foo\",\"key\":\"foo\",\"value\":{\"rev\":\"1-a2\"},\"doc\":{\"_id\":\"foo\",\"_rev\":\"1-a2\",\"_conflicts\":[\"1-a1\"]}}\n]}\n\n$ curl -X POST 'http://127.0.0.1:5984/test/_all_docs?include_docs=true&conflicts=true' -H 'Content-type:application/json' -d '{\"keys\":[\"foo\"]}'\n{\"total_rows\":1,\"offset\":0,\"rows\":[\n{\"id\":\"foo\",\"key\":\"foo\",\"value\":{\"rev\":\"1-a2\"},\"doc\":{\"_id\":\"foo\",\"_rev\":\"1-a2\",\"_conflicts\":[\"1-a1\"]}}\n]}\n{code}\n\nIn CouchDB 2.0:\n\n{code}\n$ curl -X PUT http://127.0.0.1:15984/test\n{\"ok\":true}\n\n$ curl -X POST http://127.0.0.1:15984/test/_bulk_docs -H 'Content-type:application/json' -d '{ \"docs\":[{\"_id\":\"foo\",\"_rev\": \"1-a1\"},{\"_id\":\"foo\",\"_rev\": \"1-a2\"}], \"new_edits\":false}'\n[]\n\n$ curl -X GET 'http://127.0.0.1:15984/test/_all_docs?include_docs=true&conflicts=true'\n{\"total_rows\":1,\"offset\":0,\"rows\":[\n{\"id\":\"foo\",\"key\":\"foo\",\"value\":{\"rev\":\"1-a2\"},\"doc\":{\"_id\":\"foo\",\"_rev\":\"1-a2\",\"_conflicts\":[\"1-a1\"]}}\n]}\n\n$ curl -X POST 'http://127.0.0.1:15984/test/_all_docs?include_docs=true&conflicts=true' -H 'Content-type:application/json' -d '{\"keys\":[\"foo\"]}'\n{\"total_rows\":1,\"rows\":[\n{\"id\":\"foo\",\"key\":\"foo\",\"value\":{\"rev\":\"1-a2\"},\"doc\":{\"_id\":\"foo\",\"_rev\":\"1-a2\"}}\n]}\n{code}",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "64075409077d999265d7d05c",
        "key": "GERONIMO-4423",
        "id": "12409001",
        "description": "1) Rename Debug Views category to Tools.\n2) Move the following portlets to the new Tools category:  Monitoring, Plan Creator, Apache HTTP, Java System Info\n3) Combine current Server and Services categories into one\n4) Move Log viewer portlets to Tools\n5) Move Embedded DB portlets onto one page under new Server/Services category\n6) Move Export Plugin and Server Assembly portlets to Tools",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.023291924968361855
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.917003333568573
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.09336929768323898
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "64074464d69a44c13533b257",
        "key": "KAFKA-10484",
        "id": "13327604",
        "description": "In our test cluster metrics are monitored through a monitoring service. We experienced a couple of times that a Kafka Streams client exceeded the limit of 350 metrics of the monitoring service. When the client exceeds the limit, metrics will be truncated which might result in false alerts. For example, in our cluster, we monitor the alive stream threads and trigger an alert if a stream thread dies. It happened that when the client exceeded the 350 metrics limit, the alive stream threads metric was truncated which led to a false alarm.\r\n\r\nThe main driver of the high number of metrics are the metrics on task level and below. An example for those metrics are the state store metrics. The number of such metrics per Kafka Streams client is hard to predict since it depends on which tasks are assigned to the client. A stateful task with 5 state stores reports 5 times more state store metrics than a stateful with only one state store. Sometimes it is possible to only report the metrics of some state stores. But sometimes this is not an option. For example, if we want to monitor the memory usage of RocksDB per Kafka Streams client, we need to report the memory related metrics of all RocksDB state stores of all tasks assigned to all stream threads of one client.\r\n\r\nOne option to reduce the reported metrics is to add a metric that aggregates some state store metrics, e.g., to monitor memory usage, on client-level within Kafka Streams.       ",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e4cdf4d395ee221c4c6c",
        "key": "PDFBOX-1169",
        "id": "12531304",
        "description": "Using PDFBox, tried to read file (eBook-Mini.pdf, which is attached)\nWhen images are extracted using below mentioned code, the extracted images aren't as per the ones in PDF, they have lost color.\nChecked extracting images, using other tools and images were extracted correctly.\nAttached images extracted using PDFBox as well.\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.020773492753505707
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.013563207350671291
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0033593899570405483
                }
            }
        },
        "comments": [
            {
                "author_name": "szaveri",
                "id": "13149526",
                "body": "eBook-Mini is the sample PDF that we have used for extracting image from the PDF."
            },
            {
                "author_name": "szaveri",
                "id": "13149527",
                "body": "Images which were extracted after reading the PDF using PDFBox."
            },
            {
                "author_name": "szaveri",
                "id": "13149529",
                "body": "Comment to extract the image:\n\nprivate void processImages(PDResources resources, String destinationFolder) throws IOException {\n\t\tMap images = resources.getImages();\n\n\t\tif (images != null) {\n\t\t\tIterator imageIter = images.keySet().iterator();\n\t\t\twhile (imageIter.hasNext()) {\n\t\t\t\tString key = (String) imageIter.next();\n\t\t\t\tPDXObjectImage image = (PDXObjectImage) images.get(key);\n\t\t\t\tString name = null;\n\t\t\t\tname = destinationFolder + \"image-\" + imageCounter++ + \".\" + image.getSuffix();\n\t\t\t\t\t\t\n\t\t\t\t//image.write2file(name); - Tried image.write2file as well, but retrieved images were similar\n\t\t\t\tBufferedImage bufferedImage = image.getRGBImage();\n\t\t\t\tFile outputfile = new File(name);\n\t\t\t\tImageIO.write(bufferedImage,image.getSuffix(), outputfile);\n\t\t\t\tSystem.out.println(\"szaveri - using imageio to write files \" + name + \" suffix =\" + image.getSuffix());\n\t\t\t\t\n\t\t\t}\n\t\t}\n\t}\n\n\nPlease note, out of 200 odd images in the PDF, only two got extracted correctly rest all are having images with black background. \n\nI am sure, I am missing out some configuration or someother parameter, but unable to find it out.\n\nJust to update, have also added following JAI Jars in my project:\njai_codec\njai_core\nmlibwrapper_jai"
            },
            {
                "author_name": "lehmi",
                "id": "13160791",
                "body": "I found 3 different issues:\n\n- the given pdf contains 2 images which are embedded in a XObjectForm which is embedded in another XObjectForm and can't be extracted using ExtractImages. I fixed that in revision 1209017\n- PDJpeg.write2OutputStream assumed that every PDJpeg contains jpeg image data because of the used DCTFilter, but PDJpegs may also contain CMYK-encoded image data as in the given pdf. I fixed that in revision 1209015\n- the colors of the image are wrong, but I don't know why. I'm still investigating"
            },
            {
                "author_name": "szaveri",
                "id": "13162645",
                "body": "Dear Andreas\n\nWish that you crack the thrid issue quite quickly.\n\nWe have taken your two fixes and have ran the test on the PDF that we have. Image quality has improved considerably. I am sure, once we have the final issue fix from your end, we should be able to parse the PDF image quite easily.\n\nIf you need any data / inputs from our end, kindly let us know.\n\nThanks\nSusheel Zaveri"
            },
            {
                "author_name": "lehmi",
                "id": "13278703",
                "body": "I guess the remaing issues is based on a missing feature called overprintcontrol which is part of the extended graphics state. PDFBOX-1223 describes a similar issue."
            },
            {
                "author_name": "lehmi",
                "id": "13471227",
                "body": "My former guess was wrong. The JPEG uses a CMYK-colorspace but the image data are encoded using a YCCK colorspace.\nI added a YCCK2RGB decoder in revision 1395294.\n\nThanks for the report!"
            }
        ],
        "comments_predictions": [
            [
                1015617,
                "PDFBOX-1169",
                "Comment to extract the image:\n\nprivate void processImages(PDResources resources, String destinationFolder) throws IOException {\n\t\tMap images = resources.getImages();\n\n\t\tif (images != null) {\n\t\t\tIterator imageIter = images.keySet().iterator();\n\t\t\twhile (imageIter.hasNext()) {\n\t\t\t\tString key = (String) imageIter.next();\n\t\t\t\tPDXObjectImage image = (PDXObjectImage) images.get(key);\n\t\t\t\tString name = null;\n\t\t\t\tname = destinationFolder + \"image-\" + imageCounter++ + \".\" + image.getSuffix();\n\t\t\t\t\t\t\n\t\t\t\t//image.write2file(name); - Tried image.write2file as well, but retrieved images were similar\n\t\t\t\tBufferedImage bufferedImage = image.getRGBImage();\n\t\t\t\tFile outputfile = new File(name);\n\t\t\t\tImageIO.write(bufferedImage,image.getSuffix(), outputfile);\n\t\t\t\tSystem.out.println(\"szaveri - using imageio to write files \" + name + \" suffix =\" + image.getSuffix());\n\t\t\t\t\n\t\t\t}\n\t\t}\n\t}\n\n\nPlease note, out of 200 odd images in the PDF, only two got extracted correctly rest all are having images with black background. \n\nI am sure, I am missing out some configuration or someother parameter, but unable to find it out.\n\nJust to update, have also added following JAI Jars in my project:\njai_codec\njai_core\nmlibwrapper_jai",
                {
                    "property": {
                        "confidence": 0.004123559221625328,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007659054361283779,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.022418109700083733,
                        "prediction": false
                    }
                }
            ],
            [
                1015618,
                "PDFBOX-1169",
                "I found 3 different issues:\n\n- the given pdf contains 2 images which are embedded in a XObjectForm which is embedded in another XObjectForm and can't be extracted using ExtractImages. I fixed that in revision 1209017\n- PDJpeg.write2OutputStream assumed that every PDJpeg contains jpeg image data because of the used DCTFilter, but PDJpegs may also contain CMYK-encoded image data as in the given pdf. I fixed that in revision 1209015\n- the colors of the image are wrong, but I don't know why. I'm still investigating",
                {
                    "property": {
                        "confidence": 0.003201918676495552,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010753168724477291,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023575128987431526,
                        "prediction": false
                    }
                }
            ],
            [
                1015619,
                "PDFBOX-1169",
                "Dear Andreas\n\nWish that you crack the thrid issue quite quickly.\n\nWe have taken your two fixes and have ran the test on the PDF that we have. Image quality has improved considerably. I am sure, once we have the final issue fix from your end, we should be able to parse the PDF image quite easily.\n\nIf you need any data / inputs from our end, kindly let us know.\n\nThanks\nSusheel Zaveri",
                {
                    "property": {
                        "confidence": 0.008592392317950726,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.09066222608089447,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.005819013342261314,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5dc7af4d395ee221a8b69",
        "key": "SPARK-18738",
        "id": "13025896",
        "description": "We run TPCx-BB with Spark SQL engine on local cluster using Spark 2.0.3 trunk and Hadoop 3.0 alpha 2 trunk. We run Spark SQL queries with same data size on both Erasure Coding and 3-replication.  The test results show that some queries has much worse performance on EC compared to 3-replication. After initial investigations, we found spark starts one third executors to execute queries on EC compared to 3-replication. \n\nWe use query 30 as example, our cluster can totally launch 108 executors. When we run the query from 3-replication database, spark will start all 108 executors to execute the query.  When we run the query from Erasure Coding database, spark will launch 108 executors and kill 72 executors due to they\u2019re idle, at last there are only 36 executors to execute the query which leads to poor performance.\n\nThis issue only happens when we enable dynamic allocations mechanism. When we disable the dynamic allocations, Spark SQL query on EC has the similar performance with on 3-replication.\n",
        "predictions": {},
        "comments": [
            {
                "author_name": "srowen",
                "id": "15764243",
                "body": "Don't set Fix version.\n\nNaively, in the EC case, there are fewer replicas of the data, right? is it surprising that this limits the possibilities for node-local reads?"
            },
            {
                "author_name": "srowen",
                "id": "15787317",
                "body": "I am going to close this as not a problem unless there's more info here ... clearly the problem is data locality being lower in the EC case. You can still tune Spark to not mind locality and possibly use all the executors, but 2/3 of the tasks are having to read data remotely then, which is its own overhead. It's not clear why only 1/3 of your machines appears to have data available for local execution. This also makes me wonder if you literally have 3x fewer data nodes in the EC case."
            }
        ],
        "comments_predictions": [
            [
                650785,
                "SPARK-18738",
                "I am going to close this as not a problem unless there's more info here ... clearly the problem is data locality being lower in the EC case. You can still tune Spark to not mind locality and possibly use all the executors, but 2/3 of the tasks are having to read data remotely then, which is its own overhead. It's not clear why only 1/3 of your machines appears to have data available for local execution. This also makes me wonder if you literally have 3x fewer data nodes in the EC case.",
                {
                    "property": {
                        "confidence": 0.014096498489379883,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0021636546589434147,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.16204075515270233,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640746b1adc2a215a681e468",
        "key": "SPARK-42671",
        "id": "13527102",
        "description": null,
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d622d1f4d395ee2225641c",
        "key": "CAMEL-1706",
        "id": "12486587",
        "description": "The new default error handler does currently *not* support redelivery. The error handling codebase has stabilized and we should allow this error handler to leverage the redelivery features we have in DeadLetterChannel.\n\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02388436160981655
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007360339630395174
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006245844531804323
                }
            }
        },
        "comments": [
            {
                "author_name": "davsclaus",
                "id": "12952650",
                "body": "trunk: 784652, 784665, 784685."
            },
            {
                "author_name": "davsclaus",
                "id": "12953775",
                "body": "Closing all 2.0M3 tickets"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "64074460cc1994d91233b207",
        "key": "ARROW-11082",
        "id": "13348561",
        "description": null,
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d60f9ff4d395ee2222aa1a",
        "key": "FLINK-9416",
        "id": "13161317",
        "description": "When starting a session cluster, it can happen that the job submission fails if the REST server endpoint has already gained leadership but if the leadership election for the {{Dispatcher}} is still ongoing. In such a case, we receive a error response saying that the leader election is still ongoing and fail the job submission. I think it would be nicer to also make the submission step a retriable operation in order to avoid this race condition.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.003028370440006256
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.07615877687931061
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00776672875508666
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16488629",
                "body": "GitHub user tillrohrmann opened a pull request:\n\n    https://github.com/apache/flink/pull/6069\n\n    [FLINK-9416] Make all RestClusterClient calls retriable\n\n    ## What is the purpose of the change\r\n    \r\n    This commit changes the RestClusterClient calls such that they are all retriable wrt\r\n    to connection errors and if the service is currently unavailable (return code 503).\r\n    \r\n    Moreover, it changes the retry behaviour for polling the JobResult such that it fails\r\n    now if the cluster returns a NOT_FOUND code.\r\n    \r\n    This PR is based on #6068.\r\n    \r\n    cc @GJL \r\n    \r\n    ## Verifying this change\r\n    \r\n    - Added `RestClusterClientTest#testRetriableSendOperationIfConnectionErrorOrServiceUnavailable` and `testSendIsNotRetriableIfHttpNotFound`\r\n    \r\n    ## Does this pull request potentially affect one of the following parts:\r\n    \r\n      - Dependencies (does it add or upgrade a dependency): (no)\r\n      - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)\r\n      - The serializers: (no)\r\n      - The runtime per-record code paths (performance sensitive): (no)\r\n      - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (yes)\r\n      - The S3 file system connector: (no)\r\n    \r\n    ## Documentation\r\n    \r\n      - Does this pull request introduce a new feature? (no)\r\n      - If yes, how is the feature documented? (not applicable)\r\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/tillrohrmann/flink hardenRestClient\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/flink/pull/6069.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #6069\n    \n----\ncommit 4b4d82cc5a3bb9694fd19a37c21345cbe7928962\nAuthor: Till Rohrmann <trohrmann@...>\nDate:   2018-05-23T16:50:27Z\n\n    [FLINK-9427] Fix registration and request slot race condition in TaskExecutor\n    \n    This commit fixes a race condition between the TaskExecutor and the ResourceManager. Before,\n    it could happen that the ResourceManager sends requestSlots message before the TaskExecutor\n    registration was completed. Due to this, the TaskExecutor did not have all information it needed\n    to accept task submissions.\n    \n    The problem was that the TaskExecutor sent the SlotReport at registration time. Due to this, t\n    he SlotManager could already assign these slots to pending slot requests. With this commit, the\n    registration protocol changes such that the TaskExecutor first registers at the ResourceManager\n    and only after completing this step, it will announce the available slots to the SlotManager.\n\ncommit 4d034edca41294e250c49807a3beecb2b419824d\nAuthor: Till Rohrmann <trohrmann@...>\nDate:   2018-05-23T21:48:38Z\n\n    [FLINK-9421] Remove job from RunningJobsRegistry when it reaches a terminal state\n    \n    This commit lets the Dispatcher remove the RunningJobsRegistry entry for a completed job\n    when it is removed from the Dispatcher.\n\ncommit 61817beea5dfa1fdf20dcd6266b5899769307f6b\nAuthor: Till Rohrmann <trohrmann@...>\nDate:   2018-05-24T08:01:23Z\n\n    [FLINK-9416] Make all RestClusterClient calls retriable\n    \n    This commit changes the RestClusterClient calls such that they are all retriable wrt\n    to connection errors and if the service is currently unavailable (return code 503).\n    \n    Moreover, it changes the retry behaviour for polling the JobResult such that it fails\n    now if the cluster returns a NOT_FOUND code.\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "16489106",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/6069#discussion_r190605113\n  \n    --- Diff: flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java ---\n    @@ -274,11 +275,17 @@ public JobSubmissionResult submitJob(JobGraph jobGraph, ClassLoader classLoader)\n     \t\tfinal JobMessageParameters  params = new JobMessageParameters();\n     \t\tparams.jobPathParameter.resolve(jobId);\n     \n    -\t\tCompletableFuture<JobDetailsInfo> responseFuture = sendRequest(detailsHeaders, params);\n    +\t\tCompletableFuture<JobDetailsInfo> responseFuture = sendRequest(\n    +\t\t\tdetailsHeaders,\n    +\t\t\tparams);\n     \n     \t\treturn responseFuture.thenApply(JobDetailsInfo::getJobStatus);\n     \t}\n     \n    +\tprivate Predicate<Throwable> isConnectionProblemOrServiceUnavailable() {\n    --- End diff --\n    \n    nit: can be `static` and defined closer to `isConnectionProblemException` and `isServiceUnavailable`\n"
            },
            {
                "author_name": "githubbot",
                "id": "16489107",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/6069#discussion_r190605670\n  \n    --- Diff: flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java ---\n    @@ -314,7 +319,8 @@ public JobSubmissionResult submitJob(JobGraph jobGraph, ClassLoader classLoader)\n     \n     \t\tlog.info(\"Requesting blob server port.\");\n     \t\tCompletableFuture<BlobServerPortResponseBody> portFuture = sendRequest(\n    -\t\t\tBlobServerPortHeaders.getInstance());\n    +\t\t\tBlobServerPortHeaders.getInstance(),\n    +\t\t\tEmptyMessageParameters.getInstance());\n    --- End diff --\n    \n    This is not needed. There should be an overload of `sendRequest` that does it.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16489110",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/6069#discussion_r190609681\n  \n    --- Diff: flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java ---\n    @@ -274,11 +275,17 @@ public JobSubmissionResult submitJob(JobGraph jobGraph, ClassLoader classLoader)\n     \t\tfinal JobMessageParameters  params = new JobMessageParameters();\n     \t\tparams.jobPathParameter.resolve(jobId);\n     \n    -\t\tCompletableFuture<JobDetailsInfo> responseFuture = sendRequest(detailsHeaders, params);\n    +\t\tCompletableFuture<JobDetailsInfo> responseFuture = sendRequest(\n    +\t\t\tdetailsHeaders,\n    +\t\t\tparams);\n     \n     \t\treturn responseFuture.thenApply(JobDetailsInfo::getJobStatus);\n     \t}\n     \n    +\tprivate Predicate<Throwable> isConnectionProblemOrServiceUnavailable() {\n    --- End diff --\n    \n    Good idea. Will change it.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16489111",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/6069#discussion_r190609755\n  \n    --- Diff: flink-clients/src/main/java/org/apache/flink/client/program/rest/RestClusterClient.java ---\n    @@ -314,7 +319,8 @@ public JobSubmissionResult submitJob(JobGraph jobGraph, ClassLoader classLoader)\n     \n     \t\tlog.info(\"Requesting blob server port.\");\n     \t\tCompletableFuture<BlobServerPortResponseBody> portFuture = sendRequest(\n    -\t\t\tBlobServerPortHeaders.getInstance());\n    +\t\t\tBlobServerPortHeaders.getInstance(),\n    +\t\t\tEmptyMessageParameters.getInstance());\n    --- End diff --\n    \n    Good point. Will change it.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16489116",
                "body": "Github user tillrohrmann commented on the issue:\n\n    https://github.com/apache/flink/pull/6069\n  \n    Thanks for the review @GJL. I will address your comments and then merge this PR.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16489141",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/flink/pull/6069\n"
            },
            {
                "author_name": "trohrmann",
                "id": "16489149",
                "body": "Fixed via\r\nmaster: 88987ebb93b4d56cc5a2efd7ef47dedab9b9d3d9\r\n1.5.0: 44467239ab264039b37fe5e608531ae1d60cb8a1"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e906f4d395ee221cf93b",
        "key": "OAK-1982",
        "id": "12729134",
        "description": "Currently, the ordered index does not check for full-text constraints (like the property index), and may returns a low cost for such cases.\n\nOnly full-text indexes (Lucene, Solr) know how to process full-text conditions. Only those indexes are supposed to return a low cost for such queries.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008665627799928188
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.015295944176614285
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.06624546647071838
                }
            }
        },
        "comments": [
            {
                "author_name": "thomasm",
                "id": "14071568",
                "body": "Patch (not yet tested):\n\n{noformat}\nIndex: src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\n===================================================================\n--- src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\t(revision 1612518)\n+++ src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\t(working copy)\n@@ -87,6 +87,14 @@\n             LOG.debug(\"getPlans() - rootState: {} - \", root);\n         }\n         List<IndexPlan> plans = new ArrayList<IndexPlan>();\n+        if (filter.getFullTextConstraint() != null) {\n+            // not an appropriate index for full-text search\n+            return plans;\n+        }\n+        if (filter.containsNativeConstraint()) {\n+            // not an appropriate index for native search\n+            return plans;\n+        }\n \n         OrderedPropertyIndexLookup lookup = getLookup(root);\n         Collection<PropertyRestriction> restrictions = filter.getPropertyRestrictions();\n{noformat}\n\n[~edivad], I believe you are working on a new ordered index implementation, could you ensure to do the same there please?"
            },
            {
                "author_name": "edivad",
                "id": "14072969",
                "body": "[~thomasm]\nbq. I believe you are working on a new ordered index implementation, could you ensure to do the same there please?\n\nPencilled it. I'll make sure of it.\n\nAnyhow I was reviewing the patch. The non-processing has been applied\nat the very top of the plans creation. In case of ordered index it\ncould play in case of the ORDER BY clause is the on an indexed\nproperty. I would let the query engine then apply the filters.\n\nI would go then for something like this\n\n{noformat}\ndiff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\nindex a0aaaaa..aff0473 100644\n--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\n+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\n@@ -87,15 +87,6 @@ public class OrderedPropertyIndex implements QueryIndex, AdvancedQueryIndex {\n             LOG.debug(\"getPlans() - rootState: {} - \", root);\n         }\n         List<IndexPlan> plans = new ArrayList<IndexPlan>();\n-        if (filter.getFullTextConstraint() != null) {\n-            // not an appropriate index for full-text search\n-            return plans;\n-        }\n-        if (filter.containsNativeConstraint()) {\n-            // not an appropriate index for native search\n-            return plans;\n-        }\n-\n         OrderedPropertyIndexLookup lookup = getLookup(root);\n         Collection<PropertyRestriction> restrictions = filter.getPropertyRestrictions();\n \n@@ -122,6 +113,7 @@ public class OrderedPropertyIndex implements QueryIndex, AdvancedQueryIndex {\n         }\n \n         // then we add plans for each restriction that could apply to us\n+        if (filter.getFullTextConstraint() == null && !filter.containsNativeConstraint()) {\n             for (Filter.PropertyRestriction pr : restrictions) {\n                 String propertyName = PathUtils.getName(pr.propertyName);\n                 if (lookup.isIndexed(propertyName, \"/\", filter)) {\n@@ -163,6 +155,7 @@ public class OrderedPropertyIndex implements QueryIndex, AdvancedQueryIndex {\n                     }\n                 }\n             }\n+        }\n \n         return plans;\n     }\n{noformat}\n\nWDYT?\n\n"
            },
            {
                "author_name": "thomasm",
                "id": "14073062",
                "body": "Revision 1612835 (trunk)\nRevision 1613060 (1.0 branch)\n"
            },
            {
                "author_name": "thomasm",
                "id": "14073063",
                "body": "[~edivad], only full-text indexes (Lucene, Solr) know how to process full-text conditions. The ordered index must not be used for such queries, as that way the full-text index would not be used (only one index can be used per selector of the raw query). So using the ordered index for \"order by\" clauses does not work in this case - the query result could be wrong."
            },
            {
                "author_name": "edivad",
                "id": "14073112",
                "body": "[~thomasm]: So the patch looks good :)\n\nI thought the query engine was able to merge two result sets to avoid any needed in-memory sorting."
            }
        ],
        "comments_predictions": [
            [
                1183611,
                "OAK-1982",
                "Patch (not yet tested):\n\n{noformat}\nIndex: src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\n===================================================================\n--- src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\t(revision 1612518)\n+++ src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\t(working copy)\n@@ -87,6 +87,14 @@\n             LOG.debug(\"getPlans() - rootState: {} - \", root);\n         }\n         List<IndexPlan> plans = new ArrayList<IndexPlan>();\n+        if (filter.getFullTextConstraint() != null) {\n+            // not an appropriate index for full-text search\n+            return plans;\n+        }\n+        if (filter.containsNativeConstraint()) {\n+            // not an appropriate index for native search\n+            return plans;\n+        }\n \n         OrderedPropertyIndexLookup lookup = getLookup(root);\n         Collection<PropertyRestriction> restrictions = filter.getPropertyRestrictions();\n{noformat}\n\n[~edivad], I believe you are working on a new ordered index implementation, could you ensure to do the same there please?",
                {
                    "property": {
                        "confidence": 0.004281856119632721,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0298001728951931,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006663260981440544,
                        "prediction": false
                    }
                }
            ],
            [
                1183612,
                "OAK-1982",
                "[~thomasm]\nbq. I believe you are working on a new ordered index implementation, could you ensure to do the same there please?\n\nPencilled it. I'll make sure of it.\n\nAnyhow I was reviewing the patch. The non-processing has been applied\nat the very top of the plans creation. In case of ordered index it\ncould play in case of the ORDER BY clause is the on an indexed\nproperty. I would let the query engine then apply the filters.\n\nI would go then for something like this\n\n{noformat}\ndiff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\nindex a0aaaaa..aff0473 100644\n--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\n+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java\n@@ -87,15 +87,6 @@ public class OrderedPropertyIndex implements QueryIndex, AdvancedQueryIndex {\n             LOG.debug(\"getPlans() - rootState: {} - \", root);\n         }\n         List<IndexPlan> plans = new ArrayList<IndexPlan>();\n-        if (filter.getFullTextConstraint() != null) {\n-            // not an appropriate index for full-text search\n-            return plans;\n-        }\n-        if (filter.containsNativeConstraint()) {\n-            // not an appropriate index for native search\n-            return plans;\n-        }\n-\n         OrderedPropertyIndexLookup lookup = getLookup(root);\n         Collection<PropertyRestriction> restrictions = filter.getPropertyRestrictions();\n \n@@ -122,6 +113,7 @@ public class OrderedPropertyIndex implements QueryIndex, AdvancedQueryIndex {\n         }\n \n         // then we add plans for each restriction that could apply to us\n+        if (filter.getFullTextConstraint() == null && !filter.containsNativeConstraint()) {\n             for (Filter.PropertyRestriction pr : restrictions) {\n                 String propertyName = PathUtils.getName(pr.propertyName);\n                 if (lookup.isIndexed(propertyName, \"/\", filter)) {\n@@ -163,6 +155,7 @@ public class OrderedPropertyIndex implements QueryIndex, AdvancedQueryIndex {\n                     }\n                 }\n             }\n+        }\n \n         return plans;\n     }\n{noformat}\n\nWDYT?\n\n",
                {
                    "property": {
                        "confidence": 0.0041137076914310455,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008165168575942516,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01772952266037464,
                        "prediction": false
                    }
                }
            ],
            [
                1183614,
                "OAK-1982",
                "[~edivad], only full-text indexes (Lucene, Solr) know how to process full-text conditions. The ordered index must not be used for such queries, as that way the full-text index would not be used (only one index can be used per selector of the raw query). So using the ordered index for \"order by\" clauses does not work in this case - the query result could be wrong.",
                {
                    "property": {
                        "confidence": 0.00336739351041615,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.030236991122364998,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01638810709118843,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d759f4d395ee22199111",
        "key": "THRIFT-66",
        "id": "12399339",
        "description": "The current {{TServer}} implementations expose a single service on a port. If an application has many services many ports have to be opened. This is cumbersome because:\n- you have to document which service is available on which port, and remembering the port numbers is difficult\n- to prevent the overhead of connection setup on each call, a client has to maintain to many connections: at least one to each port\n- it requires opening many ports on a firewall if one is between the client and the server.\n\nBy multiplexing multiple services on a single port the problems above are resolved:\n- instead of a port number a symbolic name can be assigned to a service\n- a client can maintain a small pool of connections to a single port\n- only one port has to be opened on the firewall\n\nThe attached Java implementation simply wraps a normal {{CALL}} message with a (new) {{SERVICE_SELECTION}} message. It is not necessary to modify or wrap the response. No changes are needed to the generated classes. Only a new type of server is introduced, and an invocation handler for a dynamic proxy around the {{Client}} classes of services is provided for the client side. The implementation does not handle communication errors (invalid data, timeouts, etc.) yet.",
        "predictions": {},
        "comments": [
            {
                "author_name": "jstuyts",
                "id": "12609476",
                "body": "I attached the following classes:\n- {{TMultiplexServer}}: a base class for services that expose multiple services on a single port\n- {{TSimpleMultiplexServer}}: an implementation of {{TMultiplexServer}} that uses a thread per connection\n- {{ThriftMultiplexInvocationHandler}}: the invocation handler around dynamic proxies for {{Client}} instances of services. The handler wraps the {{CALL}} message with a service selection message\n- {{MultiplexTestServerMain}}: a test class that starts a multiplexing server on port 9090 with a number of services\n- {{MultiplexTestClientMain}}: a test class that opens a single connection to the server and invokes multiple functions of multiple services\n- {{CalculatorImpl}}: implementation of the {{Calculator}} service for the test\n- {{SharedImpl}}: implementation of the {{SharedService}} service for the test\n\nTo test the implementation you need to add the following line to {{TMessageType}}:\n{code:java}\n  public static final byte SERVICE_SELECTION  = 4;\n{code}"
            },
            {
                "author_name": "tjake",
                "id": "12658734",
                "body": "Not sure why this is filed as a perl fix?"
            },
            {
                "author_name": "bryanduxbury",
                "id": "12664747",
                "body": "Changing to Trivial, since it's a new feature."
            },
            {
                "author_name": "bryanduxbury",
                "id": "12664749",
                "body": "Is there still interest in this issue? If so, the files attached should be converted to a patch, and we should discuss how it works and would integrate with other languages."
            },
            {
                "author_name": "ahfeel",
                "id": "12664819",
                "body": "I do think this would be a very interesting feature, but i think that it should be specced and implemented in every languages to have a consistent framework."
            },
            {
                "author_name": "tantra",
                "id": "12828037",
                "body": "I think this is interesting too!!!!"
            },
            {
                "author_name": "tantra",
                "id": "12835672",
                "body": "This is my port of multiplexing for python"
            },
            {
                "author_name": "jking",
                "id": "12848677",
                "body": "I have implemented a similar multiplexed runtime in C# and tested it with 200 concurrent clients who are pushing and receiving.  It uses no sleep loops and does proper blocking when waiting to send or receive data.  I think it would be a good idea to define a standard specification for multiplexed communications so all the language runtimes can synchronize.\n\nDefinition:  Once the client connects to the server, multiple virtual communication channels are opened in both directions for reliable RPC that can be initiated by either end.  As there are multiple communication channels each side chooses to be the client or server.  Each virtual transport handles a single thrift service declaration.  An added benefit, other than two-way communications, is that you can split your RPCs into functional areas and service them on different virtual channels.  This may help to clean up larger .thrift files.\n\nImplementation:  The wire format is simple, and as follows:\n\n01: byte, range 01-FF, indicates the virtual transport ID\n02-05: int32, network byte order, indicates the payload length\n06-end: payload\n\nThis requires no changes to the compiler / compiled code.  Note that fully integrating this into the mainline will likely tuck it under the version exchange.  Here is the preferred runtime implementation:\n\n* As there is a single communication channel, a single thread should be used to read from the socket, and a single thread should be used to write.\n* For the read thread, it should block on read of the actual transport.  When it gets some data it should route it to an appropriate virtual transport kept in a map.  The virtual transport should store incoming binary data in order and distribute it out the overridden Read function.  When there is no more data to read this should block.  This means that when data is enqueued to the virtual transport it ideally needs some form of event to wait on.\n* For the write side, when a virtual transport receives a Write call, it should store the outgoing binary data in-order and use an event to signal the write thread to do some work.  Ideally the write thread can wait on multiple events including a shutdown event, and get notification of which virtual transport needs a write, and then push the data out.  This makes the write thread block when there is nothing to do, and wake up when it is time to stop.\n* sleeping loops should be avoided where possible\n\nAcknowledgement:  charlie (d o t) mas (a t) gmail (d o t) com released an initial implementation which I overhauled\n\nComment:  Still waiting for Dell approval to release open-source code back to the community.  Once that happens I will push up a patch for review."
            },
            {
                "author_name": "jking",
                "id": "12882173",
                "body": "I took a completely different approach to solving this... there is an unused byte in the VERSION_1 Thrift message header which I designated for a \"Channel\".  I rewrote the C# runtime and added two-way communication, SSL Support, and multiple services on a single connection which is binary compatible with older clients (they can only communication on channel zero, in one direction, just like a legacy client would..) \n\nWhen an endpoint initializes it can install protocol handlers on whatever channel it wants.  Each side of the connection is able to implement a protocol handler, and each side is able to make a client to query the other side.  Each side is also able to process multiple requests in parallel on a single connection.  It is still going through testing, and I would like to refactor the shutdown logic so that it does not rely on socket exceptions before I post it though, unless folks would like to get the ball rolling on two-way communication across all Thrift languages and use this as a template to work from.."
            },
            {
                "author_name": "juzna.cz",
                "id": "12882353",
                "body": "And how do you assign channel numbers for services? Do you have to set them manually and then remember them?\nWhat about making channel eg. 255 reserved for internal service. Here could be method \"int lookupChannel(1: string channelName)\". Then, you can give your channel names or aliases and use them in clients. Each server also could have it's channels assigned in different order."
            },
            {
                "author_name": "bryanduxbury",
                "id": "12882374",
                "body": "I would be strongly against adding discovery features like this to the Thrift protocol. "
            },
            {
                "author_name": "jking",
                "id": "12882396",
                "body": "I also wanted to explitly avoid having service discovery as part of the protocol, although there is nothing preventing someone from adding their own extension that does this.  Originally I had made it so that the channel was part of the service declaration, i.e.:\n\nservice Rand channel 5\n{\n...\n}\n\nHowever that was met with some opposition.  So now the channel identifier is declared in code when starting up an endpoint.  As long as both sides have some innate knowledge of what runs on a given channel, it should be okay.  This just leaves the channel namespace up to the host application.  I will attach my Visio diageam of endpoints and channels."
            },
            {
                "author_name": "jking",
                "id": "12882397",
                "body": "Visio diagram showing how endpoints and channels work - a concept to replace the existing one-way communication mechanism.  I have not marked this as meant for inclusion yet, as there may be some changes before it is finalized.  You may need Visio 2010 to view it?"
            },
            {
                "author_name": "jking",
                "id": "12896931",
                "body": "This patch zip contains a diff to apply to the trunk as of Sunday August 8 2010.\nIt contains enhancements for the C# thrift compiler and runtime library.\nNormally patches address single issues, however given the content of the change which\nencompasses the entire C# runtime, it has to be presented as a single patch.\n\nBugfixes and Enhancements:\n\n(not in Jira): The library is now compiled for .NET 2.0 by default; moving to v3.5\n               does not cause any significant gains and excludes a large class of\n               potential implementers still at .NET 2.0.\n\n(not in Jira): The C# runtime was not properly assigning a sequence ID to requests.\n\n(not in Jira): The C# runtime forced exceptions to be created using multiple statements.\n               They can now be created on a single code line (for simple types).\n\n(not in Jira): The legacy C# runtime Server code has been refactored and simplified.\n\n(not in Jira): Thrift protocol is unidirectional.  This has changed with the introduction\n               of Endpoints.  Using the new Endpoints in C# you can host a service that\n               allows each end to register request handlers on different channels (see \n               THRIFT-66).  There is also a new TListeningEndpoint to replace the\n               [now] legacy C# Server implementation.  Tests are included.\n\nTHRIFT-66:  Allow multiplexing multiple services over a single TCP connection\n            This is now possible through Thrift Channels.  Up to 256 Thrift Services \n            can run over a single connection if both sides are channel-aware. Only the\n            C# runtime has this feature in this patch.  Compatibility with legacy\n            clients is easily maintained by providing for a channel zero implementation \n            of a thrift service.  There is no discovery protocol for this\n            mechanism.  Channel IDs are also not expressly put into the Thrift IDL\n            to bind a service to just one channel.  This will allow for flexibility \n            in API versioning and various debugging scenarios.  \n            Tests are also included.\n\nTHRIFT-181: C# SSL Support\n            Full SSL support with two-way certificate validation has been added.\n            Tests are also included.\n\nTHRIFT-509: C# Library Does Not Provide Strong Name\n            The runtime and MSVC Single File Code Generators are now strongly named.\n\nTHRIFT-740: Visual Studio 2008 .thrift file complete integration\n            This patch includes the Microsoft Visual Studio 2008 Single File Code Generator\n            patch previously submitted to the project.  The test project depends on it.\n            Tests (examples), and a tutorial are included.\n\nTo apply this patch, apply the .patch file and then copy the files from lib and test\ninto the appropriate locations; the patch generator for subverion does not handle binaries.\n\nJim King\nJames_E_K@dell.com"
            },
            {
                "author_name": "jking",
                "id": "12900843",
                "body": "Bugfix: when a remote end crashes, the local endpoint might have had user request threads blocking on a reply coming in which never would, and those threads would be blocked forever.  The patch ReleaseWaitingReplyThreadsOnDisconnect.patch fixes this bug in the larger patch I submitted."
            },
            {
                "author_name": "jking",
                "id": "12901853",
                "body": "Looks like the test .thrift files in the Channels subdirectory have a syntax error.  The IDL does not have channel specifications - those are made in code.  For anybody applying the patch, just remove the channel designation in the ThriftTest/Channels/echo.thrift and rand.thrift and everything will compile.  It was taken out a while ago, but I forgot to update the .thrift files.  I guess the Single File Code Generator for Visual Studio doesn't get invoked on a Rebuild All, which is odd."
            },
            {
                "author_name": "s0undt3ch",
                "id": "13185485",
                "body": "This is about 4 years old. Any reason why this hasn't been adopted/implemented yet?"
            },
            {
                "author_name": "bryanduxbury",
                "id": "13185786",
                "body": "I don't think it was ever 100% accepted that we wanted to add this additional complexity to Thrift. Don't get me wrong, I can see how it would be useful, but it comes at a cost, and none of the interested parties succeeded in championing through a change this significant."
            },
            {
                "author_name": "s0undt3ch",
                "id": "13186498",
                "body": "Not even two way communication? I'd like to be able to push \"events\" to the clients, is that possible? Has anyone done it?"
            },
            {
                "author_name": "nhed@aereo.com",
                "id": "13186516",
                "body": "Hi Pedro,\n\nWe are doing this by creating a server on each side.  Client established a\n''connection'' with a normal RPC call rest of the communication is with\noneway messages ...\n\nThe Connect parameters include a address+port for the client to be reached\nat.   Typically we do have a set of request+response oneway messages, but\nno order or timing is required, so a \"Push\" works, as long as the client\nensures that the connection is alive from time to time (you can have your\nown heartbeat timer).\n\nOne key major key to make this work is to do the following when\nestablishing the connection from the client:\n  1) create socket+transport\n  2) call transport::open()\n  3) call getsockname on the socket's FD\n  4) use the local addr returned (sin_addr.s_addr) to construct parameters\nthe connect-request message.\n\nThe server then takes that parameter (addr, port), converts the addr to\nstring.  This ensures that we keep DNS out of it, and that we talk on the\ncorrect interface for the return traffic (as would happen if thrift would\nhave supported this natively)\n\n\n\n\nClient                                          Server\n  ===========Connect()========>\n\n  <-------------AnyOneWayMessage() ---\n  <-------------AnyOneWayMessage() ---\n  --------------AnyOneWayMessage() --->\n  --------------AnyOneWayMessage() --->\n  --------------AnyOneWayMessage() --->\n  <-------------AnyOneWayMessage() ---\n  --------------AnyOneWayMessage() --->\n  <-------------AnyOneWayMessage() ---\n  --------------AnyOneWayMessage() --->\n  <-------------AnyOneWayMessage() ---\n\n\nOn Sun, Jan 15, 2012 at 7:44 AM, Pedro Algarvio (Commented) (JIRA) <\n\n"
            },
            {
                "author_name": "s0undt3ch",
                "id": "13186525",
                "body": "Thanks Nevo!\n\nDid I understand wrong or is this only possible with one way messages?\n\nIe, it's not possible to do regular RPC calls between the two servers?"
            },
            {
                "author_name": "nhed@aereo.com",
                "id": "13186617",
                "body": "You can use rpc ... We try to be somewhat Async for scalability\nOn Sunday, January 15, 2012, Pedro Algarvio (Commented) (JIRA) <\nhttps://issues.apache.org/jira/browse/THRIFT-66?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=13186525#comment-13186525]\nErlang - Library, Java - Library, Perl - Library, Python - Library, Ruby -\nLibrary\nMultiplexTestServerMain.java, ReleaseWaitingReplyThreadsOnDisconnect.patch,\nSharedImpl.java, TMultiplexServer.java, TMultiplexServer.py,\nTSimpleMultiplexServer.java, Thrift Endpoints and Channels.vsd,\nThriftCSharpEndpointsChannels.zip, ThriftMultiplexInvocationHandler.java\nport. If an application has many services many ports have to be opened.\nThis is cumbersome because:\nremembering the port numbers is difficult\nto maintain to many connections: at least one to each port\nclient and the server.\nare resolved:\nwith a (new) {{SERVICE_SELECTION}} message. It is not necessary to modify\nor wrap the response. No changes are needed to the generated classes. Only\na new type of server is introduced, and an invocation handler for a dynamic\nproxy around the {{Client}} classes of services is provided for the client\nside. The implementation does not handle communication errors (invalid\ndata, timeouts, etc.) yet.\nadministrators:\nhttps://issues.apache.org/jira/secure/ContactAdministrators!default.jspa\n"
            },
            {
                "author_name": "carlyeks",
                "id": "13653435",
                "body": "Any reason this sub task should stay open? Seems like the parent task has all of the necessary components."
            },
            {
                "author_name": "roger",
                "id": "13874803",
                "body": "outdated and fixed by other subtasks of THRIFT-1915"
            },
            {
                "author_name": "sebastian.zenker",
                "id": "15111316",
                "body": "I'm still interested in being able to have the server to actively push messages to the client on the same TCP connection. The current solution (workaround) that both sides implement a server/client pair is something that doesn't work well in case the client resides behind a NAT router."
            },
            {
                "author_name": "jking3",
                "id": "15111329",
                "body": "The C# engine refactoring in this ticket allows for this but it was never entered into the thrift project.  I believe two-way communication (allowing the system that initiated the connection to act as a server for one or more services) would be covered by separate tickets at this point now that the Multiplexed Protocol exists."
            },
            {
                "author_name": "jking3",
                "id": "15111335",
                "body": "I looked for \"push notification\", \"two-way\", and \"bidirectional\" in Jira and I didn't find anything interesting.  I agree with you, the ability for the client to set up a server on one of the multiplexed protocols would be quite useful.  This is something we'd like in a project I am working on as well.  I'm surprised there isn't already a ticket for this.  It's probably in there, somewhere..."
            },
            {
                "author_name": "roger",
                "id": "15111493",
                "body": "I suggest to create a new ticket for this.\nStart with the spec and as soon as we have a consensus on the spec, add subtasks for the languages and implement."
            }
        ],
        "comments_predictions": [
            [
                437339,
                "THRIFT-66",
                "I attached the following classes:\n- {{TMultiplexServer}}: a base class for services that expose multiple services on a single port\n- {{TSimpleMultiplexServer}}: an implementation of {{TMultiplexServer}} that uses a thread per connection\n- {{ThriftMultiplexInvocationHandler}}: the invocation handler around dynamic proxies for {{Client}} instances of services. The handler wraps the {{CALL}} message with a service selection message\n- {{MultiplexTestServerMain}}: a test class that starts a multiplexing server on port 9090 with a number of services\n- {{MultiplexTestClientMain}}: a test class that opens a single connection to the server and invokes multiple functions of multiple services\n- {{CalculatorImpl}}: implementation of the {{Calculator}} service for the test\n- {{SharedImpl}}: implementation of the {{SharedService}} service for the test\n\nTo test the implementation you need to add the following line to {{TMessageType}}:\n{code:java}\n  public static final byte SERVICE_SELECTION  = 4;\n{code}",
                {
                    "property": {
                        "confidence": 0.010107962414622307,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005419212393462658,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.3873264491558075,
                        "prediction": false
                    }
                }
            ],
            [
                437346,
                "THRIFT-66",
                "I have implemented a similar multiplexed runtime in C# and tested it with 200 concurrent clients who are pushing and receiving.  It uses no sleep loops and does proper blocking when waiting to send or receive data.  I think it would be a good idea to define a standard specification for multiplexed communications so all the language runtimes can synchronize.\n\nDefinition:  Once the client connects to the server, multiple virtual communication channels are opened in both directions for reliable RPC that can be initiated by either end.  As there are multiple communication channels each side chooses to be the client or server.  Each virtual transport handles a single thrift service declaration.  An added benefit, other than two-way communications, is that you can split your RPCs into functional areas and service them on different virtual channels.  This may help to clean up larger .thrift files.\n\nImplementation:  The wire format is simple, and as follows:\n\n01: byte, range 01-FF, indicates the virtual transport ID\n02-05: int32, network byte order, indicates the payload length\n06-end: payload\n\nThis requires no changes to the compiler / compiled code.  Note that fully integrating this into the mainline will likely tuck it under the version exchange.  Here is the preferred runtime implementation:\n\n* As there is a single communication channel, a single thread should be used to read from the socket, and a single thread should be used to write.\n* For the read thread, it should block on read of the actual transport.  When it gets some data it should route it to an appropriate virtual transport kept in a map.  The virtual transport should store incoming binary data in order and distribute it out the overridden Read function.  When there is no more data to read this should block.  This means that when data is enqueued to the virtual transport it ideally needs some form of event to wait on.\n* For the write side, when a virtual transport receives a Write call, it should store the outgoing binary data in-order and use an event to signal the write thread to do some work.  Ideally the write thread can wait on multiple events including a shutdown event, and get notification of which virtual transport needs a write, and then push the data out.  This makes the write thread block when there is nothing to do, and wake up when it is time to stop.\n* sleeping loops should be avoided where possible\n\nAcknowledgement:  charlie (d o t) mas (a t) gmail (d o t) com released an initial implementation which I overhauled\n\nComment:  Still waiting for Dell approval to release open-source code back to the community.  Once that happens I will push up a patch for review.",
                {
                    "property": {
                        "confidence": 0.05460362136363983,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0658441111445427,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.9376546740531921,
                        "prediction": true
                    }
                }
            ],
            [
                437347,
                "THRIFT-66",
                "I took a completely different approach to solving this... there is an unused byte in the VERSION_1 Thrift message header which I designated for a \"Channel\".  I rewrote the C# runtime and added two-way communication, SSL Support, and multiple services on a single connection which is binary compatible with older clients (they can only communication on channel zero, in one direction, just like a legacy client would..) \n\nWhen an endpoint initializes it can install protocol handlers on whatever channel it wants.  Each side of the connection is able to implement a protocol handler, and each side is able to make a client to query the other side.  Each side is also able to process multiple requests in parallel on a single connection.  It is still going through testing, and I would like to refactor the shutdown logic so that it does not rely on socket exceptions before I post it though, unless folks would like to get the ball rolling on two-way communication across all Thrift languages and use this as a template to work from..",
                {
                    "property": {
                        "confidence": 0.16951903700828552,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007155972998589277,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.924431562423706,
                        "prediction": true
                    }
                }
            ],
            [
                437348,
                "THRIFT-66",
                "And how do you assign channel numbers for services? Do you have to set them manually and then remember them?\nWhat about making channel eg. 255 reserved for internal service. Here could be method \"int lookupChannel(1: string channelName)\". Then, you can give your channel names or aliases and use them in clients. Each server also could have it's channels assigned in different order.",
                {
                    "property": {
                        "confidence": 0.005974273197352886,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004071222618222237,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.029251612722873688,
                        "prediction": false
                    }
                }
            ],
            [
                437350,
                "THRIFT-66",
                "I also wanted to explitly avoid having service discovery as part of the protocol, although there is nothing preventing someone from adding their own extension that does this.  Originally I had made it so that the channel was part of the service declaration, i.e.:\n\nservice Rand channel 5\n{\n...\n}\n\nHowever that was met with some opposition.  So now the channel identifier is declared in code when starting up an endpoint.  As long as both sides have some innate knowledge of what runs on a given channel, it should be okay.  This just leaves the channel namespace up to the host application.  I will attach my Visio diageam of endpoints and channels.",
                {
                    "property": {
                        "confidence": 0.005640159826725721,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004592505749315023,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.054289497435092926,
                        "prediction": false
                    }
                }
            ],
            [
                437351,
                "THRIFT-66",
                "Visio diagram showing how endpoints and channels work - a concept to replace the existing one-way communication mechanism.  I have not marked this as meant for inclusion yet, as there may be some changes before it is finalized.  You may need Visio 2010 to view it?",
                {
                    "property": {
                        "confidence": 0.0035525530111044645,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.040522512048482895,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.2337941974401474,
                        "prediction": false
                    }
                }
            ],
            [
                437352,
                "THRIFT-66",
                "This patch zip contains a diff to apply to the trunk as of Sunday August 8 2010.\nIt contains enhancements for the C# thrift compiler and runtime library.\nNormally patches address single issues, however given the content of the change which\nencompasses the entire C# runtime, it has to be presented as a single patch.\n\nBugfixes and Enhancements:\n\n(not in Jira): The library is now compiled for .NET 2.0 by default; moving to v3.5\n               does not cause any significant gains and excludes a large class of\n               potential implementers still at .NET 2.0.\n\n(not in Jira): The C# runtime was not properly assigning a sequence ID to requests.\n\n(not in Jira): The C# runtime forced exceptions to be created using multiple statements.\n               They can now be created on a single code line (for simple types).\n\n(not in Jira): The legacy C# runtime Server code has been refactored and simplified.\n\n(not in Jira): Thrift protocol is unidirectional.  This has changed with the introduction\n               of Endpoints.  Using the new Endpoints in C# you can host a service that\n               allows each end to register request handlers on different channels (see \n               THRIFT-66).  There is also a new TListeningEndpoint to replace the\n               [now] legacy C# Server implementation.  Tests are included.\n\nTHRIFT-66:  Allow multiplexing multiple services over a single TCP connection\n            This is now possible through Thrift Channels.  Up to 256 Thrift Services \n            can run over a single connection if both sides are channel-aware. Only the\n            C# runtime has this feature in this patch.  Compatibility with legacy\n            clients is easily maintained by providing for a channel zero implementation \n            of a thrift service.  There is no discovery protocol for this\n            mechanism.  Channel IDs are also not expressly put into the Thrift IDL\n            to bind a service to just one channel.  This will allow for flexibility \n            in API versioning and various debugging scenarios.  \n            Tests are also included.\n\nTHRIFT-181: C# SSL Support\n            Full SSL support with two-way certificate validation has been added.\n            Tests are also included.\n\nTHRIFT-509: C# Library Does Not Provide Strong Name\n            The runtime and MSVC Single File Code Generators are now strongly named.\n\nTHRIFT-740: Visual Studio 2008 .thrift file complete integration\n            This patch includes the Microsoft Visual Studio 2008 Single File Code Generator\n            patch previously submitted to the project.  The test project depends on it.\n            Tests (examples), and a tutorial are included.\n\nTo apply this patch, apply the .patch file and then copy the files from lib and test\ninto the appropriate locations; the patch generator for subverion does not handle binaries.\n\nJim King\nJames_E_K@dell.com",
                {
                    "property": {
                        "confidence": 0.007726266048848629,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.02826257050037384,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.5342773199081421,
                        "prediction": true
                    }
                }
            ],
            [
                437353,
                "THRIFT-66",
                "Bugfix: when a remote end crashes, the local endpoint might have had user request threads blocking on a reply coming in which never would, and those threads would be blocked forever.  The patch ReleaseWaitingReplyThreadsOnDisconnect.patch fixes this bug in the larger patch I submitted.",
                {
                    "property": {
                        "confidence": 0.005730621516704559,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.014651086181402206,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.00674486206844449,
                        "prediction": false
                    }
                }
            ],
            [
                437354,
                "THRIFT-66",
                "Looks like the test .thrift files in the Channels subdirectory have a syntax error.  The IDL does not have channel specifications - those are made in code.  For anybody applying the patch, just remove the channel designation in the ThriftTest/Channels/echo.thrift and rand.thrift and everything will compile.  It was taken out a while ago, but I forgot to update the .thrift files.  I guess the Single File Code Generator for Visual Studio doesn't get invoked on a Rebuild All, which is odd.",
                {
                    "property": {
                        "confidence": 0.004738887306302786,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007360841613262892,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012887170538306236,
                        "prediction": false
                    }
                }
            ],
            [
                437356,
                "THRIFT-66",
                "I don't think it was ever 100% accepted that we wanted to add this additional complexity to Thrift. Don't get me wrong, I can see how it would be useful, but it comes at a cost, and none of the interested parties succeeded in championing through a change this significant.",
                {
                    "property": {
                        "confidence": 0.018327999860048294,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002030065283179283,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.06300577521324158,
                        "prediction": false
                    }
                }
            ],
            [
                437358,
                "THRIFT-66",
                "Hi Pedro,\n\nWe are doing this by creating a server on each side.  Client established a\n''connection'' with a normal RPC call rest of the communication is with\noneway messages ...\n\nThe Connect parameters include a address+port for the client to be reached\nat.   Typically we do have a set of request+response oneway messages, but\nno order or timing is required, so a \"Push\" works, as long as the client\nensures that the connection is alive from time to time (you can have your\nown heartbeat timer).\n\nOne key major key to make this work is to do the following when\nestablishing the connection from the client:\n  1) create socket+transport\n  2) call transport::open()\n  3) call getsockname on the socket's FD\n  4) use the local addr returned (sin_addr.s_addr) to construct parameters\nthe connect-request message.\n\nThe server then takes that parameter (addr, port), converts the addr to\nstring.  This ensures that we keep DNS out of it, and that we talk on the\ncorrect interface for the return traffic (as would happen if thrift would\nhave supported this natively)\n\n\n\n\nClient                                          Server\n  ===========Connect()========>\n\n  <-------------AnyOneWayMessage() ---\n  <-------------AnyOneWayMessage() ---\n  --------------AnyOneWayMessage() --->\n  --------------AnyOneWayMessage() --->\n  --------------AnyOneWayMessage() --->\n  <-------------AnyOneWayMessage() ---\n  --------------AnyOneWayMessage() --->\n  <-------------AnyOneWayMessage() ---\n  --------------AnyOneWayMessage() --->\n  <-------------AnyOneWayMessage() ---\n\n\nOn Sun, Jan 15, 2012 at 7:44 AM, Pedro Algarvio (Commented) (JIRA) <\n\n",
                {
                    "property": {
                        "confidence": 0.03099585324525833,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004833672195672989,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.7685389518737793,
                        "prediction": true
                    }
                }
            ],
            [
                437360,
                "THRIFT-66",
                "You can use rpc ... We try to be somewhat Async for scalability\nOn Sunday, January 15, 2012, Pedro Algarvio (Commented) (JIRA) <\nhttps://issues.apache.org/jira/browse/THRIFT-66?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=13186525#comment-13186525]\nErlang - Library, Java - Library, Perl - Library, Python - Library, Ruby -\nLibrary\nMultiplexTestServerMain.java, ReleaseWaitingReplyThreadsOnDisconnect.patch,\nSharedImpl.java, TMultiplexServer.java, TMultiplexServer.py,\nTSimpleMultiplexServer.java, Thrift Endpoints and Channels.vsd,\nThriftCSharpEndpointsChannels.zip, ThriftMultiplexInvocationHandler.java\nport. If an application has many services many ports have to be opened.\nThis is cumbersome because:\nremembering the port numbers is difficult\nto maintain to many connections: at least one to each port\nclient and the server.\nare resolved:\nwith a (new) {{SERVICE_SELECTION}} message. It is not necessary to modify\nor wrap the response. No changes are needed to the generated classes. Only\na new type of server is introduced, and an invocation handler for a dynamic\nproxy around the {{Client}} classes of services is provided for the client\nside. The implementation does not handle communication errors (invalid\ndata, timeouts, etc.) yet.\nadministrators:\nhttps://issues.apache.org/jira/secure/ContactAdministrators!default.jspa\n",
                {
                    "property": {
                        "confidence": 0.9333144426345825,
                        "prediction": true
                    },
                    "executive": {
                        "confidence": 0.03129389137029648,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.09799648076295853,
                        "prediction": false
                    }
                }
            ],
            [
                437363,
                "THRIFT-66",
                "I'm still interested in being able to have the server to actively push messages to the client on the same TCP connection. The current solution (workaround) that both sides implement a server/client pair is something that doesn't work well in case the client resides behind a NAT router.",
                {
                    "property": {
                        "confidence": 0.29652953147888184,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005895303562283516,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.9552436470985413,
                        "prediction": true
                    }
                }
            ],
            [
                437364,
                "THRIFT-66",
                "The C# engine refactoring in this ticket allows for this but it was never entered into the thrift project.  I believe two-way communication (allowing the system that initiated the connection to act as a server for one or more services) would be covered by separate tickets at this point now that the Multiplexed Protocol exists.",
                {
                    "property": {
                        "confidence": 0.30146995186805725,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00312573229894042,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.892978310585022,
                        "prediction": true
                    }
                }
            ],
            [
                437365,
                "THRIFT-66",
                "I looked for \"push notification\", \"two-way\", and \"bidirectional\" in Jira and I didn't find anything interesting.  I agree with you, the ability for the client to set up a server on one of the multiplexed protocols would be quite useful.  This is something we'd like in a project I am working on as well.  I'm surprised there isn't already a ticket for this.  It's probably in there, somewhere...",
                {
                    "property": {
                        "confidence": 0.006586432922631502,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005199527367949486,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01945386826992035,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d601cbf4d395ee2220e789",
        "key": "HDFS-4601",
        "id": "12636939",
        "description": "DistCp's ThrottledInputStream.java leaks the wrapped input stream because it does not override InputStream.close().",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0106047997251153
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009806182235479355
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004694917239248753
                }
            }
        },
        "comments": [
            {
                "author_name": "hadoopqa",
                "id": "13607932",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12574585/HDFS-4601.001.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4123//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "cmccabe",
                "id": "13608146",
                "body": "resubmitting because the build was broken at the time jenkins ran"
            },
            {
                "author_name": "hadoopqa",
                "id": "13608162",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12574622/HDFS-4601.001.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.\n\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/4126//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "cnauroth",
                "id": "13608376",
                "body": "My patch on MAPREDUCE-5075 just got committed with basically the same change, so I think this is a duplicate now.  Sorry for any confusion."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e906f4d395ee221d1b5f",
        "key": "NIFI-7329",
        "id": "13296883",
        "description": "As reported in private Slack chat, the host header handler is not combining the value of {{nifi.web.proxy.host}} in {{nifi.properties}} with the {{nifi.web.https.port}} value, thus blocking a connection on {{host:port}}. The handler is only injecting {{host}} into the valid list. ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006551105994731188
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.014889393001794815
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004838927648961544
                }
            }
        },
        "comments": [
            {
                "author_name": "exceptionfactory",
                "id": "17455362",
                "body": "The current {{HostHeaderHandler}} implementation supports configuring the allowed {{Host}} header with and without the port number.\u00a0 In this scenario, the {{nifi.web.proxy.host}} property should be set to the proxy server address together with the port number, such as:\r\n\r\n{noformat}\r\nnifi.web.proxy.host=nifi.apache.org:443\r\n{noformat}\r\n\r\nSince the proxy server may or may not use the same port as NiFi, including the value of {{nifi.web.https.port}} automatically does not seem like a reliable solution."
            }
        ],
        "comments_predictions": [
            [
                1215821,
                "NIFI-7329",
                "The current {{HostHeaderHandler}} implementation supports configuring the allowed {{Host}} header with and without the port number.\u00a0 In this scenario, the {{nifi.web.proxy.host}} property should be set to the proxy server address together with the port number, such as:\r\n\r\n{noformat}\r\nnifi.web.proxy.host=nifi.apache.org:443\r\n{noformat}\r\n\r\nSince the proxy server may or may not use the same port as NiFi, including the value of {{nifi.web.https.port}} automatically does not seem like a reliable solution.",
                {
                    "property": {
                        "confidence": 0.0035623516887426376,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.014751292765140533,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.026340048760175705,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d623eff4d395ee222582ff",
        "key": "BSF-3",
        "id": "12368556",
        "description": "Method ScriptEngineManager.getFactories() (trunk code and tags/bsf-3.0-beta1/ code) returns an array of ScriptEngineFactory. However JSR 223 Scripting for the Java\u2122 Platform Final Draft Specification version 1.0 (section SCR.4.3.8.1 Discovery Mechanism, page 168) says that should return List<ScriptEngineFactory>.\n\nParticularly this issue makes impossible develop client code using bsf3.0-beta1 maintaining the compatibility with Java 6 Scripting API reference implementation",
        "predictions": {},
        "comments": [
            {
                "author_name": "rony",
                "id": "12529694",
                "body": "Do you happen to know by any chance (would help save research time) to what an List<?> translates to pre-Java-6?\n\nE.g. would an ArrayList (which implements among other interfaces \"Collection\" and \"List\" ) of \"ScriptEngineFactory\" objects be binary compatible?"
            },
            {
                "author_name": "sanka",
                "id": "12534759",
                "body": "This patch contains a fix for the described issue. Will apply the patch shortly."
            },
            {
                "author_name": "sanka",
                "id": "12536587",
                "body": "Applied the patch.\n(see committed revision 587012)\n\nI am unable to resolve this issue with the current JIRA account that I am having. Can some please grant me privileges to resolve these JIRA issues.\n\nThanks,\nSanka"
            },
            {
                "author_name": "sanka",
                "id": "12538667",
                "body": "Fixed in trunk"
            },
            {
                "author_name": "imartinez",
                "id": "12539819",
                "body": "Hi,\n\nFor Java 5 the return type is the same List<ScriptEngineFactory> due to \ngenerics are supported. I haven't seen the which minimum version of JDK \nis needed to compile BSF 3.0, but if JDK 1.4 is the minimum version, the \nreturn type should be List. For sure an \nArrayList<ScriptingEngineFactory> will be compatible with the spec.\n\nBTW I discovered the error trying to develop an application using BSF \n3.0b1 using Java 6 as compiling and runtime environment.\n\n  Regards,\n   Ivan\n\n\n"
            }
        ],
        "comments_predictions": [
            [
                3609056,
                "BSF-3",
                "Do you happen to know by any chance (would help save research time) to what an List<?> translates to pre-Java-6?\n\nE.g. would an ArrayList (which implements among other interfaces \"Collection\" and \"List\" ) of \"ScriptEngineFactory\" objects be binary compatible?",
                {
                    "property": {
                        "confidence": 0.0077549065463244915,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004375731572508812,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02046508900821209,
                        "prediction": false
                    }
                }
            ],
            [
                3609058,
                "BSF-3",
                "Applied the patch.\n(see committed revision 587012)\n\nI am unable to resolve this issue with the current JIRA account that I am having. Can some please grant me privileges to resolve these JIRA issues.\n\nThanks,\nSanka",
                {
                    "property": {
                        "confidence": 0.005077801179140806,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006016975734382868,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.020530669018626213,
                        "prediction": false
                    }
                }
            ],
            [
                3609060,
                "BSF-3",
                "Hi,\n\nFor Java 5 the return type is the same List<ScriptEngineFactory> due to \ngenerics are supported. I haven't seen the which minimum version of JDK \nis needed to compile BSF 3.0, but if JDK 1.4 is the minimum version, the \nreturn type should be List. For sure an \nArrayList<ScriptingEngineFactory> will be compatible with the spec.\n\nBTW I discovered the error trying to develop an application using BSF \n3.0b1 using Java 6 as compiling and runtime environment.\n\n  Regards,\n   Ivan\n\n\n",
                {
                    "property": {
                        "confidence": 0.003565744962543249,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012905461713671684,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013678299263119698,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d60ad6f4d395ee22221352",
        "key": "GOBBLIN-823",
        "id": "13244437",
        "description": "Lombok is useful once developer gets used to it, but it has itss own learning curve for new user, given lombok adds unnecessary complexity, mot of the things can be taken care by smart IDE anyway, I suggest we remove use of lomboke.\r\nif not, lets at least upgrade to latest version to get all bug fixes.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.9718511700630188
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.018753811717033386
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.04269791394472122
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d622d1f4d395ee2225599b",
        "key": "CAMEL-4401",
        "id": "12520947",
        "description": "If a StreamResequencer's configured Expression returns null for an Exchange (e.g., if a header does not exist) and the resequencer's pipeline is currently empty, the bad Exchange will be added to the pipeline. ResequencerEnginer.insert() succeeds in calling sequence.add() with the bad Exchange, but throws an Exception when calling sequence.successor(). This results in the message ending up at the Error Handler but the bad Exchange still in the Engine's sequence. Probably insert() should be probably be more transactional.\n\nAfter this happens:\n1) Trying to add a further exchange (even a \"good\" one) results in an Exception when calling sequence.add().\n2) ResequencerEngine.deliverNext() results in an Exception so no further messages will be delievered.\n\nI will attach a unit test to reproduce when I get a chance.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.005144433118402958
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01797810196876526
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006225306075066328
                }
            }
        },
        "comments": [
            {
                "author_name": "dgtombs",
                "id": "13094707",
                "body": "A possible kludge-fix could be to compare() every Exchange with itself before adding to the Engine's sequence. This should weed out un-comparable Exchanges."
            },
            {
                "author_name": "davsclaus",
                "id": "13103605",
                "body": "David do you have an unit test reproducing this issue?"
            },
            {
                "author_name": "davsclaus",
                "id": "13103651",
                "body": "I can reproduce the issue and I am working on a fix."
            },
            {
                "author_name": "davsclaus",
                "id": "13103703",
                "body": "Resequencer will now validate the incoming Exchange before enqueing. If invalid an exception is thrown. Added new option ignoreInvalidExchanges to ignore invalid exchanges."
            },
            {
                "author_name": "dgtombs",
                "id": "13104129",
                "body": "Thanks for the fix. Are you sure you don't want to just catch IllegalArugmentException in StreamResequencer.process(), though?"
            },
            {
                "author_name": "davsclaus",
                "id": "13104381",
                "body": "Thanks David, changed the code accordingly."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d627a6f4d395ee22261c4b",
        "key": "AURORA-1809",
        "id": "13018324",
        "description": "If you run it apart of the full test suite it fails like this:\n{noformat}\n ==================== FAILURES ====================\n                     __ TestRunnerKillProcessGroup.test_pg_is_killed __\n                     \n                     self = <test_staged_kill.TestRunnerKillProcessGroup object at 0x7f0c79893e10>\n                     \n                     \u001b[1m    def test_pg_is_killed(self):\u001b[0m\n                     \u001b[1m      runner = self.start_runner()\u001b[0m\n                     \u001b[1m      tm = TaskMonitor(runner.tempdir, runner.task_id)\u001b[0m\n                     \u001b[1m      self.wait_until_running(tm)\u001b[0m\n                     \u001b[1m      process_state, run_number = tm.get_active_processes()[0]\u001b[0m\n                     \u001b[1m      assert process_state.process == 'process'\u001b[0m\n                     \u001b[1m      assert run_number == 0\u001b[0m\n                     \u001b[1m    \u001b[0m\n                     \u001b[1m      child_pidfile = os.path.join(runner.sandbox, runner.task_id, 'child.txt')\u001b[0m\n                     \u001b[1m      while not os.path.exists(child_pidfile):\u001b[0m\n                     \u001b[1m        time.sleep(0.1)\u001b[0m\n                     \u001b[1m      parent_pidfile = os.path.join(runner.sandbox, runner.task_id, 'parent.txt')\u001b[0m\n                     \u001b[1m      while not os.path.exists(parent_pidfile):\u001b[0m\n                     \u001b[1m        time.sleep(0.1)\u001b[0m\n                     \u001b[1m      with open(child_pidfile) as fp:\u001b[0m\n                     \u001b[1m        child_pid = int(fp.read().rstrip())\u001b[0m\n                     \u001b[1m      with open(parent_pidfile) as fp:\u001b[0m\n                     \u001b[1m        parent_pid = int(fp.read().rstrip())\u001b[0m\n                     \u001b[1m    \u001b[0m\n                     \u001b[1m      ps = ProcessProviderFactory.get()\u001b[0m\n                     \u001b[1m      ps.collect_all()\u001b[0m\n                     \u001b[1m      assert parent_pid in ps.pids()\u001b[0m\n                     \u001b[1m      assert child_pid in ps.pids()\u001b[0m\n                     \u001b[1m      assert child_pid in ps.children_of(parent_pid)\u001b[0m\n                     \u001b[1m    \u001b[0m\n                     \u001b[1m      with open(os.path.join(runner.sandbox, runner.task_id, 'exit.txt'), 'w') as fp:\u001b[0m\n                     \u001b[1m        fp.write('go away!')\u001b[0m\n                     \u001b[1m    \u001b[0m\n                     \u001b[1m      while tm.task_state() is not TaskState.SUCCESS:\u001b[0m\n                     \u001b[1m        time.sleep(0.1)\u001b[0m\n                     \u001b[1m    \u001b[0m\n                     \u001b[1m      state = tm.get_state()\u001b[0m\n                     \u001b[1m      assert state.processes['process'][0].state == ProcessState.SUCCESS\u001b[0m\n                     \u001b[1m    \u001b[0m\n                     \u001b[1m      ps.collect_all()\u001b[0m\n                     \u001b[1m      assert parent_pid not in ps.pids()\u001b[0m\n                     \u001b[1m>     assert child_pid not in ps.pids()\u001b[0m\n                     \u001b[1m\u001b[31mE     assert 30475 not in set([1, 2, 3, 5, 7, 8, ...])\u001b[0m\n                     \u001b[1m\u001b[31mE      +  where set([1, 2, 3, 5, 7, 8, ...]) = <bound method ProcessProvider_Procfs.pids of <twitter.common.process.process_provider_procfs.ProcessProvider_Procfs object at 0x7f0c798b1990>>()\u001b[0m\n                     \u001b[1m\u001b[31mE      +    where <bound method ProcessProvider_Procfs.pids of <twitter.common.process.process_provider_procfs.ProcessProvider_Procfs object at 0x7f0c798b1990>> = <twitter.common.process.process_provider_procfs.ProcessProvider_Procfs object at 0x7f0c798b1990>.pids\u001b[0m\n                     \n                     src/test/python/apache/thermos/core/test_staged_kill.py:287: AssertionError\n                     -------------- Captured stderr call --------------\n                     WARNING:root:Could not read from checkpoint /tmp/tmp9WSRnw/checkpoints/1478305991773556-runner-base/runner\n                     WARNING:root:Could not read from checkpoint /tmp/tmp9WSRnw/checkpoints/1478305991773556-runner-base/runner\n                     WARNING:root:Could not read from checkpoint /tmp/tmp9WSRnw/checkpoints/1478305991773556-runner-base/runner\n                     WARNING:root:Could not read from checkpoint /tmp/tmp9WSRnw/checkpoints/1478305991773556-runner-base/runner\n                     WARNING:root:Could not read from checkpoint /tmp/tmp9WSRnw/checkpoints/1478305991773556-runner-base/runner\n                     WARNING:root:Could not read from checkpoint /tmp/tmp9WSRnw/checkpoints/1478305991773556-runner-base/runner\n                     WARNING:root:Could not read from checkpoint /tmp/tmp9WSRnw/checkpoints/1478305991773556-runner-base/runner\n                      generated xml file: /home/jenkins/jenkins-slave/workspace/AuroraBot/dist/test-results/415337499eb72578eab327a6487c1f5c9452b3d6.xml \n                     \u001b[1m\u001b[31m 1 failed, 719 passed, 6 skipped, 1 warnings in 206.00 seconds \u001b[0m\n                     \nFAILURE\n{noformat}\n\n\nIf you run the test as a one off you see this:\n{noformat}\n00:45:32 00:00 [main]\n               (To run a reporting server: ./pants server)\n00:45:32 00:00   [setup]\n00:45:32 00:00     [parse]fatal: Not a git repository (or any of the parent directories): .git\n\n               Executing tasks in goals: test\n00:45:32 00:00   [test]\n00:45:32 00:00     [test-prep-command]\n00:45:32 00:00     [test]\n00:45:32 00:00     [pytest]\n00:45:32 00:00       [run]\n                     ============== test session starts ===============\n                     platform linux2 -- Python 2.7.6 -- py-1.4.31 -- pytest-2.6.4 -- /usr/bin/python2.7\n                     plugins: cov, timeout\n                     collected 83 items\n\n                     src/test/python/apache/thermos/core/test_staged_kill.py::TestRunnerKillProcessGroup::test_pg_is_killed PASSED\n\n                      generated xml file: /home/vagrant/aurora/dist/test-results/src.test.python.apache.thermos.core.core.xml\n                      82 tests deselected by '-kTestRunnerKillProcessGroup'\n                      1 passed, 82 deselected, 1 warnings in 2.49 seconds\n{noformat}\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008102179504930973
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009770816192030907
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005727774929255247
                }
            }
        },
        "comments": [
            {
                "author_name": "StephanErb",
                "id": "15836806",
                "body": "This test fails due to the recent introduction of {{PR_SET_CHILD_SUBREAPER}}. Only in the full suite {{setup_child_subreaping()}} is called before the above mentioned test case is run. If we additionally call {{setup_child_subreaping()}} from within the testcase it fails all the time.\n"
            },
            {
                "author_name": "StephanErb",
                "id": "15844573",
                "body": "https://reviews.apache.org/r/56062/"
            },
            {
                "author_name": "StephanErb",
                "id": "15845875",
                "body": "{code}\ncommit e0c9e08d0c4e2226da772fa1199c51765442f160\nAuthor: Stephan Erb <serb@apache.org>\nDate:   Mon Jan 30 21:40:14 2017 +0100\n\n    Fix flapping TestRunnerKillProcessGroup test.\n\n    The test was working when run in isolation, but failed when executing the\n    entire Thermos test suite.\n\n    Bugs closed: AURORA-1809\n\n    Reviewed at https://reviews.apache.org/r/56062/\n\n src/test/python/apache/thermos/core/test_staged_kill.py | 7 ++++++-\n 1 file changed, 6 insertions(+), 1 deletion(-)\n{code}"
            }
        ],
        "comments_predictions": [
            [
                3728883,
                "AURORA-1809",
                "This test fails due to the recent introduction of {{PR_SET_CHILD_SUBREAPER}}. Only in the full suite {{setup_child_subreaping()}} is called before the above mentioned test case is run. If we additionally call {{setup_child_subreaping()}} from within the testcase it fails all the time.\n",
                {
                    "property": {
                        "confidence": 0.005144655238837004,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009870302863419056,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008985942229628563,
                        "prediction": false
                    }
                }
            ],
            [
                3728885,
                "AURORA-1809",
                "{code}\ncommit e0c9e08d0c4e2226da772fa1199c51765442f160\nAuthor: Stephan Erb <serb@apache.org>\nDate:   Mon Jan 30 21:40:14 2017 +0100\n\n    Fix flapping TestRunnerKillProcessGroup test.\n\n    The test was working when run in isolation, but failed when executing the\n    entire Thermos test suite.\n\n    Bugs closed: AURORA-1809\n\n    Reviewed at https://reviews.apache.org/r/56062/\n\n src/test/python/apache/thermos/core/test_staged_kill.py | 7 ++++++-\n 1 file changed, 6 insertions(+), 1 deletion(-)\n{code}",
                {
                    "property": {
                        "confidence": 0.005593759007751942,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008319880813360214,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010887970216572285,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "64074665dc5b3e8de781d286",
        "key": "AVRO-3544",
        "id": "13468335",
        "description": "All of the content from https://github.com/apache/avro/tree/master/doc/content/en/project is missing from the published website.\r\n\r\nI suspect this has something to do with the templates.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.055677786469459534
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0074225664138793945
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004166435915976763
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d759f4d395ee22199726",
        "key": "TEZ-2864",
        "id": "12901720",
        "description": " We encountered PIG-4649 with HCatStorer where it was hardcoding the part file name and not honoring mapreduce.output.basename. If there were two vertex groups writing to same output directory one was overwriting another as file names were same without part-v000-o000 prefix. Tez should fail the job in that case instead of silently losing data.  ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0046880971640348434
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.03664248809218407
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005318215116858482
                }
            }
        },
        "comments": [
            {
                "author_name": "jlowe",
                "id": "14949296",
                "body": "Is this a Tez issue? I'm not sure how Tez is supposed to know about, and somehow fix, the specific internals of the output format and output committer which is arbitrary user code. Seems to me this specific instance is an artifact of the way FileOutputCommitter works, as it resolves output pathname conflicts by choosing one rather than failing. That behavior of FileOutputCommitter has been there since the 0.20 days, so we may need a config option to restore the original behavior if we decide to change it.\n\nIn general this appears to be a problem with Tez trying to reuse output formats and committers that may assume MapReduce semantics.  MapReduce output formats have been able to assume, safely, that no two tasks will have the same task number.  Tez invalidates that assumption.  The only way I can see that Tez can generically support unmodified MapReduce output formats is to guarantee that no two tasks have the same task number, even if they belong to different vertices.  Besides probably being complicated to implement internally, this would also have some unfortunate side effects such as output pathnames that could have gaps in the numbering and making it more difficult to track down which vertex task generated a particular output."
            },
            {
                "author_name": "rohini",
                "id": "14949379",
                "body": "Will be handling this in Pig."
            }
        ],
        "comments_predictions": [
            [
                447231,
                "TEZ-2864",
                "Is this a Tez issue? I'm not sure how Tez is supposed to know about, and somehow fix, the specific internals of the output format and output committer which is arbitrary user code. Seems to me this specific instance is an artifact of the way FileOutputCommitter works, as it resolves output pathname conflicts by choosing one rather than failing. That behavior of FileOutputCommitter has been there since the 0.20 days, so we may need a config option to restore the original behavior if we decide to change it.\n\nIn general this appears to be a problem with Tez trying to reuse output formats and committers that may assume MapReduce semantics.  MapReduce output formats have been able to assume, safely, that no two tasks will have the same task number.  Tez invalidates that assumption.  The only way I can see that Tez can generically support unmodified MapReduce output formats is to guarantee that no two tasks have the same task number, even if they belong to different vertices.  Besides probably being complicated to implement internally, this would also have some unfortunate side effects such as output pathnames that could have gaps in the numbering and making it more difficult to track down which vertex task generated a particular output.",
                {
                    "property": {
                        "confidence": 0.005768789444118738,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004727184772491455,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.029388081282377243,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d6119ef4d395ee2222fc6a",
        "key": "FLEX-23725",
        "id": "12584600",
        "description": "Steps to reproduce:\n\n1. Build/Run RuntimeEmbeddedFonts-brokenWithReleaseSDK.mxml using Release SDK (14159) making sure that appropriate font swfs are in bin-debug (or bin-release) folder.\n2.  The file RuntimeEmbeddedFonts-worksWithBetaSDK.mxml correctly compiles and runs with Beta SDK (10485)\n\nNote: Font swfs must be compiled with same SDK as main application\n \n\n Actual Results:\n It seems that the release SDK does not properly render fonts loaded in at runtime.  When using the spark textarea, only the font declared using the fontFamily attribute renders properly when using html and TextConverter/TextFlow.  Beta SDK works as expected.\n \n Expected Results:\n All fonts that have been loaded in should display properly. \n\n \n \n Workaround (if any):\n \n Use BETA SDK (not really a workaround)",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13366250",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-26187\nOriginal Reporter: peteranselmo\nOriginal Resolution: Retired\nDiscoverability: High\nNumber of votes: 9\nRegression: Yes\nReproducibility: Every Time\nResolved by: aharui\nSeverity: Non Functioning\nreporter: peteranselmo"
            },
            {
                "author_name": "adobejira",
                "id": "13366251",
                "body": "created: 2010-04-09 09:36:03.000\nresolved: 2010-07-20 16:24:27.399\nupdated: 2010-08-03 09:01:57.000"
            },
            {
                "author_name": "adobejira",
                "id": "13366252",
                "body": "On 2010-04-19 09:53:49.149 gauravj commented:\nreproduced. \n\nIt may be a NAB. \n\nAlex's comment on a similar bug(https://bugs.adobe.com/jira/browse/SDK-23453) suggest that setting fontFamily is required and flex doesn't look inside HTML for <FONT> tags\nOn 2010-04-19 12:34:40.723 peteranselmo commented:\nthe fontFamily parameter is set in the example applications however it only will accept (and render properly) a single font.  The fonts that are loaded in from the external source are definitely available because creating a second textarea with the other font will exhibit the same behavior.\n\nI would have to believe that it is a bug because it works properly on the beta SDK and I don't believe that not allowing more than one externally loaded font in a textarea would be a desired behavior.\nOn 2010-04-19 14:14:32.527 tan commented:\nIRB -> Investigate to Alex.\nOn 2010-04-20 00:03:41.884 aharui commented:\nThis is UTR for me.  I see two lines of text.\nOn 2010-04-20 06:57:30.334 peteranselmo commented:\nThis screen shot is the proper rendering of BOTH fonts used in the textarea.\nOn 2010-04-20 06:59:27.706 peteranselmo commented:\nAlex.. thanks for looking into this.  I have attached a screenshot of what it should look like when both fonts are rendered.  I used the fonts \"Flood\" and \"Daisy\" because they are easy to recognize when they are rendered.\nOn 2010-04-20 14:24:03.370 aharui commented:\nSo, in theory, this configuration should not work, for the reasons described in this post: http://blogs.adobe.com/aharui/2010/03/flex_and_embedded_fonts.html\n\nBasically, you cannot get a single text control to display fonts from two different SWFs without registering the fonts.\n\nHowever, it turns out that when compiling a Styles module, the Flex CSS compiler incorrectly adds code to register the font.  It is incorrect because registering the font will prevent the Styles module from unloading and can cause font-subset collisions as described in the post.   Someday we may fix that bug and the test case supplied with this bug will have no chance of working.\n\nHowever, it is still possible to have a supported configuration that registers the fonts from two or more SWFs on purpose knowing full well that it won't ever unload the SWFs.  Yet another bug is preventing that from working.  The TextUtil.as resolveFontLookup method does not consider registered fonts.\n\nBecause multiple fonts from separate SWFs causes memory leaks, the test case is considered an edge case so TextUtil will probably not get fixed until 4.5.  However, a workaround for this particular test case is to override the GlobalSettings.resolveFontLookup method with a correct version.\n\nThere are two steps to the workaround.  First is to create a method that will resolve the font lookup correctly.  Here is the version I used to get the test case to work:\n\n\t\t\timport flash.text.engine.FontDescription;\n\t\t\timport flash.text.engine.FontLookup;\n\t\t\t\n\t\t\timport flashx.textLayout.compose.ISWFContext;\n\t\t\timport flashx.textLayout.elements.GlobalSettings;\n\t\t\timport flashx.textLayout.formats.ITextLayoutFormat;\n\t\t\t\n\t\t\timport mx.core.EmbeddedFont;\n\t\t\timport mx.core.IEmbeddedFontRegistry;\n\t\t\timport mx.core.IFlexModuleFactory;\n\t\t\timport mx.core.Singleton;\n\t\t\t\n\t\t\tpublic static function fixForRegisteredFontLookups(swfContext:ISWFContext, format:ITextLayoutFormat):String\n\t\t\t{\n\t\t\t\t// If the font isn't embedded as advertised, first fall back to \n\t\t\t\t// corresponding device font and, only if that fails, fail back to the\n\t\t\t\t// player's default font.\n\t\t\t\tif (swfContext && format.fontLookup == FontLookup.EMBEDDED_CFF)\n\t\t\t\t{\n\t\t\t\t\tvar name:String = format.fontFamily;\n\t\t\t\t\tvar bold:Boolean = format.fontWeight == \"bold\";\n\t\t\t\t\tvar italic:Boolean = format.fontStyle == \"italic\";\n\t\t\t\t\tvar font:EmbeddedFont = new EmbeddedFont(name, bold, italic);\n\t\t\t\t\t\n\t\t\t\t\tvar registry:IEmbeddedFontRegistry = \n\t\t\t\t\t\tIEmbeddedFontRegistry(\n\t\t\t\t\t\t\tSingleton.getInstance(\"mx.core::IEmbeddedFontRegistry\"));\n\t\t\t\t\t\n\t\t\t\t\tif (registry && \n\t\t\t\t\t\tregistry.isFontRegistered(font, IFlexModuleFactory(swfContext)))\n\t\t\t\t\t{\n\t\t\t\t\t\treturn FontLookup.EMBEDDED_CFF;\n\t\t\t\t\t}\n\t\t\t\t\tif (swfContext.callInContext(FontDescription.isFontCompatible, FontDescription, [name, format.fontWeight, format.fontStyle]))\n\t\t\t\t\t\treturn FontLookup.EMBEDDED_CFF;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\treturn FontLookup.DEVICE; \t\t\t\t\n\t\t\t}\n\nAnd the second step is to use that method in the GlobalSettings after the text components have been initialized.  Unless the text components are loaded and initialized \"late\" via modules, it should be sufficient to make the assignment in creationComplete or before assigning the textFlow.  The assignment looks like:\n\n\t\t\t\tGlobalSettings.resolveFontLookupFunction = fixForRegisteredFontLookups;\nOn 2010-04-20 14:24:57.334 aharui commented:\nSee prior comment.  Open to someone for 4.5, even community.\nOn 2010-04-23 16:41:12.090 laupark commented:\nOpened to SDK Community.\nOn 2010-05-25 10:06:29.954 warhammerkid commented:\nI ran into this issue on my application moving to the final release of Flex 4. However I have a bit different situation and so I'm somewhat confused why I'm affected. In my build process, I compile a CSS swf and then embed it into a \"theme\" swf which packages all the images, CSS, and fonts needed for that theme. Once the theme swf is loaded, I call Font.registerFont on each included font class from the main application swf code. Then I use ModuleLoader's ability to load from a ByteArray to load in the CSS swf and initialize it using the code from StyleManagerImpl#loadStyleDeclarations2. I have absolutely no assets embedded in the CSS swf, so I'm kind of confused about how I'm still affected by this bug, based on your comments in http://blogs.adobe.com/aharui/2010/03/flex_and_embedded_fonts.html.\n\nCan you explain why it still affects me, when my styles and fonts work perfectly for Label tags and my own custom TextBlock components find and use the loaded in fonts without issues? In addition, I'm kind of confused about how exactly I would apply the GlobalSettings fix in my code.\nOn 2010-07-20 15:41:24.559 aharui commented:\n@stephen\n\nThe current code doesn't consider registered fonts so if you are registering your own fonts and don't have the CSS structures that go with it you could run into issues."
            }
        ],
        "comments_predictions": [
            [
                2991418,
                "FLEX-23725",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-26187\nOriginal Reporter: peteranselmo\nOriginal Resolution: Retired\nDiscoverability: High\nNumber of votes: 9\nRegression: Yes\nReproducibility: Every Time\nResolved by: aharui\nSeverity: Non Functioning\nreporter: peteranselmo",
                {
                    "property": {
                        "confidence": 0.003613679204136133,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.04298555478453636,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010706200264394283,
                        "prediction": false
                    }
                }
            ],
            [
                2991420,
                "FLEX-23725",
                "On 2010-04-19 09:53:49.149 gauravj commented:\nreproduced. \n\nIt may be a NAB. \n\nAlex's comment on a similar bug(https://bugs.adobe.com/jira/browse/SDK-23453) suggest that setting fontFamily is required and flex doesn't look inside HTML for <FONT> tags\nOn 2010-04-19 12:34:40.723 peteranselmo commented:\nthe fontFamily parameter is set in the example applications however it only will accept (and render properly) a single font.  The fonts that are loaded in from the external source are definitely available because creating a second textarea with the other font will exhibit the same behavior.\n\nI would have to believe that it is a bug because it works properly on the beta SDK and I don't believe that not allowing more than one externally loaded font in a textarea would be a desired behavior.\nOn 2010-04-19 14:14:32.527 tan commented:\nIRB -> Investigate to Alex.\nOn 2010-04-20 00:03:41.884 aharui commented:\nThis is UTR for me.  I see two lines of text.\nOn 2010-04-20 06:57:30.334 peteranselmo commented:\nThis screen shot is the proper rendering of BOTH fonts used in the textarea.\nOn 2010-04-20 06:59:27.706 peteranselmo commented:\nAlex.. thanks for looking into this.  I have attached a screenshot of what it should look like when both fonts are rendered.  I used the fonts \"Flood\" and \"Daisy\" because they are easy to recognize when they are rendered.\nOn 2010-04-20 14:24:03.370 aharui commented:\nSo, in theory, this configuration should not work, for the reasons described in this post: http://blogs.adobe.com/aharui/2010/03/flex_and_embedded_fonts.html\n\nBasically, you cannot get a single text control to display fonts from two different SWFs without registering the fonts.\n\nHowever, it turns out that when compiling a Styles module, the Flex CSS compiler incorrectly adds code to register the font.  It is incorrect because registering the font will prevent the Styles module from unloading and can cause font-subset collisions as described in the post.   Someday we may fix that bug and the test case supplied with this bug will have no chance of working.\n\nHowever, it is still possible to have a supported configuration that registers the fonts from two or more SWFs on purpose knowing full well that it won't ever unload the SWFs.  Yet another bug is preventing that from working.  The TextUtil.as resolveFontLookup method does not consider registered fonts.\n\nBecause multiple fonts from separate SWFs causes memory leaks, the test case is considered an edge case so TextUtil will probably not get fixed until 4.5.  However, a workaround for this particular test case is to override the GlobalSettings.resolveFontLookup method with a correct version.\n\nThere are two steps to the workaround.  First is to create a method that will resolve the font lookup correctly.  Here is the version I used to get the test case to work:\n\n\t\t\timport flash.text.engine.FontDescription;\n\t\t\timport flash.text.engine.FontLookup;\n\t\t\t\n\t\t\timport flashx.textLayout.compose.ISWFContext;\n\t\t\timport flashx.textLayout.elements.GlobalSettings;\n\t\t\timport flashx.textLayout.formats.ITextLayoutFormat;\n\t\t\t\n\t\t\timport mx.core.EmbeddedFont;\n\t\t\timport mx.core.IEmbeddedFontRegistry;\n\t\t\timport mx.core.IFlexModuleFactory;\n\t\t\timport mx.core.Singleton;\n\t\t\t\n\t\t\tpublic static function fixForRegisteredFontLookups(swfContext:ISWFContext, format:ITextLayoutFormat):String\n\t\t\t{\n\t\t\t\t// If the font isn't embedded as advertised, first fall back to \n\t\t\t\t// corresponding device font and, only if that fails, fail back to the\n\t\t\t\t// player's default font.\n\t\t\t\tif (swfContext && format.fontLookup == FontLookup.EMBEDDED_CFF)\n\t\t\t\t{\n\t\t\t\t\tvar name:String = format.fontFamily;\n\t\t\t\t\tvar bold:Boolean = format.fontWeight == \"bold\";\n\t\t\t\t\tvar italic:Boolean = format.fontStyle == \"italic\";\n\t\t\t\t\tvar font:EmbeddedFont = new EmbeddedFont(name, bold, italic);\n\t\t\t\t\t\n\t\t\t\t\tvar registry:IEmbeddedFontRegistry = \n\t\t\t\t\t\tIEmbeddedFontRegistry(\n\t\t\t\t\t\t\tSingleton.getInstance(\"mx.core::IEmbeddedFontRegistry\"));\n\t\t\t\t\t\n\t\t\t\t\tif (registry && \n\t\t\t\t\t\tregistry.isFontRegistered(font, IFlexModuleFactory(swfContext)))\n\t\t\t\t\t{\n\t\t\t\t\t\treturn FontLookup.EMBEDDED_CFF;\n\t\t\t\t\t}\n\t\t\t\t\tif (swfContext.callInContext(FontDescription.isFontCompatible, FontDescription, [name, format.fontWeight, format.fontStyle]))\n\t\t\t\t\t\treturn FontLookup.EMBEDDED_CFF;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\treturn FontLookup.DEVICE; \t\t\t\t\n\t\t\t}\n\nAnd the second step is to use that method in the GlobalSettings after the text components have been initialized.  Unless the text components are loaded and initialized \"late\" via modules, it should be sufficient to make the assignment in creationComplete or before assigning the textFlow.  The assignment looks like:\n\n\t\t\t\tGlobalSettings.resolveFontLookupFunction = fixForRegisteredFontLookups;\nOn 2010-04-20 14:24:57.334 aharui commented:\nSee prior comment.  Open to someone for 4.5, even community.\nOn 2010-04-23 16:41:12.090 laupark commented:\nOpened to SDK Community.\nOn 2010-05-25 10:06:29.954 warhammerkid commented:\nI ran into this issue on my application moving to the final release of Flex 4. However I have a bit different situation and so I'm somewhat confused why I'm affected. In my build process, I compile a CSS swf and then embed it into a \"theme\" swf which packages all the images, CSS, and fonts needed for that theme. Once the theme swf is loaded, I call Font.registerFont on each included font class from the main application swf code. Then I use ModuleLoader's ability to load from a ByteArray to load in the CSS swf and initialize it using the code from StyleManagerImpl#loadStyleDeclarations2. I have absolutely no assets embedded in the CSS swf, so I'm kind of confused about how I'm still affected by this bug, based on your comments in http://blogs.adobe.com/aharui/2010/03/flex_and_embedded_fonts.html.\n\nCan you explain why it still affects me, when my styles and fonts work perfectly for Label tags and my own custom TextBlock components find and use the loaded in fonts without issues? In addition, I'm kind of confused about how exactly I would apply the GlobalSettings fix in my code.\nOn 2010-07-20 15:41:24.559 aharui commented:\n@stephen\n\nThe current code doesn't consider registered fonts so if you are registering your own fonts and don't have the CSS structures that go with it you could run into issues.",
                {
                    "property": {
                        "confidence": 0.00404760055243969,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010528117418289185,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023108595982193947,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "64074392262d7902a6d2ac70",
        "key": "MAPREDUCE-4815",
        "id": "12617132",
        "description": "If a job generates many files to commit then the commitJob method call at the end of the job can take minutes.  This is a performance regression from 1.x, as 1.x had the tasks commit directly to the final output directory as they were completing and commitJob had very little to do.  The commit work was processed in parallel and overlapped the processing of outstanding tasks.  In 0.23/2.x, the commit is single-threaded and waits until all tasks have completed before commencing.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.004551470745354891
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.021835841238498688
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.3524799048900604
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d626a4f4d395ee2225f46e",
        "key": "AXIS2-3088",
        "id": "12375478",
        "description": "I need to set the two JMS message header fields \"Content_type\" and \"Mime_Version\". I achieved to set the content type with:\n\n Options options = stub._getServiceClient().getOptions();\n options.setProperty(org.apache.axis2.Constants.Configuration.CONTENT_TYPE, \"application/xml; charset=\\\"iso-8859-1\\\"  \");\n\nShouldn't this also be possible for the Mime Version?\n\nI read the workaround proposed by you to replace the JMSSender class by a copy where these two properties are set with a string property in the class itself, but this is not an option for me.\n\nRegards,\nDominik",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009257073514163494
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.02327287197113037
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0032030008733272552
                }
            }
        },
        "comments": [
            {
                "author_name": "asankha",
                "id": "12654503",
                "body": "Please set transport level headers as necessary"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d60bfaf4d395ee22223378",
        "key": "GEODE-5478",
        "id": "13174633",
        "description": "The lowRedundancyBucketCount statistic is not maintained properly when multiple members are stopped and restarted\r\n\r\nA test where multiple members are stopped simultaneously so that all copies of a bucket are offlineshows the numBucketsWithoutRedundancy metric not set properly:\r\n\r\nInitially:\r\n{noformat}\r\n(2) Executing - show metrics --categories=partition --region=/rewards\r\n\r\nCategory | Metric | Value\r\n--------- | --------------------------- | ------\r\npartition | putLocalRate | 0.0\r\n | putRemoteRate | 0.0\r\n | putRemoteLatency | 0\r\n | putRemoteAvgLatency | 0\r\n | bucketCount | 226\r\n | primaryBucketCount | 113\r\n | numBucketsWithoutRedundancy | 0\r\n | totalBucketSize | 200000\r\n | averageBucketSize | 221\r\n\r\n(3) Executing - show metrics --categories=partition --region=/customer\r\n\r\nCategory | Metric | Value\r\n--------- | --------------------------- | -----\r\npartition | putLocalRate | 0.0\r\n | putRemoteRate | 0.0\r\n | putRemoteLatency | 0\r\n | putRemoteAvgLatency | 0\r\n | bucketCount | 226\r\n | primaryBucketCount | 113\r\n | numBucketsWithoutRedundancy | 0\r\n | totalBucketSize | 20000\r\n | averageBucketSize | 22\r\n{noformat}\r\nAfter stopping 2 members (of 4):\r\n{noformat}\r\n(2) Executing - show metrics --categories=partition --region=/rewards\r\n\r\nCategory | Metric | Value\r\n--------- | --------------------------- | -----\r\npartition | putLocalRate | 0.0\r\n | putRemoteRate | 0.0\r\n | putRemoteLatency | 0\r\n | putRemoteAvgLatency | 0\r\n | bucketCount | 112\r\n | primaryBucketCount | 73\r\n | numBucketsWithoutRedundancy | 57\r\n | totalBucketSize | 99107\r\n | averageBucketSize | 442\r\n\r\n(3) Executing - show metrics --categories=partition --region=/customer\r\n\r\nCategory | Metric | Value\r\n--------- | --------------------------- | -----\r\npartition | putLocalRate | 0.0\r\n | putRemoteRate | 0.0\r\n | putRemoteLatency | 0\r\n | putRemoteAvgLatency | 0\r\n | bucketCount | 112\r\n | primaryBucketCount | 76\r\n | numBucketsWithoutRedundancy | 57\r\n | totalBucketSize | 9915\r\n | averageBucketSize | 44\r\n{noformat}\r\nAfter restarting both members, numBucketsWithoutRedundancy > 0:\r\n{noformat}\r\n(2) Executing - show metrics --categories=partition --region=/rewards\r\n\r\nCategory | Metric | Value\r\n--------- | --------------------------- | ------\r\npartition | putLocalRate | 0.0\r\n | putRemoteRate | 0.0\r\n | putRemoteLatency | 0\r\n | putRemoteAvgLatency | 0\r\n | bucketCount | 226\r\n | primaryBucketCount | 113\r\n | numBucketsWithoutRedundancy | 0\r\n | totalBucketSize | 200000\r\n | averageBucketSize | 221\r\n\r\n(3) Executing - show metrics --categories=partition --region=/customer\r\n\r\nCategory | Metric | Value\r\n--------- | --------------------------- | -----\r\npartition | putLocalRate | 0.0\r\n | putRemoteRate | 0.0\r\n | putRemoteLatency | 0\r\n | putRemoteAvgLatency | 0\r\n | bucketCount | 226\r\n | primaryBucketCount | 113\r\n | numBucketsWithoutRedundancy | 21\r\n | totalBucketSize | 20000\r\n | averageBucketSize | 22\r\n{noformat}\r\nAll the buckets and data are recovered, but the numBucketsWithoutRedundancy is not 0.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012367448769509792
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007702112663537264
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005000588018447161
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "16558926",
                "body": "Commit 18b9fd47fcd21ab9eb3bf0d2d325f9871e5453a8 in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=18b9fd4 ]\n\nGEODE-5478: Simplified low redundancy calculation\n\nCo-authored-by: Darrel Schneider <dschneider@pivotal.io>\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16558983",
                "body": "Commit b4b3cc34ffc0bdcfbd0461cf0b8da642251bea7f in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=b4b3cc3 ]\n\nGEODE-5478: Modified BucketRedundancyTracker to not increment low redundnancy bucket count twice\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16558984",
                "body": "Commit 36dca4d20bdcc2eaf27f5fd62c53fc9c9d1bc18c in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=36dca4d ]\n\nGEODE-5478: Simplified low redundancy calculation\n\nCo-authored-by: Darrel Schneider <dschneider@pivotal.io>\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16558985",
                "body": "Commit c93fafd93e090d8ed280bfd02c8759e760a3cc7b in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=c93fafd ]\n\nGEODE-5478: Updated distributed test after rebase\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16560007",
                "body": "Commit 46a4e26d82065a3f7bddefcb4ec533c33d3e49cc in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=46a4e26 ]\n\nGEODE-5478: Force CI re-run\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16560008",
                "body": "Commit a9e9ba494115b3b20097d3c307431e1ed1b20b79 in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=a9e9ba4 ]\n\nGEODE-5478: Force CI re-run\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16560293",
                "body": "Commit 12e17d80629bfd4193b3bcd603a75eb9694c8107 in geode's branch refs/heads/develop from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=12e17d8 ]\n\nGEODE-5478: Modified to not increment low redundancy bucket count twice\n\nCo-authored-by: Darrel Schneider <dschneider@pivotal.io>"
            },
            {
                "author_name": "jira-bot",
                "id": "16560295",
                "body": "Commit b4b3cc34ffc0bdcfbd0461cf0b8da642251bea7f in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=b4b3cc3 ]\n\nGEODE-5478: Modified BucketRedundancyTracker to not increment low redundnancy bucket count twice\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16560296",
                "body": "Commit 36dca4d20bdcc2eaf27f5fd62c53fc9c9d1bc18c in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=36dca4d ]\n\nGEODE-5478: Simplified low redundancy calculation\n\nCo-authored-by: Darrel Schneider <dschneider@pivotal.io>\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16560297",
                "body": "Commit c93fafd93e090d8ed280bfd02c8759e760a3cc7b in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=c93fafd ]\n\nGEODE-5478: Updated distributed test after rebase\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16560298",
                "body": "Commit 46a4e26d82065a3f7bddefcb4ec533c33d3e49cc in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=46a4e26 ]\n\nGEODE-5478: Force CI re-run\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16560299",
                "body": "Commit a9e9ba494115b3b20097d3c307431e1ed1b20b79 in geode's branch refs/heads/feature/GEODE-5478 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=a9e9ba4 ]\n\nGEODE-5478: Force CI re-run\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16560493",
                "body": "Commit 12e17d80629bfd4193b3bcd603a75eb9694c8107 in geode's branch refs/heads/feature/GEODE-5212-export-logs from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=12e17d8 ]\n\nGEODE-5478: Modified to not increment low redundancy bucket count twice\n\nCo-authored-by: Darrel Schneider <dschneider@pivotal.io>"
            },
            {
                "author_name": "jira-bot",
                "id": "16562334",
                "body": "Commit 12e17d80629bfd4193b3bcd603a75eb9694c8107 in geode's branch refs/heads/feature/GEODE-5400 from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=12e17d8 ]\n\nGEODE-5478: Modified to not increment low redundancy bucket count twice\n\nCo-authored-by: Darrel Schneider <dschneider@pivotal.io>"
            },
            {
                "author_name": "jira-bot",
                "id": "16563976",
                "body": "Commit e0288945084f319f3a3d00b1689785693e1e7c4b in geode's branch refs/heads/develop from [~barry.oglesby]\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=e028894 ]\n\nGEODE-5478: Modified updateNoCopiesStatistics to handle never had copies case\n\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d7e4f4d395ee2219abcd",
        "key": "TAPESTRY-2440",
        "id": "12397638",
        "description": "Once the application is somewhat stable, the developers can explicilty reduce logging back to info.  Note that I mean the root logger should be info, but there should be a log4j.category for the root package to log at debug.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02665257453918457
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.14229561388492584
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.002961043268442154
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f83bf4d395ee221f68e2",
        "key": "ISIS-1655",
        "id": "13088126",
        "description": "... so that rendering is correct.\n\nThe problem has been recreated within Kitchensink, BusRulesObject's disabling of actions via a result held in QueryResultsCache.\n\nNOTE: that it *isn't* correct to invalidate the other two transaction-scoped services (ChangedObjectsServicesInternal, and MetricsServiceDefault) because these don't flush until the end.    I've raised ISIS-1656 for that improvement.\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008499247021973133
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0081802261993289
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005873559974133968
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "16092650",
                "body": "Commit 82d9b34e4d0cc8589a1f67678c690dedd4fbf280 in isis's branch refs/heads/master from [~danhaywood]\n[ https://git-wip-us.apache.org/repos/asf?p=isis.git;h=82d9b34 ]\n\nISIS-1655: resets QueryResultsCache prior to respond phase\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16094200",
                "body": "Commit ace3f33a8c43f5c900edc00cec382becbded5eae in isis's branch refs/heads/master from [~danhaywood]\n[ https://git-wip-us.apache.org/repos/asf?p=isis.git;h=ace3f33 ]\n\nISIS-1655: fixes logger to use\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d4cff4d395ee2218d1a4",
        "key": "WAGON-159",
        "id": "12811184",
        "description": "I have a m2 plugin (webstart-maven-plugin) that I wish to deploy using scp to a remote server. The plugin code is split in several modules according to the following layout:\n\npom.xml\nmodule1/\nmodule2/\nmodule3/\nplugin/pom.xml (maven-plugin packaging)\n\nplugin/pom.xml contains the <distributionManagement> and  I am using both <repository> and <snapshotRepository>. My ~/.m2/settings.xml contains info for my server access.\n\nIf I deploy from within the plugin directory, I have no problem. \nIf I deploy from the root directory, 'mvn deploy' fails with the following error:\n\n[INFO] Failed to configure plugin parameters for: org.apache.maven.plugins:maven-deploy-plugin:2.1\nCause: Class 'org.apache.maven.artifact.repository.ArtifactRepository' cannot be instantiated\n[INFO] ----------------------------------------------------------------------------\n[DEBUG] Trace\norg.apache.maven.lifecycle.LifecycleExecutionException: Error configuring: org.apache.maven.plugins:maven-deploy-plugin. Reason: Unable\nto parse the created DOM for plugin configuration\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:560)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalWithLifecycle(DefaultLifecycleExecutor.java:472)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoal(DefaultLifecycleExecutor.java:451)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoalAndHandleFailures(DefaultLifecycleExecutor.java:303)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeTaskSegments(DefaultLifecycleExecutor.java:270)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.execute(DefaultLifecycleExecutor.java:139)\n        at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:322)\n        at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:115)\n        at org.apache.maven.cli.MavenCli.main(MavenCli.java:249)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n        at java.lang.reflect.Method.invoke(Method.java:585)\n        at org.codehaus.classworlds.Launcher.launchEnhanced(Launcher.java:315)\n        at org.codehaus.classworlds.Launcher.launch(Launcher.java:255)\n        at org.codehaus.classworlds.Launcher.mainWithExitCode(Launcher.java:430)\n        at org.codehaus.classworlds.Launcher.main(Launcher.java:375)\nCaused by: org.apache.maven.plugin.PluginConfigurationException: Error configuring: org.apache.maven.plugins:maven-deploy-plugin. Reason: Unable to parse the created DOM for plugin configuration\n        at org.apache.maven.plugin.DefaultPluginManager.populatePluginFields(DefaultPluginManager.java:1039)\n        at org.apache.maven.plugin.DefaultPluginManager.getConfiguredMojo(DefaultPluginManager.java:579)\n        at org.apache.maven.plugin.DefaultPluginManager.executeMojo(DefaultPluginManager.java:393)\n        at org.apache.maven.lifecycle.DefaultLifecycleExecutor.executeGoals(DefaultLifecycleExecutor.java:531)\n        ... 16 more\nCaused by: org.codehaus.plexus.component.configurator.ComponentConfigurationException: Class 'org.apache.maven.artifact.repository.ArtifactRepository' cannot be instantiated\n        at org.codehaus.plexus.component.configurator.converters.AbstractConfigurationConverter.instantiateObject(AbstractConfigurationConverter.java:121)\n        at org.codehaus.plexus.component.configurator.converters.composite.ObjectWithFieldsConverter.fromConfiguration(ObjectWithFieldsConverter.java:88)\n        at org.codehaus.plexus.component.configurator.converters.ComponentValueSetter.configure(ComponentValueSetter.java:247)\n        at org.codehaus.plexus.component.configurator.converters.composite.ObjectWithFieldsConverter.processConfiguration(ObjectWithFieldsConverter.java:137)\n        at org.codehaus.plexus.component.configurator.BasicComponentConfigurator.configureComponent(BasicComponentConfigurator.java:56)\n        at org.apache.maven.plugin.DefaultPluginManager.populatePluginFields(DefaultPluginManager.java:1033)\n        ... 19 more\nCaused by: java.lang.InstantiationException: org.apache.maven.artifact.repository.ArtifactRepository\n        at java.lang.Class.newInstance0(Class.java:335)\n        at java.lang.Class.newInstance(Class.java:303)\n        at org.codehaus.plexus.component.configurator.converters.AbstractConfigurationConverter.instantiateObject(AbstractConfigurationConverter.java:111)\n        ... 24 more\n\nError message looks like MNG-734\n\nNot sure if this setup is to be supported, but the exception is clearly not what I expected :)\n\nJust in case, I tried to place a <distributionManagement> block in both the pom.xml and the plugin/pom.xml, but that didn't help.\n\nProblem can be reproduced with the webstart-maven-plugin from the mojo-sandbox. Take it out, add a distribution section in your plugin/pom.xml and test.",
        "predictions": {},
        "comments": [
            {
                "author_name": "brettporter",
                "id": "14458878",
                "body": "current webstart doesn't seem to exhibit this with latest Maven - maybe it was a Maven bug that was fixed. Doesn't appear to be in Wagon's realm at all."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5dc7af4d395ee221aa549",
        "key": "SPARK-12082",
        "id": "12917404",
        "description": "The NettyBlockTransferSecuritySuite \"security mismatch auth off on client\" test is flaky in Jenkins. Here's a link to a report that lists the latest failures over the past week+:\n\nhttps://spark-tests.appspot.com/tests/org.apache.spark.network.netty.NettyBlockTransferSecuritySuite/security%20mismatch%20auth%20off%20on%20client#latest-failures\n\nIn all of these failures, the test failed with the following exception:\n\n{code}\nFutures timed out after [1000 milliseconds]\n\n\n      java.util.concurrent.TimeoutException: Futures timed out after [1000 milliseconds]\n      at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)\n      at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:153)\n      at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala:86)\n      at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala:86)\n      at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)\n      at scala.concurrent.Await$.ready(package.scala:86)\n      at org.apache.spark.network.netty.NettyBlockTransferSecuritySuite.fetchBlock(NettyBlockTransferSecuritySuite.scala:151)\n      at org.apache.spark.network.netty.NettyBlockTransferSecuritySuite.org$apache$spark$network$netty$NettyBlockTransferSecuritySuite$$testConnection(NettyBlockTransferSecuritySuite.scala:116)\n      at org.apache.spark.network.netty.NettyBlockTransferSecuritySuite$$anonfun$5.apply$mcV$sp(NettyBlockTransferSecuritySuite.scala:90)\n      at org.apache.spark.network.netty.NettyBlockTransferSecuritySuite$$anonfun$5.apply(NettyBlockTransferSecuritySuite.scala:84)\n      at org.apache.spark.network.netty.NettyBlockTransferSecuritySuite$$anonfun$5.apply(NettyBlockTransferSecuritySuite.scala:84)\n      at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)\n      at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)\n      at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\n      at org.scalatest.Transformer.apply(Transformer.scala:22)\n      at org.scalatest.Transformer.apply(Transformer.scala:20)\n      at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)\n      at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:42)\n      at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)\n      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)\n      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)\n      at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\n      at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)\n      at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)\n      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)\n      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)\n      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)\n      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)\n      at scala.collection.immutable.List.foreach(List.scala:318)\n      at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\n      at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)\n      at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)\n      at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)\n      at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)\n      at org.scalatest.Suite$class.run(Suite.scala:1424)\n      at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)\n      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)\n      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)\n      at org.scalatest.SuperEngine.runImpl(Engine.scala:545)\n      at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)\n      at org.scalatest.FunSuite.run(FunSuite.scala:1555)\n      at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)\n      at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)\n      at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)\n      at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n      at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)\n      at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)\n      at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)\n      at org.scalatest.Suite$class.run(Suite.scala:1421)\n      at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)\n      at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)\n      at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)\n      at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)\n      at scala.collection.immutable.List.foreach(List.scala:318)\n      at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)\n      at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)\n      at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)\n      at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)\n      at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)\n      at org.scalatest.tools.Runner$.main(Runner.scala:860)\n      at org.scalatest.tools.Runner.main(Runner.scala)\n{code}\n\n/cc [~adav]",
        "predictions": {},
        "comments": [
            {
                "author_name": "vanzin",
                "id": "15034814",
                "body": "The test is \"working\", it's just not waiting long enough...\n\n{noformat}\n15/12/01 13:09:42.045 shuffle-server-0 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() on RPC id 6025146086366897917\njava.lang.IllegalStateException: Expected SaslMessage, received something else (maybe your client does not have SASL enabled?)\n        at org.apache.spark.network.sasl.SaslMessage.decode(SaslMessage.java:69)\n        at org.apache.spark.network.sasl.SaslRpcHandler.receive(SaslRpcHandler.java:87)\n15/12/01 13:09:43.285 ScalaTest-main-running-NettyBlockTransferSecuritySuite INFO NettyBlockTransferSecuritySuite:\n\n===== FINISHED o.a.s.network.netty.NettyBlockTransferSecuritySuite: 'security mismatch auth off on client' =====\n\n15/12/01 13:09:43.300 shuffle-client-0 ERROR OneForOneBlockFetcher: Failed while starting block fetches\njava.lang.RuntimeException: java.lang.IllegalStateException: Expected SaslMessage, received something else (maybe your client does not have SASL enabled?)\n        at org.apache.spark.network.sasl.SaslMessage.decode(SaslMessage.java:69)\n        at org.apache.spark.network.sasl.SaslRpcHandler.receive(SaslRpcHandler.java:87)\n        at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:149)\n        at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:102)\n{noformat}\n\n\nIn this case it took more than 1 second (the test timeout) for the error to arrive at the client."
            },
            {
                "author_name": "joshrosen",
                "id": "15036661",
                "body": "What's slightly odd to me is the huge variability in how long this test takes to run. In [most cases|https://spark-tests.appspot.com/tests/org.apache.spark.network.netty.NettyBlockTransferSecuritySuite/security%20mismatch%20auth%20off%20on%20client], it runs in less than 30ms, and rarely in under 200ms, so I wonder what causes it to take > 1 second in those failed tests."
            },
            {
                "author_name": "vanzin",
                "id": "15036738",
                "body": "If the build machines run on VMs, run multiple jobs, or have anything else that may lead to sporadic stalls / slowness, I wouldn't be surprised when timeouts turn out to be unreliable.\n\nOur internal test machines are way more loaded than those used by Spark's jenkins, and we run into a bunch of different time outs that the Spark builds never see."
            },
            {
                "author_name": "joshrosen",
                "id": "15036743",
                "body": "For now, I'm going to try bumping the timeout to something higher, like 10 seconds, and keep an eye on the test dashboard to see if that's a sufficient fix."
            },
            {
                "author_name": "apachespark",
                "id": "15036911",
                "body": "User 'JoshRosen' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/10113"
            }
        ],
        "comments_predictions": [
            [
                673567,
                "SPARK-12082",
                "The test is \"working\", it's just not waiting long enough...\n\n{noformat}\n15/12/01 13:09:42.045 shuffle-server-0 ERROR TransportRequestHandler: Error while invoking RpcHandler#receive() on RPC id 6025146086366897917\njava.lang.IllegalStateException: Expected SaslMessage, received something else (maybe your client does not have SASL enabled?)\n        at org.apache.spark.network.sasl.SaslMessage.decode(SaslMessage.java:69)\n        at org.apache.spark.network.sasl.SaslRpcHandler.receive(SaslRpcHandler.java:87)\n15/12/01 13:09:43.285 ScalaTest-main-running-NettyBlockTransferSecuritySuite INFO NettyBlockTransferSecuritySuite:\n\n===== FINISHED o.a.s.network.netty.NettyBlockTransferSecuritySuite: 'security mismatch auth off on client' =====\n\n15/12/01 13:09:43.300 shuffle-client-0 ERROR OneForOneBlockFetcher: Failed while starting block fetches\njava.lang.RuntimeException: java.lang.IllegalStateException: Expected SaslMessage, received something else (maybe your client does not have SASL enabled?)\n        at org.apache.spark.network.sasl.SaslMessage.decode(SaslMessage.java:69)\n        at org.apache.spark.network.sasl.SaslRpcHandler.receive(SaslRpcHandler.java:87)\n        at org.apache.spark.network.server.TransportRequestHandler.processRpcRequest(TransportRequestHandler.java:149)\n        at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:102)\n{noformat}\n\n\nIn this case it took more than 1 second (the test timeout) for the error to arrive at the client.",
                {
                    "property": {
                        "confidence": 0.007146888878196478,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005872354377061129,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011289804242551327,
                        "prediction": false
                    }
                }
            ],
            [
                673568,
                "SPARK-12082",
                "What's slightly odd to me is the huge variability in how long this test takes to run. In [most cases|https://spark-tests.appspot.com/tests/org.apache.spark.network.netty.NettyBlockTransferSecuritySuite/security%20mismatch%20auth%20off%20on%20client], it runs in less than 30ms, and rarely in under 200ms, so I wonder what causes it to take > 1 second in those failed tests.",
                {
                    "property": {
                        "confidence": 0.008762683719396591,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005022162105888128,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.021791333332657814,
                        "prediction": false
                    }
                }
            ],
            [
                673569,
                "SPARK-12082",
                "If the build machines run on VMs, run multiple jobs, or have anything else that may lead to sporadic stalls / slowness, I wouldn't be surprised when timeouts turn out to be unreliable.\n\nOur internal test machines are way more loaded than those used by Spark's jenkins, and we run into a bunch of different time outs that the Spark builds never see.",
                {
                    "property": {
                        "confidence": 0.03329391032457352,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0020724486093968153,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.024979958310723305,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "64075409077d999265d7d0f1",
        "key": "GERONIMO-4572",
        "id": "12416210",
        "description": "When using JAAS and loging in from a web container one can access the HttpServletRequest like this:\nHttpServletRequest request = (HttpServletRequest) PolicyContext.getContext(\"javax.servlet.http.HttpServletRequest\"); \n\nHowever this doesn't work when using BASIC authentication on Webservices made from EJBs - the request object is null.\n\nCan this feature also be enabled for EJB based webservices.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.10192469507455826
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.03746804967522621
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004708370193839073
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d62595f4d395ee2225ae18",
        "key": "BEAM-10243",
        "id": "13310941",
        "description": "\u00a0\r\n\r\nIn the following code:\r\n{code:java}\r\npublic FieldValueBuilder withFieldValues(Map<String, Object> values) { \r\n   checkState(values.isEmpty()); \r\n   return new FieldValueBuilder(schema, null).withFieldValues(values); \r\n} \u00a0\r\n{code}\r\n\u00a0\r\n\r\ncheckState should check `this.values` instead of the passed arguments.\r\n\r\nThe issue is that as it is now, we cannot use this function to build a Row from Map.\r\n\r\n\u00a0\r\n\r\nthanks.\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008571007288992405
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008964472450315952
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006299473345279694
                }
            }
        },
        "comments": [
            {
                "author_name": "pedro.teixeira",
                "id": "17134185",
                "body": "I was going to try fix and test this method with\r\n{code:java}\r\n  public void testWithFieldValues() {\r\n    EnumerationType enumerationType = EnumerationType.create(\"zero\", \"one\", \"two\");\r\n    Schema type =\r\n        Stream.of(Schema.Field.of(\"f1_enum\", FieldType.logicalType(enumerationType)))\r\n            .collect(toSchema());\r\n    Row row =\r\n        Row.withSchema(type)\r\n            .withFieldValues(ImmutableMap.of(\"f1_enum\", enumerationType.valueOf(\"zero\")))\r\n            .build();\r\n    assertEquals(enumerationType.valueOf(0), row.getValue(0));\r\n    assertEquals(\r\n        enumerationType.valueOf(\"zero\"), row.getLogicalTypeValue(0, EnumerationType.Value.class));\r\n  }\r\n{code}\r\nbut it throws `java.lang.NullPointerException`\u00a0 at `FieldAccessNode.addOverride(RowUtils.java:280)` due to .getFieldId() returning null\r\n\r\n\u00a0"
            },
            {
                "author_name": "ibzib",
                "id": "17134514",
                "body": "Thanks for preparing a test. It looks like the exception is due to the schema not being resolved.\r\n\r\nI changed this line to {{FieldAccessDescriptor.withFieldNames(e.getKey()).resolve(getSchema()),}} and your test passed.\r\n\r\nhttps://github.com/apache/beam/blob/13411a6b546253336d862f8495ca57aa2376ac67/sdks/java/core/src/main/java/org/apache/beam/sdk/values/Row.java#L684"
            }
        ],
        "comments_predictions": [
            [
                3650307,
                "BEAM-10243",
                "I was going to try fix and test this method with\r\n{code:java}\r\n  public void testWithFieldValues() {\r\n    EnumerationType enumerationType = EnumerationType.create(\"zero\", \"one\", \"two\");\r\n    Schema type =\r\n        Stream.of(Schema.Field.of(\"f1_enum\", FieldType.logicalType(enumerationType)))\r\n            .collect(toSchema());\r\n    Row row =\r\n        Row.withSchema(type)\r\n            .withFieldValues(ImmutableMap.of(\"f1_enum\", enumerationType.valueOf(\"zero\")))\r\n            .build();\r\n    assertEquals(enumerationType.valueOf(0), row.getValue(0));\r\n    assertEquals(\r\n        enumerationType.valueOf(\"zero\"), row.getLogicalTypeValue(0, EnumerationType.Value.class));\r\n  }\r\n{code}\r\nbut it throws `java.lang.NullPointerException`\u00a0 at `FieldAccessNode.addOverride(RowUtils.java:280)` due to .getFieldId() returning null\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.0055773332715034485,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008533293381333351,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009640638716518879,
                        "prediction": false
                    }
                }
            ],
            [
                3650308,
                "BEAM-10243",
                "Thanks for preparing a test. It looks like the exception is due to the schema not being resolved.\r\n\r\nI changed this line to {{FieldAccessDescriptor.withFieldNames(e.getKey()).resolve(getSchema()),}} and your test passed.\r\n\r\nhttps://github.com/apache/beam/blob/13411a6b546253336d862f8495ca57aa2376ac67/sdks/java/core/src/main/java/org/apache/beam/sdk/values/Row.java#L684",
                {
                    "property": {
                        "confidence": 0.0038479287177324295,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.030345024541020393,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007784863002598286,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d61d07f4d395ee2224af0d",
        "key": "CB-6698",
        "id": "12714411",
        "description": "Make plugman capable of referencing an Android library project from within a plugin. \n\nCurrently there's no viable way to do it and it is becoming common to try to circumvent this limitation by abusing *plugin.xml* to (try to) merge a library's resources, code and configuration. (see https://github.com/wildabeast/BarcodeScanner)",
        "predictions": {},
        "comments": [
            {
                "author_name": "githubbot",
                "id": "14011126",
                "body": "GitHub user mbektchiev opened a pull request:\n\n    https://github.com/apache/cordova-lib/pull/21\n\n    CB-6698: Support library references for Android via the framework tag\n\n    The framework tag can be contain the following attributes:\n    \t\n    * **src** - (**required**) relative path to the directory containing the referenced library project.\n    * **custom** - (optional) specifies how to treat **src**. If **true** it is a relative path from the application project's directory, otherwise -- the Android SDK directory.\n    * **parent** - (optional) relative path to the directory containing the project to which to add the reference. The default is the application project.\n    \n    Example: A plugin that installs a library (**FeedbackLib**) which refers another library from the Android SDK (**appcompat**)\n    \n    ```xml\n    <source-file src=\"src/android/FeedbackLib\" target-dir=\"./\" />\n    \n    <framework src=\"FeedbackLib\" custom=\"true\" />\n    <framework src=\"extras/android/support/v7/appcompat\" parent=\"FeedbackLib\" />\n    ```\n    \n    \n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/Icenium/cordova-lib bektchiev/framework-tag-for-android\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/cordova-lib/pull/21.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #21\n    \n----\ncommit 0227d7bb7831ad1dfe0c6531e319bf8106256a03\nAuthor: Martin Bektchiev <martin.bektchiev@telerik.com>\nDate:   2014-05-27T11:53:19Z\n\n    CB-6698: Support library references for Android via the framework tag\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "14011207",
                "body": "Github user kamrik commented on a diff in the pull request:\n\n    https://github.com/apache/cordova-lib/pull/21#discussion_r13137628\n  \n    --- Diff: cordova-lib/src/plugman/platforms/android.js ---\n    @@ -80,10 +84,115 @@ module.exports = {\n         },\n         \"framework\": {\n             install:function(source_el, plugin_dir, project_dir, plugin_id) {\n    -            events.emit('verbose', 'framework.install is not supported for android');\n    +            var src = source_el.attrib.src;\n    +            var custom = source_el.attrib.custom;\n    +            if (!src) throw new Error('src not specified in framework element');\n    +\n    +            events.emit('verbose', \"Installing Android library: \" + src);\n    +            var parent = source_el.attrib.parent;\n    +            var parentDir = parent ? path.resolve(project_dir, parent) : project_dir;\n    +            var subDir;\n    +            if (custom) {\n    +                subDir = path.resolve(project_dir, src);\n    +            } else {\n    +                var localProperties = properties_parser.createEditor(path.resolve(project_dir, \"local.properties\"));\n    +                subDir = path.resolve(localProperties.get(\"sdk.dir\"), src);\n    +            }\n    +            var projectConfig = module.exports.parseProjectFile(project_dir);\n    +            projectConfig.addSubProject(parentDir, subDir);\n             },\n             uninstall:function(source_el, project_dir, plugin_id) {\n    -            events.emit('verbose', 'framework.uninstall is not supported for android');\n    +            var src = source_el.attrib.src;\n    +            if (!src) throw new Error('src not specified in framework element');\n    +\n    +            events.emit('verbose', \"Uninstalling Android library: \" + src);\n    +            var parent = source_el.attrib.parent;\n    +            var parentDir = parent ? path.resolve(project_dir, parent) : project_dir;\n    +            var subDir = path.resolve(project_dir, src);\n    +            var projectConfig = module.exports.parseProjectFile(project_dir);\n    +            projectConfig.removeSubProject(parentDir, subDir);\n             }\n    +    },\n    +    parseProjectFile: function(project_dir){\n    +        if (!projectFileCache[project_dir]) {\n    +            projectFileCache[project_dir] = {\n    --- End diff --\n    \n    This is an inline definition of a pretty rich object with non trivial methods. I think it will be way more readable to define a separate class like AndroidProjectFile (naming is up to you) and have this line look like this:\n    projectFileCache[project_dir] = new AndroidProjectFile(...);\n    \n    I would even define the AndroidProjectFile class in a separate js file, this way other platforms similar to Android might reuse or subclass it if they want.\n    The windows8 parser does something similar with the util/w8jsproj.js\n    \n    Otherwise LGTM.\n"
            },
            {
                "author_name": "githubbot",
                "id": "14016392",
                "body": "Github user mbektchiev commented on a diff in the pull request:\n\n    https://github.com/apache/cordova-lib/pull/21#discussion_r13329193\n  \n    --- Diff: cordova-lib/src/plugman/platforms/android.js ---\n    @@ -80,10 +84,115 @@ module.exports = {\n         },\n         \"framework\": {\n             install:function(source_el, plugin_dir, project_dir, plugin_id) {\n    -            events.emit('verbose', 'framework.install is not supported for android');\n    +            var src = source_el.attrib.src;\n    +            var custom = source_el.attrib.custom;\n    +            if (!src) throw new Error('src not specified in framework element');\n    +\n    +            events.emit('verbose', \"Installing Android library: \" + src);\n    +            var parent = source_el.attrib.parent;\n    +            var parentDir = parent ? path.resolve(project_dir, parent) : project_dir;\n    +            var subDir;\n    +            if (custom) {\n    +                subDir = path.resolve(project_dir, src);\n    +            } else {\n    +                var localProperties = properties_parser.createEditor(path.resolve(project_dir, \"local.properties\"));\n    +                subDir = path.resolve(localProperties.get(\"sdk.dir\"), src);\n    +            }\n    +            var projectConfig = module.exports.parseProjectFile(project_dir);\n    +            projectConfig.addSubProject(parentDir, subDir);\n             },\n             uninstall:function(source_el, project_dir, plugin_id) {\n    -            events.emit('verbose', 'framework.uninstall is not supported for android');\n    +            var src = source_el.attrib.src;\n    +            if (!src) throw new Error('src not specified in framework element');\n    +\n    +            events.emit('verbose', \"Uninstalling Android library: \" + src);\n    +            var parent = source_el.attrib.parent;\n    +            var parentDir = parent ? path.resolve(project_dir, parent) : project_dir;\n    +            var subDir = path.resolve(project_dir, src);\n    +            var projectConfig = module.exports.parseProjectFile(project_dir);\n    +            projectConfig.removeSubProject(parentDir, subDir);\n             }\n    +    },\n    +    parseProjectFile: function(project_dir){\n    +        if (!projectFileCache[project_dir]) {\n    +            projectFileCache[project_dir] = {\n    --- End diff --\n    \n    I totally agree! I extracted it in a separate js.\n"
            },
            {
                "author_name": "githubbot",
                "id": "14016564",
                "body": "Github user kamrik commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/21#issuecomment-44973356\n  \n    Looks good, will merge later today.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14016984",
                "body": "Commit 513967dbc8f983ebfe08ba7b96cfc4211ffd7515 in cordova-lib's branch refs/heads/master from [~mbektchiev]\n[ https://git-wip-us.apache.org/repos/asf?p=cordova-lib.git;h=513967d ]\n\nCB-6698: Support library references for Android via the framework tag\n"
            },
            {
                "author_name": "githubbot",
                "id": "14016992",
                "body": "Github user kamrik commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/21#issuecomment-45005347\n  \n    Merged, but to forgot to add the magic words for the apache robots to auto-close this pull request. @mbektchiev , could you please close it.\n    Thanks.\n    \n    The change on apache gitweb\n    https://git-wip-us.apache.org/repos/asf?p=cordova-lib.git;h=85974b0f9bac6769e3f0fe4e4a61a84f554b6e5d\n"
            },
            {
                "author_name": "githubbot",
                "id": "14017038",
                "body": "Github user purplecabbage commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/21#issuecomment-45009544\n  \n    Please also make the appropriate changes to the docs[1] and send a pull request there also.\n    \n    [1] https://github.com/apache/cordova-docs/blob/master/docs/en/edge/plugin_ref/spec.md\n\n"
            },
            {
                "author_name": "githubbot",
                "id": "14017766",
                "body": "Github user mbektchiev commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/21#issuecomment-45105399\n  \n    Thank you for merging and tipping me for the docs! I created a pull request for the docs: https://github.com/apache/cordova-docs/pull/210 and I am closing this one. \n"
            },
            {
                "author_name": "githubbot",
                "id": "14017767",
                "body": "Github user mbektchiev closed the pull request at:\n\n    https://github.com/apache/cordova-lib/pull/21\n"
            },
            {
                "author_name": "githubbot",
                "id": "14017778",
                "body": "Github user purplecabbage commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/21#issuecomment-45106692\n  \n    Thanks Martin!\n    \n    \n    > On Jun 4, 2014, at 8:27 AM, Martin Bektchiev <notifications@github.com> wrote:\n    > \n    > Closed #21.\n    > \n    > \u2014\n    > Reply to this email directly or view it on GitHub.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14020319",
                "body": "Commit 04588a42067a5ba0d303f4b69f99f44640c3b9e0 in cordova-lib's branch refs/heads/master from [~agrieve]\n[ https://git-wip-us.apache.org/repos/asf?p=cordova-lib.git;h=04588a4 ]\n\nCB-6698 Resolve android <framework> relative to plugin_dir when custom=true\n"
            },
            {
                "author_name": "githubbot",
                "id": "14030818",
                "body": "GitHub user mbektchiev opened a pull request:\n\n    https://github.com/apache/cordova-lib/pull/29\n\n    CB-6698 Automatically copy sub-libraries to project's directory\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/Icenium/cordova-lib bektchiev/auto-copy-android-libs\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/cordova-lib/pull/29.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #29\n    \n----\ncommit bb3284ca8aa65fc85fde99210dcdf68c13dc785c\nAuthor: Martin Bektchiev <martin.bektchiev@telerik.com>\nDate:   2014-06-13T15:12:02Z\n\n    Revert \"CB-6698 Resolve android <framework> relative to plugin_dir when custom=true\"\n    \n    This reverts commit 04588a42067a5ba0d303f4b69f99f44640c3b9e0.\n\ncommit d049da772107ed6fd3501e458ccc63bc3e254594\nAuthor: Martin Bektchiev <martin.bektchiev@telerik.com>\nDate:   2014-06-13T16:00:36Z\n\n    CB-6698 Automatically copy sub-libraries to project's directory\n\n----\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14033384",
                "body": "Commit 95772a1774906b5abc3dee46a19b3d7a1c2fcce5 in cordova-lib's branch refs/heads/master from [~mbektchiev]\n[ https://git-wip-us.apache.org/repos/asf?p=cordova-lib.git;h=95772a1 ]\n\nRevert \"CB-6698 Resolve android <framework> relative to plugin_dir when custom=true\"\n\nThis reverts commit 04588a42067a5ba0d303f4b69f99f44640c3b9e0.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14033385",
                "body": "Commit ffc17dd1bdc89b515cfff0a14a31f4bd0e097234 in cordova-lib's branch refs/heads/master from [~mbektchiev]\n[ https://git-wip-us.apache.org/repos/asf?p=cordova-lib.git;h=ffc17dd ]\n\nCB-6698 Automatically copy sub-libraries to project's directory\n\nGithub: close #29\n"
            },
            {
                "author_name": "githubbot",
                "id": "14033386",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/cordova-lib/pull/29\n"
            },
            {
                "author_name": "agrieve",
                "id": "14033846",
                "body": "Fixed in 0.21.4-dev"
            },
            {
                "author_name": "githubbot",
                "id": "14037567",
                "body": "GitHub user mbektchiev opened a pull request:\n\n    https://github.com/apache/cordova-lib/pull/36\n\n    CB-6698 Fix 'android update lib-project' command to work with paths containing spaces\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/Icenium/cordova-lib bektchiev/fix-android-lib-paths-with-spaces\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/cordova-lib/pull/36.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #36\n    \n----\ncommit f48e9b5d633ef212969a57053b7af1abaa71a129\nAuthor: Martin Bektchiev <martin.bektchiev@telerik.com>\nDate:   2014-06-19T17:29:15Z\n\n    CB-6698 Fix 'android update lib-project' command to work with paths containing spaces\n\n----\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14037679",
                "body": "Commit e59181b51c12ea19c4824903909fdd3bc0302b8e in cordova-lib's branch refs/heads/master from [~mbektchiev]\n[ https://git-wip-us.apache.org/repos/asf?p=cordova-lib.git;h=e59181b ]\n\nCB-6698: Fix 'android update lib-project' to work with paths containing spaces\n\ngithub: close #36\n"
            },
            {
                "author_name": "githubbot",
                "id": "14037680",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/cordova-lib/pull/36\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14046058",
                "body": "Commit 900c43ef42a3d793ef314ff3910a67f9296df0c0 in cordova-docs's branch refs/heads/master from [~mbektchiev]\n[ https://git-wip-us.apache.org/repos/asf?p=cordova-docs.git;h=900c43e ]\n\nCB-6344 CB-6698 `after` for `<config-changes>`, `<framework>` for Android\n\nclose #210\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14046059",
                "body": "Commit cfcf1de96b88cb416bab63292256afaf4542df7f in cordova-docs's branch refs/heads/master from [~agrieve]\n[ https://git-wip-us.apache.org/repos/asf?p=cordova-docs.git;h=cfcf1de ]\n\nCB-6698 Remove explicit `<source-file>` from example since `<framework>` now copies it in by default\n"
            },
            {
                "author_name": "githubbot",
                "id": "14716449",
                "body": "GitHub user mbektchiev opened a pull request:\n\n    https://github.com/apache/cordova-lib/pull/289\n\n    CB-6698 Fix directory resolution of framework with parent\n\n    Due to a refactoring after the original implementation the installation of plugins containing frameworks with parent=true were broken. \n    This pull request fixes the paths and adds two unit tests for such frameworks\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/Icenium/cordova-lib bektchiev/CB-6698\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/cordova-lib/pull/289.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #289\n    \n----\ncommit 999db66cb5b4d79b598812e279f7b69e08946464\nAuthor: Martin Bektchiev <martin.bektchiev@telerik.com>\nDate:   2015-08-27T09:44:45Z\n\n    CB-6698 Fix directory resolution of framework with parent\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "14728595",
                "body": "Github user mbektchiev commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/289#issuecomment-137356795\n  \n    @stevengill Can you please review this PR?\n"
            },
            {
                "author_name": "githubbot",
                "id": "14968312",
                "body": "Github user stevengill commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/289#issuecomment-150069617\n  \n    It looks good to me. It is essentially just fixing `parent=true`\n"
            },
            {
                "author_name": "githubbot",
                "id": "14979840",
                "body": "Github user stevengill commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/289#issuecomment-152079604\n  \n    Failing tests!\n"
            },
            {
                "author_name": "githubbot",
                "id": "14998074",
                "body": "Github user mbektchiev commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/289#issuecomment-155330596\n  \n    Rebased on latest master and now tests pass.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15028274",
                "body": "Github user mbektchiev commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/289#issuecomment-159824863\n  \n    @stevengill do you think this can be merged now?\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15042558",
                "body": "Commit bc3e973ccc18079194e9a3638d036a671b351ac8 in cordova-lib's branch refs/heads/master from [~mbektchiev]\n[ https://git-wip-us.apache.org/repos/asf?p=cordova-lib.git;h=bc3e973 ]\n\nCB-6698 Fix directory resolution of framework with parent. This closes #289\n"
            },
            {
                "author_name": "githubbot",
                "id": "15042559",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/cordova-lib/pull/289\n"
            },
            {
                "author_name": "githubbot",
                "id": "15042560",
                "body": "Github user stevengill commented on the pull request:\n\n    https://github.com/apache/cordova-lib/pull/289#issuecomment-162125224\n  \n    Merged!\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d6055df4d395ee22214db1",
        "key": "HBASE-11508",
        "id": "12727027",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02948673442006111
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0084699597209692
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.003555898554623127
                }
            }
        },
        "comments": [
            {
                "author_name": "misty",
                "id": "14061522",
                "body": "Added a section to Troubleshooting and looked through the rest of the docs to find instances of the old name and changed to the new name."
            },
            {
                "author_name": "hadoopqa",
                "id": "14061529",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12655661/HBASE-11492.patch\n  against trunk revision .\n  ATTACHMENT ID: 12655661\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-HBASE-Build/10064//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "misty",
                "id": "14075806",
                "body": "Added late-breaking additions from HBASE-11492, patch incoming and named correctly."
            },
            {
                "author_name": "hadoopqa",
                "id": "14075834",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12658049/HBASE-11508-1.patch\n  against trunk revision .\n  ATTACHMENT ID: 12658049\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100\n\n  {color:green}+1 site{color}.  The mvn site goal succeeds with this patch.\n\n     {color:red}-1 core tests{color}.  The patch failed these unit tests:\n                       org.apache.hadoop.hbase.TestRegionRebalancing\n\nTest results: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-server.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-examples.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-common.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-thrift.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-protocol.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//artifact/patchprocess/newPatchFindbugsWarningshbase-client.html\nConsole output: https://builds.apache.org/job/PreCommit-HBASE-Build/10198//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "jmhsieh",
                "id": "14089857",
                "body": "for these kinds of changes it is really helpful to say what versions the old and new.  It seems we have one set of docs for all the 0.94 line, the 0.98/10 line, and will have another for the 2.0 line -- and making this clear will prevent confusion."
            },
            {
                "author_name": "misty",
                "id": "14090214",
                "body": "Clarified version info."
            },
            {
                "author_name": "jmhsieh",
                "id": "14101347",
                "body": "thanks misty.  I've committed to branch-1 and master."
            },
            {
                "author_name": "hudson",
                "id": "14101644",
                "body": "FAILURE: Integrated in HBase-1.0 #109 (See [https://builds.apache.org/job/HBase-1.0/109/])\nHBASE-11508 Document changes to IPC config parameters from HBASE-11492 (Misty Stanley-Jones) (jmhsieh: rev 137fea8a768e31659461a2414e3ca9912fbcb1eb)\n* src/main/docbkx/troubleshooting.xml\n"
            },
            {
                "author_name": "hudson",
                "id": "14101744",
                "body": "FAILURE: Integrated in HBase-TRUNK #5408 (See [https://builds.apache.org/job/HBase-TRUNK/5408/])\nHBASE-11508 Document changes to IPC config parameters from HBASE-11492 (Misty Stanley-Jones) (jmhsieh: rev 454389a4b7e63a731c025748a3d595a168d61640)\n* src/main/docbkx/troubleshooting.xml\n"
            },
            {
                "author_name": "enis",
                "id": "14330982",
                "body": "Closing this issue after 0.99.0 release. "
            }
        ],
        "comments_predictions": [
            [
                2375415,
                "HBASE-11508",
                "for these kinds of changes it is really helpful to say what versions the old and new.  It seems we have one set of docs for all the 0.94 line, the 0.98/10 line, and will have another for the 2.0 line -- and making this clear will prevent confusion.",
                {
                    "property": {
                        "confidence": 0.005720788612961769,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005563532002270222,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.015156245790421963,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d62595f4d395ee2225b8a3",
        "key": "BEAM-7543",
        "id": "13239039",
        "description": "When combing associative commutative function directly, the translation can be done more effectively, then when we have to resort to reducing Stream.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.004015112761408091
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.014622670598328114
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.011003301478922367
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d6055df4d395ee2221541f",
        "key": "HBASE-9859",
        "id": "12676495",
        "description": "Disabling a table causes the Canary to go off with an error message.  We should make it so that doesn't cause an error.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006672232877463102
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.015148438513278961
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005115233827382326
                }
            }
        },
        "comments": [
            {
                "author_name": "eclark",
                "id": "13811699",
                "body": "Patch that changes the exception thrown from a DNRIOE to TableNotEnabledException which is a DNRIOE"
            },
            {
                "author_name": "eclark",
                "id": "13811730",
                "body": "One more log line just to help operators understand a little better."
            },
            {
                "author_name": "jdcryans",
                "id": "13811765",
                "body": "+1"
            },
            {
                "author_name": "hadoopqa",
                "id": "13811822",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12611705/HBASE-9859-1.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 hadoop1.0{color}.  The patch compiles against the hadoop 1.0 profile.\n\n    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 2 new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100\n\n    {color:red}-1 site{color}.  The patch appears to cause mvn site goal to fail.\n\n     {color:red}-1 core tests{color}.  The patch failed these unit tests:\n                       org.apache.hadoop.hbase.security.access.TestNamespaceCommands\n\nTest results: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-thrift.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html\nConsole output: https://builds.apache.org/job/PreCommit-HBASE-Build/7707//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "eclark",
                "id": "13813453",
                "body": "Thanks for the review."
            },
            {
                "author_name": "hudson",
                "id": "13813744",
                "body": "SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #826 (See [https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/826/])\nHBASE-9859 Canary Shouldn't go off if the table being read from is disabled (eclark: rev 1538842)\n* /hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java\n* /hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13813755",
                "body": "FAILURE: Integrated in hbase-0.96-hadoop2 #113 (See [https://builds.apache.org/job/hbase-0.96-hadoop2/113/])\nHBASE-9859 Canary Shouldn't go off if the table being read from is disabled (eclark: rev 1538843)\n* /hbase/branches/0.96/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java\n* /hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13813842",
                "body": "SUCCESS: Integrated in hbase-0.96 #180 (See [https://builds.apache.org/job/hbase-0.96/180/])\nHBASE-9859 Canary Shouldn't go off if the table being read from is disabled (eclark: rev 1538843)\n* /hbase/branches/0.96/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java\n* /hbase/branches/0.96/hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13813851",
                "body": "SUCCESS: Integrated in HBase-TRUNK #4668 (See [https://builds.apache.org/job/HBase-TRUNK/4668/])\nHBASE-9859 Canary Shouldn't go off if the table being read from is disabled (eclark: rev 1538842)\n* /hbase/trunk/hbase-client/src/main/java/org/apache/hadoop/hbase/client/HConnectionManager.java\n* /hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/tool/Canary.java\n"
            },
            {
                "author_name": "stack",
                "id": "13849473",
                "body": "Released in 0.96.1.  Issue closed."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5eccef4d395ee221db478",
        "key": "MINVOKER-129",
        "id": "12803694",
        "description": "Found some stuff in the code that can be cleaned up. Unused imports and also some Java 5-related casts.",
        "predictions": {},
        "comments": [
            {
                "author_name": "olamy",
                "id": "14437363",
                "body": "fixed r1326204\nThanks!"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640744b14395ab3e3e33ba28",
        "key": "BEAM-14056",
        "id": "13432441",
        "description": "The [Java quickstart|https://beam.apache.org/get-started/quickstart-java/] should show how to create and run Gradle builds for all runners.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.09952443093061447
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01634831540286541
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.003206853289157152
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e4cdf4d395ee221c3817",
        "key": "PHOENIX-1014",
        "id": "12717635",
        "description": "On http://phoenix.incubator.apache.org/ , in the \"Salting\" section, there is a hyperlink on the word \"here\" in \"along with a nice comparison on write throughput between salted and unsalted tables here\".\nThis link leads to a 404 error page because the link is to \"performance.htm\" instead of \"performance.html\"",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.07254383713006973
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.004201060626655817
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008647182025015354
                }
            }
        },
        "comments": [
            {
                "author_name": "gabriel.reid",
                "id": "14017131",
                "body": "Fixed (although not yet published while waiting on necessary updates in the move to a TLP). Thanks for pointing this out [~cvrebert]!"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f46cf4d395ee221ede69",
        "key": "KAFKA-13248",
        "id": "13397991",
        "description": "I have noticed a mismatch with the class name passed to the LoggerFactory.getLogger method. This would make it hard to track the source of log messages.\r\n\r\npublic class {color:#00875a}TimeOrderedWindowStoreBuilder{color}<K, V> extends AbstractStoreBuilder<K, V, WindowStore<K, V>> {\r\n private final Logger log = LoggerFactory.getLogger({color:#de350b}WindowStoreBuilder{color}.class);\r\n\r\nprivate final WindowBytesStoreSupplier storeSupplier;\r\n\r\npublic {color:#00875a}TimeOrderedWindowStoreBuilder{color}(final WindowBytesStoreSupplier storeSupplier,\r\n final Serde<K> keySerde,",
        "predictions": {},
        "comments": [
            {
                "author_name": "ableegoldman",
                "id": "17406991",
                "body": "Nice find, thanks for the report \u2013 would you be interested in submitting a patch for this?"
            },
            {
                "author_name": "sider-bughunter",
                "id": "17407070",
                "body": "I would love to. I already have changed the code on my forked repository. Can I create the PR?\r\nhttps://github.com/sider-bughunter/kafka/commit/fbca00c7656378b6dc43320fc9ce4d3d83b58b4a"
            },
            {
                "author_name": "guozhang",
                "id": "17411347",
                "body": "[~sider-bughunter] Thanks for the find. I'm currently working on KAFKA-13216 in which I've used a kv-store instead of a window store, and hence I've renamed the whole class as well. Do you mind if I just incorporate your findings in the other PR?"
            },
            {
                "author_name": "sider-bughunter",
                "id": "17411631",
                "body": "No. Go right ahead. Thank you for your handling my findings swiftly."
            }
        ],
        "comments_predictions": [
            [
                1632179,
                "KAFKA-13248",
                "[~sider-bughunter] Thanks for the find. I'm currently working on KAFKA-13216 in which I've used a kv-store instead of a window store, and hence I've renamed the whole class as well. Do you mind if I just incorporate your findings in the other PR?",
                {
                    "property": {
                        "confidence": 0.0032880001235753298,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01665814220905304,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01365943718701601,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d61297f4d395ee222328da",
        "key": "FLEX-12349",
        "id": "12573222",
        "description": "I am using the latest SDK (build 3.0.1179146) and it seems like the data binding feature does not work in all cases\n\nExample:\n\n<mx:FormItem label=\"Label\" direction=\"horizontal\">\n    <mx:TextInput id=\"filename\" editable=\"false\" />\n     <mx:Button label=\"Upload\"\n         enabled=\"{filename.text != ''}\" />\n</mx:FormItem>\n\nFor this code I get this warning: Severity and Description\tPath\tResource\n\tLocation\tCreation Time\tId\nData binding will not be able to detect assignments to \"filename\".\n\tPROJECT/src/thepacakge/view\n\tAView.mxml\tline 178\t1188467481932\t27703\n\nAnother example is\n\n[Bindable]\npublic var someInt:int;\n\nwhen I bind \"someInt\" within MXML I get same warning and the binding does not work.\nAnyway this does only happen for some variables but I could not see any difference with other bindings.\n\n Actual Results:\nWarning that data binding is not possible\n \n Expected Results:\ndata binding should work\n \n \n Workaround (if any):",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13333199",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-12483\nOriginal Reporter: srohde\nOriginal Resolution: Cannot Reproduce\nConfirmed Version: 10290\nConfirmed Version: Next Build\nDiscoverability: High\nNumber of votes: 0\nRegression: Yes\nReproducibility: Intermittent\nResolved by: preilly\nSeverity: Data Loss/Corruption\nreporter: srohde"
            },
            {
                "author_name": "adobejira",
                "id": "13333200",
                "body": "created: 2007-08-31 04:24:16.000\nresolved: 2007-11-28 09:06:48.607\nupdated: 2011-04-29 10:37:44.000"
            },
            {
                "author_name": "adobejira",
                "id": "13333201",
                "body": "On 2007-09-14 06:31:00.726 srohde commented:\nI tried the latest build and now it works so please close the bug.\nThanks,\nS\u00f6nke\nOn 2007-11-01 11:17:04.559 lmcliste commented:\nyup, utr for me in 186287\nOn 2007-11-05 09:00:56.267 gauravj commented:\nTried again. Still UTR. Please submit a test case.\nOn 2007-11-13 12:04:27.169 gauravj commented:\nI was able to reproduce it once. I am not able to reproduce it after that. Definitely something worth investigating. Soenke gets these warning every 10-15 minutes. The generated source also looks similar between a clean build and incremental with warnings.\nOn 2007-11-13 15:04:29.308 laupark commented:\nInvestigate.\nOn 2007-11-26 11:07:40.155 laupark commented:\nOpened.\nOn 2007-11-28 06:38:11.481 preilly commented:\nI have this fixed locally.  I'm waiting on Pete to test a cyclone mxmlc.jar that I sent him.\nOn 2007-11-28 09:06:48.835 preilly commented:\nThis should be fixed by change 189127.\nOn 2007-11-30 13:51:06.386 laupark commented:\nre-assigned to Kristen\nOn 2007-12-03 01:37:45.683 krsindac commented:\nConfirmed fix using FB plugin build 189434 with SDK 189154. \nTested using the project where original bug was reproduced."
            }
        ],
        "comments_predictions": [
            [
                3024792,
                "FLEX-12349",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-12483\nOriginal Reporter: srohde\nOriginal Resolution: Cannot Reproduce\nConfirmed Version: 10290\nConfirmed Version: Next Build\nDiscoverability: High\nNumber of votes: 0\nRegression: Yes\nReproducibility: Intermittent\nResolved by: preilly\nSeverity: Data Loss/Corruption\nreporter: srohde",
                {
                    "property": {
                        "confidence": 0.0036321606021374464,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.04175638034939766,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014499048702418804,
                        "prediction": false
                    }
                }
            ],
            [
                3024794,
                "FLEX-12349",
                "On 2007-09-14 06:31:00.726 srohde commented:\nI tried the latest build and now it works so please close the bug.\nThanks,\nS\u00f6nke\nOn 2007-11-01 11:17:04.559 lmcliste commented:\nyup, utr for me in 186287\nOn 2007-11-05 09:00:56.267 gauravj commented:\nTried again. Still UTR. Please submit a test case.\nOn 2007-11-13 12:04:27.169 gauravj commented:\nI was able to reproduce it once. I am not able to reproduce it after that. Definitely something worth investigating. Soenke gets these warning every 10-15 minutes. The generated source also looks similar between a clean build and incremental with warnings.\nOn 2007-11-13 15:04:29.308 laupark commented:\nInvestigate.\nOn 2007-11-26 11:07:40.155 laupark commented:\nOpened.\nOn 2007-11-28 06:38:11.481 preilly commented:\nI have this fixed locally.  I'm waiting on Pete to test a cyclone mxmlc.jar that I sent him.\nOn 2007-11-28 09:06:48.835 preilly commented:\nThis should be fixed by change 189127.\nOn 2007-11-30 13:51:06.386 laupark commented:\nre-assigned to Kristen\nOn 2007-12-03 01:37:45.683 krsindac commented:\nConfirmed fix using FB plugin build 189434 with SDK 189154. \nTested using the project where original bug was reproduced.",
                {
                    "property": {
                        "confidence": 0.0037306533195078373,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.02975917048752308,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008786377497017384,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640743b58b22ceafe0d2b035",
        "key": "SPARK-20166",
        "id": "13060549",
        "description": "We can use {{XXX}} format instead of {{ZZ}}. {{ZZ}} seems a {{FastDateFormat}} specific Please see https://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html#iso8601timezone and https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/time/FastDateFormat.html\n\n{{ZZ}} supports \"ISO 8601 extended format time zones\" but it seems {{FastDateFormat}} specific option.\n\nIt seems we better replace {{ZZ}} to {{XXX}} because they look use the same strategy - https://github.com/apache/commons-lang/blob/8767cd4f1a6af07093c1e6c422dae8e574be7e5e/src/main/java/org/apache/commons/lang3/time/FastDateParser.java#L930. \n\nI also checked the codes and manually debugged it for sure. It seems both cases use the same pattern {code}( Z|(?:[+-]\\\\d{2}(?::)\\\\d{2})) {code}.\n\nNote that this is a fix about documentation not the behaviour change because {{ZZ}} seems invalid date format in {{SimpleDateFormat}} as documented in {{DataFrameReader}}:\n\n{quote}\n   * <li>`timestampFormat` (default `yyyy-MM-dd'T'HH:mm:ss.SSSZZ`): sets the string that\n   * indicates a timestamp format. Custom date formats follow the formats at\n   * `java.text.SimpleDateFormat`. This applies to timestamp type.</li>\n{quote}\n\n\n{code}\nscala> new java.text.SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\").parse(\"2017-03-21T00:00:00.000-11:00\")\nres4: java.util.Date = Tue Mar 21 20:00:00 KST 2017\n\nscala>  new java.text.SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\").parse(\"2017-03-21T00:00:00.000Z\")\nres10: java.util.Date = Tue Mar 21 09:00:00 KST 2017\n\nscala> new java.text.SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSSZZ\").parse(\"2017-03-21T00:00:00.000-11:00\")\njava.text.ParseException: Unparseable date: \"2017-03-21T00:00:00.000-11:00\"\n  at java.text.DateFormat.parse(DateFormat.java:366)\n  ... 48 elided\nscala>  new java.text.SimpleDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSSZZ\").parse(\"2017-03-21T00:00:00.000Z\")\njava.text.ParseException: Unparseable date: \"2017-03-21T00:00:00.000Z\"\n  at java.text.DateFormat.parse(DateFormat.java:366)\n  ... 48 elided\n{code}\n\n{code}\nscala> org.apache.commons.lang3.time.FastDateFormat.getInstance(\"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\").parse(\"2017-03-21T00:00:00.000-11:00\")\nres7: java.util.Date = Tue Mar 21 20:00:00 KST 2017\n\nscala> org.apache.commons.lang3.time.FastDateFormat.getInstance(\"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\").parse(\"2017-03-21T00:00:00.000Z\")\nres1: java.util.Date = Tue Mar 21 09:00:00 KST 2017\n\nscala> org.apache.commons.lang3.time.FastDateFormat.getInstance(\"yyyy-MM-dd'T'HH:mm:ss.SSSZZ\").parse(\"2017-03-21T00:00:00.000-11:00\")\nres8: java.util.Date = Tue Mar 21 20:00:00 KST 2017\n\nscala> org.apache.commons.lang3.time.FastDateFormat.getInstance(\"yyyy-MM-dd'T'HH:mm:ss.SSSZZ\").parse(\"2017-03-21T00:00:00.000Z\")\nres2: java.util.Date = Tue Mar 21 09:00:00 KST 2017\n{code}",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d61e22f4d395ee2224d661",
        "key": "CASSANDRA-16399",
        "id": "13353921",
        "description": "It looks like there are two problems:\r\n - collection of tests to run fails when there are log messages in stderr\r\n - collection of resource intensive tests (with\r\n{code:java}\r\n--only-resource-intensive-tests{code}\r\n) is broken\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0050807432271540165
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01224703062325716
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007611836306750774
                }
            }
        },
        "comments": [
            {
                "author_name": "mck",
                "id": "17269981",
                "body": "CI\r\n - pipeline :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/317/\r\n - dtest-upgrade :: https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-dtest-upgrade/15/"
            },
            {
                "author_name": "mck",
                "id": "17270119",
                "body": "CI looks good. \r\n\r\nHere you can see the disitribution of tests among the splits more balanced than previous runs:\r\n https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-dtest-large/84/testReport/"
            },
            {
                "author_name": "jlewandowski",
                "id": "17270589",
                "body": "Summary:\r\n\r\n\u00a0\r\n\r\nThis patch fixes behaviour for both {{run_dtests.py}}\u00a0and {{pytest}}.\r\n\r\nIn particular:\r\n- Error handling for invalid parameter values / combinations is in a single place ({{dtest_config.py}}) and is executed before we actually traverse through the tests\r\n- We exit with just a clean error message instead of tons of spam\r\n- {{run_dtests.sh}}\u00a0will not loose the exit code of {{pytest}}\u00a0any more so we can clearly detect when test cases collection fails\r\n- removed a bit of boilerplate code from {{run_dtests.py}}\u00a0- in particular what it did with xml processing is simply provided with {{-q}}\u00a0argument of {{pytest}}\r\n- tests filtering has been refactored to be cleaner\r\n- fixed filtering of resource intensive tests\r\n\r\nNote that now {{run_dtests.py}}\u00a0seems to be redundant. If we need it only for listing dtests, we can simply achieve exactly the same effect using {{\\-\\-collect-only -q \\-\\-ignore=meta_tests}}\u00a0arguments for {{pytest}}\u00a0instead of {{\\-\\-dtest-print-tests-only}}, plus we need to filter output with {{grep '.py::'}}\u00a0(in order to not include the summary line) and pipe stdout to the target file. Anyway I simplified {{run_dtests.sh}}\u00a0so that it just use {{pytest}}\u00a0with those arguments.\r\n\r\nRegarding Cassandra CI, I suppose most of the configurations will benefit with this fix:\r\n - {{no-vnodes}}, {{vnodes}}, {{off-heap-memtables}}\u00a0- previously included resource intensive tests although it was specified to skip them in the build script\r\n - {{large}}\u00a0- instead of listing just resource intensive tests it listed all tests\r\n\r\nSome examples of error handling now vs before:\r\n * before:\r\n\r\n{noformat}\r\n$ ./run_dtests.py --dtest-print-tests-only\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<Modules>\r\n      </Instance>\r\n    </Class>\r\n  </Module>\r\n</Modules>\r\n\r\n$ pytest --collect-only\r\n==================================================== test session starts =====================================================\r\nplatform darwin -- Python 3.9.1, pytest-3.6.4, py-1.10.0, pluggy-0.7.1\r\nrootdir: /Users/jlewandowski/dev/datastax/cassandra-dtest/trunk, inifile: pytest.ini\r\nplugins: timeout-1.4.2, flaky-3.7.0\r\ntimeout: 900.0s\r\ntimeout method: signal\r\ntimeout func_only: False\r\ncollecting 0 items / 1 errors                                                                                                INTERNALERROR> Traceback (most recent call last):\r\nINTERNALERROR>   File \"/Users/jlewandowski/dev/datastax/cassandra-dtest/trunk/venv/lib/python3.9/site-packages/_pytest/main.py\", line 178, in wrap_session\r\nINTERNALERROR>     session.exitstatus = doit(config, session) or 0\r\n...\r\nINTERNALERROR> FileNotFoundError: [Errno 2] No such file or directory: 'build.xml'================================================== 1 error in 0.18 seconds ===================================================\r\n\r\n$ ./run_dtests.py --cassandra-dir=../../cassandra/ds-trunk --dtest-print-tests-only --only-resource-intensive-tests --skip-resource-intensive-tests\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<Modules>\r\n  <Module name=\"auditlog_test.py\">\r\n...\r\nauth_test.py::TestAuthUnavailable::test_permission_cache_background_reload_handle_unavailable\r\nauth_test.py::TestNetworkAuth::test_full_dc_access\r\nauth_test.py::TestNetworkAuth::test_single_dc_access\r\n...\r\n(no error)\r\n{noformat}\r\n\r\n * now:\r\n\r\n{noformat}\r\n $ ./run_dtests.py --dtest-print-tests-only\r\nERROR: Required dtest arguments were missing! You must provide either --cassandra-dir or --cassandra-version. You can also set 'cassandra_dir' in pytest.ini. Refer to the documentation or invoke the help with --help.\r\n\r\n$ pytest --collect-only\r\nERROR: Required dtest arguments were missing! You must provide either --cassandra-dir or --cassandra-version. You can also set 'cassandra_dir' in pytest.ini. Refer to the documentation or invoke the help with --help.\r\n\r\n$ ./run_dtests.py --cassandra-dir=../../cassandra/ds-trunk --dtest-print-tests-only --only-resource-intensive-tests --skip-resource-intensive-tests\r\nERROR: --skip-resource-intensive-tests does not make any sense with either --only-resource-intensive-tests or --force-resource-intensive-tests.\r\n\r\n$ pytest --cassandra-dir=../../cassandra/ds-trunk --collect-only --only-resource-intensive-tests --skip-resource-intensive-tests\r\nERROR: --skip-resource-intensive-tests does not make any sense with either --only-resource-intensive-tests or --force-resource-intensive-tests.\r\n{noformat}"
            },
            {
                "author_name": "mck",
                "id": "17270626",
                "body": "CI runs off [jacek-lewandowski/cassandra-dtest:b4fc4f07c2cc4c2779250f672bc09d9403647bb1|https://github.com/jacek-lewandowski/cassandra-dtest/commit/b4fc4f07c2cc4c2779250f672bc09d9403647bb1]\r\n- cassandra-2.2 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/319/pipeline\r\n- cassandra-3.0 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/320/pipeline\r\n- cassandra-3.11 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/321/pipeline\r\n- trunk :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/322/pipeline"
            },
            {
                "author_name": "tomasz.lasica",
                "id": "17272334",
                "body": "Code LGTM."
            },
            {
                "author_name": "mck",
                "id": "17273497",
                "body": "+1 (most of the review communication has happened in the PR)"
            },
            {
                "author_name": "mck",
                "id": "17273498",
                "body": "PR was https://github.com/apache/cassandra-dtest/pull/115\r\n\r\n"
            }
        ],
        "comments_predictions": [
            [
                3421438,
                "CASSANDRA-16399",
                "CI\r\n - pipeline :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/317/\r\n - dtest-upgrade :: https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-dtest-upgrade/15/",
                {
                    "property": {
                        "confidence": 0.004024924244731665,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.013234623707830906,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03401724249124527,
                        "prediction": false
                    }
                }
            ],
            [
                3421439,
                "CASSANDRA-16399",
                "CI looks good. \r\n\r\nHere you can see the disitribution of tests among the splits more balanced than previous runs:\r\n https://ci-cassandra.apache.org/view/patches/job/Cassandra-devbranch-dtest-large/84/testReport/",
                {
                    "property": {
                        "confidence": 0.005796230863779783,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.028707323595881462,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006074754986912012,
                        "prediction": false
                    }
                }
            ],
            [
                3421440,
                "CASSANDRA-16399",
                "Summary:\r\n\r\n\u00a0\r\n\r\nThis patch fixes behaviour for both {{run_dtests.py}}\u00a0and {{pytest}}.\r\n\r\nIn particular:\r\n- Error handling for invalid parameter values / combinations is in a single place ({{dtest_config.py}}) and is executed before we actually traverse through the tests\r\n- We exit with just a clean error message instead of tons of spam\r\n- {{run_dtests.sh}}\u00a0will not loose the exit code of {{pytest}}\u00a0any more so we can clearly detect when test cases collection fails\r\n- removed a bit of boilerplate code from {{run_dtests.py}}\u00a0- in particular what it did with xml processing is simply provided with {{-q}}\u00a0argument of {{pytest}}\r\n- tests filtering has been refactored to be cleaner\r\n- fixed filtering of resource intensive tests\r\n\r\nNote that now {{run_dtests.py}}\u00a0seems to be redundant. If we need it only for listing dtests, we can simply achieve exactly the same effect using {{\\-\\-collect-only -q \\-\\-ignore=meta_tests}}\u00a0arguments for {{pytest}}\u00a0instead of {{\\-\\-dtest-print-tests-only}}, plus we need to filter output with {{grep '.py::'}}\u00a0(in order to not include the summary line) and pipe stdout to the target file. Anyway I simplified {{run_dtests.sh}}\u00a0so that it just use {{pytest}}\u00a0with those arguments.\r\n\r\nRegarding Cassandra CI, I suppose most of the configurations will benefit with this fix:\r\n - {{no-vnodes}}, {{vnodes}}, {{off-heap-memtables}}\u00a0- previously included resource intensive tests although it was specified to skip them in the build script\r\n - {{large}}\u00a0- instead of listing just resource intensive tests it listed all tests\r\n\r\nSome examples of error handling now vs before:\r\n * before:\r\n\r\n{noformat}\r\n$ ./run_dtests.py --dtest-print-tests-only\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<Modules>\r\n      </Instance>\r\n    </Class>\r\n  </Module>\r\n</Modules>\r\n\r\n$ pytest --collect-only\r\n==================================================== test session starts =====================================================\r\nplatform darwin -- Python 3.9.1, pytest-3.6.4, py-1.10.0, pluggy-0.7.1\r\nrootdir: /Users/jlewandowski/dev/datastax/cassandra-dtest/trunk, inifile: pytest.ini\r\nplugins: timeout-1.4.2, flaky-3.7.0\r\ntimeout: 900.0s\r\ntimeout method: signal\r\ntimeout func_only: False\r\ncollecting 0 items / 1 errors                                                                                                INTERNALERROR> Traceback (most recent call last):\r\nINTERNALERROR>   File \"/Users/jlewandowski/dev/datastax/cassandra-dtest/trunk/venv/lib/python3.9/site-packages/_pytest/main.py\", line 178, in wrap_session\r\nINTERNALERROR>     session.exitstatus = doit(config, session) or 0\r\n...\r\nINTERNALERROR> FileNotFoundError: [Errno 2] No such file or directory: 'build.xml'================================================== 1 error in 0.18 seconds ===================================================\r\n\r\n$ ./run_dtests.py --cassandra-dir=../../cassandra/ds-trunk --dtest-print-tests-only --only-resource-intensive-tests --skip-resource-intensive-tests\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<Modules>\r\n  <Module name=\"auditlog_test.py\">\r\n...\r\nauth_test.py::TestAuthUnavailable::test_permission_cache_background_reload_handle_unavailable\r\nauth_test.py::TestNetworkAuth::test_full_dc_access\r\nauth_test.py::TestNetworkAuth::test_single_dc_access\r\n...\r\n(no error)\r\n{noformat}\r\n\r\n * now:\r\n\r\n{noformat}\r\n $ ./run_dtests.py --dtest-print-tests-only\r\nERROR: Required dtest arguments were missing! You must provide either --cassandra-dir or --cassandra-version. You can also set 'cassandra_dir' in pytest.ini. Refer to the documentation or invoke the help with --help.\r\n\r\n$ pytest --collect-only\r\nERROR: Required dtest arguments were missing! You must provide either --cassandra-dir or --cassandra-version. You can also set 'cassandra_dir' in pytest.ini. Refer to the documentation or invoke the help with --help.\r\n\r\n$ ./run_dtests.py --cassandra-dir=../../cassandra/ds-trunk --dtest-print-tests-only --only-resource-intensive-tests --skip-resource-intensive-tests\r\nERROR: --skip-resource-intensive-tests does not make any sense with either --only-resource-intensive-tests or --force-resource-intensive-tests.\r\n\r\n$ pytest --cassandra-dir=../../cassandra/ds-trunk --collect-only --only-resource-intensive-tests --skip-resource-intensive-tests\r\nERROR: --skip-resource-intensive-tests does not make any sense with either --only-resource-intensive-tests or --force-resource-intensive-tests.\r\n{noformat}",
                {
                    "property": {
                        "confidence": 0.005094605032354593,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005744445603340864,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03057897835969925,
                        "prediction": false
                    }
                }
            ],
            [
                3421441,
                "CASSANDRA-16399",
                "CI runs off [jacek-lewandowski/cassandra-dtest:b4fc4f07c2cc4c2779250f672bc09d9403647bb1|https://github.com/jacek-lewandowski/cassandra-dtest/commit/b4fc4f07c2cc4c2779250f672bc09d9403647bb1]\r\n- cassandra-2.2 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/319/pipeline\r\n- cassandra-3.0 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/320/pipeline\r\n- cassandra-3.11 :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/321/pipeline\r\n- trunk :: https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/322/pipeline",
                {
                    "property": {
                        "confidence": 0.006483389995992184,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.015967052429914474,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02887960523366928,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640754b66f0281e31e3338ec",
        "key": "SOLR-1318",
        "id": "12431898",
        "description": "explain() functions may use top-level readers, causing bloated memory for anything caching.  related to LUCENE-1771 and LUCENE-1749",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.034319017082452774
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.1496012806892395
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.013491084799170494
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d601cbf4d395ee2220c81c",
        "key": "HDFS-13172",
        "id": "13139582",
        "description": "This Jira proposes to add a Taskmanager in SnapshotManager. The TaskManager will maintain a TaskQueue. Each task in the task queue will handle creation of multiple levels of a node or or balancing of the list in case of deletion of\u00a0 a node in the SnapshotSkipList.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012247982434928417
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.8709082007408142
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.02232109010219574
                }
            }
        },
        "comments": [
            {
                "author_name": "shashikant",
                "id": "16440649",
                "body": "Inline deletion of multilevel nodes in snapshotSkipList is quite fast. Moreover, async deletion of multilevel nodes from snapshotSkipList containing snapshotDiffs leads to complicated scenarios of maintaining quota consistency semantics in HDFS. It won't be done for now.\u00a0"
            }
        ],
        "comments_predictions": [
            [
                2077095,
                "HDFS-13172",
                "Inline deletion of multilevel nodes in snapshotSkipList is quite fast. Moreover, async deletion of multilevel nodes from snapshotSkipList containing snapshotDiffs leads to complicated scenarios of maintaining quota consistency semantics in HDFS. It won't be done for now.\u00a0",
                {
                    "property": {
                        "confidence": 0.029568728059530258,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002455223584547639,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.017919886857271194,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640744b1aa1c3d637833ba50",
        "key": "ANY23-566",
        "id": "13426770",
        "description": "https://github.com/apache/any23/pull/258",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e595f4d395ee221c6516",
        "key": "OPENNLP-1124",
        "id": "13098247",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.06124155968427658
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007665758952498436
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004317013546824455
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16145289",
                "body": "wcolen opened a new pull request #257: OPENNLP-1124: Optimize XML Parser configuration\nURL: https://github.com/apache/opennlp/pull/257\n \n \n   Thank you for contributing to Apache OpenNLP.\n   \n   In order to streamline the review of the contribution we ask you\n   to ensure the following steps have been taken:\n   \n   ### For all changes:\n   - [X] Is there a JIRA ticket associated with this PR? Is it referenced \n        in the commit message?\n   \n   - [X] Does your PR title start with OPENNLP-XXXX where XXXX is the JIRA number you are trying to resolve? Pay particular attention to the hyphen \"-\" character.\n   \n   - [X] Has your PR been rebased against the latest commit within the target branch (typically master)?\n   \n   - [X] Is your initial contribution a single, squashed commit?\n   \n   ### For code changes:\n   - [X] Have you ensured that the full suite of tests is executed via mvn clean install at the root opennlp folder?\n   - [X] Have you written or updated unit tests to verify your changes?\n   - [] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? \n   - [ ] If applicable, have you updated the LICENSE file, including the main LICENSE file in opennlp folder?\n   - [ ] If applicable, have you updated the NOTICE file, including the main NOTICE file found in opennlp folder?\n   \n   ### For documentation related changes:\n   - [ ] Have you ensured that format looks appropriate for the output in which it is rendered?\n   \n   ### Note:\n   Please ensure that once the PR is submitted, you check travis-ci for build issues and submit an update to your PR as soon as possible.\n   \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16145329",
                "body": "kottmann opened a new pull request #258: OPENNLP-1124: Optimize XML parser configuration\nURL: https://github.com/apache/opennlp/pull/258\n \n \n   Thank you for contributing to Apache OpenNLP.\n   \n   In order to streamline the review of the contribution we ask you\n   to ensure the following steps have been taken:\n   \n   ### For all changes:\n   - [ ] Is there a JIRA ticket associated with this PR? Is it referenced \n        in the commit message?\n   \n   - [ ] Does your PR title start with OPENNLP-XXXX where XXXX is the JIRA number you are trying to resolve? Pay particular attention to the hyphen \"-\" character.\n   \n   - [ ] Has your PR been rebased against the latest commit within the target branch (typically master)?\n   \n   - [ ] Is your initial contribution a single, squashed commit?\n   \n   ### For code changes:\n   - [ ] Have you ensured that the full suite of tests is executed via mvn clean install at the root opennlp folder?\n   - [ ] Have you written or updated unit tests to verify your changes?\n   - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)? \n   - [ ] If applicable, have you updated the LICENSE file, including the main LICENSE file in opennlp folder?\n   - [ ] If applicable, have you updated the NOTICE file, including the main NOTICE file found in opennlp folder?\n   \n   ### For documentation related changes:\n   - [ ] Have you ensured that format looks appropriate for the output in which it is rendered?\n   \n   ### Note:\n   Please ensure that once the PR is submitted, you check travis-ci for build issues and submit an update to your PR as soon as possible.\n   \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16146360",
                "body": "wcolen commented on issue #257: OPENNLP-1124: Optimize XML Parser configuration\nURL: https://github.com/apache/opennlp/pull/257#issuecomment-325837021\n \n \n   PR duplicated. Closing this one.\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16146361",
                "body": "wcolen closed pull request #257: OPENNLP-1124: Optimize XML Parser configuration\nURL: https://github.com/apache/opennlp/pull/257\n \n \n   \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16146422",
                "body": "smarthi commented on a change in pull request #258: OPENNLP-1124: Optimize XML parser configuration\nURL: https://github.com/apache/opennlp/pull/258#discussion_r135948080\n \n \n\n ##########\n File path: opennlp-tools/src/main/java/opennlp/tools/util/XmlUtil.java\n ##########\n @@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package opennlp.tools.util;\n+\n+import javax.xml.XMLConstants;\n+import javax.xml.parsers.DocumentBuilder;\n+import javax.xml.parsers.DocumentBuilderFactory;\n+import javax.xml.parsers.ParserConfigurationException;\n+import javax.xml.parsers.SAXParser;\n+import javax.xml.parsers.SAXParserFactory;\n+\n+import org.xml.sax.SAXException;\n+\n+public class XmlUtil {\n+\n+  /**\n+   * Create a new DocumentBuilder which processes XML securely.\n+   *\n+   * @return a DocumentBuilder\n+   */\n+  public static DocumentBuilder createDocumentBuilder() {\n+    try {\n+      DocumentBuilderFactory documentBuilderFacoty = DocumentBuilderFactory.newInstance();\n \n Review comment:\n   spelling typo\n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16148660",
                "body": "kottmann closed pull request #258: OPENNLP-1124: Optimize XML parser configuration\nURL: https://github.com/apache/opennlp/pull/258\n \n \n   \n \n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d6055df4d395ee22215965",
        "key": "HBASE-8488",
        "id": "12645915",
        "description": "Here is a snippet of the errors seen when building against Hbase....\n{code}\n[WARNING] Invalid POM for org.apache.hbase:hbase-common:jar:0.97.0-SNAPSHOT, transitive dependencies (if any) will not be available, enable debug logging for more details: Some problems were encountered while processing the POMs:\n[ERROR] 'dependencyManagement.dependencies.dependency.artifactId' for org.apache.hbase:${compat.module}:jar with value '${compat.module}' does not match a valid id pattern. @ org.apache.hbase:hbase:0.97.0-SNAPSHOT, /Users/rnaik/.m2/repository/org/apache/hbase/hbase/0.97.0-SNAPSHOT/hbase-0.97.0-SNAPSHOT.pom, line 982, column 21\n[ERROR] 'dependencyManagement.dependencies.dependency.artifactId' for org.apache.hbase:${compat.module}:test-jar with value '${compat.module}' does not match a valid id pattern. @ org.apache.hbase:hbase:0.97.0-SNAPSHOT, /Users/rnaik/.m2/repository/org/apache/hbase/hbase/0.97.0-SNAPSHOT/hbase-0.97.0-SNAPSHOT.pom, line 987, column 21\n{code}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.03103526309132576
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006819567177444696
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0043489099480211735
                }
            }
        },
        "comments": [
            {
                "author_name": "roshan_naik",
                "id": "13648139",
                "body": "The problem initially appears to be indicate that ${compat.module} property is not defined .. although it actually is (inside the hadoop 1/2 profiles in parent pom). But these are unfortunately not visible when building apps that depend on hbase."
            },
            {
                "author_name": "stack",
                "id": "13648184",
                "body": "If you define it on the command line when building, will that work?\n\nHow are you refering to hbase in your pom?  Are you trying to build against the SNAPSHOTS for hadoop1 and hadoop2?\n\nThanks."
            },
            {
                "author_name": "enis",
                "id": "13648215",
                "body": "I think the problem kicks in because when you refer the installed pom as a dependency, then no profile kicks in, and hence compat.module and the runtime dependency cannot be resolved. We did some testing with roshan to add hadoop1|2-compat modules as normal modules (not as defined inside profiles), but did not do change the hbase-server's dependency on compat as a runtime dependency. "
            },
            {
                "author_name": "enis",
                "id": "13648246",
                "body": "Turns out the way we do compat modules, we cannot do depend on the hadoop1|2 compat only on runtime unless we use reflection, or add hadoop dependency to hadoop-compat. I am leaning more and more towards having two different poms for hadoop versions. "
            },
            {
                "author_name": "roshan_naik",
                "id": "13648646",
                "body": "i built a hadoop 2 version of hbase locally (0.97.0-SNAPSHOT) and pointed the flume pom to hbase as follows:\n\n{code}\n     <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-common</artifactId>\n        <version>${hbaseversion}</version>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-common</artifactId>\n        <version>${hbaseversion}</version>\n        <classifier>tests</classifier>\n        <scope>test</scope>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-client</artifactId>\n        <version>${hbaseversion}</version>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-server</artifactId>\n        <version>${hbaseversion}</version>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-server</artifactId>\n        <version>${hbaseversion}</version>\n        <classifier>tests</classifier>\n        <scope>test</scope>\n      </dependency>\n\n{code}\n\nThen built hbase as follows:\n{code}\nmvn install -Dhadoop.profile=2.0 -Dhadoop-two.version=2.0.4-alpha -DskipTests\n{code}\n\n\n\nI built flume as follows:\n\nmvn   -Dhadoop-two.version=2.0.4-alpha -Dhbaseversion=0.97.0-SNAPSHOT -Dhadoop.profile=2 clean package -X -DskipTests\n\n\n"
            },
            {
                "author_name": "stack",
                "id": "13666753",
                "body": "[~roshan_naik] Your workaround works for you?  Do these snapshots help at all?  We are trying to figure out how to publish our artifacts.  Will this work for you?  See:\n\nhttps://repository.apache.org/content/repositories/snapshots/org/apache/hbase/hbase-client/0.95.0-hadoop1-SNAPSHOT/\nhttps://repository.apache.org/content/repositories/snapshots/org/apache/hbase/hbase-client/0.95.0-hadoop2-SNAPSHOT/\n\netc."
            },
            {
                "author_name": "roshan_naik",
                "id": "13668565",
                "body": "taking a look. will revert back soon."
            },
            {
                "author_name": "roshan_naik",
                "id": "13668582",
                "body": "The issue with transitive dependencies not getting pulled remains..\n\n\n[WARNING] The POM for org.apache.hbase:hbase-common:jar:tests:0.95.0-hadoop2-20130524.222913-2 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details\n[WARNING] The POM for org.apache.hbase:hbase-client:jar:0.95.0-hadoop2-20130524.222944-2 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details\n[WARNING] The POM for org.apache.hbase:hbase-server:jar:0.95.0-hadoop2-20130524.223047-2 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details\n[WARNING] The POM for org.apache.hbase:hbase-server:jar:tests:0.95.0-hadoop2-20130524.223047-2 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details"
            },
            {
                "author_name": "roshan_naik",
                "id": "13668586",
                "body": "mvn -X output\n\n\n[WARNING] The POM for org.apache.hbase:hbase-common:jar:tests:0.95.0-hadoop2-20130524.222913-2 is invalid, transitive dependencies (if any) will not be available: 2 problems were encountered while building the effective model for org.apache.hbase:hbase-common:0.95.0-hadoop2-SNAPSHOT\n[ERROR] 'dependencyManagement.dependencies.dependency.artifactId' for org.apache.hbase:${compat.module}:jar with value '${compat.module}' does not match a valid id pattern. @ \n[ERROR] 'dependencyManagement.dependencies.dependency.artifactId' for org.apache.hbase:${compat.module}:test-jar with value '${compat.module}' does not match a valid id pattern. @ \n\n"
            },
            {
                "author_name": "enis",
                "id": "13709326",
                "body": "Marking this critical for 0.95.2. We should fix this before 0.96 to unblock downstream projects. "
            },
            {
                "author_name": "stack",
                "id": "13723418",
                "body": "My little downstream project.  Let me redo and check it in somewhere better named.  Useful reproducing the downstreamer's experience."
            },
            {
                "author_name": "stack",
                "id": "13725014",
                "body": "Here is pointer to downstream project up on github https://github.com/saintstack/hbase-downstreamer\n"
            },
            {
                "author_name": "stack",
                "id": "13726892",
                "body": "Marking as duplicate HBASE-8224.  HBASE-8224 fixes the original issue where we had a variable in our poms that was not being interpolated."
            },
            {
                "author_name": "dportabella",
                "id": "15307889",
                "body": "This issue is not fixed yet.\nAll versions from 0.99.0 to the latest 1.2.1 of hbase-testing-util still depend on the unresolved dependency org.apache.hbase ${compat.module}.\n\nAll versions from 0.96.0-hadoop1 to 0.98.19-hadoop2 work fine.\n\nSee here:\nhttp://mvnrepository.com/artifact/org.apache.hbase/hbase-testing-util/1.2.1\n"
            },
            {
                "author_name": "ndimiduk",
                "id": "15308015",
                "body": "Thanks for bringing this up [~dportabella]. We don't re-open closed issues, so I've filed a new blocker vs. all release branches: HBASE-15925. We can continue discussion over there."
            }
        ],
        "comments_predictions": [
            [
                2408650,
                "HBASE-8488",
                "The problem initially appears to be indicate that ${compat.module} property is not defined .. although it actually is (inside the hadoop 1/2 profiles in parent pom). But these are unfortunately not visible when building apps that depend on hbase.",
                {
                    "property": {
                        "confidence": 0.0049118902534246445,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005882320459932089,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016175607219338417,
                        "prediction": false
                    }
                }
            ],
            [
                2408652,
                "HBASE-8488",
                "I think the problem kicks in because when you refer the installed pom as a dependency, then no profile kicks in, and hence compat.module and the runtime dependency cannot be resolved. We did some testing with roshan to add hadoop1|2-compat modules as normal modules (not as defined inside profiles), but did not do change the hbase-server's dependency on compat as a runtime dependency. ",
                {
                    "property": {
                        "confidence": 0.0032478002831339836,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.039005424827337265,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008266647346317768,
                        "prediction": false
                    }
                }
            ],
            [
                2408653,
                "HBASE-8488",
                "Turns out the way we do compat modules, we cannot do depend on the hadoop1|2 compat only on runtime unless we use reflection, or add hadoop dependency to hadoop-compat. I am leaning more and more towards having two different poms for hadoop versions. ",
                {
                    "property": {
                        "confidence": 0.0048842234537005424,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.11595247685909271,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.005620979238301516,
                        "prediction": false
                    }
                }
            ],
            [
                2408654,
                "HBASE-8488",
                "i built a hadoop 2 version of hbase locally (0.97.0-SNAPSHOT) and pointed the flume pom to hbase as follows:\n\n{code}\n     <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-common</artifactId>\n        <version>${hbaseversion}</version>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-common</artifactId>\n        <version>${hbaseversion}</version>\n        <classifier>tests</classifier>\n        <scope>test</scope>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-client</artifactId>\n        <version>${hbaseversion}</version>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-server</artifactId>\n        <version>${hbaseversion}</version>\n      </dependency>\n\n      <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-server</artifactId>\n        <version>${hbaseversion}</version>\n        <classifier>tests</classifier>\n        <scope>test</scope>\n      </dependency>\n\n{code}\n\nThen built hbase as follows:\n{code}\nmvn install -Dhadoop.profile=2.0 -Dhadoop-two.version=2.0.4-alpha -DskipTests\n{code}\n\n\n\nI built flume as follows:\n\nmvn   -Dhadoop-two.version=2.0.4-alpha -Dhbaseversion=0.97.0-SNAPSHOT -Dhadoop.profile=2 clean package -X -DskipTests\n\n\n",
                {
                    "property": {
                        "confidence": 0.0035245351027697325,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.013174832798540592,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012412107549607754,
                        "prediction": false
                    }
                }
            ],
            [
                2408655,
                "HBASE-8488",
                "[~roshan_naik] Your workaround works for you?  Do these snapshots help at all?  We are trying to figure out how to publish our artifacts.  Will this work for you?  See:\n\nhttps://repository.apache.org/content/repositories/snapshots/org/apache/hbase/hbase-client/0.95.0-hadoop1-SNAPSHOT/\nhttps://repository.apache.org/content/repositories/snapshots/org/apache/hbase/hbase-client/0.95.0-hadoop2-SNAPSHOT/\n\netc.",
                {
                    "property": {
                        "confidence": 0.005994519684463739,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0037638135254383087,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03645576536655426,
                        "prediction": false
                    }
                }
            ],
            [
                2408657,
                "HBASE-8488",
                "The issue with transitive dependencies not getting pulled remains..\n\n\n[WARNING] The POM for org.apache.hbase:hbase-common:jar:tests:0.95.0-hadoop2-20130524.222913-2 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details\n[WARNING] The POM for org.apache.hbase:hbase-client:jar:0.95.0-hadoop2-20130524.222944-2 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details\n[WARNING] The POM for org.apache.hbase:hbase-server:jar:0.95.0-hadoop2-20130524.223047-2 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details\n[WARNING] The POM for org.apache.hbase:hbase-server:jar:tests:0.95.0-hadoop2-20130524.223047-2 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details",
                {
                    "property": {
                        "confidence": 0.0060028331354260445,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009027699008584023,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008135994896292686,
                        "prediction": false
                    }
                }
            ],
            [
                2408658,
                "HBASE-8488",
                "mvn -X output\n\n\n[WARNING] The POM for org.apache.hbase:hbase-common:jar:tests:0.95.0-hadoop2-20130524.222913-2 is invalid, transitive dependencies (if any) will not be available: 2 problems were encountered while building the effective model for org.apache.hbase:hbase-common:0.95.0-hadoop2-SNAPSHOT\n[ERROR] 'dependencyManagement.dependencies.dependency.artifactId' for org.apache.hbase:${compat.module}:jar with value '${compat.module}' does not match a valid id pattern. @ \n[ERROR] 'dependencyManagement.dependencies.dependency.artifactId' for org.apache.hbase:${compat.module}:test-jar with value '${compat.module}' does not match a valid id pattern. @ \n\n",
                {
                    "property": {
                        "confidence": 0.005737140774726868,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0139692397788167,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0064907134510576725,
                        "prediction": false
                    }
                }
            ],
            [
                2408663,
                "HBASE-8488",
                "This issue is not fixed yet.\nAll versions from 0.99.0 to the latest 1.2.1 of hbase-testing-util still depend on the unresolved dependency org.apache.hbase ${compat.module}.\n\nAll versions from 0.96.0-hadoop1 to 0.98.19-hadoop2 work fine.\n\nSee here:\nhttp://mvnrepository.com/artifact/org.apache.hbase/hbase-testing-util/1.2.1\n",
                {
                    "property": {
                        "confidence": 0.0046625398099422455,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01613348349928856,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007894461043179035,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d460f4d395ee22189f27",
        "key": "WW-1052",
        "id": "12453787",
        "description": "in the com.opensymphony.webwork.dispatcher.ActionContextCleanUp atribute is always false.\n\n  public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {\n        try {\n            req.setAttribute(CLEANUP_PRESENT, Boolean.TRUE);\n            chain.doFilter(req, res);\n        } finally {\n            req.setAttribute(CLEANUP_PRESENT, Boolean.FALSE);  // always executed\n            cleanUp(req);\n        }\n    }\n\nAlways cleanup\n\n protected static void cleanUp(ServletRequest req) {\n        // should we clean up yet?\n        Boolean dontClean = (Boolean) req.getAttribute(CLEANUP_PRESENT);\n        if (dontClean != null && dontClean.booleanValue()) {\n            return;\n        }",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009191235527396202
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008967154659330845
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005673288367688656
                }
            }
        },
        "comments": [
            {
                "author_name": "tm_jee",
                "id": "12819333",
                "body": "Looks like it is working as it should be. Or am i missing somthing? "
            },
            {
                "author_name": "plightbo@gmail.com",
                "id": "12825442",
                "body": "This is not a bug... the behavior is correct, though I suppose the variable names are a bit confusing. Notice this line:\n\n        Boolean dontClean = (Boolean) req.getAttribute(CLEANUP_PRESENT);\n        if (dontClean != null && dontClean.booleanValue()) {\n            return;\n        }\n\n\nThat means if the value is TRUE, we don't clean up. That's why we set it to false before cleaning up."
            }
        ],
        "comments_predictions": [
            [
                236605,
                "WW-1052",
                "This is not a bug... the behavior is correct, though I suppose the variable names are a bit confusing. Notice this line:\n\n        Boolean dontClean = (Boolean) req.getAttribute(CLEANUP_PRESENT);\n        if (dontClean != null && dontClean.booleanValue()) {\n            return;\n        }\n\n\nThat means if the value is TRUE, we don't clean up. That's why we set it to false before cleaning up.",
                {
                    "property": {
                        "confidence": 0.004788970109075308,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.014324966818094254,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.00784231722354889,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5fd64f4d395ee222046bf",
        "key": "HTTPASYNC-94",
        "id": "12909591",
        "description": "\ufffcClass Name\tShallow Heap\tRetained Heap\n  java.util.LinkedList @ 0x750a89d08\t32\t3657440400\n  org.apache.http.impl.nio.conn.CPool @ 0x750a86508\t88\t3764053968\n  org.apache.http.impl.nio.conn.PoolingNHttpClientConnectionManager @ 0x751d65730\t32\t5640\n  org.apache.http.impl.nio.client.CloseableHttpAsyncClientBase$1 @ 0x752621b08\t24\t24\n java.lang.Thread @ 0x751d470f8 pool-17-thread-1\t104\t5184\n  org.apache.http.impl.nio.client.InternalHttpAsyncClient @ 0x7537dd778\t72\t88",
        "predictions": {},
        "comments": [
            {
                "author_name": "olegk",
                "id": "14984989",
                "body": "My guess is that your own code leaks PoolingNHttpClientConnectionManager instances and as a result you end up with tons of LinkedList instances on the heap. One is not supposed to have more than one (or very few) PoolingNHttpClientConnectionManager instances. \n\nOleg"
            },
            {
                "author_name": "sunqi",
                "id": "14986810",
                "body": "only one PoolingNHttpClientConnectionManager  instance on the heap,and only two linkedList instances on the heap,one is \"leasingRequests\", and the other is \"available\", linkedList is unlimited\uff0cat last it used 3.6G ,  the heap config is -Xms5g -Xmx5g"
            },
            {
                "author_name": "olegk",
                "id": "14986873",
                "body": "So, where is exactly the memory leak? The \"available\" LinkedLink contains re-usable connections available for lease from the pool. It is its purpose. If your pool is configured to have thousands connections and those connections use SSL encryption one can easily end up with gigabytes of heap consumed by those connections.\n\nOlg"
            },
            {
                "author_name": "sunqi",
                "id": "14988675",
                "body": " connManager.setMaxTotal(4096);\n connManager.setDefaultMaxPerRoute(1024);\n\t "
            },
            {
                "author_name": "sunqi",
                "id": "14988692",
                "body": "the unlimited linkedlist is  the memory leak,too many instances in the linkedlist,i try btrace but fail to connect ,in the normal machine\uff0c\"available \" list size is about 600,and \"leasingRequests\" list size is 0"
            },
            {
                "author_name": "olegk",
                "id": "14989127",
                "body": "The list is limited to 4096 max entries by the pool. Consider using saner pool settings.\n\nOleg"
            },
            {
                "author_name": "sunqi",
                "id": "14989213",
                "body": "4096 instances in the list  will never caused memory leak,so i guess the max size is not limited in special case"
            },
            {
                "author_name": "olegk",
                "id": "14989222",
                "body": "I am sorry but guesses are not good enough. Could you please reproduce the issue with a test case? Otherwise I'll have no choice but close this issue as invalid.\n\nOleg"
            },
            {
                "author_name": "sunqi",
                "id": "14989400",
                "body": "i am running in test environment for two days\uff0cbut it's not happen, online environment is happened on some machine\uff0cand btrace is fail to conect ,but jmap dump and mat  resulet as description, it's leak on the linkedlist,  this linkedlist is only mange by PoolingNHttpClientConnectionManager, so i suspect some special case caused leak"
            },
            {
                "author_name": "olegk",
                "id": "14989425",
                "body": "There is not much I can do about guesses and suspicions. Consider running your server with connection management logging turned on as described here\n\nhttp://hc.apache.org/httpcomponents-client-4.5.x/logging.html\n\nI'll close the issue as 'cant reproduce' for now.\n\nOleg"
            },
            {
                "author_name": "czheo",
                "id": "16614136",
                "body": "I have observed exactly the same\u00a0issue in my code. I found it was caused by the default settings of maxConnection (20) and maxConnectionPerRoute (2). After setting those configs to higher numbers, the problem\u00a0was solved."
            }
        ],
        "comments_predictions": [
            [
                1891657,
                "HTTPASYNC-94",
                "My guess is that your own code leaks PoolingNHttpClientConnectionManager instances and as a result you end up with tons of LinkedList instances on the heap. One is not supposed to have more than one (or very few) PoolingNHttpClientConnectionManager instances. \n\nOleg",
                {
                    "property": {
                        "confidence": 0.005750769749283791,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006302728317677975,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013276122510433197,
                        "prediction": false
                    }
                }
            ],
            [
                1891658,
                "HTTPASYNC-94",
                "only one PoolingNHttpClientConnectionManager  instance on the heap,and only two linkedList instances on the heap,one is \"leasingRequests\", and the other is \"available\", linkedList is unlimited\uff0cat last it used 3.6G ,  the heap config is -Xms5g -Xmx5g",
                {
                    "property": {
                        "confidence": 0.005550522357225418,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0060387663543224335,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01678137481212616,
                        "prediction": false
                    }
                }
            ],
            [
                1891659,
                "HTTPASYNC-94",
                "So, where is exactly the memory leak? The \"available\" LinkedLink contains re-usable connections available for lease from the pool. It is its purpose. If your pool is configured to have thousands connections and those connections use SSL encryption one can easily end up with gigabytes of heap consumed by those connections.\n\nOlg",
                {
                    "property": {
                        "confidence": 0.015604120679199696,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006949183065444231,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007802119012922049,
                        "prediction": false
                    }
                }
            ],
            [
                1891661,
                "HTTPASYNC-94",
                "the unlimited linkedlist is  the memory leak,too many instances in the linkedlist,i try btrace but fail to connect ,in the normal machine\uff0c\"available \" list size is about 600,and \"leasingRequests\" list size is 0",
                {
                    "property": {
                        "confidence": 0.0065605537965893745,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0063190460205078125,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011102505028247833,
                        "prediction": false
                    }
                }
            ],
            [
                1891665,
                "HTTPASYNC-94",
                "i am running in test environment for two days\uff0cbut it's not happen, online environment is happened on some machine\uff0cand btrace is fail to conect ,but jmap dump and mat  resulet as description, it's leak on the linkedlist,  this linkedlist is only mange by PoolingNHttpClientConnectionManager, so i suspect some special case caused leak",
                {
                    "property": {
                        "confidence": 0.0050050667487084866,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00943440105766058,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009780306369066238,
                        "prediction": false
                    }
                }
            ],
            [
                1891666,
                "HTTPASYNC-94",
                "There is not much I can do about guesses and suspicions. Consider running your server with connection management logging turned on as described here\n\nhttp://hc.apache.org/httpcomponents-client-4.5.x/logging.html\n\nI'll close the issue as 'cant reproduce' for now.\n\nOleg",
                {
                    "property": {
                        "confidence": 0.006365986540913582,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008916572667658329,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009827734902501106,
                        "prediction": false
                    }
                }
            ],
            [
                1891667,
                "HTTPASYNC-94",
                "I have observed exactly the same\u00a0issue in my code. I found it was caused by the default settings of maxConnection (20) and maxConnectionPerRoute (2). After setting those configs to higher numbers, the problem\u00a0was solved.",
                {
                    "property": {
                        "confidence": 0.005238056648522615,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007831527851521969,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010805311612784863,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d608b7f4d395ee2221b587",
        "key": "HADOOP-12218",
        "id": "12844238",
        "description": "Fix a bunch of typos in comments, strings, variable names, and method names in the hadoop-tools module.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.01774015463888645
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.012408822774887085
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0034442998003214598
                }
            }
        },
        "comments": [
            {
                "author_name": "rchiang",
                "id": "14622670",
                "body": "Initial version based off HADOOP-11854.005.patch."
            },
            {
                "author_name": "rchiang",
                "id": "14622671",
                "body": "Initial version"
            },
            {
                "author_name": "hadoopqa",
                "id": "14622776",
                "body": "\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | pre-patch |  19m 45s | Findbugs (version 3.0.0) appears to be broken on trunk. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 10 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 55s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 52s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |\n| {color:green}+1{color} | checkstyle |   2m 53s | There were no new checkstyle issues. |\n| {color:green}+1{color} | whitespace |   0m  2s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 23s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   6m 22s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |\n| {color:green}+1{color} | tools/hadoop tests |   0m 50s | Tests passed in hadoop-archives. |\n| {color:green}+1{color} | tools/hadoop tests |   0m 14s | Tests passed in hadoop-aws. |\n| {color:green}+1{color} | tools/hadoop tests |   1m 11s | Tests passed in hadoop-azure. |\n| {color:green}+1{color} | tools/hadoop tests |   0m 24s | Tests passed in hadoop-datajoin. |\n| {color:green}+1{color} | tools/hadoop tests |   0m 20s | Tests passed in hadoop-openstack. |\n| {color:green}+1{color} | tools/hadoop tests |   0m 19s | Tests passed in hadoop-rumen. |\n| {color:green}+1{color} | tools/hadoop tests |   0m 52s | Tests passed in hadoop-sls. |\n| {color:green}+1{color} | tools/hadoop tests |   6m 23s | Tests passed in hadoop-streaming. |\n| | |  59m 46s | |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12744754/HADOOP-12218.001.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / 0824426 |\n| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/trunkFindbugsWarningshadoop-datajoin.html |\n| hadoop-archives test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/testrun_hadoop-archives.txt |\n| hadoop-aws test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/testrun_hadoop-aws.txt |\n| hadoop-azure test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/testrun_hadoop-azure.txt |\n| hadoop-datajoin test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/testrun_hadoop-datajoin.txt |\n| hadoop-openstack test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/testrun_hadoop-openstack.txt |\n| hadoop-rumen test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/testrun_hadoop-rumen.txt |\n| hadoop-sls test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/testrun_hadoop-sls.txt |\n| hadoop-streaming test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/artifact/patchprocess/testrun_hadoop-streaming.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf908.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7236/console |\n\n\nThis message was automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "14951433",
                "body": "\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12744754/HADOOP-12218.001.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / def374e |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7789/console |\n\n\nThis message was automatically generated."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d376f4d395ee2218451d",
        "key": "YARN-10386",
        "id": "13321084",
        "description": "Tasks in this JIRA:\r\n # Create new JSON schema\r\n # Add Maven plugin which generates Java POJOs based on the schema\r\n # Add helper class which essentially does the same as #2 (for dev purposes)",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014831571839749813
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.11839711666107178
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0028057312592864037
                }
            }
        },
        "comments": [
            {
                "author_name": "pbacsko",
                "id": "17171532",
                "body": "Attached v1 version of the schema.\r\n\r\nExplanation:\r\n* {{type}}: user / group / application --- pretty much the first column of the current format.\r\n* {{matches}}: it's either \"\\*\" or a specific group/user -- the second column of the current format (will use \"*\" instead of \"%user\").\r\n* {{policy}}: a fixed set of mapping policies, basically the same as an FS placement rule.\r\n* {{queue}}: if the policy is {{user}}, {{primaryGroup}}, {{secondaryGroup}}, then this is prepended to the queue string. If the rule is {{defaultQueue}} then \"root.default\" will be overridden.\r\n* {{nestedUserRule}}: optional, used only if {{nestedUser}} policy is defined. Note that unlike to Fair Scheduler, we don't have \"outer\" create flag, because it would require very deep changes in Capacity Scheduler. So we only support \"innerCreate\" for the \"%user\" part.\r\n* {{fallbackResult}}: what happens if the placement fails, eg. the target queue does not exist or cannot be created. Right now in CS, we return \"null\" for the placement context which is interpreted as \"root.default\". In FS, we proceed to the next rule. Here, we can fine-tune this behavior: {{skip}} is the FS approach, {{placeDefault}} is the CS approach, {{reject}} is new and straightforward (submission will be rejected on the client side).\r\n* {{defaultQueue}}: what should be the default queue in case of {{placeDefault}} fallback result.\r\n* {{create}}: whether the queue should be created or not if it does not exist. Note that the parent queue of the leaf must be a managed parent in order for this switch to have effect. \r\n"
            },
            {
                "author_name": "pbacsko",
                "id": "17175571",
                "body": "I've been thinking, probably \"defaultQueue\" should be renamed to something else. There's also a \"defaultQueue\" policy and users might think that they have to use \"defaultQueue\" to override \"root.default\". But it only affects \"placeDefault\" fallback rule, at least that's my intention right now. So we need to come up with some clever naming. I think \"fallbackDefaultQueue\" sounds better."
            },
            {
                "author_name": "hadoopci",
                "id": "17176210",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 36s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  1s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 14s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 10s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 26s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 40s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 33s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 20m 23s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 37m  5s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 39s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 16s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue} 41m 17s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 41m 10s{color} | {color:red} root in trunk has 2 extant findbugs warnings. {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 42s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red} 26m 28s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 24m 28s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 24m 28s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 21m 26s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 21m 26s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  3m  9s{color} | {color:orange} root: The patch generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 22m 12s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red} 14m 51s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  7m  1s{color} | {color:red} root in the patch failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  7m 58s{color} | {color:red} root in the patch failed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  1s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 31m 53s{color} | {color:red} root generated 2 new + 2 unchanged - 0 fixed = 4 total (was 2) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}569m 27s{color} | {color:red} root in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 25s{color} | {color:red} The patch generated 5 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}888m 13s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n| FindBugs | module:root |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n| Failed junit tests | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer |\r\n|   | hadoop.yarn.server.timelineservice.security.TestTimelineAuthFilterForV2 |\r\n|   | hadoop.hdfs.TestDFSUpgradeFromImage |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13009462/YARN-10386-001.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux f180a78ba028 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 3fd3aeb621e |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/branch-findbugs-root-warnings.html |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/patch-mvninstall-root.txt |\r\n| checkstyle | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/new-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.html |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/new-findbugs-root.html |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 5037 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/68/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "pbacsko",
                "id": "17176413",
                "body": "Wow, there are a lot of failures.\r\n\r\nI'll investigate the enforcer failure, because we added a new dependency to a pom."
            },
            {
                "author_name": "pbacsko",
                "id": "17176572",
                "body": "[~snemeth] [~adam.antal] [~shuzirra] [~sunilg] - do you guys have any comments?\r\n\r\nThe maven extension was contributed by [~bteke]."
            },
            {
                "author_name": "hadoopci",
                "id": "17176661",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 30m 27s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  3m 12s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m 28s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 20m 44s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 27s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 45s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 20m 54s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 38m 58s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 25s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 20s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue}  1m 49s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 16s{color} | {color:blue} branch/hadoop-project no findbugs output file (findbugsXml.xml) {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 35s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 25s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  6m 51s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} compile {color} | {color:red}  9m  7s{color} | {color:red} root in the patch failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} javac {color} | {color:red}  9m  7s{color} | {color:red} root in the patch failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} compile {color} | {color:red}  8m 35s{color} | {color:red} root in the patch failed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01. {color} |\r\n| {color:red}-1{color} | {color:red} javac {color} | {color:red}  8m 35s{color} | {color:red} root in the patch failed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01. {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 40s{color} | {color:orange} root: The patch generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  3m 24s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red}  4m 21s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  3m 28s{color} | {color:red} root in the patch failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  7m 29s{color} | {color:red} root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 2 new + 4206 unchanged - 0 fixed = 4208 total (was 4206) {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 15s{color} | {color:blue} hadoop-project has no data from findbugs {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 26s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 16m 10s{color} | {color:red} root in the patch failed. {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}207m 33s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 53s{color} | {color:red} The patch generated 4 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}465m 32s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.server.federation.router.TestRouterRpc |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterRpcMultiDestination |\r\n|   | hadoop.hdfs.server.datanode.TestBPOfferService |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.qjournal.server.TestJournalNodeSync |\r\n|   | hadoop.hdfs.TestDFSOutputStream |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13009556/YARN-10386-002.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux 985c330a263a 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 10716040a85 |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-mvninstall-root.txt |\r\n| compile | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-compile-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| javac | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-compile-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| compile | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| javac | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-compile-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| checkstyle | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/diff-checkstyle-root.txt |\r\n| mvnsite | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-mvnsite-root.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/diff-javadoc-javadoc-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-findbugs-root.txt |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 3254 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/70/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopci",
                "id": "17177006",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 53s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 12s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red} 23m 52s{color} | {color:red} root in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 32s{color} | {color:red} root in trunk failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 30s{color} | {color:red} root in trunk failed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01. {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 28s{color} | {color:orange} The patch fails to run checkstyle in root {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 24m 33s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 38m 44s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 20s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  5s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue} 32m 30s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 19s{color} | {color:blue} branch/hadoop-project no findbugs output file (findbugsXml.xml) {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 33s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red} 19m 43s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 23s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:red}-1{color} | {color:red} javac {color} | {color:red} 19m 23s{color} | {color:red} root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 generated 2047 new + 0 unchanged - 0 fixed = 2047 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 40s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:red}-1{color} | {color:red} javac {color} | {color:red} 16m 40s{color} | {color:red} root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 1942 new + 0 unchanged - 0 fixed = 1942 total (was 0) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 34s{color} | {color:orange} root: The patch generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 17m  8s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red} 14m 25s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  6m 56s{color} | {color:red} root in the patch failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  7m 36s{color} | {color:red} root in the patch failed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 17s{color} | {color:blue} hadoop-project has no data from findbugs {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  3s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 34m 42s{color} | {color:red} root generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}149m 33s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 51s{color} | {color:red} The patch generated 4 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}410m 13s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n| FindBugs | module:root |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n| Failed CTEST tests | test_hdfs_ext_hdfspp_test_shim_static |\r\n| Failed junit tests | hadoop.hdfs.TestDecommissionWithStriped |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeUUID |\r\n|   | hadoop.hdfs.TestFileCorruption |\r\n|   | hadoop.hdfs.TestStripedFileAppend |\r\n|   | hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |\r\n|   | hadoop.hdfs.server.datanode.TestBPOfferService |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStream |\r\n|   | hadoop.hdfs.TestGetFileChecksum |\r\n|   | hadoop.hdfs.TestErasureCodingPolicyWithSnapshotWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |\r\n|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |\r\n|   | hadoop.hdfs.TestRollingUpgrade |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13009754/YARN-10386-003.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux 36cfa42582cc 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / e592ec5f8bf |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/branch-mvninstall-root.txt |\r\n| compile | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/branch-compile-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| compile | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| checkstyle | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/buildtool-branch-checkstyle-root.txt |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/patch-mvninstall-root.txt |\r\n| javac | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/diff-compile-javac-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| javac | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/diff-compile-javac-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| checkstyle | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/new-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.html |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/new-findbugs-root.html |\r\n| CTEST | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/patch-root-ctest.txt |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 3548 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/71/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopci",
                "id": "17178135",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 37s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m  6s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m  7s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 41s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 47s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 39s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 22m 14s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 38m 49s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 23s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 58s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue} 31m  4s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 19s{color} | {color:blue} branch/hadoop-project no findbugs output file (findbugsXml.xml) {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 35s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red} 19m 34s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 59s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 18m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 34s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 18m 34s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 55s{color} | {color:orange} root: The patch generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 18m  3s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red} 14m 51s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  6m 24s{color} | {color:red} root in the patch failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  7m  0s{color} | {color:red} root in the patch failed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 19s{color} | {color:blue} hadoop-project has no data from findbugs {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 50s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 33m  1s{color} | {color:red} root generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}579m 57s{color} | {color:red} root in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 30s{color} | {color:red} The patch generated 5 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}870m 10s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n| FindBugs | module:root |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n|  |  Comparison of String objects using == or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:== or != in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule.equals(Object)   At Rule.java:[line 209] |\r\n| Failed junit tests | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.sls.TestSLSRunner |\r\n|   | hadoop.hdfs.TestGetFileChecksum |\r\n|   | hadoop.hdfs.server.namenode.ha.TestUpdateBlockTailing |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\r\n|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13009754/YARN-10386-003.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux bc4ce720f9ee 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 86bbd38c8dc |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/patch-mvninstall-root.txt |\r\n| checkstyle | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/new-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.html |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/new-findbugs-root.html |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 4014 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/74/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopci",
                "id": "17184888",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 33m 47s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 22s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 18s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 24m 13s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 49s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 50s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 20m 10s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 39m  7s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 31s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 51s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue}  2m  8s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 18s{color} | {color:blue} branch/hadoop-project no findbugs output file (findbugsXml.xml) {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red} 32m 58s{color} | {color:red} root in trunk failed. {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 28s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red} 23m 55s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 20m 22s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 20m 22s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 49s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 34s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 17m 13s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red} 14m 22s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  6m 16s{color} | {color:red} root in the patch failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  7m  5s{color} | {color:red} root in the patch failed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 20s{color} | {color:blue} hadoop-project has no data from findbugs {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}579m  2s{color} | {color:red} root in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 22s{color} | {color:red} The patch generated 5 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}949m 30s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.sls.appmaster.TestAMSimulator |\r\n|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.hdfs.server.namenode.TestAddStripedBlockInFBR |\r\n|   | hadoop.hdfs.TestGetFileChecksum |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.server.namenode.ha.TestHASafeMode |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13010454/YARN-10386-004.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux dde4623cecf5 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 82a75056463 |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| findbugs | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/artifact/out/branch-findbugs-root.txt |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/artifact/out/patch-mvninstall-root.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/artifact/out/patch-javadoc-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| javadoc | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/artifact/out/patch-javadoc-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 4255 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/85/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopci",
                "id": "17185406",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 13s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m  9s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 39s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 17s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 46s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 37s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 20m  4s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 36m 36s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 23s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  4s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue} 29m 42s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 18s{color} | {color:blue} branch/hadoop-project no findbugs output file (findbugsXml.xml) {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 31s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m  9s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 58s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 18m 58s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 44s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m 44s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 32s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 17m 14s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 52s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 17s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  7s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 19s{color} | {color:blue} hadoop-project has no data from findbugs {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}201m 53s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m  5s{color} | {color:red} The patch generated 5 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}508m 12s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.fs.contract.router.web.TestRouterWebHDFSContractRootDirectory |\r\n|   | hadoop.fs.contract.router.web.TestRouterWebHDFSContractDelete |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterNamenodeMonitoring |\r\n|   | hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek |\r\n|   | hadoop.hdfs.server.federation.router.TestRouterMultiRack |\r\n|   | hadoop.fs.contract.router.TestRouterHDFSContractMkdirSecure |\r\n|   | hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.server.datanode.TestBPOfferService |\r\n|   | hadoop.hdfs.server.balancer.TestBalancer |\r\n|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlocksWithNotEnoughRacks |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/96/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13010547/YARN-10386-006.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux 1ffe744b1b52 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 75db5526b5d |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/96/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/96/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/96/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 3442 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/96/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopci",
                "id": "17185508",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 53s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 30s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  9m 24s{color} | {color:red} root in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} compile {color} | {color:red} 17m  2s{color} | {color:red} root in trunk failed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1. {color} |\r\n| {color:red}-1{color} | {color:red} compile {color} | {color:red}  2m 17s{color} | {color:red} root in trunk failed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01. {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 11s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 22m  3s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 41m  0s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 44s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  5s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue} 31m 14s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 19s{color} | {color:blue} branch/hadoop-project no findbugs output file (findbugsXml.xml) {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 35s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red} 20m  1s{color} | {color:red} root in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 21m  9s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:red}-1{color} | {color:red} javac {color} | {color:red} 21m  9s{color} | {color:red} root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 generated 210 new + 1841 unchanged - 0 fixed = 2051 total (was 1841) {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 50s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:red}-1{color} | {color:red} javac {color} | {color:red} 17m 50s{color} | {color:red} root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 generated 1639 new + 307 unchanged - 0 fixed = 1946 total (was 307) {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 32s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 17m 13s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:red}-1{color} | {color:red} shadedclient {color} | {color:red} 14m 33s{color} | {color:red} patch has errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 17s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  4s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 19s{color} | {color:blue} hadoop-project has no data from findbugs {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}571m 52s{color} | {color:red} root in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 27s{color} | {color:red} The patch generated 5 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}863m 15s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.server.nodemanager.amrmproxy.TestFederationInterceptor |\r\n|   | hadoop.yarn.sls.TestReservationSystemInvariants |\r\n|   | hadoop.hdfs.TestRollingUpgrade |\r\n|   | hadoop.hdfs.TestStripedFileAppend |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.TestGetFileChecksum |\r\n|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13010544/YARN-10386-005.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux e23bfa000092 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 75db5526b5d |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/branch-mvninstall-root.txt |\r\n| compile | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/branch-compile-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| compile | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/branch-compile-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| mvninstall | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/patch-mvninstall-root.txt |\r\n| javac | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/diff-compile-javac-root-jdkUbuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1.txt |\r\n| javac | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/diff-compile-javac-root-jdkPrivateBuild-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01.txt |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 3800 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/95/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "pbacsko",
                "id": "17185738",
                "body": "Ok, the build what matters is https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/96/.\r\n\r\nASF license warnings and the unit test failures can be ignored. Tests were executed for the whole project, but several times the forked process ran into resource limits.\r\n\r\n"
            },
            {
                "author_name": "adam.antal",
                "id": "17185764",
                "body": "Thanks for working on this [~pbacsko].\r\n\r\nI saw you had some troubles with the jenkins. I don't see what exactly causes the jenkins failures but we should make sure that after we merge this, it won't appear in other jenkins results.\r\n\r\nRegarding the patch I have two comments:\r\n\r\nI am a little concerned about the checkstyle ignores:\r\n{noformat}\r\n@SuppressWarnings({\"checkstyle:hideutilityclassconstructor\", \"checkstyle:linelength\"})\r\n{noformat}\r\n- I don't see problems creating a private constructor for this class to prevent instantiation of this utility class.\r\n- Also, this can be moved to a constant: {{\"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema\"}} any maybe we can add the checkstyle warning annotation to only to the constant to be as restrictive as we can.\r\n\r\nOther: \r\n- In {{hadoop-yarn-server-resourcemanager/pom.xml}} can we also use the ${jsonschema2pojo.version} constant for the version if possible?\r\n\r\nI also add that I checked the new maven dependency and I saw no associated CVE-s to that, so I think it's fine to use it."
            },
            {
                "author_name": "pbacsko",
                "id": "17185770",
                "body": "[~adam.antal] the entire project is findbugs/style checked and compiled many times over due to the modification in {{hadoop-project/pom.xml}}. That makes the build very slow and eventually it runs out of resources. \r\n\r\nAnyway I'll make the changes.\r\n\r\nAny thoughts about the JSON schema itself?"
            },
            {
                "author_name": "shuzirra",
                "id": "17185790",
                "body": "I'm not sure I understand your defaultQueue comment properly, but on the backend %default means root.default initially and if you user a VariableUpdateAction, it will change it for default placement targets and default fallbacks as well.\r\n\r\nWhy is the \"defaultQueue\" property a separate option not a policy? It is just a similar action to anything, and it cannot be added as an extra to any rule. I mean you cannot have a policy AND a change default queue, also default queue change is for the whole application submission, not only for the given rule.\r\n\r\nI think we are overusing the defaultQueue in the schema, we should use other names like, changeDefaultQueue, placeToDefaultQueue, fallbackToDefaultQueue or something along these lines to make sure it is clear what it will do.\r\n\r\nI think we have too many options under the properties and it can easily lead to incorrect configuration, I think we should move the nesterUserRule and the (change)defaultQueue into the policies. Nested user rules are just complex target paths, like root.%primary_group.%user, but nothing else, so I don't think we should move them to a separate property (I don't even think we need to do a separate policy for them, since we can just use regular queue placement).\r\n\r\nThe nested rules in FS always map to something like root.some.path.XXXX.%user, and the rule decides the XXXX part, if create is not allowed and the queue does not exist then it moves onto the next. (I know it also supports default, but it's like place to %default) So all this can be easily mapped to regular queue placement with rules like: root.%primary_group.%user on fallback skip.\r\n\r\nI would also add a \"custom\" to the type, since matcher also can be custom, not only rules.\r\n\r\n\u00a0\r\n\r\n\u00a0"
            },
            {
                "author_name": "pbacsko",
                "id": "17185799",
                "body": "\"Why is the \"defaultQueue\" property a separate option not a policy?\"\r\n\r\nThat's what I explained, it's confusing.  That's intended to set the fallback default queue, in case a fallback occurs and the {{fallbackResult}} is {{placeToDefault}}. \r\n\r\n\"I think we are overusing the defaultQueue in the schema, we should use other names like, changeDefaultQueue, placeToDefaultQueue, fallbackToDefaultQueue or something along these lines to make sure it is clear what it will do.\"\r\n\r\nYep, that's what my first command is about :)\r\n\r\n\"Nested\" is already a policy itself and the \"nestedUserRule\" is only interpreted if this particular policy is used.\r\n\r\nThe reason for a separate nested policy is to prevent users from all kinds of crazy configurations. Yes, the engine itself can happily resolve stuff like \"root.%default.%primary_group\", but I don't think these kind of configurations should be allowed. So the schema itself takes care of the allowed combinations. \r\n\r\nRegarding changing the default, I think it's an overkill to have a separate changeDefault policy. It's certainly how it works under the hood as an action, but I don't see too much benefit of exposing this. "
            },
            {
                "author_name": "pbacsko",
                "id": "17185899",
                "body": "Ok, had a discussion with [~shuzirra]. Now I can better understand what he meant above.\r\n\r\nThe following changes will be introduced:\r\n1. \"nestedUserRule\" will be removed, because it's used only in case of \"nestedUserRule\" policy.\r\n2. Add two new policies \"secondaryGroupUser\" and \"primaryGroupUser\".\r\n3. Remove \"defaultQueue\" setting. The default queue will be set with a different rule.\r\n4. Also introduce \"setDefaultQueue\" policy. This will change the default queue until it's set to something else.\r\n5. The naming of \"queue\" is misleading, let's change that to sth like \"parentQueue\" or \"parentQueuePath\".\r\n6. Custom policy: we can keep this and add a \"custom\" field perhaps. This can contain any random definition like {{root.user.%primary_group.%secondary_group}} and it will not be rejected. The tool won't validate whether the string makes any sense or not."
            },
            {
                "author_name": "pbacsko",
                "id": "17186087",
                "body": "Some examples:\r\n\r\n{{u:%user:%user}}\r\n{noformat}\r\n\"rules\":\r\n{\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"user\",\r\n\t\t\"fallbackResult\": \"placeDefault\"\r\n\t}\r\n}\r\n{noformat}\r\n\u00a0\r\n\r\n{{u:%user:root.dev.%primary_group.%user}}\r\n{noformat}\r\n\"rules\":\r\n{\t\r\n    {\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"primaryGroupUser\",\r\n\t\t\"parentQueue\": \"root.dev\",\r\n\t\t\"fallbackResult\": \"placeDefault\"\r\n\t}\r\n}\r\n{noformat}\r\n\u00a0\r\n\r\n{{u:%user:%secondary_group.%user}}\r\n{noformat}\r\n\"rules\":\r\n{\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"secondaryGroupUser\",\r\n\t\t\"fallbackResult\": \"placeDefault\"\r\n\t}\r\n}\r\n{noformat}\r\n\u00a0\r\n\r\n{{u:%user:root.users}}\r\n{noformat}\r\n\"rules\":\r\n{\t\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"setDefaultQueue\",\r\n\t\t\"value\": \"root.users\",\r\n\t\t\"fallbackResult\": \"skip\"\r\n\t},\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"defaultQueue\",\r\n\t\t\"fallbackResult\": \"placeDefault\"\r\n\t}\r\n}\r\n{noformat}\r\n\r\nAs we can see, we need two rules for a hard-coded path like \"root.users\". This might look weird, but this very similar to FS, where the rule is also called {{<default>}} with an overridden default queue. So in theory it's the same. \r\n\r\nThere is also an alternative for {{u:%user:root.users}}  (in fact, all rules could be rewritten with \"custom\", which is kind of a non-restriced way of specifying a target queue with arbitrary combination of placeholder variables).\r\n\r\n{noformat}\r\n\"rules\":\r\n{\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"custom\",\r\n\t\t\"customPlacement\": \"root.users\"\r\n\t}\r\n}\r\n{noformat}"
            },
            {
                "author_name": "hadoopci",
                "id": "17186398",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 48s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  1s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  1s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 13s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 22m 43s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 22m 51s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 36s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 48s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 22m 10s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 40m 49s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  2s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 28s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue} 35m  3s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 15s{color} | {color:blue} branch/hadoop-project no findbugs output file (findbugsXml.xml) {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 30s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 22m  0s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 22m  0s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 47s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 18m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 44s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 19m 11s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 18s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  2s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 31s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 15s{color} | {color:blue} hadoop-project has no data from findbugs {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}661m  4s{color} | {color:red} root in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  5m 22s{color} | {color:red} The patch generated 4 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}1014m 41s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.hdfs.server.federation.router.TestRouterRpc |\r\n|   | hadoop.hdfs.TestFileChecksumCompositeCrc |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.TestFileChecksum |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics |\r\n|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.server.timelineservice.storage.TestTimelineWriterHBaseDown |\r\n|   | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/100/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13010626/YARN-10386-007.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux f749cc464372 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / d1c60a53f60 |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/100/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/100/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/100/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 2765 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/100/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopci",
                "id": "17186538",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 59s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 14s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 25m 48s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 26m  1s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 21m 56s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 18s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 24m 55s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 45m 13s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 47s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  8m 40s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} spotbugs {color} | {color:blue} 36m 46s{color} | {color:blue} Used deprecated FindBugs config; considering switching to SpotBugs. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 16s{color} | {color:blue} branch/hadoop-project no findbugs output file (findbugsXml.xml) {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 58s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 39s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 20m 15s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 20m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 35s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 17m 35s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 44s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 18m  9s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 19s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  6m 30s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  5s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 15s{color} | {color:blue} hadoop-project has no data from findbugs {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}618m 13s{color} | {color:red} root in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 20s{color} | {color:red} The patch generated 4 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}977m 47s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption |\r\n|   | hadoop.yarn.server.resourcemanager.TestRMRestart |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeRespectsBindHostKeys |\r\n|   | hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader |\r\n|   | hadoop.hdfs.TestFileChecksum |\r\n|   | hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes |\r\n|   | hadoop.hdfs.TestGetFileChecksum |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics |\r\n|   | hadoop.hdfs.server.namenode.TestNameNodeMXBean |\r\n|   | hadoop.hdfs.server.namenode.ha.TestPipelinesFailover |\r\n|   | hadoop.hdfs.TestFileChecksumCompositeCrc |\r\n|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |\r\n|   | hadoop.fs.contract.router.TestRouterHDFSContractDelete |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/101/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13010631/YARN-10386-008.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml findbugs checkstyle |\r\n| uname | Linux 188e0b435189 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 06793da1001 |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/101/artifact/out/patch-unit-root.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/101/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/101/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 2911 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-project hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager . U: . |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/101/console |\r\n| versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "snemeth",
                "id": "17186614",
                "body": "Hi [~pbacsko],\r\nThanks for working on this patch and thanks for the meaningful discussion with [~shuzirra], very informative.\r\nI think the schema is more than good enough for the first commit, so I'm committing this right now.\r\nAs we discussed offline, if any change is required we can always create a subjira to this umbrella and fix / modify the schema.\r\nThanks again.\r\nThanks [~shuzirra] and [~adam.antal] for the reviews.\r\nCommitted to trunk."
            },
            {
                "author_name": "brahmareddy",
                "id": "17187290",
                "body": "[~snemeth]\u00a0and [~pbacsko].\r\n\r\n\u00a0\r\n\r\nLooks this patch introduced some ASF Warnings, please try to address check following for same. (Even last yetus report of the this Jira also show this errors.)\r\n\r\n[https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/116/artifact/out/patch-asflicense-problems.txt]"
            },
            {
                "author_name": "pbacsko",
                "id": "17187504",
                "body": "[~brahmareddy] I'll upload an addendum patch to solve this."
            },
            {
                "author_name": "hadoopci",
                "id": "17187655",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 32m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 18s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 47s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 39m 26s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 37s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 32s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 42s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 19s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 33s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 31s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 92m 49s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 27s{color} | {color:red} The patch generated 2 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}187m  8s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/113/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13010759/YARN-10386-appendum.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient |\r\n| uname | Linux 414a65a5ba63 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 60de592a883 |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/113/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/113/testReport/ |\r\n| asflicense | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/113/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 825 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/113/console |\r\n| versions | git=2.17.1 maven=3.6.0 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "pbacsko",
                "id": "17187674",
                "body": "The JSON schema now contains the license string.\r\n\r\nThe two files are automatically generated so it's a bit difficult to add to them, I'm not even sure if it's possible. We might need to resort to manual code generation + adding the license header.\r\n\r\ncc [~bteke] [~snemeth]."
            },
            {
                "author_name": "hadoopci",
                "id": "17187799",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 11s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} dupname {color} | {color:green}  0m  0s{color} | {color:green} No case conflicting files found. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m 20s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 56s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 48s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 39m 23s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 36s{color} | {color:green} trunk passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 32s{color} | {color:green} trunk passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 42s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 15s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 34s{color} | {color:green} the patch passed with JDK Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} the patch passed with JDK Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 93m  4s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 27s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}156m  9s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerPreemption |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | ClientAPI=1.40 ServerAPI=1.40 base: https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/115/artifact/out/Dockerfile |\r\n| JIRA Issue | YARN-10386 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/13010774/YARN-10386-appendum2.patch |\r\n| Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient xml |\r\n| uname | Linux 9d2a11de74b3 4.15.0-112-generic #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | personality/hadoop.sh |\r\n| git revision | trunk / 60de592a883 |\r\n| Default Java | Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.8+10-post-Ubuntu-0ubuntu118.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_265-8u265-b01-0ubuntu2~18.04-b01 |\r\n| unit | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/115/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n|  Test Results | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/115/testReport/ |\r\n| Max. process+thread count | 829 (vs. ulimit of 5500) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |\r\n| Console output | https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/115/console |\r\n| versions | git=2.17.1 maven=3.6.0 |\r\n| Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "pbacsko",
                "id": "17187811",
                "body": "OK, no more ASF warning. I added the two generated files to the RAT plugin ignore list. Since those are generated by a tool, this shouldn't be a problem.\r\n\r\n[~snemeth] [~bteke] pls review addendum-2."
            },
            {
                "author_name": "bteke",
                "id": "17187830",
                "body": "[~pbacsko], the addendum looks good to me. +1 (non-binding)"
            },
            {
                "author_name": "adam.antal",
                "id": "17188421",
                "body": "Thanks for the addendum patch [~pbacsko]. +1 from me, committed to trunk (let's not block other issues with this)."
            },
            {
                "author_name": "stevel@apache.org",
                "id": "17432649",
                "body": "This is somehow stopping java 17 (maybe 11_+?) compilation, as the generated classes have an import javax.annotation.Generated which is not in the JRE classes. \r\n\r\n{code}\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hadoop-yarn-server-resourcemanager: Compilation failure: Compilation failure:\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/MappingRulesDescription.java:[8,24] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: package javax.annotation\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/MappingRulesDescription.java:[20,2] cannot find symbol\r\n[ERROR]   symbol: class Generated\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[6,24] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: package javax.annotation\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[27,2] cannot find symbol\r\n[ERROR]   symbol: class Generated\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[304,6] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[255,6] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[214,6] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule\r\n[ERROR] -> [Help 1]\r\n[ERROR]\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR]\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\r\n[ERROR]\r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n[ERROR]   mvn <args> -rf :hadoop-yarn-server-resourcemanager\r\n{code}"
            },
            {
                "author_name": "tdomok",
                "id": "17433629",
                "body": "Hi [~stevel@apache.org]. Could you open a separate ticket for that compile issue with a reproduction step? (Locally I couldn't reproduce this yet, just a very similar issue: my generated code contained the wrong import statement\u00a0\r\n\r\n_import javax.annotation.processing.Generated;_ instead of the correct one _import javax.annotation.Generated;_)\r\n\r\n\u00a0\r\n\r\nProbably a missing dependency in the resource manager's pom file would solve this.\r\n{code:java}\r\n<dependency>\r\n  <groupId>javax.annotation</groupId>\r\n  <artifactId>javax.annotation-api</artifactId>\r\n  <scope>compile</scope>\r\n</dependency> {code}"
            },
            {
                "author_name": "stevel@apache.org",
                "id": "17435352",
                "body": "done: YARN-10992"
            }
        ],
        "comments_predictions": [
            [
                70160,
                "YARN-10386",
                "Attached v1 version of the schema.\r\n\r\nExplanation:\r\n* {{type}}: user / group / application --- pretty much the first column of the current format.\r\n* {{matches}}: it's either \"\\*\" or a specific group/user -- the second column of the current format (will use \"*\" instead of \"%user\").\r\n* {{policy}}: a fixed set of mapping policies, basically the same as an FS placement rule.\r\n* {{queue}}: if the policy is {{user}}, {{primaryGroup}}, {{secondaryGroup}}, then this is prepended to the queue string. If the rule is {{defaultQueue}} then \"root.default\" will be overridden.\r\n* {{nestedUserRule}}: optional, used only if {{nestedUser}} policy is defined. Note that unlike to Fair Scheduler, we don't have \"outer\" create flag, because it would require very deep changes in Capacity Scheduler. So we only support \"innerCreate\" for the \"%user\" part.\r\n* {{fallbackResult}}: what happens if the placement fails, eg. the target queue does not exist or cannot be created. Right now in CS, we return \"null\" for the placement context which is interpreted as \"root.default\". In FS, we proceed to the next rule. Here, we can fine-tune this behavior: {{skip}} is the FS approach, {{placeDefault}} is the CS approach, {{reject}} is new and straightforward (submission will be rejected on the client side).\r\n* {{defaultQueue}}: what should be the default queue in case of {{placeDefault}} fallback result.\r\n* {{create}}: whether the queue should be created or not if it does not exist. Note that the parent queue of the leaf must be a managed parent in order for this switch to have effect. \r\n",
                {
                    "property": {
                        "confidence": 0.005065775476396084,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006427475716918707,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.18178336322307587,
                        "prediction": false
                    }
                }
            ],
            [
                70161,
                "YARN-10386",
                "I've been thinking, probably \"defaultQueue\" should be renamed to something else. There's also a \"defaultQueue\" policy and users might think that they have to use \"defaultQueue\" to override \"root.default\". But it only affects \"placeDefault\" fallback rule, at least that's my intention right now. So we need to come up with some clever naming. I think \"fallbackDefaultQueue\" sounds better.",
                {
                    "property": {
                        "confidence": 0.005991349928081036,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00859782099723816,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007995368912816048,
                        "prediction": false
                    }
                }
            ],
            [
                70171,
                "YARN-10386",
                "Ok, the build what matters is https://ci-hadoop.apache.org/job/PreCommit-YARN-Build/96/.\r\n\r\nASF license warnings and the unit test failures can be ignored. Tests were executed for the whole project, but several times the forked process ran into resource limits.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004062592517584562,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.017159484326839447,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009791884571313858,
                        "prediction": false
                    }
                }
            ],
            [
                70172,
                "YARN-10386",
                "Thanks for working on this [~pbacsko].\r\n\r\nI saw you had some troubles with the jenkins. I don't see what exactly causes the jenkins failures but we should make sure that after we merge this, it won't appear in other jenkins results.\r\n\r\nRegarding the patch I have two comments:\r\n\r\nI am a little concerned about the checkstyle ignores:\r\n{noformat}\r\n@SuppressWarnings({\"checkstyle:hideutilityclassconstructor\", \"checkstyle:linelength\"})\r\n{noformat}\r\n- I don't see problems creating a private constructor for this class to prevent instantiation of this utility class.\r\n- Also, this can be moved to a constant: {{\"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema\"}} any maybe we can add the checkstyle warning annotation to only to the constant to be as restrictive as we can.\r\n\r\nOther: \r\n- In {{hadoop-yarn-server-resourcemanager/pom.xml}} can we also use the ${jsonschema2pojo.version} constant for the version if possible?\r\n\r\nI also add that I checked the new maven dependency and I saw no associated CVE-s to that, so I think it's fine to use it.",
                {
                    "property": {
                        "confidence": 0.006313658785074949,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012445761822164059,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0071479277685284615,
                        "prediction": false
                    }
                }
            ],
            [
                70173,
                "YARN-10386",
                "[~adam.antal] the entire project is findbugs/style checked and compiled many times over due to the modification in {{hadoop-project/pom.xml}}. That makes the build very slow and eventually it runs out of resources. \r\n\r\nAnyway I'll make the changes.\r\n\r\nAny thoughts about the JSON schema itself?",
                {
                    "property": {
                        "confidence": 0.004440214950591326,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.014876634813845158,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008140475489199162,
                        "prediction": false
                    }
                }
            ],
            [
                70174,
                "YARN-10386",
                "I'm not sure I understand your defaultQueue comment properly, but on the backend %default means root.default initially and if you user a VariableUpdateAction, it will change it for default placement targets and default fallbacks as well.\r\n\r\nWhy is the \"defaultQueue\" property a separate option not a policy? It is just a similar action to anything, and it cannot be added as an extra to any rule. I mean you cannot have a policy AND a change default queue, also default queue change is for the whole application submission, not only for the given rule.\r\n\r\nI think we are overusing the defaultQueue in the schema, we should use other names like, changeDefaultQueue, placeToDefaultQueue, fallbackToDefaultQueue or something along these lines to make sure it is clear what it will do.\r\n\r\nI think we have too many options under the properties and it can easily lead to incorrect configuration, I think we should move the nesterUserRule and the (change)defaultQueue into the policies. Nested user rules are just complex target paths, like root.%primary_group.%user, but nothing else, so I don't think we should move them to a separate property (I don't even think we need to do a separate policy for them, since we can just use regular queue placement).\r\n\r\nThe nested rules in FS always map to something like root.some.path.XXXX.%user, and the rule decides the XXXX part, if create is not allowed and the queue does not exist then it moves onto the next. (I know it also supports default, but it's like place to %default) So all this can be easily mapped to regular queue placement with rules like: root.%primary_group.%user on fallback skip.\r\n\r\nI would also add a \"custom\" to the type, since matcher also can be custom, not only rules.\r\n\r\n\u00a0\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.004932002630084753,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004697003401815891,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.07652636617422104,
                        "prediction": false
                    }
                }
            ],
            [
                70175,
                "YARN-10386",
                "\"Why is the \"defaultQueue\" property a separate option not a policy?\"\r\n\r\nThat's what I explained, it's confusing.  That's intended to set the fallback default queue, in case a fallback occurs and the {{fallbackResult}} is {{placeToDefault}}. \r\n\r\n\"I think we are overusing the defaultQueue in the schema, we should use other names like, changeDefaultQueue, placeToDefaultQueue, fallbackToDefaultQueue or something along these lines to make sure it is clear what it will do.\"\r\n\r\nYep, that's what my first command is about :)\r\n\r\n\"Nested\" is already a policy itself and the \"nestedUserRule\" is only interpreted if this particular policy is used.\r\n\r\nThe reason for a separate nested policy is to prevent users from all kinds of crazy configurations. Yes, the engine itself can happily resolve stuff like \"root.%default.%primary_group\", but I don't think these kind of configurations should be allowed. So the schema itself takes care of the allowed combinations. \r\n\r\nRegarding changing the default, I think it's an overkill to have a separate changeDefault policy. It's certainly how it works under the hood as an action, but I don't see too much benefit of exposing this. ",
                {
                    "property": {
                        "confidence": 0.0071969046257436275,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0032982060220092535,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03125346824526787,
                        "prediction": false
                    }
                }
            ],
            [
                70176,
                "YARN-10386",
                "Ok, had a discussion with [~shuzirra]. Now I can better understand what he meant above.\r\n\r\nThe following changes will be introduced:\r\n1. \"nestedUserRule\" will be removed, because it's used only in case of \"nestedUserRule\" policy.\r\n2. Add two new policies \"secondaryGroupUser\" and \"primaryGroupUser\".\r\n3. Remove \"defaultQueue\" setting. The default queue will be set with a different rule.\r\n4. Also introduce \"setDefaultQueue\" policy. This will change the default queue until it's set to something else.\r\n5. The naming of \"queue\" is misleading, let's change that to sth like \"parentQueue\" or \"parentQueuePath\".\r\n6. Custom policy: we can keep this and add a \"custom\" field perhaps. This can contain any random definition like {{root.user.%primary_group.%secondary_group}} and it will not be rejected. The tool won't validate whether the string makes any sense or not.",
                {
                    "property": {
                        "confidence": 0.00448929239064455,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008218460716307163,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014213590882718563,
                        "prediction": false
                    }
                }
            ],
            [
                70177,
                "YARN-10386",
                "Some examples:\r\n\r\n{{u:%user:%user}}\r\n{noformat}\r\n\"rules\":\r\n{\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"user\",\r\n\t\t\"fallbackResult\": \"placeDefault\"\r\n\t}\r\n}\r\n{noformat}\r\n\u00a0\r\n\r\n{{u:%user:root.dev.%primary_group.%user}}\r\n{noformat}\r\n\"rules\":\r\n{\t\r\n    {\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"primaryGroupUser\",\r\n\t\t\"parentQueue\": \"root.dev\",\r\n\t\t\"fallbackResult\": \"placeDefault\"\r\n\t}\r\n}\r\n{noformat}\r\n\u00a0\r\n\r\n{{u:%user:%secondary_group.%user}}\r\n{noformat}\r\n\"rules\":\r\n{\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"secondaryGroupUser\",\r\n\t\t\"fallbackResult\": \"placeDefault\"\r\n\t}\r\n}\r\n{noformat}\r\n\u00a0\r\n\r\n{{u:%user:root.users}}\r\n{noformat}\r\n\"rules\":\r\n{\t\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"setDefaultQueue\",\r\n\t\t\"value\": \"root.users\",\r\n\t\t\"fallbackResult\": \"skip\"\r\n\t},\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"defaultQueue\",\r\n\t\t\"fallbackResult\": \"placeDefault\"\r\n\t}\r\n}\r\n{noformat}\r\n\r\nAs we can see, we need two rules for a hard-coded path like \"root.users\". This might look weird, but this very similar to FS, where the rule is also called {{<default>}} with an overridden default queue. So in theory it's the same. \r\n\r\nThere is also an alternative for {{u:%user:root.users}}  (in fact, all rules could be rewritten with \"custom\", which is kind of a non-restriced way of specifying a target queue with arbitrary combination of placeholder variables).\r\n\r\n{noformat}\r\n\"rules\":\r\n{\r\n\t{\r\n\t\t\"type\": \"user\",\r\n\t\t\"matches\": \"*\",\r\n\t\t\"policy\": \"custom\",\r\n\t\t\"customPlacement\": \"root.users\"\r\n\t}\r\n}\r\n{noformat}",
                {
                    "property": {
                        "confidence": 0.0044005680829286575,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006057906895875931,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.028215162456035614,
                        "prediction": false
                    }
                }
            ],
            [
                70180,
                "YARN-10386",
                "Hi [~pbacsko],\r\nThanks for working on this patch and thanks for the meaningful discussion with [~shuzirra], very informative.\r\nI think the schema is more than good enough for the first commit, so I'm committing this right now.\r\nAs we discussed offline, if any change is required we can always create a subjira to this umbrella and fix / modify the schema.\r\nThanks again.\r\nThanks [~shuzirra] and [~adam.antal] for the reviews.\r\nCommitted to trunk.",
                {
                    "property": {
                        "confidence": 0.005305190104991198,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004843462258577347,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03569957613945007,
                        "prediction": false
                    }
                }
            ],
            [
                70181,
                "YARN-10386",
                "[~snemeth]\u00a0and [~pbacsko].\r\n\r\n\u00a0\r\n\r\nLooks this patch introduced some ASF Warnings, please try to address check following for same. (Even last yetus report of the this Jira also show this errors.)\r\n\r\n[https://ci-hadoop.apache.org/job/PreCommit-HDFS-Build/116/artifact/out/patch-asflicense-problems.txt]",
                {
                    "property": {
                        "confidence": 0.00441668601706624,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009643898345530033,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01121648121625185,
                        "prediction": false
                    }
                }
            ],
            [
                70184,
                "YARN-10386",
                "The JSON schema now contains the license string.\r\n\r\nThe two files are automatically generated so it's a bit difficult to add to them, I'm not even sure if it's possible. We might need to resort to manual code generation + adding the license header.\r\n\r\ncc [~bteke] [~snemeth].",
                {
                    "property": {
                        "confidence": 0.004067150875926018,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007216200698167086,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.034743644297122955,
                        "prediction": false
                    }
                }
            ],
            [
                70189,
                "YARN-10386",
                "This is somehow stopping java 17 (maybe 11_+?) compilation, as the generated classes have an import javax.annotation.Generated which is not in the JRE classes. \r\n\r\n{code}\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.1:compile (default-compile) on project hadoop-yarn-server-resourcemanager: Compilation failure: Compilation failure:\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/MappingRulesDescription.java:[8,24] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: package javax.annotation\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/MappingRulesDescription.java:[20,2] cannot find symbol\r\n[ERROR]   symbol: class Generated\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[6,24] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: package javax.annotation\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[27,2] cannot find symbol\r\n[ERROR]   symbol: class Generated\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[304,6] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[255,6] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule\r\n[ERROR] /Users/stevel/hadoop/commit/apache-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/placement/schema/Rule.java:[214,6] cannot find symbol\r\n[ERROR]   symbol:   class Generated\r\n[ERROR]   location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.placement.schema.Rule\r\n[ERROR] -> [Help 1]\r\n[ERROR]\r\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\r\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\r\n[ERROR]\r\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\r\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException\r\n[ERROR]\r\n[ERROR] After correcting the problems, you can resume the build with the command\r\n[ERROR]   mvn <args> -rf :hadoop-yarn-server-resourcemanager\r\n{code}",
                {
                    "property": {
                        "confidence": 0.0061203246004879475,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009494735859334469,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007634804118424654,
                        "prediction": false
                    }
                }
            ],
            [
                70190,
                "YARN-10386",
                "Hi [~stevel@apache.org]. Could you open a separate ticket for that compile issue with a reproduction step? (Locally I couldn't reproduce this yet, just a very similar issue: my generated code contained the wrong import statement\u00a0\r\n\r\n_import javax.annotation.processing.Generated;_ instead of the correct one _import javax.annotation.Generated;_)\r\n\r\n\u00a0\r\n\r\nProbably a missing dependency in the resource manager's pom file would solve this.\r\n{code:java}\r\n<dependency>\r\n  <groupId>javax.annotation</groupId>\r\n  <artifactId>javax.annotation-api</artifactId>\r\n  <scope>compile</scope>\r\n</dependency> {code}",
                {
                    "property": {
                        "confidence": 0.005586525890976191,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004649485927075148,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.024242401123046875,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d616c0f4d395ee2223c15d",
        "key": "DISPATCH-1802",
        "id": "13335242",
        "description": "Use after free crash:\u00a0 the router core thread attempts to activate the HTTP1 adaptor's connection at the same moment the I/O thread frees the proactor connection in response to endpoint connection drop.\r\n\r\nFairly easy to reproduce therefore blocker status.",
        "predictions": {},
        "comments": [
            {
                "author_name": "githubbot",
                "id": "17213350",
                "body": "kgiusti opened a new pull request #878:\nURL: https://github.com/apache/qpid-dispatch/pull/878\n\n\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "jira-bot",
                "id": "17214750",
                "body": "Commit 22dd27bf239911683efccea440de5a353a3cbdc5 in qpid-dispatch's branch refs/heads/dev-protocol-adaptors-2 from Ken Giusti\n[ https://gitbox.apache.org/repos/asf?p=qpid-dispatch.git;h=22dd27b ]\n\nDISPATCH-1802: HTTP/1.x prevent core connection activation race\n\nThis closes #878\n"
            },
            {
                "author_name": "githubbot",
                "id": "17214752",
                "body": "kgiusti closed pull request #878:\nURL: https://github.com/apache/qpid-dispatch/pull/878\n\n\n   \n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "17214753",
                "body": "kgiusti commented on pull request #878:\nURL: https://github.com/apache/qpid-dispatch/pull/878#issuecomment-709373619\n\n\n   Merged to dev-protocol-adaptors-2 branch\n\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on to GitHub and use the\nURL above to go to the specific comment.\n\nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5fc52f4d395ee22201edb",
        "key": "IGNITE-2897",
        "id": "12953574",
        "description": "*Problem*\nCurrently each node has ODBC enabled by default. ODBC processor has a single default port and each node tries to occupy it. As a result, second node cannot start due to port conflict.\n\n*Possible solutions*\n1) Do not start ODBC processor by default. \nCons: will require explicit config for ODBC users.\n\n2) Scan several ports until free port is found.\nCons: will require changes on client side.\n\nAnything else?\n\nI think that for now could go with the most easy and straightforward solution - do not start ODBC processor by default. This way we merge ODBC faster. In future releases we could easily make it start by default with normal port scan. It should not affect compatibility anyhow.\n\nThoughts?",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.003737322986125946
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.5780659914016724
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.07582829892635345
                }
            }
        },
        "comments": [
            {
                "author_name": "isapego",
                "id": "15214197",
                "body": "I believe we should disable ODBC by default for now. Scanning of several ports would be not just a fix for the issue but more like new feature."
            },
            {
                "author_name": "githubbot",
                "id": "15214251",
                "body": "GitHub user isapego opened a pull request:\n\n    https://github.com/apache/ignite/pull/583\n\n    IGNITE-2897: ODBC is now disabled by default.\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/isapego/ignite ignite-2897\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/ignite/pull/583.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #583\n    \n----\ncommit 546eeca158bb128641a1a602e8b081501d4b3286\nAuthor: isapego <isapego@gridgain.com>\nDate:   2016-03-28T14:27:14Z\n\n    IGNITE-2897: ODBC is now disabled by default.\n\n----\n"
            },
            {
                "author_name": "isapego",
                "id": "15214252",
                "body": "Ready for review."
            },
            {
                "author_name": "githubbot",
                "id": "15272424",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/ignite/pull/583\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d874f4d395ee2219e15a",
        "key": "SVN-4634",
        "id": "12969793",
        "description": "ra_serf can fail to commit the replacement of a directory containing locked files.\n\nThe issue occurs, if the directory which is to be replaced contains multiple locks.\n\nThe problem is related to Apache httpd's LimitRequestFieldSize setting, which SVN can exceed in cases of multiple locks being involved.\n\nNote: According to SVN-4557 (which this bugreport was split up from) the issue was introduced as part of the fix for SVN-3674. Hence it actually affects 1.8.10 already (couldn't select it in the version list though - therefore selected the next version instead).",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d627a5f4d395ee2226065f",
        "key": "AXIS-1367",
        "id": "21527",
        "description": "I reported this on the dev list to see if it was a bug and had no response:\n\nI have a WSDL doc that contains a schema and I'm running WSDL2Java -server.\n\nThe schema contains a simple type that is a parameter to one of the\n'methods' on the web service. The SimpleType looks like this:\n\n<xsd:simpleType name=\"ISBNType\">\n    <xsd:restriction base=\"xsd:string\">\n        <xsd:pattern value=\"[0-9]{3}-[0-9]{3}\"/>\n    </xsd:restriction>\n</xsd:simpleType>\n\n<xsd:element name=\"BookAvailabilityByISBN\" type=\"tns:ISBNType\"/>\n\nand then the WSDL has this\n\n<message name=\"getBookAvailabilityByISBNMsg\">\n    <part name=\"parameters\" element=\"operations:BookAvailabilityByISBN\"/>\n</message>\n\nThe generated Java for this looks like\n\npublic AvailabilityDetails getBookAvailabilityByISBN(String parameters)\nthrows java.rmi.RemoteException;\n\ni.e. it is defined as taking a String and no ISBNType Java type is defined. \n\nThe WSDD looks like this\n\n<typeMapping\n    xmlns:ns=\"urn:com.develop.ejws:orinoco\"\n    qname=\"ns:ISBNType\"\n    type=\"java:java.lang.String\"\n    serializer=\"org.apache.axis.encoding.ser.SimpleSerializerFactory\"\n    deserializer=\"org.apache.axis.encoding.ser.SimpleDeserializerFactory\"\n    encodingStyle=\"\"\n/>\n\nand when I browse to the generated WSDL (I'm letting the server re-generate\nthe WSDL) I get the following\n\n<element name=\"BookAvailabilityByISBN\" type=\"tns1:ISBNType\"/>\n\nbut no ISBNType is defined in the WSDL/Schema, so either the type here should be xsd:string or the WSDL needs to contain a definition for ISBNType",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.04538308456540108
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006931305397301912
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004955257289111614
                }
            }
        },
        "comments": [
            {
                "author_name": "dims",
                "id": "12316967",
                "body": "I believe this is fixed in Axis 1.2.1 as well. If not, please add a comment and i'll reopen the bug.\n\n-- dims"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d626a4f4d395ee2225ebbb",
        "key": "AXIS2-5364",
        "id": "12598132",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008355149999260902
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.04747921973466873
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0033277771435678005
                }
            }
        },
        "comments": [
            {
                "author_name": "sagara",
                "id": "13410099",
                "body": "Fixed in r1359499."
            },
            {
                "author_name": "hudson",
                "id": "15799521",
                "body": "SUCCESS: Integrated in Jenkins build Axis2 #3623 (See [https://builds.apache.org/job/Axis2/3623/])\nModify the Maven plugins so that they use SLF4J instead of Commons Logging. The SLF4J API is supported by recent Maven versions and the -X option is honored for log messages sent via that API.\n\nThis also eliminates the warning message about missing log4j configuration generated by the axis2-wsdl2code-maven-plugin described in AXIS2-5827 and caused by the change introduced in AXIS2-5364. (veithen: rev 1777379)\n* (edit) axis2/modules/tool/axis2-aar-maven-plugin/pom.xml\n* (edit) axis2/modules/tool/axis2-java2wsdl-maven-plugin/pom.xml\n* (edit) axis2/modules/tool/axis2-wsdl2code-maven-plugin/pom.xml\n* (edit) axis2/modules/tool/simple-server-maven-plugin/pom.xml\n* (edit) axis2/pom.xml\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d60f9ff4d395ee2222ae59",
        "key": "FLINK-8328",
        "id": "13127693",
        "description": "In order to make the {{FlinkYarnSessionCli}} work with Flip-6, we have to pull the Yarn {{ApplicationStatus}} polling out of the {{YarnClusterClient}}. I propose to introduce a dedicated {{YarnApplicationStatusMonitor}}. This has also the benefit of separating concerns better.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0038748662918806076
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.175851508975029
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0072774761356413364
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16306391",
                "body": "GitHub user tillrohrmann opened a pull request:\n\n    https://github.com/apache/flink/pull/5215\n\n    [FLINK-8328] [flip6] Move Yarn ApplicationStatus polling out of YarnClusterClient\n\n    ## What is the purpose of the change\r\n    \r\n    Introduce YarnApplicationStatusMonitor which does the Yarn ApplicationStatus polling in\r\n    the FlinkYarnSessionCli. This decouples the YarnClusterClient from the actual communication\r\n    with Yarn and, thus, gives a better separation of concerns.\r\n    \r\n    ## Brief change log\r\n    \r\n    - Replace the `PollingThread` with the `YarnApplicationStatusMonitor`\r\n    - Decouple `YarnClusterClient` from Yarn `ApplicationStatus` polling\r\n    \r\n    ## Verifying this change\r\n    \r\n    - Changes covered by existing tests\r\n    \r\n    ## Does this pull request potentially affect one of the following parts:\r\n    \r\n      - Dependencies (does it add or upgrade a dependency): (no)\r\n      - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (no)\r\n      - The serializers: (no)\r\n      - The runtime per-record code paths (performance sensitive): (no)\r\n      - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (yes)\r\n      - The S3 file system connector: (no)\r\n    \r\n    ## Documentation\r\n    \r\n      - Does this pull request introduce a new feature? (no)\r\n      - If yes, how is the feature documented? (not applicable)\r\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/tillrohrmann/flink removeSpecialClusterClients\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/flink/pull/5215.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #5215\n    \n----\ncommit 69ef9787f1278f40bfeaa685379648297e1cb6f0\nAuthor: Till Rohrmann <trohrmann@...>\nDate:   2017-12-07T12:57:24Z\n\n    [FLINK-8328] [flip6] Move Yarn ApplicationStatus polling out of YarnClusterClient\n    \n    Introduce YarnApplicationStatusMonitor which does the Yarn ApplicationStatus polling in\n    the FlinkYarnSessionCli. This decouples the YarnClusterClient from the actual communication\n    with Yarn and, thus, gives a better separation of concerns.\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "16308115",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r159227421\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -660,7 +570,25 @@ public int run(\n     \t\t\t\t\t\"yarn application -kill \" + applicationId.getOpt());\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, true);\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))) {\n    --- End diff --\n    \n    Why do we need to use the `ScheduledExecutor` interface from Flink? Why not use Java's `ScheduledExecutorService` directly?\n"
            },
            {
                "author_name": "githubbot",
                "id": "16308116",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r159227955\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -660,7 +570,25 @@ public int run(\n     \t\t\t\t\t\"yarn application -kill \" + applicationId.getOpt());\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, true);\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    --- End diff --\n    \n    I think the executor could as well be in the Monitor. If needed in the future, one could provide a constructor that accepts an external executor (e.g., for unit tests).\n"
            },
            {
                "author_name": "githubbot",
                "id": "16308117",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r159230885\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -743,6 +690,142 @@ private void logAndSysout(String message) {\n     \t\tSystem.out.println(message);\n     \t}\n     \n    +\tpublic static void main(final String[] args) throws Exception {\n    +\t\tfinal FlinkYarnSessionCli cli = new FlinkYarnSessionCli(\"\", \"\"); // no prefix for the YARN session\n    +\n    +\t\tfinal String configurationDirectory = CliFrontend.getConfigurationDirectoryFromEnv();\n    +\n    +\t\tfinal Configuration flinkConfiguration = GlobalConfiguration.loadConfiguration();\n    +\t\tSecurityUtils.install(new SecurityConfiguration(flinkConfiguration));\n    +\t\tint retCode = SecurityUtils.getInstalledContext().runSecured(new Callable<Integer>() {\n    +\t\t\t@Override\n    +\t\t\tpublic Integer call() {\n    +\t\t\t\treturn cli.run(args, flinkConfiguration, configurationDirectory);\n    +\t\t\t}\n    +\t\t});\n    +\t\tSystem.exit(retCode);\n    +\t}\n    +\n    +\tprivate static void runInteractiveCli(\n    +\t\tYarnClusterClient clusterClient,\n    +\t\tYarnApplicationStatusMonitor yarnApplicationStatusMonitor,\n    +\t\tboolean readConsoleInput) {\n    +\t\ttry (BufferedReader in = new BufferedReader(new InputStreamReader(System.in))) {\n    +\t\t\tboolean continueRepl = true;\n    +\t\t\tint numTaskmanagers = 0;\n    +\t\t\tlong unknownStatusSince = System.currentTimeMillis();\n    --- End diff --\n    \n    nit: `System.nanoTime()` should be preferred to measure elapsed time because it does not depend on wall clock, i.e., it is not affected by the user changing the system's time: https://stackoverflow.com/a/351571\r\n    However, if you use `nanoTime()`, the trick in line `729` with negative `unknownStatusSince` won't work.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16308118",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r159227619\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -717,7 +645,26 @@ public int run(\n     \t\t\t\tyarnCluster.waitForClusterToBeReady();\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, acceptInteractiveInput);\n    +\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))){\n    +\t\t\t\t\trunInteractiveCli(\n    +\t\t\t\t\t\tyarnCluster,\n    +\t\t\t\t\t\tyarnApplicationStatusMonitor,\n    +\t\t\t\t\t\tacceptInteractiveInput);\n    +\t\t\t\t} catch (Exception e) {\n    +\t\t\t\t\tLOG.info(\"Could not properly close the Yarn application status monitor.\", e);\n    --- End diff --\n    \n    Same here. Catch block could be avoided.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16308119",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r159225871\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/YarnApplicationStatusMonitor.java ---\n    @@ -0,0 +1,101 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + * or more contributor license agreements.  See the NOTICE file\n    + * distributed with this work for additional information\n    + * regarding copyright ownership.  The ASF licenses this file\n    + * to you under the Apache License, Version 2.0 (the\n    + * \"License\"); you may not use this file except in compliance\n    + * with the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +\n    +package org.apache.flink.yarn.cli;\n    +\n    +import org.apache.flink.runtime.clusterframework.ApplicationStatus;\n    +import org.apache.flink.runtime.concurrent.ScheduledExecutor;\n    +import org.apache.flink.util.Preconditions;\n    +\n    +import org.apache.hadoop.service.Service;\n    +import org.apache.hadoop.yarn.api.records.ApplicationId;\n    +import org.apache.hadoop.yarn.api.records.ApplicationReport;\n    +import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n    +import org.apache.hadoop.yarn.client.api.YarnClient;\n    +import org.slf4j.Logger;\n    +import org.slf4j.LoggerFactory;\n    +\n    +import java.util.concurrent.ScheduledFuture;\n    +import java.util.concurrent.TimeUnit;\n    +\n    +/**\n    + * Utility class which monitors the specified yarn application status periodically.\n    + */\n    +public class YarnApplicationStatusMonitor implements AutoCloseable {\n    +\n    +\tprivate static final Logger LOG = LoggerFactory.getLogger(YarnApplicationStatusMonitor.class);\n    +\n    +\tprivate static final long UPDATE_INTERVAL = 1000L;\n    +\n    +\tprivate final YarnClient yarnClient;\n    +\n    +\tprivate final ApplicationId yarnApplicationId;\n    +\n    +\tprivate final ScheduledFuture<?> applicationStatusUpdateFuture;\n    +\n    +\tprivate volatile ApplicationStatus applicationStatus;\n    +\n    +\tpublic YarnApplicationStatusMonitor(\n    +\t\t\tYarnClient yarnClient,\n    +\t\t\tApplicationId yarnApplicationId,\n    +\t\t\tScheduledExecutor scheduledExecutor) {\n    +\t\tthis.yarnClient = Preconditions.checkNotNull(yarnClient);\n    +\t\tthis.yarnApplicationId = Preconditions.checkNotNull(yarnApplicationId);\n    +\n    +\t\tapplicationStatusUpdateFuture = scheduledExecutor.scheduleWithFixedDelay(\n    +\t\t\tthis::updateApplicationStatus,\n    +\t\t\tUPDATE_INTERVAL,\n    +\t\t\tUPDATE_INTERVAL,\n    +\t\t\tTimeUnit.MILLISECONDS);\n    +\n    +\t\tapplicationStatus = ApplicationStatus.UNKNOWN;\n    +\t}\n    +\n    +\tpublic ApplicationStatus getApplicationStatusNow() {\n    +\t\treturn applicationStatus;\n    +\t}\n    +\n    +\t@Override\n    +\tpublic void close() throws Exception {\n    +\t\tapplicationStatusUpdateFuture.cancel(false);\n    --- End diff --\n    \n    There is no need to declare `throws Exception` here because `cancel()` does not throw any checked exceptions.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16308120",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r159224695\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -743,6 +690,142 @@ private void logAndSysout(String message) {\n     \t\tSystem.out.println(message);\n     \t}\n     \n    +\tpublic static void main(final String[] args) throws Exception {\n    +\t\tfinal FlinkYarnSessionCli cli = new FlinkYarnSessionCli(\"\", \"\"); // no prefix for the YARN session\n    +\n    +\t\tfinal String configurationDirectory = CliFrontend.getConfigurationDirectoryFromEnv();\n    +\n    +\t\tfinal Configuration flinkConfiguration = GlobalConfiguration.loadConfiguration();\n    +\t\tSecurityUtils.install(new SecurityConfiguration(flinkConfiguration));\n    +\t\tint retCode = SecurityUtils.getInstalledContext().runSecured(new Callable<Integer>() {\n    +\t\t\t@Override\n    +\t\t\tpublic Integer call() {\n    +\t\t\t\treturn cli.run(args, flinkConfiguration, configurationDirectory);\n    +\t\t\t}\n    +\t\t});\n    +\t\tSystem.exit(retCode);\n    +\t}\n    +\n    +\tprivate static void runInteractiveCli(\n    +\t\tYarnClusterClient clusterClient,\n    +\t\tYarnApplicationStatusMonitor yarnApplicationStatusMonitor,\n    +\t\tboolean readConsoleInput) {\n    +\t\ttry (BufferedReader in = new BufferedReader(new InputStreamReader(System.in))) {\n    +\t\t\tboolean continueRepl = true;\n    +\t\t\tint numTaskmanagers = 0;\n    +\t\t\tlong unknownStatusSince = System.currentTimeMillis();\n    +\n    +\t\t\twhile (continueRepl) {\n    +\n    +\t\t\t\tfinal ApplicationStatus applicationStatus = yarnApplicationStatusMonitor.getApplicationStatusNow();\n    +\n    +\t\t\t\tswitch (applicationStatus) {\n    +\t\t\t\t\tcase FAILED:\n    +\t\t\t\t\tcase CANCELED:\n    +\t\t\t\t\t\tSystem.err.println(\"The Flink Yarn cluster has failed.\");\n    +\t\t\t\t\t\tcontinueRepl = false;\n    +\t\t\t\t\t\tbreak;\n    +\t\t\t\t\tcase UNKNOWN:\n    +\t\t\t\t\t\tif (unknownStatusSince < 0L) {\n    +\t\t\t\t\t\t\tunknownStatusSince = System.currentTimeMillis();\n    +\t\t\t\t\t\t}\n    +\n    +\t\t\t\t\t\tif ((System.currentTimeMillis() - unknownStatusSince) > CLIENT_POLLING_INTERVAL_MS) {\n    +\t\t\t\t\t\t\tSystem.err.println(\"The Flink Yarn cluster is in an unknown state. Please check the Yarn cluster.\");\n    +\t\t\t\t\t\t\tcontinueRepl = false;\n    +\t\t\t\t\t\t} else {\n    +\t\t\t\t\t\t\tcontinueRepl = repStep(in, readConsoleInput);\n    +\t\t\t\t\t\t}\n    +\t\t\t\t\t\tbreak;\n    +\t\t\t\t\tcase SUCCEEDED:\n    +\t\t\t\t\t\tif (unknownStatusSince > 0L) {\n    +\t\t\t\t\t\t\tunknownStatusSince = -1L;\n    +\t\t\t\t\t\t}\n    +\n    +\t\t\t\t\t\t// ------------------ check if there are updates by the cluster -----------\n    +\t\t\t\t\t\ttry {\n    +\t\t\t\t\t\t\tfinal GetClusterStatusResponse status = clusterClient.getClusterStatus();\n    +\n    +\t\t\t\t\t\t\tif (status != null && numTaskmanagers != status.numRegisteredTaskManagers()) {\n    +\t\t\t\t\t\t\t\tSystem.err.println(\"Number of connected TaskManagers changed to \" +\n    +\t\t\t\t\t\t\t\t\tstatus.numRegisteredTaskManagers() + \". \" +\n    +\t\t\t\t\t\t\t\t\t\"Slots available: \" + status.totalNumberOfSlots());\n    +\t\t\t\t\t\t\t\tnumTaskmanagers = status.numRegisteredTaskManagers();\n    +\t\t\t\t\t\t\t}\n    +\t\t\t\t\t\t} catch (Exception e) {\n    +\t\t\t\t\t\t\tLOG.warn(\"Could not retrieve the current cluster status. Skipping current retrieval attempt ...\", e);\n    +\t\t\t\t\t\t}\n    +\n    +\t\t\t\t\t\tprintClusterMessages(clusterClient);\n    +\n    +\t\t\t\t\t\tcontinueRepl = repStep(in, readConsoleInput);\n    +\t\t\t\t}\n    +\t\t\t}\n    +\t\t} catch (Exception e) {\n    +\t\t\tLOG.warn(\"Exception while running the interactive command line interface.\", e);\n    +\t\t}\n    +\t}\n    +\n    +\tprivate static void printClusterMessages(YarnClusterClient clusterClient) {\n    +\t\tfinal List<String> messages = clusterClient.getNewMessages();\n    +\t\tif (messages != null && messages.size() > 0) {\n    --- End diff --\n    \n    nit: ```if (!messages.isEmpty())``` should suffice because `messages` is never null\n"
            },
            {
                "author_name": "githubbot",
                "id": "16308121",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r159226314\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -660,7 +570,25 @@ public int run(\n     \t\t\t\t\t\"yarn application -kill \" + applicationId.getOpt());\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, true);\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))) {\n    +\t\t\t\t\trunInteractiveCli(\n    +\t\t\t\t\t\tyarnCluster,\n    +\t\t\t\t\t\tyarnApplicationStatusMonitor,\n    +\t\t\t\t\t\ttrue);\n    +\t\t\t\t} catch (Exception e) {\n    --- End diff --\n    \n    Closing `YarnApplicationStatusMonitor` should not throw any checked exceptions. If you change the signature, this catch block won't be needed.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16308122",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r159228367\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -717,7 +645,26 @@ public int run(\n     \t\t\t\tyarnCluster.waitForClusterToBeReady();\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, acceptInteractiveInput);\n    +\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))){\n    +\t\t\t\t\trunInteractiveCli(\n    +\t\t\t\t\t\tyarnCluster,\n    +\t\t\t\t\t\tyarnApplicationStatusMonitor,\n    +\t\t\t\t\t\tacceptInteractiveInput);\n    --- End diff --\n    \n    The code block looks duplicated except for this flag.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320215",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160674117\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -660,7 +570,25 @@ public int run(\n     \t\t\t\t\t\"yarn application -kill \" + applicationId.getOpt());\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, true);\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    --- End diff --\n    \n    Yes it could be. That way, however, we support that we can use an arbitrary executor which is available (as you've mentioned for tests). Since refactoring wouldn't add much value, I'll keep it like this.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320216",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160674427\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -660,7 +570,25 @@ public int run(\n     \t\t\t\t\t\"yarn application -kill \" + applicationId.getOpt());\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, true);\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))) {\n    --- End diff --\n    \n    The `ScheduledExecutor` gives a better abstraction because it does not expose service control methods like shutdown to the callee. I think the Java abstraction is slightly broken in this regard.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320218",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160674586\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/YarnApplicationStatusMonitor.java ---\n    @@ -0,0 +1,101 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one\n    + * or more contributor license agreements.  See the NOTICE file\n    + * distributed with this work for additional information\n    + * regarding copyright ownership.  The ASF licenses this file\n    + * to you under the Apache License, Version 2.0 (the\n    + * \"License\"); you may not use this file except in compliance\n    + * with the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +\n    +package org.apache.flink.yarn.cli;\n    +\n    +import org.apache.flink.runtime.clusterframework.ApplicationStatus;\n    +import org.apache.flink.runtime.concurrent.ScheduledExecutor;\n    +import org.apache.flink.util.Preconditions;\n    +\n    +import org.apache.hadoop.service.Service;\n    +import org.apache.hadoop.yarn.api.records.ApplicationId;\n    +import org.apache.hadoop.yarn.api.records.ApplicationReport;\n    +import org.apache.hadoop.yarn.api.records.YarnApplicationState;\n    +import org.apache.hadoop.yarn.client.api.YarnClient;\n    +import org.slf4j.Logger;\n    +import org.slf4j.LoggerFactory;\n    +\n    +import java.util.concurrent.ScheduledFuture;\n    +import java.util.concurrent.TimeUnit;\n    +\n    +/**\n    + * Utility class which monitors the specified yarn application status periodically.\n    + */\n    +public class YarnApplicationStatusMonitor implements AutoCloseable {\n    +\n    +\tprivate static final Logger LOG = LoggerFactory.getLogger(YarnApplicationStatusMonitor.class);\n    +\n    +\tprivate static final long UPDATE_INTERVAL = 1000L;\n    +\n    +\tprivate final YarnClient yarnClient;\n    +\n    +\tprivate final ApplicationId yarnApplicationId;\n    +\n    +\tprivate final ScheduledFuture<?> applicationStatusUpdateFuture;\n    +\n    +\tprivate volatile ApplicationStatus applicationStatus;\n    +\n    +\tpublic YarnApplicationStatusMonitor(\n    +\t\t\tYarnClient yarnClient,\n    +\t\t\tApplicationId yarnApplicationId,\n    +\t\t\tScheduledExecutor scheduledExecutor) {\n    +\t\tthis.yarnClient = Preconditions.checkNotNull(yarnClient);\n    +\t\tthis.yarnApplicationId = Preconditions.checkNotNull(yarnApplicationId);\n    +\n    +\t\tapplicationStatusUpdateFuture = scheduledExecutor.scheduleWithFixedDelay(\n    +\t\t\tthis::updateApplicationStatus,\n    +\t\t\tUPDATE_INTERVAL,\n    +\t\t\tUPDATE_INTERVAL,\n    +\t\t\tTimeUnit.MILLISECONDS);\n    +\n    +\t\tapplicationStatus = ApplicationStatus.UNKNOWN;\n    +\t}\n    +\n    +\tpublic ApplicationStatus getApplicationStatusNow() {\n    +\t\treturn applicationStatus;\n    +\t}\n    +\n    +\t@Override\n    +\tpublic void close() throws Exception {\n    +\t\tapplicationStatusUpdateFuture.cancel(false);\n    --- End diff --\n    \n    true, will remove it.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320219",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160674722\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -660,7 +570,25 @@ public int run(\n     \t\t\t\t\t\"yarn application -kill \" + applicationId.getOpt());\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, true);\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))) {\n    +\t\t\t\t\trunInteractiveCli(\n    +\t\t\t\t\t\tyarnCluster,\n    +\t\t\t\t\t\tyarnApplicationStatusMonitor,\n    +\t\t\t\t\t\ttrue);\n    +\t\t\t\t} catch (Exception e) {\n    --- End diff --\n    \n    True, will remove it.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320220",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160674931\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -717,7 +645,26 @@ public int run(\n     \t\t\t\tyarnCluster.waitForClusterToBeReady();\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, acceptInteractiveInput);\n    +\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))){\n    +\t\t\t\t\trunInteractiveCli(\n    +\t\t\t\t\t\tyarnCluster,\n    +\t\t\t\t\t\tyarnApplicationStatusMonitor,\n    +\t\t\t\t\t\tacceptInteractiveInput);\n    +\t\t\t\t} catch (Exception e) {\n    +\t\t\t\t\tLOG.info(\"Could not properly close the Yarn application status monitor.\", e);\n    --- End diff --\n    \n    Changed it.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320221",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160674936\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -717,7 +645,26 @@ public int run(\n     \t\t\t\tyarnCluster.waitForClusterToBeReady();\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, acceptInteractiveInput);\n    +\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))){\n    +\t\t\t\t\trunInteractiveCli(\n    +\t\t\t\t\t\tyarnCluster,\n    +\t\t\t\t\t\tyarnApplicationStatusMonitor,\n    +\t\t\t\t\t\tacceptInteractiveInput);\n    --- End diff --\n    \n    Yes it is. In one of my later PRs, I removed this code duplication. Therefore I leave it like this for the moment.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320223",
                "body": "Github user tillrohrmann commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160675128\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -743,6 +690,142 @@ private void logAndSysout(String message) {\n     \t\tSystem.out.println(message);\n     \t}\n     \n    +\tpublic static void main(final String[] args) throws Exception {\n    +\t\tfinal FlinkYarnSessionCli cli = new FlinkYarnSessionCli(\"\", \"\"); // no prefix for the YARN session\n    +\n    +\t\tfinal String configurationDirectory = CliFrontend.getConfigurationDirectoryFromEnv();\n    +\n    +\t\tfinal Configuration flinkConfiguration = GlobalConfiguration.loadConfiguration();\n    +\t\tSecurityUtils.install(new SecurityConfiguration(flinkConfiguration));\n    +\t\tint retCode = SecurityUtils.getInstalledContext().runSecured(new Callable<Integer>() {\n    +\t\t\t@Override\n    +\t\t\tpublic Integer call() {\n    +\t\t\t\treturn cli.run(args, flinkConfiguration, configurationDirectory);\n    +\t\t\t}\n    +\t\t});\n    +\t\tSystem.exit(retCode);\n    +\t}\n    +\n    +\tprivate static void runInteractiveCli(\n    +\t\tYarnClusterClient clusterClient,\n    +\t\tYarnApplicationStatusMonitor yarnApplicationStatusMonitor,\n    +\t\tboolean readConsoleInput) {\n    +\t\ttry (BufferedReader in = new BufferedReader(new InputStreamReader(System.in))) {\n    +\t\t\tboolean continueRepl = true;\n    +\t\t\tint numTaskmanagers = 0;\n    +\t\t\tlong unknownStatusSince = System.currentTimeMillis();\n    +\n    +\t\t\twhile (continueRepl) {\n    +\n    +\t\t\t\tfinal ApplicationStatus applicationStatus = yarnApplicationStatusMonitor.getApplicationStatusNow();\n    +\n    +\t\t\t\tswitch (applicationStatus) {\n    +\t\t\t\t\tcase FAILED:\n    +\t\t\t\t\tcase CANCELED:\n    +\t\t\t\t\t\tSystem.err.println(\"The Flink Yarn cluster has failed.\");\n    +\t\t\t\t\t\tcontinueRepl = false;\n    +\t\t\t\t\t\tbreak;\n    +\t\t\t\t\tcase UNKNOWN:\n    +\t\t\t\t\t\tif (unknownStatusSince < 0L) {\n    +\t\t\t\t\t\t\tunknownStatusSince = System.currentTimeMillis();\n    +\t\t\t\t\t\t}\n    +\n    +\t\t\t\t\t\tif ((System.currentTimeMillis() - unknownStatusSince) > CLIENT_POLLING_INTERVAL_MS) {\n    +\t\t\t\t\t\t\tSystem.err.println(\"The Flink Yarn cluster is in an unknown state. Please check the Yarn cluster.\");\n    +\t\t\t\t\t\t\tcontinueRepl = false;\n    +\t\t\t\t\t\t} else {\n    +\t\t\t\t\t\t\tcontinueRepl = repStep(in, readConsoleInput);\n    +\t\t\t\t\t\t}\n    +\t\t\t\t\t\tbreak;\n    +\t\t\t\t\tcase SUCCEEDED:\n    +\t\t\t\t\t\tif (unknownStatusSince > 0L) {\n    +\t\t\t\t\t\t\tunknownStatusSince = -1L;\n    +\t\t\t\t\t\t}\n    +\n    +\t\t\t\t\t\t// ------------------ check if there are updates by the cluster -----------\n    +\t\t\t\t\t\ttry {\n    +\t\t\t\t\t\t\tfinal GetClusterStatusResponse status = clusterClient.getClusterStatus();\n    +\n    +\t\t\t\t\t\t\tif (status != null && numTaskmanagers != status.numRegisteredTaskManagers()) {\n    +\t\t\t\t\t\t\t\tSystem.err.println(\"Number of connected TaskManagers changed to \" +\n    +\t\t\t\t\t\t\t\t\tstatus.numRegisteredTaskManagers() + \". \" +\n    +\t\t\t\t\t\t\t\t\t\"Slots available: \" + status.totalNumberOfSlots());\n    +\t\t\t\t\t\t\t\tnumTaskmanagers = status.numRegisteredTaskManagers();\n    +\t\t\t\t\t\t\t}\n    +\t\t\t\t\t\t} catch (Exception e) {\n    +\t\t\t\t\t\t\tLOG.warn(\"Could not retrieve the current cluster status. Skipping current retrieval attempt ...\", e);\n    +\t\t\t\t\t\t}\n    +\n    +\t\t\t\t\t\tprintClusterMessages(clusterClient);\n    +\n    +\t\t\t\t\t\tcontinueRepl = repStep(in, readConsoleInput);\n    +\t\t\t\t}\n    +\t\t\t}\n    +\t\t} catch (Exception e) {\n    +\t\t\tLOG.warn(\"Exception while running the interactive command line interface.\", e);\n    +\t\t}\n    +\t}\n    +\n    +\tprivate static void printClusterMessages(YarnClusterClient clusterClient) {\n    +\t\tfinal List<String> messages = clusterClient.getNewMessages();\n    +\t\tif (messages != null && messages.size() > 0) {\n    --- End diff --\n    \n    true. Will change it.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320258",
                "body": "Github user tillrohrmann commented on the issue:\n\n    https://github.com/apache/flink/pull/5215\n  \n    Thanks for the review @GJL. I've addressed your comments. Once Travis gives green light, I'll merge the PR.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320374",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160699235\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -660,7 +570,25 @@ public int run(\n     \t\t\t\t\t\"yarn application -kill \" + applicationId.getOpt());\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, true);\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    --- End diff --\n    \n    ok\n"
            },
            {
                "author_name": "githubbot",
                "id": "16320376",
                "body": "Github user GJL commented on a diff in the pull request:\n\n    https://github.com/apache/flink/pull/5215#discussion_r160699294\n  \n    --- Diff: flink-yarn/src/main/java/org/apache/flink/yarn/cli/FlinkYarnSessionCli.java ---\n    @@ -717,7 +645,26 @@ public int run(\n     \t\t\t\tyarnCluster.waitForClusterToBeReady();\n     \t\t\t\tyarnCluster.disconnect();\n     \t\t\t} else {\n    -\t\t\t\trunInteractiveCli(yarnCluster, acceptInteractiveInput);\n    +\n    +\t\t\t\tScheduledThreadPoolExecutor scheduledExecutorService = new ScheduledThreadPoolExecutor(1);\n    +\n    +\t\t\t\ttry (YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(\n    +\t\t\t\t\t\tyarnDescriptor.getYarnClient(),\n    +\t\t\t\t\t\tyarnCluster.getApplicationId(),\n    +\t\t\t\t\t\tnew ScheduledExecutorServiceAdapter(scheduledExecutorService))){\n    +\t\t\t\t\trunInteractiveCli(\n    +\t\t\t\t\t\tyarnCluster,\n    +\t\t\t\t\t\tyarnApplicationStatusMonitor,\n    +\t\t\t\t\t\tacceptInteractiveInput);\n    --- End diff --\n    \n    ok\n"
            },
            {
                "author_name": "githubbot",
                "id": "16322477",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/flink/pull/5215\n"
            },
            {
                "author_name": "trohrmann",
                "id": "16322481",
                "body": "Fixed via 2ce5b98da04cb3850ff91757cc4b74a98b8ce082"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d60e54f4d395ee22229644",
        "key": "FLINK-14513",
        "id": "13264156",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.07545625418424606
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007418057415634394
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0041975234635174274
                }
            }
        },
        "comments": [
            {
                "author_name": "Terry1897",
                "id": "16958469",
                "body": "Feel free to assign this task to me :)"
            },
            {
                "author_name": "ykt836",
                "id": "16991426",
                "body": "master:\u00a047f29391cf4c0c856e2401289c06658471508654"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640743e39752de65d7d2b159",
        "key": "ZOOKEEPER-3286",
        "id": "13217308",
        "description": "*Description:*\r\n\r\nThe get_xid functions in mt_adaptor.c/st_adaptor.c return a 32 bit signed integer that is initialized to the current unix epoch timestamp on startup.\r\n\r\nThis counter will eventually wrap around, which is not a problem per se, since the client does not expect XID values to monotonically increase: It just verifies that replies to operations come back in order by checking the XID of a request received against the next XID expected. (zookeeper.c:zookeeper_process).\r\n\r\nHowever, after a wrap-around the XID values will eventually collide with the reserved XIDs ad defined in zk_adaptor.h:\r\n * The first collision will be with SET_WATCHES_XID (-8): The reply to the request that happens to get tagged with -8 will be misinterpreted as a reply to SET_WATCHES. This causes the client to see a connection timeout.\r\n * The next collision will be with AUTH_XID (-4): At that point the client will segfault, when mis-interpreting the reply:\r\n\r\n#0\u00a0 0x0000000000407645 in auth_completion_func (zh=0x61d010, rc=0) at src/zookeeper.c:1823\r\n #1\u00a0 zookeeper_process (zh=zh@entry=0x61d010, events=<optimized out>) at src/zookeeper.c:2896\r\n #2\u00a0 0x000000000040c34c in do_io (v=0x61d010) at src/mt_adaptor.c:451\r\n #3\u00a0 0x00007ffff7bc8dc5 in start_thread () from /lib64/libpthread.so.0\r\n #4\u00a0 0x00007ffff75f573d in clone () from /lib64/libc.so.6\r\n\r\nI hit this with a busy C client that runs for a very long time (months). Also, when a client spins in a tight loop trying to submit more operations even for a short period of time after a connection loss the xid values will increment very fast.\r\n\r\n\u00a0\r\n\r\n*Proposed patch:*\r\n\r\nTo avoid introducing any additional locking, this can be solved by just masking out the MSB in the xid returned by get_xid. Effectively this prevents the returned XID from ever going negative.\r\n\r\nTo avoid a race when the static xid variable hits -1 eventually after a wrap, around, I propose to not initialize xid with the result of time(0) on startup. This is not needed. This also means that the get_xid function in mt_adapter.c no longer needs to be flagged as constructor.\r\n\r\n\u00a0Proposed patch is attached.\r\n\r\n\u00a0\r\n\r\nI ran into this on zookeeper 3.5.4 but other versions are likely affected as well.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.004892013967037201
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.017303386703133583
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006008446216583252
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5debaf4d395ee221b1d43",
        "key": "SMX4-440",
        "id": "12489859",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.010404262691736221
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.017236603423953056
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.003987468779087067
                }
            }
        },
        "comments": [
            {
                "author_name": "ffang",
                "id": "12961072",
                "body": "commit fix\nhttp://svn.apache.org/viewvc?rev=886725&view=rev"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640744b0d1992f944d33b8b5",
        "key": "LUCENE-10429",
        "id": "13429639",
        "description": "Currently the contract of DocIdSetBulder#grow says:\r\n\r\n{noformat}\r\n/**\r\n * Reserve space and return a \\{@link BulkAdder} object that can be used to add up to \\{@code * numDocs}documents.\r\n*/\r\npublic BulkAdder grow(int numDocs)\r\n{noformat}\r\n\r\n\u00a0\r\nI would expect that from the PointValues API I could call this method by using the following:\r\n\r\n{noformat}\r\nDocIdSetBulder#grow((int) Math.min(docCount, node.size()));\r\n{noformat}\r\n\r\nBut it seems it is not true as the implementation expects that the method is grow for all the call to growAdder, counting duplicated documents. Therefore we have this other implementation of addAll instead, to make happy the implementation:\r\n\r\n{noformat}\r\n public void addAll(PointValues.IntersectVisitor visitor, boolean grown) throws IOException {\r\n      if (grown == false) {\r\n        final long size = size();\r\n        if (size <= Integer.MAX_VALUE) {\r\n          visitor.grow((int) size);\r\n          grown = true;\r\n        }\r\n      }\r\n      if (isLeafNode()) {\r\n        // Leaf node\r\n        leafNodes.seek(getLeafBlockFP());\r\n        // How many points are stored in this leaf cell:\r\n        int count = leafNodes.readVInt();\r\n        // No need to call grow(), it has been called up-front\r\n        docIdsWriter.readInts(leafNodes, count, visitor);\r\n      } else {\r\n        pushLeft();\r\n        addAll(visitor, grown);\r\n        pop();\r\n        pushRight();\r\n        addAll(visitor, grown);\r\n        pop();\r\n      }\r\n    }\r\n\r\n{noformat}\r\n\r\nTherefore we have three options here:\r\n\r\n1) Modify the grow API to reflect that it can be called more than Integer#MAX_VALUE, and therefore change the input parameter from int to long. Note that this method is exposed due to the points API so we have tried this implementation in LUCENE-10311 by creating a specific implementation of DocIdSetBuilder for points. This has so far been rejected.\r\n\r\n2) Modify the implementation of DocIdSetBuilder. Currently the issue is that we have a counter inside the implementation that it is used to compute the cost for the dense case of the final iterator. Therefore we need to change the way we compute the cost.\r\nThe proposal here is to change the way we compute cost from:\r\n{noformat}\r\n final long cost = Math.round(counter / numValuesPerDoc);\r\n{noformat}\r\nWhich might underestimate the cost of the iterator to the following that overestimate the cost:\r\n{noformat}\r\n final long cost = Math.min(counter, docCount))\r\n{noformat}\r\nI lack of intuition of how this might affect performance down the line. One thing I notice is that for the Terms API (that is when we add docs using a DocIdSetIterator via DocIdSetBuilder#add), we ignore the counter in the dense case, so we are already providing a totally wrong cost on that case! \r\n\r\n3) If none of this proposals is successful we should at least update the java docs to reflect reality.\r\n\r\n\r\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.019262244924902916
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01655646227300167
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0033420997206121683
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640743bec8b42db502d2af6b",
        "key": "ARROW-2633",
        "id": "13161545",
        "description": "\u00a0\r\nI am trying to read a parquet file in pandas dataframe, do some manipulation and write it back in the same file, however it seems file is not accessible to write after the first read in same function.\r\n\r\nIt only works, if I don't perform STEP 1 below. Is there anyway to unlock the file as such?\r\n\r\n{code:python}\r\n#STEP 1: Read entire parquet file\r\npq_file = pq.ParquetFile('\\dev\\abc.parquet')\r\nexp_df = pq_file.read(nthreads=1, use_pandas_metadata=True).to_pandas()\r\n#STEP 2: Change some data in dataframe\r\n#\r\n#STEP 3: write merged dataframe\r\npyarrow_table = pa.Table.from_pandas(exp_df)\r\npq.write_table(pyarrow_table, '\\dev\\abc.parquet',compression='none',)\r\n{code}\r\n\r\nError:\r\n\r\n{code}\r\nFile \"C:\\Python36\\lib\\site-packages\\pyarrow\\parquet.py\", line 943, in write_table\r\n **kwargs)\r\nFile \"C:\\Python36\\lib\\site-packages\\pyarrow\\parquet.py\", line 286, in __init__\r\n **options)\r\nFile \"_parquet.pyx\", line 832, in pyarrow._parquet.ParquetWriter.__cinit__\r\nFile \"error.pxi\", line 79, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowIOError: Failed to open local file: \\dev\\abc.parquet , error: Invalid argument\r\n{code}",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d4cff4d395ee2218b1b7",
        "key": "WICKET-5388",
        "id": "12673628",
        "description": "Please add a way to unregister DebugBar contributors.\n\nI wish to remove some of the default contributors and currently have to do this by using reflection to lookup the \"CONTRIBS_META_KEY\" field.\n\nThe reason why I'm removing contributors (perhaps there's a better solution?):\n\n* PageSizeDebugPanel tries to serialize the whole page during page rendering, while models are still attached. This causes most of our database-backed models to complain that they're being serialized without being detached (as this usually means somebody probably forgot to call detach() somewhere).\n* InspectorDebugPanel - InspectorPage currently shows me a blank component tree because it doesn't have @RequireHttps as all our other pages do and thus redirects to an http:// URL and can't see the session. So we copied InspectorPage (since it's final and can't be subclassed) to add @RequireHttps and likewise copied InspectorDebugPanel.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.013727309182286263
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.010229934938251972
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00412548054009676
                }
            }
        },
        "comments": [
            {
                "author_name": "mgrigorov",
                "id": "13807934",
                "body": "You can use now org.apache.wicket.devutils.debugbar.DebugBar#getContributors(Application) and org.apache.wicket.devutils.debugbar.DebugBar#setContributors(List<IDebugBarContributor>, Application)"
            },
            {
                "author_name": "alexgrant",
                "id": "13820432",
                "body": "Works perfectly; thank you."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640753b1e9b5871d5cb8614d",
        "key": "CLOUDSTACK-4825",
        "id": "12672720",
        "description": "Management server failed start in master build, observed below error \n\n2013-10-07 15:42:24,998 INFO  [o.s.b.f.a.AutowiredAnnotationBeanPostProcessor] (main:null) JSR-330 'javax.inject.Inject' annotation found and supported for autowiring\n2013-10-07 15:42:25,003 INFO  [o.s.b.f.a.AutowiredAnnotationBeanPostProcessor] (main:null) JSR-330 'javax.inject.Inject' annotation found and supported for autowiring\n2013-10-07 15:42:25,006 INFO  [o.s.b.f.a.AutowiredAnnotationBeanPostProcessor] (main:null) JSR-330 'javax.inject.Inject' annotation found and supported for autowiring\n2013-10-07 15:42:37,118 FATAL [o.a.c.c.CallContext] (Timer-2:null) Exiting the system because we're unable to register the system call context.\ncom.cloud.utils.exception.CloudRuntimeException: DB Exception on: com.mysql.jdbc.JDBC4PreparedStatement@346ab6ce: SELECT account.id, account.account_name, account.type, account.domain_id, account.state, account.removed, account.cleanup_needed, account.network_domain, account.uuid, account.default_zone_id, account.default FROM account WHERE account.id = 1  AND account.removed IS NULL\n        at com.cloud.utils.db.GenericDaoBase.findById(GenericDaoBase.java:986)\n        at com.cloud.utils.component.ComponentInstantiationPostProcessor$InterceptorDispatcher.intercept(ComponentInstantiationPostProcessor.java:125)\n        at com.cloud.utils.db.GenericDaoBase.lockRow(GenericDaoBase.java:963)\n        at com.cloud.utils.component.ComponentInstantiationPostProcessor$InterceptorDispatcher.intercept(ComponentInstantiationPostProcessor.java:125)\n        at com.cloud.utils.db.GenericDaoBase.findById(GenericDaoBase.java:926)\n        at com.cloud.utils.component.ComponentInstantiationPostProcessor$InterceptorDispatcher.intercept(ComponentInstantiationPostProcessor.java:125)\n        at com.cloud.dao.EntityManagerImpl.findById(EntityManagerImpl.java:45)\n        at org.apache.cloudstack.context.CallContext.register(CallContext.java:166)\n        at org.apache.cloudstack.context.CallContext.registerSystemCallContextOnceOnly(CallContext.java:141)\n        at org.apache.cloudstack.context.CallContextListener.onEnterContext(CallContextListener.java:36)\n        at org.apache.cloudstack.managed.context.impl.DefaultManagedContext.callWithContext(DefaultManagedContext.java:83)\n        at org.apache.cloudstack.managed.context.impl.DefaultManagedContext.runWithContext(DefaultManagedContext.java:53)\n        at org.apache.cloudstack.managed.context.ManagedContextRunnable.run(ManagedContextRunnable.java:46)\n        at org.apache.cloudstack.managed.context.ManagedContextTimerTask.run(ManagedContextTimerTask.java:27)\n        at java.util.TimerThread.mainLoop(Timer.java:555)\n        at java.util.TimerThread.run(Timer.java:505)\nCaused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column 'account.default' in 'field list'\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:525)\n        at com.mysql.jdbc.Util.handleNewInstance(Util.java:411)\n        at com.mysql.jdbc.Util.getInstance(Util.java:386)\n        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1053)\n        at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4074)\n        at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4006)\n        at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2468)\n        at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2629)\n        at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2719)\n        at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2155)\n        at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:2318)\n        at org.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96)\n        at org.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96)\n        at com.cloud.utils.db.GenericDaoBase.findById(GenericDaoBase.java:983)\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.013272618874907494
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007555825170129538
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005212252493947744
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d62595f4d395ee2225bf0d",
        "key": "BEAM-5900",
        "id": "13194831",
        "description": "\n\n ------------------------- 2018-10-29 12:15:39.784226 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.16.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2018-11-05 12:13:25.803905 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.16.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2018-11-12 12:13:24.852038 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.16.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2018-11-19 12:14:01.597088 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.16.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2018-11-26 12:13:08.128451 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.16.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2018-12-03 12:13:31.144567 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.16.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2018-12-10 12:16:00.942592 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.17.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2018-12-17 12:16:20.023379 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.17.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2018-12-31 15:22:38.061354 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.17.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-01-07 12:25:51.701533 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.17.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-01-14 12:14:48.113706 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.17.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-01-21 12:21:22.296709 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.18.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-01-28 12:12:50.663200 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.18.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-02-04 12:14:10.912221 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.18.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-02-11 12:13:32.854697 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.18.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-02-18 12:23:23.925107 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.18.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-02-25 12:13:07.559576 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.18.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-03-04 12:14:40.217255 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.19.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-03-11 12:14:15.249831 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.19.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-03-25 04:19:09.432204 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.19.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-04-01 12:10:35.784209 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.19.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-04-08 12:12:19.383060 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.19.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-04-15 12:32:04.190006 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.20.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-04-22 12:09:54.760858 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.13.1. The latest version is 1.20.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-11-12 22:48:58.049377 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-11-12 23:27:38.898504 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-11-15 19:41:26.746735 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-11-18 12:08:17.001190 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-11-18 20:44:23.880457 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-11-19 20:02:34.060825 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-11-19 21:08:07.645546 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-12-02 12:14:08.823581 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-12-09 12:13:20.671135 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.25.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-12-23 12:13:44.872739 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.26.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2019-12-30 14:08:49.446965 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.26.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-01-06 12:12:31.373837 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.26.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-01-13 12:11:54.125779 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.21.0. The latest version is 1.26.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-06-29 12:13:05.825552 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.30.2 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-07-06 12:11:50.847208 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.30.2 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-07-08 10:38:03.741498 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.30.2 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-07-13 12:13:53.194229 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.30.2 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-07-20 12:15:06.971716 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.30.2 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-07-27 12:18:45.121574 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.30.2 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-08-03 12:14:45.559553 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-08-10 12:13:13.225439 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-08-17 12:13:05.166092 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-08-24 12:15:44.916458 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-08-28 09:18:56.952229 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-08-28 15:56:03.717789 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-08-28 16:27:27.495448 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-08-31 12:16:58.579106 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-09-07 12:16:17.920849 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.31.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-09-14 12:28:59.545996 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.32.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-09-21 12:25:22.278332 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.32.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-10-05 12:19:47.146215 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.32.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-10-12 12:21:17.090909 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.32.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-10-19 12:21:33.337448 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.32.2 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-10-26 12:21:13.841964 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.33.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-11-02 12:21:31.518159 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.33.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-11-09 12:18:30.887249 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.33.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-11-16 12:21:19.865777 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.33.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-11-23 12:22:39.908331 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.33.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-11-30 12:20:22.167888 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.33.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-12-07 12:24:02.696638 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.34.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-12-14 12:31:57.152472 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.34.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-12-21 12:22:25.983007 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.34.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2020-12-28 12:21:05.837630 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.34.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-01-04 12:21:27.577632 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.34.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-01-11 12:22:29.961126 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.34.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-01-18 12:44:03.177115 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.35.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-01-25 12:25:57.228673 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.35.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-02-01 12:25:57.110504 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.35.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-02-08 12:29:25.777913 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.35.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-02-15 12:27:13.430744 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.35.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-02-22 12:24:16.433677 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.35.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-03-01 12:25:00.280579 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.36.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-03-08 12:26:50.127900 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.36.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-03-15 12:28:23.187392 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.36.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-03-22 12:26:09.351036 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.26.0. The latest version is 1.36.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-07-05 12:29:50.272275 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.39.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-07-19 12:29:20.479619 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.39.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-07-26 12:28:54.904329 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.39.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-02 12:27:58.969789 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.39.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-09 12:36:28.412513 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.39.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-16 12:32:50.899178 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.39.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-23 12:41:39.801996 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.40.0 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-30 12:35:10.601944 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.40.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-09-06 12:35:19.988385 -------------------------\n\n        Please consider upgrading the dependency io.grpc:grpc-protobuf. \n\n        The current version is 1.36.0. The latest version is 1.40.1 \n\n        cc: [~chamikara], \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.42994800209999084
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009850154630839825
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.010621288791298866
                }
            }
        },
        "comments": [
            {
                "author_name": "BeamJiraBot",
                "id": "17123035",
                "body": "This issue is P2 but has been unassigned without any comment for 60 days so it has been labeled \"stale-P2\". If this issue is still affecting you, we care! Please comment and remove the label. Otherwise, in 14 days the issue will be moved to P3.\n\nPlease see https://beam.apache.org/contribute/jira-priorities/ for a detailed explanation of what these priorities mean.\n"
            },
            {
                "author_name": "BeamJiraBot",
                "id": "17137482",
                "body": "This issue was marked \"stale-P2\" and has not received a public comment in 14 days. It is now automatically moved to P3. If you are still affected by it, you can comment and move it back to P2."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d60bfaf4d395ee222246a5",
        "key": "GEODE-559",
        "id": "12912991",
        "description": "junit.framework.AssertionFailedError: testInterestNotify failed due to exception: dunit.RMIException: While invoking com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.doValidation in VM 1 running on Host timor.gemstone.com with 4 VMs\n\tat dunit.VM.invoke(VM.java:170)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.performSteps(ClientInterestNotifyDUnitTest.java:294)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.testInterestNotify(ClientInterestNotifyDUnitTest.java:171)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat junit.framework.TestCase.runTest(TestCase.java:176)\n\tat junit.framework.TestCase.runBare(TestCase.java:141)\n\tat junit.framework.TestResult$1.protect(TestResult.java:122)\n\tat junit.framework.TestResult.runProtected(TestResult.java:142)\n\tat junit.framework.TestResult.run(TestResult.java:125)\n\tat junit.framework.TestCase.run(TestCase.java:129)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:252)\n\tat junit.framework.TestSuite.run(TestSuite.java:247)\n\tat org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:86)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:105)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:56)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n\tat org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n\tat com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)\n\tat org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: junit.framework.AssertionFailedError: expected:<2> but was:<1>\n\tat junit.framework.Assert.fail(Assert.java:57)\n\tat junit.framework.Assert.failNotEquals(Assert.java:329)\n\tat junit.framework.Assert.assertEquals(Assert.java:78)\n\tat junit.framework.Assert.assertEquals(Assert.java:234)\n\tat junit.framework.Assert.assertEquals(Assert.java:241)\n\tat junit.framework.TestCase.assertEquals(TestCase.java:409)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest$EventListener.validate(ClientInterestNotifyDUnitTest.java:112)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.doValidation(ClientInterestNotifyDUnitTest.java:354)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat hydra.MethExecutor.execute(MethExecutor.java:198)\n\tat dunit.standalone.RemoteDUnitVM.executeMethodOnClass(RemoteDUnitVM.java:117)\n\tat sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:323)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:200)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:197)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.Transport.serviceCall(Transport.java:196)\n\tat sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:568)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$241(TCPTransport.java:683)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler$$Lambda$1/1242147135.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682)\n\t... 3 more\nStacktrace\n\njunit.framework.AssertionFailedError: testInterestNotify failed due to exception: dunit.RMIException: While invoking com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.doValidation in VM 1 running on Host timor.gemstone.com with 4 VMs\n\tat dunit.VM.invoke(VM.java:170)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.performSteps(ClientInterestNotifyDUnitTest.java:294)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.testInterestNotify(ClientInterestNotifyDUnitTest.java:171)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat junit.framework.TestCase.runTest(TestCase.java:176)\n\tat junit.framework.TestCase.runBare(TestCase.java:141)\n\tat junit.framework.TestResult$1.protect(TestResult.java:122)\n\tat junit.framework.TestResult.runProtected(TestResult.java:142)\n\tat junit.framework.TestResult.run(TestResult.java:125)\n\tat junit.framework.TestCase.run(TestCase.java:129)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:252)\n\tat junit.framework.TestSuite.run(TestSuite.java:247)\n\tat org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:86)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:105)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:56)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n\tat org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n\tat com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)\n\tat org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: junit.framework.AssertionFailedError: expected:<2> but was:<1>\n\tat junit.framework.Assert.fail(Assert.java:57)\n\tat junit.framework.Assert.failNotEquals(Assert.java:329)\n\tat junit.framework.Assert.assertEquals(Assert.java:78)\n\tat junit.framework.Assert.assertEquals(Assert.java:234)\n\tat junit.framework.Assert.assertEquals(Assert.java:241)\n\tat junit.framework.TestCase.assertEquals(TestCase.java:409)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest$EventListener.validate(ClientInterestNotifyDUnitTest.java:112)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.doValidation(ClientInterestNotifyDUnitTest.java:354)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat hydra.MethExecutor.execute(MethExecutor.java:198)\n\tat dunit.standalone.RemoteDUnitVM.executeMethodOnClass(RemoteDUnitVM.java:117)\n\tat sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:323)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:200)\n\tat sun.rmi.transport.Transport$1.run(Transport.java:197)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.Transport.serviceCall(Transport.java:196)\n\tat sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:568)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$241(TCPTransport.java:683)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler$$Lambda$1/1242147135.run(Unknown Source)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682)\n\t... 3 more\n\n\tat junit.framework.Assert.fail(Assert.java:57)\n\tat junit.framework.TestCase.fail(TestCase.java:227)\n\tat dunit.DistributedTestCase.fail(DistributedTestCase.java:1006)\n\tat com.gemstone.gemfire.internal.cache.tier.sockets.ClientInterestNotifyDUnitTest.testInterestNotify(ClientInterestNotifyDUnitTest.java:174)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat junit.framework.TestCase.runTest(TestCase.java:176)\n\tat junit.framework.TestCase.runBare(TestCase.java:141)\n\tat junit.framework.TestResult$1.protect(TestResult.java:122)\n\tat junit.framework.TestResult.runProtected(TestResult.java:142)\n\tat junit.framework.TestResult.run(TestResult.java:125)\n\tat junit.framework.TestCase.run(TestCase.java:129)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:252)\n\tat junit.framework.TestSuite.run(TestSuite.java:247)\n\tat org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:86)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:105)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:56)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n\tat org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n\tat com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)\n\tat org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.01966172456741333
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006641197483986616
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005977929569780827
                }
            }
        },
        "comments": [
            {
                "author_name": "boglesby",
                "id": "15012389",
                "body": "This test failed again.\n\nGeode_develop_DistributedTests\nPrivate Build #606 (Nov 17, 2015 5:09:12 AM)\nRevision: e8ddd3398d90818f552dcec00eff29d01bc93795\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15205183",
                "body": "Commit 60266fd56b1aa6a541387a3e539692d4f1bc2c9b in incubator-geode's branch refs/heads/develop from [~agingade]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=60266fd ]\n\nGEODE-559: CI Failure: ClientInterestNotifyDUnitTest.testInterestNotify failed\n\nTest issue. Before validation test checks to see if the events are drained on the server side, but doesn't count for time taken to receive the event on client side and invoke its cache listener. Based on the machine speed and thread invocation timing, this test can intermediately fail.\n\nAdded wait logic at client side CacheListener.\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f741f4d395ee221f485a",
        "key": "JCLOUDS-1239",
        "id": "13043006",
        "description": "It is very common to gzip userdata on openstack to preserve space (when using cloud-init for example).\nIf debug logging is enabled, then this binary data is shown as is which disrupts the log.\n\nExample output:\n{noformat}\n>> creating new server region(RegionOne) name(foo-f2e) image(41c50bca-cb94-4dc4-b4ce-6c98242eaaa6) flavor(08fbed24-7fcf-42e3-bc5a-cdd7a701ef0c) options(CreateServerOptions{keyName=null, securityGroupNames=[default], metadata={Name=foo, jclouds-group=foo}, userData=*lots of \"garbage\"*, networks=[73cbec8a-f53d-41af-843b-1cd4a6afc025], availabilityZone=null, configDrive=false})\n{noformat}\n\nSee https://github.com/jclouds/jclouds/pull/1061 (master) and https://github.com/jclouds/jclouds/pull/1062 (2.0.x branch)",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.011690325103700161
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.012438752688467503
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004439177922904491
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "15869663",
                "body": "Commit e26146c6c17c11200f7d186f01c76155423424b0 in jclouds's branch refs/heads/master from [~felfert]\n[ https://git-wip-us.apache.org/repos/asf?p=jclouds.git;h=e26146c ]\n\nJCLOUDS-1239: Handle gzipped userdata in logging\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15869665",
                "body": "Commit 0c1fe36a6635835d59e50a18e7bf55f7f65de7eb in jclouds's branch refs/heads/2.0.x from [~felfert]\n[ https://git-wip-us.apache.org/repos/asf?p=jclouds.git;h=0c1fe36 ]\n\nJCLOUDS-1239: Handle gzipped userdata in logging\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d62e56f4d395ee2226e631",
        "key": "AMBARI-18062",
        "id": "12995643",
        "description": "Review the implementation of the Falcon/Atlas hook enabling/disabling",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.20228999853134155
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.10248435288667679
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.018735114485025406
                }
            }
        },
        "comments": [
            {
                "author_name": "hadoopqa",
                "id": "15411740",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12822566/AMBARI-18062.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  Top-level trunk compilation may be broken.\n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/8324//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "15411885",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12822566/AMBARI-18062.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  Top-level trunk compilation may be broken.\n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/8327//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "aonishuk",
                "id": "15411960",
                "body": "Ran the tests manually:\n{noformat}\n[INFO] Rat check: Summary of files. Unapproved: 0 unknown: 0 generated: 0 approved: 148 licence.\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Ambari Views ...................................... SUCCESS [2.762s]\n[INFO] Ambari Metrics Common ............................. SUCCESS [3.029s]\n[INFO] Ambari Server ..................................... SUCCESS [1:11.649s]\n[INFO] Ambari Agent ...................................... SUCCESS [12.521s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:30.810s\n[INFO] Finished at: Mon Aug 08 17:31:56 EEST 2016\n[INFO] Final Memory: 70M/1168M\n[INFO] ------------------------------------------------------------------------\n{noformat}"
            },
            {
                "author_name": "aonishuk",
                "id": "15411961",
                "body": "Committed to trunk and branch-2.4"
            },
            {
                "author_name": "hudson",
                "id": "15412284",
                "body": "FAILURE: Integrated in Ambari-trunk-Commit #5482 (See [https://builds.apache.org/job/Ambari-trunk-Commit/5482/])\nAMBARI-18062. Review the implementation of the Falcon/Atlas hook (aonishuk: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=b5dbee8542a22d9aee1aa2f7fa2b755330cbd1e2])\n* ambari-common/src/main/python/resource_management/libraries/functions/setup_atlas_hook.py\n* ambari-server/src/main/resources/common-services/FALCON/0.5.0.2.1/configuration/falcon-env.xml\n* ambari-server/src/main/resources/common-services/FALCON/0.5.0.2.1/package/scripts/falcon.py\n* ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog240.java\n* ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog240Test.java\n* ambari-server/src/main/resources/common-services/FALCON/0.5.0.2.1/package/scripts/params_linux.py\n"
            }
        ],
        "comments_predictions": [
            [
                3843148,
                "AMBARI-18062",
                "Ran the tests manually:\n{noformat}\n[INFO] Rat check: Summary of files. Unapproved: 0 unknown: 0 generated: 0 approved: 148 licence.\n[INFO] ------------------------------------------------------------------------\n[INFO] Reactor Summary:\n[INFO] \n[INFO] Ambari Views ...................................... SUCCESS [2.762s]\n[INFO] Ambari Metrics Common ............................. SUCCESS [3.029s]\n[INFO] Ambari Server ..................................... SUCCESS [1:11.649s]\n[INFO] Ambari Agent ...................................... SUCCESS [12.521s]\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:30.810s\n[INFO] Finished at: Mon Aug 08 17:31:56 EEST 2016\n[INFO] Final Memory: 70M/1168M\n[INFO] ------------------------------------------------------------------------\n{noformat}",
                {
                    "property": {
                        "confidence": 0.005876434501260519,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01331078726798296,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006918673869222403,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5f741f4d395ee221f5def",
        "key": "IVY-1535",
        "id": "12902379",
        "description": "I have Java code, that at one point calls {{Ivy.findModule()}}. If there are new ivys and artifacts for this module in repository, then {{Ivy.findModule()}} updates ivys, but does not delete artifacts. Subsequent resolutions then return cached new ivys and outdated artifacts. That poses a problem.\n\nThe proposed solution is to use {{changing=true}} in synthetic {{DependencyDescriptor}} created by {{ResolveEngine.findModule()}}.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009900069795548916
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009517655707895756
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005774382501840591
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e742f4d395ee221ccd07",
        "key": "OFBIZ-2017",
        "id": "12407084",
        "description": "here are the french translations for the webPOS user interface.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.4790922999382019
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.025015993043780327
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005008406471461058
                }
            }
        },
        "comments": [
            {
                "author_name": "jleroux",
                "id": "12642652",
                "body": "Thanks Erwan,\n\nYour slightly modified (see below) patch is in trunk revision 707897.\n\nMarco, Erwan, for the sake of clarity for users, I think that we should take care of any differences we introduce between POS and WebPOS. \n\nFor instance \n* What is the WebPosTransactionDateFormat, why it's EEE MMM dd ?\n* In French (Erwan, I kept VENTE in place of PPAL because it's the translation I used in POS since it make more sence (as it's about sales not main). \n* In POS French translation I used Vente instead of VENTE, and I'm not sure it's a good decision (though I'm still thinking that it's easier to read, especially when you have a lot of uppercase strings on the same screen)\n\nThis does not mean that the POS should be the reference and I'm open for discussion ;) I will try to make a list of the differences, any help would be greatly appreciated..."
            },
            {
                "author_name": "risalitm",
                "id": "12643041",
                "body": "Hi Jacques,\n\nthe label WebPosTransactionDateFormat can be removed from WebPos because it is now used only to see the transaction date on the header.\nI will work on it as soon as I can do it.\n\nThanks\nMarco"
            }
        ],
        "comments_predictions": [
            [
                1135938,
                "OFBIZ-2017",
                "Thanks Erwan,\n\nYour slightly modified (see below) patch is in trunk revision 707897.\n\nMarco, Erwan, for the sake of clarity for users, I think that we should take care of any differences we introduce between POS and WebPOS. \n\nFor instance \n* What is the WebPosTransactionDateFormat, why it's EEE MMM dd ?\n* In French (Erwan, I kept VENTE in place of PPAL because it's the translation I used in POS since it make more sence (as it's about sales not main). \n* In POS French translation I used Vente instead of VENTE, and I'm not sure it's a good decision (though I'm still thinking that it's easier to read, especially when you have a lot of uppercase strings on the same screen)\n\nThis does not mean that the POS should be the reference and I'm open for discussion ;) I will try to make a list of the differences, any help would be greatly appreciated...",
                {
                    "property": {
                        "confidence": 0.0035757431760430336,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03761785104870796,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008824224583804607,
                        "prediction": false
                    }
                }
            ],
            [
                1135939,
                "OFBIZ-2017",
                "Hi Jacques,\n\nthe label WebPosTransactionDateFormat can be removed from WebPos because it is now used only to see the transaction date on the header.\nI will work on it as soon as I can do it.\n\nThanks\nMarco",
                {
                    "property": {
                        "confidence": 0.004397721495479345,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00933764223009348,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010806444101035595,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d460f4d395ee22189c7f",
        "key": "WW-1741",
        "id": "12452420",
        "description": "If the interceptor stack is configured as per the documentaion and the ExecuteAndWaitInterceptor is placed last, then the token interceptor will execute first, validate the token, and then remove it from the session.  The execute and wait interceptor could very easily replace the token, if one exists in the parameters, in the session before returning a wait result.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006465091835707426
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.011435258202254772
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007286558393388987
                }
            }
        },
        "comments": [
            {
                "author_name": "ersatztom",
                "id": "12820237",
                "body": "This patch implements the change described."
            },
            {
                "author_name": "husted",
                "id": "12822441",
                "body": "Completed: At revision: 612104  -- Thanks Thomas! \n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d62d47f4d395ee2226d74e",
        "key": "AMBARI-21893",
        "id": "13100224",
        "description": "Underlying Issue\n\nThis issue is because of AMS HTTPS + HA scenario. The CA cert file (/etc/ambari-metrics-monitor/conf/ca.pem) found on every host is generated by fetching a specific metric collector host's certificate from the truststore.\n\nThis certificate file is being used by alert script, service check and even monitors to talk to collector.\n\n* For example, in a cluster with hosts H1 to H5, let's say there are 2 collectors - H1 & H2.\n* On a node H3, let's say the ca.pem file was constructed using the certificate for collector H2.\n* Service check or metric monitor on H3 will NOT be able to talk to H1 since it does not have the certificate for that host.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.00964423455297947
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.021366139873862267
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005894339177757502
                }
            }
        },
        "comments": [
            {
                "author_name": "hadoopqa",
                "id": "16159681",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12885625/AMBARI-21893.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:red}-1 core tests{color}.  The test build failed in [ambari-server|https://builds.apache.org/job/Ambari-trunk-test-patch/12165//artifact/patch-work/testrun_ambari-server.txt] \n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/12165//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hudson",
                "id": "16163944",
                "body": "FAILURE: Integrated in Jenkins build Ambari-branch-2.6 #201 (See [https://builds.apache.org/job/Ambari-branch-2.6/201/])\nAMBARI-21893 : NameNode Heap Usage (Daily) metric alert status flips to (avijayan: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=01e8e50a216c3494a00a53626eb7386be1cb5ebc])\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/configuration/ams-ssl-client.xml\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/ams.py\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog260.java\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/params.py\n* (edit) ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog260Test.java\n"
            },
            {
                "author_name": "avijayan",
                "id": "16164068",
                "body": "Pushed to branch-2.6 and trunk."
            },
            {
                "author_name": "hudson",
                "id": "16164092",
                "body": "FAILURE: Integrated in Jenkins build Ambari-branch-2.6 #202 (See [https://builds.apache.org/job/Ambari-branch-2.6/202/])\nRevert \"AMBARI-21893 : NameNode Heap Usage (Daily) metric alert status (avijayan: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=c69b750bde1c6964bda4894898d28495c6370221])\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/ams.py\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/params.py\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog260.java\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/configuration/ams-ssl-client.xml\n* (edit) ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog260Test.java\n"
            },
            {
                "author_name": "hudson",
                "id": "16164101",
                "body": "FAILURE: Integrated in Jenkins build Ambari-trunk-Commit #8050 (See [https://builds.apache.org/job/Ambari-trunk-Commit/8050/])\nAMBARI-21893 : NameNode Heap Usage (Daily) metric alert status flips to (avijayan: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=7fa7a6c17607341e8a6888f3dd8b938dce7425ff])\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog260.java\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/configuration/ams-ssl-client.xml\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/ams.py\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/params.py\n* (edit) ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog260Test.java\nAMBARI-21893 : NameNode Heap Usage (Daily) metric alert status flips to (avijayan: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=4f6ef91f33cefeea97629dd4dc45ec993b27b4f6])\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/ams.py\n"
            },
            {
                "author_name": "hudson",
                "id": "16164112",
                "body": "FAILURE: Integrated in Jenkins build Ambari-branch-2.6 #203 (See [https://builds.apache.org/job/Ambari-branch-2.6/203/])\nAMBARI-21893 : NameNode Heap Usage (Daily) metric alert status flips to (avijayan: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=536c346eb8a9478c620e92956be41c3d70c15cbe])\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/configuration/ams-ssl-client.xml\n* (edit) ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog260Test.java\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/params.py\n* (edit) ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/package/scripts/ams.py\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog260.java\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "6407446412e32c77d333b205",
        "key": "ARROW-9220",
        "id": "13313337",
        "description": "utf8proc should not be a hard dependency of ARROW_COMPUTE",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e9f5f4d395ee221d27bc",
        "key": "NIFI-4152",
        "id": "13084901",
        "description": "We should implement a ListenTCPRecord that can pass the underlying InputStream from a TCP connection to a record reader.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.021325260400772095
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.8994813561439514
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.02661684900522232
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16076773",
                "body": "GitHub user bbende opened a pull request:\n\n    https://github.com/apache/nifi/pull/1987\n\n    NIFI-4152 Initial commit of ListenTCPRecord\n\n    Adds a ListenTCPRecord processor which can read records from the InputStream of a TCP connection. \n    \n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/bbende/nifi NIFI-4152\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/nifi/pull/1987.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #1987\n    \n----\n\n----\n"
            },
            {
                "author_name": "bbende",
                "id": "16076774",
                "body": "Attaching template."
            },
            {
                "author_name": "githubbot",
                "id": "16094492",
                "body": "Github user pvillard31 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/1987#discussion_r128477951\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListenTCPRecord.java ---\n    @@ -0,0 +1,432 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.commons.io.IOUtils;\n    +import org.apache.commons.lang3.StringUtils;\n    +import org.apache.nifi.annotation.behavior.InputRequirement;\n    +import org.apache.nifi.annotation.behavior.SupportsBatching;\n    +import org.apache.nifi.annotation.behavior.WritesAttribute;\n    +import org.apache.nifi.annotation.behavior.WritesAttributes;\n    +import org.apache.nifi.annotation.documentation.CapabilityDescription;\n    +import org.apache.nifi.annotation.documentation.Tags;\n    +import org.apache.nifi.annotation.lifecycle.OnScheduled;\n    +import org.apache.nifi.annotation.lifecycle.OnStopped;\n    +import org.apache.nifi.components.AllowableValue;\n    +import org.apache.nifi.components.PropertyDescriptor;\n    +import org.apache.nifi.components.ValidationContext;\n    +import org.apache.nifi.components.ValidationResult;\n    +import org.apache.nifi.flowfile.FlowFile;\n    +import org.apache.nifi.flowfile.attributes.CoreAttributes;\n    +import org.apache.nifi.processor.AbstractProcessor;\n    +import org.apache.nifi.processor.DataUnit;\n    +import org.apache.nifi.processor.ProcessContext;\n    +import org.apache.nifi.processor.ProcessSession;\n    +import org.apache.nifi.processor.Relationship;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.processor.util.StandardValidators;\n    +import org.apache.nifi.processor.util.listen.ListenerProperties;\n    +import org.apache.nifi.record.listen.SocketChannelRecordReader;\n    +import org.apache.nifi.record.listen.SocketChannelRecordReaderDispatcher;\n    +import org.apache.nifi.security.util.SslContextFactory;\n    +import org.apache.nifi.serialization.RecordReader;\n    +import org.apache.nifi.serialization.RecordReaderFactory;\n    +import org.apache.nifi.serialization.RecordSetWriter;\n    +import org.apache.nifi.serialization.RecordSetWriterFactory;\n    +import org.apache.nifi.serialization.WriteResult;\n    +import org.apache.nifi.serialization.record.Record;\n    +import org.apache.nifi.serialization.record.RecordSchema;\n    +import org.apache.nifi.ssl.SSLContextService;\n    +\n    +import javax.net.ssl.SSLContext;\n    +import java.io.IOException;\n    +import java.io.OutputStream;\n    +import java.net.InetAddress;\n    +import java.net.InetSocketAddress;\n    +import java.net.NetworkInterface;\n    +import java.nio.channels.ServerSocketChannel;\n    +import java.util.ArrayList;\n    +import java.util.Collection;\n    +import java.util.Collections;\n    +import java.util.HashMap;\n    +import java.util.HashSet;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +import java.util.concurrent.BlockingQueue;\n    +import java.util.concurrent.LinkedBlockingQueue;\n    +import java.util.concurrent.TimeUnit;\n    +\n    +import static org.apache.nifi.processor.util.listen.ListenerProperties.NETWORK_INTF_NAME;\n    +\n    +@SupportsBatching\n    +@InputRequirement(InputRequirement.Requirement.INPUT_FORBIDDEN)\n    +@Tags({\"listen\", \"tcp\", \"record\", \"tls\", \"ssl\"})\n    +@CapabilityDescription(\"Listens for incoming TCP connections and reads data from each connection using a configured record \" +\n    +        \"reader, and writes the records to a flow file using a configured record writer. The type of record reader selected will \" +\n    +        \"determine how clients are expected to send data. For example, when using a Grok reader to read logs, a client can keep an \" +\n    +        \"open connection and continuously stream data, but when using an JSON reader, the client cannot send an array of JSON \" +\n    +        \"documents and then send another array on the same connection, as the reader would be in a bad state at that point. Records \" +\n    +        \"will be read from the connection in blocking mode, and will timeout according to the Read Timeout specified in the processor. \" +\n    +        \"If the read times out, or if any other error is encountered when reading, the connection will be closed, and any records \" +\n    +        \"read up to that point will be handled according to the configured Read Error Strategy (Discard or Transfer). In cases where \" +\n    +        \"clients are keeping a connection open, the concurrent tasks for the processor should be adjusted to match the Max Number of \" +\n    +        \"TCP Connections allowed, so that there is a task processing each connection.\")\n    +@WritesAttributes({\n    +        @WritesAttribute(attribute=\"tcp.sender\", description=\"The host that sent the data.\"),\n    +        @WritesAttribute(attribute=\"tcp.port\", description=\"The port that the processor accepted the connection on.\"),\n    +        @WritesAttribute(attribute=\"record.count\", description=\"The number of records written to the flow file.\"),\n    +        @WritesAttribute(attribute=\"mime.type\", description=\"The mime-type of the writer used to write the records to the flow file.\")\n    +})\n    +public class ListenTCPRecord extends AbstractProcessor {\n    +\n    +    static final PropertyDescriptor PORT = new PropertyDescriptor\n    +            .Builder().name(\"Port\")\n    --- End diff --\n    \n    ``displayName()`` is missing on few properties\n"
            },
            {
                "author_name": "githubbot",
                "id": "16094493",
                "body": "Github user pvillard31 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/1987#discussion_r128478338\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListenTCPRecord.java ---\n    @@ -0,0 +1,432 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.commons.io.IOUtils;\n    +import org.apache.commons.lang3.StringUtils;\n    +import org.apache.nifi.annotation.behavior.InputRequirement;\n    +import org.apache.nifi.annotation.behavior.SupportsBatching;\n    +import org.apache.nifi.annotation.behavior.WritesAttribute;\n    +import org.apache.nifi.annotation.behavior.WritesAttributes;\n    +import org.apache.nifi.annotation.documentation.CapabilityDescription;\n    +import org.apache.nifi.annotation.documentation.Tags;\n    +import org.apache.nifi.annotation.lifecycle.OnScheduled;\n    +import org.apache.nifi.annotation.lifecycle.OnStopped;\n    +import org.apache.nifi.components.AllowableValue;\n    +import org.apache.nifi.components.PropertyDescriptor;\n    +import org.apache.nifi.components.ValidationContext;\n    +import org.apache.nifi.components.ValidationResult;\n    +import org.apache.nifi.flowfile.FlowFile;\n    +import org.apache.nifi.flowfile.attributes.CoreAttributes;\n    +import org.apache.nifi.processor.AbstractProcessor;\n    +import org.apache.nifi.processor.DataUnit;\n    +import org.apache.nifi.processor.ProcessContext;\n    +import org.apache.nifi.processor.ProcessSession;\n    +import org.apache.nifi.processor.Relationship;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.processor.util.StandardValidators;\n    +import org.apache.nifi.processor.util.listen.ListenerProperties;\n    +import org.apache.nifi.record.listen.SocketChannelRecordReader;\n    +import org.apache.nifi.record.listen.SocketChannelRecordReaderDispatcher;\n    +import org.apache.nifi.security.util.SslContextFactory;\n    +import org.apache.nifi.serialization.RecordReader;\n    +import org.apache.nifi.serialization.RecordReaderFactory;\n    +import org.apache.nifi.serialization.RecordSetWriter;\n    +import org.apache.nifi.serialization.RecordSetWriterFactory;\n    +import org.apache.nifi.serialization.WriteResult;\n    +import org.apache.nifi.serialization.record.Record;\n    +import org.apache.nifi.serialization.record.RecordSchema;\n    +import org.apache.nifi.ssl.SSLContextService;\n    +\n    +import javax.net.ssl.SSLContext;\n    +import java.io.IOException;\n    +import java.io.OutputStream;\n    +import java.net.InetAddress;\n    +import java.net.InetSocketAddress;\n    +import java.net.NetworkInterface;\n    +import java.nio.channels.ServerSocketChannel;\n    +import java.util.ArrayList;\n    +import java.util.Collection;\n    +import java.util.Collections;\n    +import java.util.HashMap;\n    +import java.util.HashSet;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +import java.util.concurrent.BlockingQueue;\n    +import java.util.concurrent.LinkedBlockingQueue;\n    +import java.util.concurrent.TimeUnit;\n    +\n    +import static org.apache.nifi.processor.util.listen.ListenerProperties.NETWORK_INTF_NAME;\n    +\n    +@SupportsBatching\n    +@InputRequirement(InputRequirement.Requirement.INPUT_FORBIDDEN)\n    +@Tags({\"listen\", \"tcp\", \"record\", \"tls\", \"ssl\"})\n    +@CapabilityDescription(\"Listens for incoming TCP connections and reads data from each connection using a configured record \" +\n    +        \"reader, and writes the records to a flow file using a configured record writer. The type of record reader selected will \" +\n    +        \"determine how clients are expected to send data. For example, when using a Grok reader to read logs, a client can keep an \" +\n    +        \"open connection and continuously stream data, but when using an JSON reader, the client cannot send an array of JSON \" +\n    +        \"documents and then send another array on the same connection, as the reader would be in a bad state at that point. Records \" +\n    +        \"will be read from the connection in blocking mode, and will timeout according to the Read Timeout specified in the processor. \" +\n    +        \"If the read times out, or if any other error is encountered when reading, the connection will be closed, and any records \" +\n    +        \"read up to that point will be handled according to the configured Read Error Strategy (Discard or Transfer). In cases where \" +\n    +        \"clients are keeping a connection open, the concurrent tasks for the processor should be adjusted to match the Max Number of \" +\n    +        \"TCP Connections allowed, so that there is a task processing each connection.\")\n    +@WritesAttributes({\n    +        @WritesAttribute(attribute=\"tcp.sender\", description=\"The host that sent the data.\"),\n    +        @WritesAttribute(attribute=\"tcp.port\", description=\"The port that the processor accepted the connection on.\"),\n    +        @WritesAttribute(attribute=\"record.count\", description=\"The number of records written to the flow file.\"),\n    +        @WritesAttribute(attribute=\"mime.type\", description=\"The mime-type of the writer used to write the records to the flow file.\")\n    +})\n    +public class ListenTCPRecord extends AbstractProcessor {\n    +\n    +    static final PropertyDescriptor PORT = new PropertyDescriptor\n    +            .Builder().name(\"Port\")\n    +            .description(\"The port to listen on for communication.\")\n    +            .required(true)\n    +            .addValidator(StandardValidators.PORT_VALIDATOR)\n    +            .expressionLanguageSupported(true)\n    +            .build();\n    +\n    +    static final PropertyDescriptor READ_TIMEOUT = new PropertyDescriptor.Builder()\n    +            .name(\"Read Timeout\")\n    +            .description(\"The amount of time to wait before timing out when reading from a connection.\")\n    +            .addValidator(StandardValidators.TIME_PERIOD_VALIDATOR)\n    +            .defaultValue(\"30 seconds\")\n    +            .required(true)\n    +            .build();\n    +\n    +    static final PropertyDescriptor MAX_SOCKET_BUFFER_SIZE = new PropertyDescriptor.Builder()\n    +            .name(\"Max Size of Socket Buffer\")\n    +            .description(\"The maximum size of the socket buffer that should be used. This is a suggestion to the Operating System \" +\n    +                    \"to indicate how big the socket buffer should be. If this value is set too low, the buffer may fill up before \" +\n    +                    \"the data can be read, and incoming data will be dropped.\")\n    +            .addValidator(StandardValidators.DATA_SIZE_VALIDATOR)\n    +            .defaultValue(\"1 MB\")\n    +            .required(true)\n    +            .build();\n    +\n    +    static final PropertyDescriptor MAX_CONNECTIONS = new PropertyDescriptor.Builder()\n    +            .name(\"Max Number of TCP Connections\")\n    +            .description(\"The maximum number of concurrent TCP connections to accept.\")\n    --- End diff --\n    \n    Should we add in the property description the comment you added in the capability description?\n    \"In cases where clients are keeping a connection open, the concurrent tasks for the processor should be adjusted to match the Max Number of TCP Connections allowed, so that there is a task processing each connection.\"\n"
            },
            {
                "author_name": "githubbot",
                "id": "16107407",
                "body": "Github user bbende commented on the issue:\n\n    https://github.com/apache/nifi/pull/1987\n  \n    @pvillard31 thanks for reviewing, I just rebased against master and made your suggested changes, let me know of anything else, thanks!\n"
            },
            {
                "author_name": "githubbot",
                "id": "16114973",
                "body": "Github user pvillard31 commented on the issue:\n\n    https://github.com/apache/nifi/pull/1987\n  \n    Hey @bbende, just built this PR and did some tests. \n    \n    The template I used is here:\n    https://gist.github.com/pvillard31/5ecea5932bf70fc622e30be8512601b6\n    \n    Then I send messages using nc:\n    ````\n    $> nc localhost 9876\n    2016-11-08 21:24:23,029 FINE Yellow\n    2016-11-08 21:24:23,029 INFO Test Message 1\n    2016-11-08 21:24:23,029 WARN Red\n    2016-11-08 21:24:23,029 ERROR Green\n    2016-11-08 21:24:23,029 FATAL Blue\n    ...\n    ````\n    \n    Observations:\n    - If I start ``nc`` but don't send any message, it'll fail after the read timeout with the following message (and kill my ``nc`` connection):\n    ````\n    ListenTCPRecord[id=aefaaba3-015d-1000-cecb-dd76899c8193] Error processing records: null: java.net.SocketTimeoutException\n    ````\n    I'm not sure if we want to raise a bulletin alert if the source is not sending any message. Thoughts?\n    \n    - If I start ``nc`` and send messages, but less than the maximum number of records per flow file (1000), then it'll generate a flow file only after 30 seconds without receiving any message (and it'll generate a bulletin).\n    \n    - If I start ``nc`` and keep sending messages, it'll generate flow files containing exactly the number set for the property \"record batch size\".\n    \n    While I understand this is the intended behaviour, I'm not sure if this is clear enough in the description of the processor. In particular, raising a bulletin and killing the connection in case no data is received could seem weird (and it's not similar to the way ListenTCP is working).\n    \n    Instead of killing the connection, what about just generating a flow file with the amount data available at this moment? Or change the level of the log message to info? And probably improve the message to let the user knows that the connection has been closed because no data has been received since X seconds? Thoughts?\n"
            },
            {
                "author_name": "githubbot",
                "id": "16116952",
                "body": "Github user bbende commented on the issue:\n\n    https://github.com/apache/nifi/pull/1987\n  \n    @pvillard31 thanks for trying it out... I made some changes so that it should only produce a bulletin when there is an error other than a read timeout, and on read timeouts I made it leave it the connection open and requeue it to try again, so it will only close the connection on other errors.\n    \n    Also, I found a bug in PutTCP that I introduced in another PR, so I fixed that here as well.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16117234",
                "body": "Commit 0029f025f833ca3addc7efc81cec575ec07cb1ef in nifi's branch refs/heads/master from [~bbende]\n[ https://git-wip-us.apache.org/repos/asf?p=nifi.git;h=0029f02 ]\n\nNIFI-4152 Initial commit of ListenTCPRecord\n"
            },
            {
                "author_name": "githubbot",
                "id": "16117250",
                "body": "Github user pvillard31 commented on the issue:\n\n    https://github.com/apache/nifi/pull/1987\n  \n    Forgot the magic words after rebasing... Can you close the PR @bbende? sorry about that.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16118298",
                "body": "Github user bbende commented on the issue:\n\n    https://github.com/apache/nifi/pull/1987\n  \n    Thanks! closing...\n"
            },
            {
                "author_name": "githubbot",
                "id": "16118299",
                "body": "Github user bbende closed the pull request at:\n\n    https://github.com/apache/nifi/pull/1987\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640746652112148e1181d95c",
        "key": "RANGER-3895",
        "id": "13479616",
        "description": "Show database/table is not giving any result from beeline\u00a0\r\n\r\nSteps to reproduce :\u00a0\r\ncm_hive\u00a0 : All access\u00a0 for user\r\ncm_hdfs : Access to all path for user\u00a0\r\nHit query on beeline :\r\n{code:java}\r\n0: jdbc:hive2://********> show databases;\r\nINFO : Compiling command(queryId=hive_20220824053200_90698f18-6b9d-480b-b2c9-12b28c96c7f6): show databases\r\nINFO : Semantic Analysis Completed (retrial = false)\r\nINFO : Created Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)\r\nINFO : Completed compiling command(queryId=-6b9d-480b-b2c9-12b28c96c7f6); Time taken: 0.023 seconds\r\nINFO : Executing command(queryId=-6b9d-480b-b2c9-12b28c96c7f6): show databases\r\nINFO : Starting task [Stage-0:DDL] in serial mode\r\nINFO : Completed executing command(queryId=-6b9d-480b-b2c9-12b28c96c7f6); Time taken: 0.006 seconds\r\nINFO : OK\r\n+----------------+\r\n| database_name |\r\n+----------------+\r\n+----------------+ {code}\r\nTry same using spark Db\u00a0\r\n{code:java}\r\nscala> spark.sql(\"show databases\").show()\r\n22/08/24 05:35:39 WARN conf.HiveConf: HiveConf of name hive.masking.algo does not exist\r\nHive Session ID = 5e7e8200-84d1\r\n+------------------+\r\n|\u00a0\u00a0 databaseName|\r\n+------------------+\r\n|\u00a0\u00a0\u00a0\u00a0\u00a0 default|\r\n|information_schema|\r\n|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 sys|\r\n| test*****|\r\n+------------------+ {code}\r\nGetting proper result from spark DB while beeline doesnot show any database / tables\u00a0\r\n\r\n\u00a0\r\n\r\nExpected result : Users should be able to get all table details\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012009511701762676
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.012025799602270126
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004072202369570732
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e662f4d395ee221ca305",
        "key": "OJB-39",
        "id": "32341",
        "description": "When using multiple m:n relation with same referenced object type in same class, only the first found relation will be used. More detailed, only the first found indirection table will be used all other are ignored.",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d610a2f4d395ee2222e1c9",
        "key": "FLEX-30542",
        "id": "12591416",
        "description": "This bug was imported from another system and requires review from a project committer before some of the details can be marked public. For more information about historical bugs, please read: [Why are some bugs missing information?|https://bugs.adobe.com/confluence/display/ADOBE/Why+are+some+bugs+missing+information]\n\nYou can request a review of this bug report by sending an e-mail to: [Request Public Review for This Bug|mailto:jira_support@adobe.com?subject=Bug%20Review%20Request%20-%20FLEXDMV-58&amp;body=Please%20review%20this%20historical%20bug%20report%20and%20consider%20making%20additional%20information%20public.%20%20I%20understand%20that%20my%20request%20(including%20this%20e-mail)%20may%20be%20included%20as%20part%20of%20the%20public%20history%20in%20the%20bug%20comments.%0D%0A%0D%0AAdditional Information: ]\n\nPlease be sure to include the bug number in your request.",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13385941",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/FLEXDMV-58\nOriginal Reporter: bolaughl\nOriginal Resolution: Deferred\nNeeds Release Note: No\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nSeverity: Incorrectly Functioning\nreporter: bolaughl"
            },
            {
                "author_name": "adobejira",
                "id": "13385942",
                "body": "created: 2006-04-13 14:30:19.000\nresolved: 2006-04-17 06:03:06.737\nupdated: 2006-04-17 06:03:06.000"
            },
            {
                "author_name": "adobejira",
                "id": "13385943",
                "body": "On 2007-06-04 10:42:21.023 customware commented:\nMove from BugDB issue number 167059\nOn 2007-06-04 10:42:21.033 customware commented:\nMilestone ID = null\nMilestone = null\nBuild ID = 24651\nBuild = SDK Build 2.0.1\nFix Build ID = null\nFix Build = null"
            }
        ],
        "comments_predictions": [
            [
                2971292,
                "FLEX-30542",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/FLEXDMV-58\nOriginal Reporter: bolaughl\nOriginal Resolution: Deferred\nNeeds Release Note: No\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nSeverity: Incorrectly Functioning\nreporter: bolaughl",
                {
                    "property": {
                        "confidence": 0.0038173727225512266,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.04570972919464111,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010019004344940186,
                        "prediction": false
                    }
                }
            ],
            [
                2971294,
                "FLEX-30542",
                "On 2007-06-04 10:42:21.023 customware commented:\nMove from BugDB issue number 167059\nOn 2007-06-04 10:42:21.033 customware commented:\nMilestone ID = null\nMilestone = null\nBuild ID = 24651\nBuild = SDK Build 2.0.1\nFix Build ID = null\nFix Build = null",
                {
                    "property": {
                        "confidence": 0.003966531250625849,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01205694954842329,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011910469271242619,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d4cff4d395ee2218c03f",
        "key": "WICKET-1664",
        "id": "12396853",
        "description": "\nWith latest trunk, the following message occurs in the logs:\n\n09:41:50.297 ERROR [org.apache.wicket.markup.html.WebPage        ] -  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n09:41:50.314 ERROR [org.apache.wicket.markup.html.WebPage        ] - You probably forgot to add a <body> or <header> tag to your markup since no Header Container was found but components where found which want to write to the <head> section.\n\nThis happens, when using TransparentResolver with the html-Tag.\n\nA quickstart is attached.\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014775608666241169
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008176219649612904
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005567179061472416
                }
            }
        },
        "comments": [
            {
                "author_name": "frankbille",
                "id": "12606378",
                "body": "Could it be related to WICKET-1682?"
            },
            {
                "author_name": "ivaynberg",
                "id": "12607773",
                "body": "juergen, there is a todo in there for you? webpage:449"
            },
            {
                "author_name": "ivaynberg",
                "id": "12607775",
                "body": "i just committed a fix for this particular usecase. juergen, you should still look at the todo and if nothing is there feel free to close this one."
            },
            {
                "author_name": "ivaynberg",
                "id": "12635100",
                "body": "could not reproduce with latest branch and trunk. must already be fixed."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5edc6f4d395ee221dd361",
        "key": "MESOS-7922",
        "id": "13098050",
        "description": "For re-registration, agents currently send the resources in tasks\nand executors to the master in the \"post-reservation-refinement\" format,\nwhich is incompatible for pre-1.4 masters. We should change the agent\nsuch that it always downgrades the resources to\nthe \"pre-reservation-refinement\" format, and the master unconditionally\nupgrade the resources to \"post-reservation-refinement\" format.",
        "predictions": {},
        "comments": [
            {
                "author_name": "mcypark",
                "id": "16144168",
                "body": "https://reviews.apache.org/r/61952"
            },
            {
                "author_name": "mcypark",
                "id": "16144546",
                "body": "{noformat}\ncommit 30e2b2ad818e4e90c8df03b9802a4b1a431605c7\nAuthor: Michael Park <mpark@apache.org>\nDate:   Mon Aug 28 15:19:31 2017 -0700\n\n    Fixed the communication between old masters and new agents.\n\n    For re-registration, 1.4 agents used to send the resources in tasks\n    and executors to the master in the \"post-reservation-refinement\" format,\n    which is incompatible for pre-1.4 masters. This patch changes the agent\n    such that it always downgrades the resources to\n    the \"pre-reservation-refinement\" format, and the master unconditionally\n    upgrades the resources to \"post-reservation-refinement\" format.\n\n    Review: https://reviews.apache.org/r/61952/\n{noformat}"
            }
        ],
        "comments_predictions": [
            [
                1376891,
                "MESOS-7922",
                "{noformat}\ncommit 30e2b2ad818e4e90c8df03b9802a4b1a431605c7\nAuthor: Michael Park <mpark@apache.org>\nDate:   Mon Aug 28 15:19:31 2017 -0700\n\n    Fixed the communication between old masters and new agents.\n\n    For re-registration, 1.4 agents used to send the resources in tasks\n    and executors to the master in the \"post-reservation-refinement\" format,\n    which is incompatible for pre-1.4 masters. This patch changes the agent\n    such that it always downgrades the resources to\n    the \"pre-reservation-refinement\" format, and the master unconditionally\n    upgrades the resources to \"post-reservation-refinement\" format.\n\n    Review: https://reviews.apache.org/r/61952/\n{noformat}",
                {
                    "property": {
                        "confidence": 0.0048922584392130375,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00913539994508028,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01158039178699255,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "64074665dc5b3e8de781d3eb",
        "key": "YARN-11200",
        "id": "13468787",
        "description": "Few users who are on 2.10 are looking for NUMA Support in YARN. Backporting YARN-5764 to 2.10.3",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.518846869468689
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.03237259387969971
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.026311533525586128
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d62e56f4d395ee2226efa8",
        "key": "AMBARI-15388",
        "id": "12949232",
        "description": "Currently the upgrade is defined as a series of xml files specific to the current stack version and the target stack version.  Each upgrade xml defines the overall sequence of the upgrade and what needs to be done for each service.  Custom services need to be able to specify their upgrade process and how those steps fit into the upgrade process.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02391129545867443
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.6897960305213928
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008413685485720634
                }
            }
        },
        "comments": [
            {
                "author_name": "ncole@hortonworks.com",
                "id": "15202045",
                "body": "How is <order> being maintained?  The <order> element is key to indicate dependencies for upgrading, and is not random.  Oozie must go before Falcon (at the service level).  Datanodes must be upgraded before RegionServers before NodeManagers within the same host.  The CLIENTS group spans multiple services.\n\n What about pre-requisite checks?  Order there also may be important.  ClusterGrouping definitely has order - you can't execute Save Database State before HDFS Finalization occurs.\n\n<priority> within a service check group is also important.\n\nIt's difficult to see all the changes based on just a plain text diff, can you add Review Board review or create a feature branch?  This is a really large commit.  We also have to balance stability here, especially when trying to maintain upgrade packs.  It's already hard enough maintaining the source->target upgrade packs, but if we now need one per service as well, that increases the number of files as a multiple of the number of services."
            },
            {
                "author_name": "jonathanhurley",
                "id": "15202193",
                "body": "I agree about the priority/ordering. If you're going to break up the files, then you still need some sort of master XML to define ordering. The idea of adding new services on your own to be a part of upgrade is an interesting proposal. But it comes with a lot of questions:\n\n- Are other stack services affected by this service's upgrade?\n- When does the new service upgrade?\n- Does the service upgrade all together, or broken apart (things like clients/slaves/masters)\n\nI suppose you could always argue that the \"master\" XML file defines ordering for the stack as it ships. And then you can tack on the to end of it services which define their own upgrade. But now you hit issues with services that are already part of the main upgrade overriding their parent and so on.\n\nI think that:\n- At the very least, this needs a design sent out the community - especially before any code is written\n- A feature branch is a great starting point too; allows iterative development and smaller, more understandable reviews. The sheer size of this review makes it very difficult to find problems\n- ReviewBoard use is a must"
            },
            {
                "author_name": "afernandez",
                "id": "15202235",
                "body": "I agree about sending a design review to the community and the points mentioned above. I completely agree that upgrade packs should be extensible to facilitate adding other services. The reason why a single file exists today is because we had to capture the order, prechecks, and of course other groups that are not associated with any service but instead the Cluster.\n\nIf we do split it out, then a service should define its dependencies (or references to other steps that must complete before). This model actually lends itself to parallelizing groups such as say Atlas, Falcon, Storm."
            },
            {
                "author_name": "hadoopqa",
                "id": "15202797",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12794186/AMBARI-15388.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/5934//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "15208359",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12794806/AMBARI-15388%20Design.pdf\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/5984//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "Tim Thorpe",
                "id": "15280518",
                "body": "Patch file is mostly changes to the java classes.  The upgrade*.xml files have been updated to have distinct naming for the service check sections: SERVICE_CHECK1, SERVICE_CHECK2 and SERVICE_CHECK3 for rolling upgrade."
            },
            {
                "author_name": "Tim Thorpe",
                "id": "15288941",
                "body": "Changes based on review board comments"
            },
            {
                "author_name": "hadoopqa",
                "id": "15289406",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12804645/AMBARI-15388.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 13 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in ambari-server:\n\n                  org.apache.ambari.server.controller.internal.UpgradeResourceProviderHDP22Test\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/6881//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/6881//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "Tim Thorpe",
                "id": "15289526",
                "body": "Switched the target version in src/test/resources/stacks/HDP/2.2.0/upgrades/upgrade_test_15388.xml to 2.4.\n\nRe-patched and ran the failing test:\n\nRunning org.apache.ambari.server.controller.internal.UpgradeResourceProviderHDP22Test\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.467 sec"
            },
            {
                "author_name": "hadoopqa",
                "id": "15291167",
                "body": "{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12804741/AMBARI-15388.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 13 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in ambari-server.\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/6895//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/6895//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "Tim Thorpe",
                "id": "15291292",
                "body": "More changes from review board.  Switched the <after> tag to be <add-after-group> and <add-after-group-entry>.  This distinguishes between the two possible meanings the <after> tag used to have."
            },
            {
                "author_name": "hadoopqa",
                "id": "15292039",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12804960/AMBARI-15388.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 13 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in ambari-server:\n\n                  org.apache.ambari.server.controller.internal.HostResourceProviderTest\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/6903//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/6903//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "Tim Thorpe",
                "id": "15292074",
                "body": "The failure encountered doesn't seem related to my changes:\n\njava.lang.Exception: Unexpected exception, expected<org.apache.ambari.server.security.authorization.AuthorizationException> but was<java.lang.NullPointerException>\n\tat org.apache.ambari.server.controller.internal.HostResourceProviderTest.testUpdateResources(HostResourceProviderTest.java:1025)\n\tat org.apache.ambari.server.controller.internal.HostResourceProviderTest.testUpdateResourcesAsServiceAdministrator(HostResourceProviderTest.java:956)"
            },
            {
                "author_name": "jluniya",
                "id": "15292166",
                "body": "commit f8b427494b36c92f8a36c59d1a7233b5a130f4e7\nAuthor: Jayush Luniya <jluniya@hortonworks.com>\nDate:   Thu May 19 14:21:22 2016 -0700\n\n    AMBARI-15388 - Upgrade XML should be pushed down as much as possible to the services (Tim Thorpe via jluniya)"
            },
            {
                "author_name": "jluniya",
                "id": "15292169",
                "body": "Branch-2.4\ncommit cec0b24018517d47e686eba77156810c64cd89e3\nAuthor: Jayush Luniya <jluniya@hortonworks.com>\nDate:   Thu May 19 14:21:22 2016 -0700\n\n    AMBARI-15388 - Upgrade XML should be pushed down as much as possible to the services (Tim Thorpe via jluniya)"
            },
            {
                "author_name": "hudson",
                "id": "15292549",
                "body": "FAILURE: Integrated in Ambari-trunk-Commit #4881 (See [https://builds.apache.org/job/Ambari-trunk-Commit/4881/])\nAMBARI-15388 - Upgrade XML should be pushed down as much as possible to (jluniya: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=f8b427494b36c92f8a36c59d1a7233b5a130f4e7])\n* ambari-server/src/main/java/org/apache/ambari/server/stack/StackServiceDirectory.java\n* ambari-server/src/main/java/org/apache/ambari/server/state/stack/upgrade/ClusterGrouping.java\n* ambari-server/src/main/resources/stacks/HDP/2.5/upgrades/upgrade-2.5.xml\n* ambari-server/src/main/resources/stacks/HDP/2.3/upgrades/upgrade-2.5.xml\n* ambari-server/src/test/java/org/apache/ambari/server/state/stack/UpgradePackTest.java\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/role_command_order.json\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/repos/version-2.2.0.4-123.xml\n* ambari-server/src/main/java/org/apache/ambari/server/state/stack/upgrade/Grouping.java\n* ambari-server/src/main/java/org/apache/ambari/server/stack/ServiceDirectory.java\n* ambari-server/src/main/resources/stacks/HDP/2.4/upgrades/upgrade-2.4.xml\n* ambari-server/src/test/resources/stacks/HDP/2.0.5/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml\n* ambari-server/src/main/java/org/apache/ambari/server/state/stack/upgrade/ServiceCheckGrouping.java\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/repos/repoinfo.xml\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/repos/hdp.json\n* ambari-server/src/test/java/org/apache/ambari/server/stack/StackManagerMiscTest.java\n* ambari-server/src/main/java/org/apache/ambari/server/stack/CommonServiceDirectory.java\n* ambari-server/src/test/resources/stacks/HDP/2.2.0/upgrades/upgrade_test_15388.xml\n* ambari-server/src/main/resources/stacks/HDP/2.3/upgrades/upgrade-2.4.xml\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/upgrades/config-upgrade.xml\n* ambari-server/src/main/java/org/apache/ambari/server/stack/StackDirectory.java\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/upgrades/upgrade_test_15388.xml\n* ambari-server/src/main/java/org/apache/ambari/server/stack/StackModule.java\n* ambari-server/src/main/java/org/apache/ambari/server/stack/ServiceModule.java\n* ambari-server/src/main/resources/stacks/HDP/2.4/upgrades/upgrade-2.5.xml\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/services/HDFS/metainfo.xml\n* ambari-server/src/main/resources/stacks/HDP/2.3/upgrades/upgrade-2.3.xml\n* ambari-server/src/main/java/org/apache/ambari/server/state/ServiceInfo.java\n* ambari-server/src/test/resources/stacks_with_upgrade_cycle/HDP/2.2.0/metainfo.xml\n* ambari-server/src/main/java/org/apache/ambari/server/state/stack/UpgradePack.java\n"
            },
            {
                "author_name": "Tim Thorpe",
                "id": "15293273",
                "body": "I created a new trunk workspace, and successfully ran the HostResourceProviderTest which failed."
            }
        ],
        "comments_predictions": [
            [
                3852026,
                "AMBARI-15388",
                "How is <order> being maintained?  The <order> element is key to indicate dependencies for upgrading, and is not random.  Oozie must go before Falcon (at the service level).  Datanodes must be upgraded before RegionServers before NodeManagers within the same host.  The CLIENTS group spans multiple services.\n\n What about pre-requisite checks?  Order there also may be important.  ClusterGrouping definitely has order - you can't execute Save Database State before HDFS Finalization occurs.\n\n<priority> within a service check group is also important.\n\nIt's difficult to see all the changes based on just a plain text diff, can you add Review Board review or create a feature branch?  This is a really large commit.  We also have to balance stability here, especially when trying to maintain upgrade packs.  It's already hard enough maintaining the source->target upgrade packs, but if we now need one per service as well, that increases the number of files as a multiple of the number of services.",
                {
                    "property": {
                        "confidence": 0.017387302592396736,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002842785557731986,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.3725823760032654,
                        "prediction": false
                    }
                }
            ],
            [
                3852027,
                "AMBARI-15388",
                "I agree about the priority/ordering. If you're going to break up the files, then you still need some sort of master XML to define ordering. The idea of adding new services on your own to be a part of upgrade is an interesting proposal. But it comes with a lot of questions:\n\n- Are other stack services affected by this service's upgrade?\n- When does the new service upgrade?\n- Does the service upgrade all together, or broken apart (things like clients/slaves/masters)\n\nI suppose you could always argue that the \"master\" XML file defines ordering for the stack as it ships. And then you can tack on the to end of it services which define their own upgrade. But now you hit issues with services that are already part of the main upgrade overriding their parent and so on.\n\nI think that:\n- At the very least, this needs a design sent out the community - especially before any code is written\n- A feature branch is a great starting point too; allows iterative development and smaller, more understandable reviews. The sheer size of this review makes it very difficult to find problems\n- ReviewBoard use is a must",
                {
                    "property": {
                        "confidence": 0.027921902015805244,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0049668001011013985,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.8002042174339294,
                        "prediction": true
                    }
                }
            ],
            [
                3852028,
                "AMBARI-15388",
                "I agree about sending a design review to the community and the points mentioned above. I completely agree that upgrade packs should be extensible to facilitate adding other services. The reason why a single file exists today is because we had to capture the order, prechecks, and of course other groups that are not associated with any service but instead the Cluster.\n\nIf we do split it out, then a service should define its dependencies (or references to other steps that must complete before). This model actually lends itself to parallelizing groups such as say Atlas, Falcon, Storm.",
                {
                    "property": {
                        "confidence": 0.017541684210300446,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00296742282807827,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.1871427744626999,
                        "prediction": false
                    }
                }
            ],
            [
                3852031,
                "AMBARI-15388",
                "Patch file is mostly changes to the java classes.  The upgrade*.xml files have been updated to have distinct naming for the service check sections: SERVICE_CHECK1, SERVICE_CHECK2 and SERVICE_CHECK3 for rolling upgrade.",
                {
                    "property": {
                        "confidence": 0.0038634994998574257,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006749018561094999,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03243812173604965,
                        "prediction": false
                    }
                }
            ],
            [
                3852034,
                "AMBARI-15388",
                "Switched the target version in src/test/resources/stacks/HDP/2.2.0/upgrades/upgrade_test_15388.xml to 2.4.\n\nRe-patched and ran the failing test:\n\nRunning org.apache.ambari.server.controller.internal.UpgradeResourceProviderHDP22Test\nTests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.467 sec",
                {
                    "property": {
                        "confidence": 0.005985070951282978,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006414051633328199,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012289576232433319,
                        "prediction": false
                    }
                }
            ],
            [
                3852038,
                "AMBARI-15388",
                "The failure encountered doesn't seem related to my changes:\n\njava.lang.Exception: Unexpected exception, expected<org.apache.ambari.server.security.authorization.AuthorizationException> but was<java.lang.NullPointerException>\n\tat org.apache.ambari.server.controller.internal.HostResourceProviderTest.testUpdateResources(HostResourceProviderTest.java:1025)\n\tat org.apache.ambari.server.controller.internal.HostResourceProviderTest.testUpdateResourcesAsServiceAdministrator(HostResourceProviderTest.java:956)",
                {
                    "property": {
                        "confidence": 0.008604118600487709,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006390212569385767,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.00812461320310831,
                        "prediction": false
                    }
                }
            ],
            [
                3852039,
                "AMBARI-15388",
                "commit f8b427494b36c92f8a36c59d1a7233b5a130f4e7\nAuthor: Jayush Luniya <jluniya@hortonworks.com>\nDate:   Thu May 19 14:21:22 2016 -0700\n\n    AMBARI-15388 - Upgrade XML should be pushed down as much as possible to the services (Tim Thorpe via jluniya)",
                {
                    "property": {
                        "confidence": 0.008023647591471672,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.2681426405906677,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013487682677805424,
                        "prediction": false
                    }
                }
            ],
            [
                3852040,
                "AMBARI-15388",
                "Branch-2.4\ncommit cec0b24018517d47e686eba77156810c64cd89e3\nAuthor: Jayush Luniya <jluniya@hortonworks.com>\nDate:   Thu May 19 14:21:22 2016 -0700\n\n    AMBARI-15388 - Upgrade XML should be pushed down as much as possible to the services (Tim Thorpe via jluniya)",
                {
                    "property": {
                        "confidence": 0.005634452681988478,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.050970081239938736,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006618900690227747,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640744b0a3a0f968fd33b746",
        "key": "HBASE-26665",
        "id": "13422629",
        "description": "Andor is already working on this with nimbus, but filing this for him.\r\n\r\nWe should have a unit test which exercises the oauth bearer authentication mechanism so that we know if the feature is functional at a basic level (without having to set up on OAuth server).",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.15751419961452484
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.02138134092092514
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.009446042589843273
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d62595f4d395ee2225c400",
        "key": "BEAM-4632",
        "id": "13167810",
        "description": "Dear sir,\r\n\r\nThe following\u00a0versions of related tools are set in my running program:\r\n\r\n==================================\r\n\r\nBeam 2.4.0 (Direct runner and Spark runner)\r\n\r\nSpark 2.2.1 (local mode\u00a0and standalone mode)\r\n\r\nKafka: 2.11-0.10.1.1\r\n\r\nscala: 2.11.8\r\n\r\njava: 1.8\r\n\r\n==================================\r\n\r\nMy programs (KafkaToKafka.java and StarterPipeline.java) are as shown on my github:\u00a0[https://github.com/LinRick/beamkafkaIO],\r\n\r\nThe description of my situation is as:\r\n\r\n{color:#14892c}The kafka broker is working and kafkaIO.read (consumer) is used to capture data from the\u00a0assigned\u00a0broker ip ([http://ubuntu7:9092)|http://ubuntu7:9092)./].{color}\r\n\r\n{color:#14892c}The\u00a0user manual of kafkaIO SDK (on\u00a0web:[https://beam.apache.org/documentation/sdks/javadoc/2.4.0/])\u00a0\u00a0indicates that the following parameters need to be set, and then the\u00a0kafkaIO can work well.{color}\r\n\r\n {color:#FF0000}.withBootstrapServers(\"kafka broker ip:9092\"){color}\r\n{color:#FF0000} .withTopic(\"kafkasink\"){color}\r\n{color:#FF0000} .withKeyDeserializer(IntegerDeserializer.class){color}\r\n{color:#FF0000} .withValueDeserializer(StringDeserializer.class) {color}\r\n\r\nWhen i run my program with these settings over direct runner, i can find that\u00a0my program perform well. In addition,\u00a0my running program is the streaming mode. *However, i run these codes with the same settings (kafkaIO) over spark runner, and my running program\u00a0is not the streaming mode and is shutdown*. Here,\u00a0as mentioned on the website:\u00a0[https://beam.apache.org/documentation/runners/spark/], the performing program will automatically set streaming mode.\u00a0\r\n\r\nUnfortunately, it failed for my program.\r\n\r\nOn the other hand, If i set the parameter\u00a0 kafkaIO.read.withMaxNumRecords (1000) or\u00a0 kafkaIO.read.withMaxReadTime (Duration second), my program will\u00a0successfully execute as\u00a0the batch mode (batch processing).\r\n\r\nThe steps of performing\u00a0StarterPipeline.java in my program are:\r\n\r\nstep1 mvn compile exec:java -Dexec.mainClass=com.itri.beam.StarterPipeline -Pspark2-runner -Dexec.args=\"--runner=SparkRunner\"\r\nstep2 mvn clean package\r\nstep3 cp -rf target/beamkafkaIO-0.1.jar /root/\r\nstep4 cd /spark-2.2.1-bin-hadoop2.6/bin\r\nstep5 ./spark-submit --class com.itri.beam.StarterPipeline --master local[4] /root/beamkafkaIO-0.1.jar --runner=SparkRunner\r\n\r\nI am not sure if this issue is a bug about kafkaIO or I was wrong with some parameter settings over spark runner ?\r\n\r\nI really can't handle it, so I hope to get help from you.\r\n\r\nif any further information is needed, i am glad to be informed and will provide to you as soon as possible.\r\n\r\nI will highly appreciate it if you can help me to deal with this issue.\r\n\r\n\r\ni am looking forward to hearing from you.\r\n \r\nSincerely yours,\r\n \r\nRick\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02878052555024624
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.00659357151016593
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005008138250559568
                }
            }
        },
        "comments": [
            {
                "author_name": "aromanenko",
                "id": "16522486",
                "body": "Hello Rick, thank you for report.\u00a0\r\n\r\nDo you\u00a0see any error messages when you run your pipeline on Spark? Could you attach Spark logs to this Jira issue?"
            },
            {
                "author_name": "aromanenko",
                "id": "16522491",
                "body": "One remark - according to your [pom file|https://github.com/LinRick/beamkafkaIO/blob/1d65cc72c0e29ddf6080873507ab2db7d0cc8671/pom.xml#L35]\u00a0you use Beam 2.5.0-SNAPSHOT"
            },
            {
                "author_name": "rangadi",
                "id": "16522533",
                "body": "Hi [~aromanenko], I am assigning this to you. Since it is works with `BoundedSource` wrapper when\u00a0withMaxNumRecords (1000) is set, it is likely a issue between Beam unbounded sources and streaming Spark. I don't think I can get to this this week. Please assign it to onwers or Spark-runner if appropriate.."
            },
            {
                "author_name": "rangadi",
                "id": "16522850",
                "body": "cc [~amitsela]."
            },
            {
                "author_name": "kenn",
                "id": "16522866",
                "body": "I removed the \"Fix Version\" as I don't know that this was resolved."
            },
            {
                "author_name": "aromanenko",
                "id": "16523937",
                "body": "Seems that it works in streaming mode only when I run a pipeline with {{waitUntilFinish()}}. Otherwise, it just stops after running. So, probably it's an issue with SparkRunner, I'll investigate it.\r\n\r\n[~Ricklin] Could you run your pipeline with {{p.run().waitUntilFinish();}} to check if it works for you?"
            },
            {
                "author_name": "Ricklin",
                "id": "16524523",
                "body": "Dear all,\r\n\r\nThanks very much for your attention to this problem.\r\n\r\n\u00a0\r\n\r\nHi [~aromanenko],\r\n\r\nYes, this project have been changed *beam.version*\u00a0*from\u00a02.5.0-SNAPSHOT\u00a0 to 2.4.0*\u00a0and\u00a0*spark2.jackson.version from\u00a02.9.5 to\u00a0 2.8.9*\u00a0to run my project (updated on my Github).\u00a0\r\n\r\nWhen running my pipeline with\u00a0p.run().waitUntilFinish() for StarterPipeline.java program,{color:#d04437} *KafkaIO can be on streaming mode (spark runner with local[4])*.{color}\r\n\r\nThe output of my pipeline is to write the amount of data into the PostgreSQL (raw_c42a25f4bd3d74429dbeb6162e60e5c7/kafkabeamdata) each second, as follows:\r\n{quote}{color:#205081}countData.apply(JdbcIO.<KV<String, Long>>write(){color}\r\n {color:#205081} .withDataSourceConfiguration(JdbcIO.DataSourceConfiguration.create({color}\r\n {color:#205081} \"org.postgresql.Driver\",{color}\r\n {color:#205081} \"jdbc:postgresql://ubuntu7:5432/raw_c42a25f4bd3d74429dbeb6162e60e5c7\"){color}\r\n {color:#205081} .withUsername(\"postgres\"){color}\r\n {color:#205081} .withPassword(\"postgres\")){color}\r\n {color:#205081} .withStatement(\"insert into kafkabeamdata (count) values(?)\"){color}\r\n {color:#205081} .withPreparedStatementSetter(new JdbcIO.PreparedStatementSetter<KV<String, Long>>() {{color}\r\n {color:#205081} @Override{color}\r\n {color:#205081} public void setParameters(KV<String, Long> element, PreparedStatement query){color}\r\n {color:#205081} throws SQLException {{color}\r\n {color:#205081} double count = element.getValue().doubleValue();{color}\r\n {color:#205081} query.setDouble(1, count);{color}\r\n {color:#205081} }{color}\r\n {color:#205081} }));{color}\r\n{quote}\r\nThe\u00a0following figure shows that the amount of data can be wrote into the DB,as:\r\n\r\n!DB_table_kafkabeamdata_count.JPG!\r\n\r\nIn the above table, we can see many zero values (count), and that means there is no data in most windows with the applied window/triggering/Watermark:\r\n{quote}\".apply(Window.<KV<Integer, String>>into(FixedWindows.of(Duration.standardSeconds(1)))\r\n .triggering(AfterWatermark.pastEndOfWindow()\r\n .withLateFirings(AfterProcessingTime.pastFirstElementInPane().plusDelayOf(Duration.ZERO)))\r\n .withAllowedLateness(Duration.ZERO)\r\n .discardingFiredPanes())\".\r\n{quote}\r\nIn this project, I hope that the count of data can mostly be equal than the amount of data generated in kafka producer. For example,\u00a0the figure shows when using setting \"kafkaIO.Read.withMaxNumRecords(500000)\" in the pipeline, as:\r\n\r\n!.withMaxNumRecords(500000).JPG!\r\n\r\n{color:#d04437}The table shows that there is a expected quantity of streaming\u00a0data in each window.{color}\r\n\r\n{color:#d04437}If I would like to realize the situation on a streaming mode, {color}\r\n\r\n{color:#d04437}what can i do related settings for spark runner (set standalone mode), spark pipeline (set MaxRecordsPerBatch), and kafkaIO.Read ?{color}\r\n\r\n\u00a0\r\n\r\nOn the other hand, there is another error:\r\n\r\n\"Caused by: java.lang.ClassNotFoundException: com.google.protobuf.GeneratedMessageV3\"\r\n\r\nas shown in\u00a0attachments\r\n\r\n!the error GeneratedMessageV3.JPG|width=1156,height=249!\r\n\r\nFor dealing with this error, I have added the required dependency (added on my Github), as:\r\n\r\n\"{color:#14892c}<protobuf-java.version>3.4.0</protobuf-java.version>{color}\r\n\r\n{color:#14892c}<!-- [https://mvnrepository.com/artifact/com.google.protobuf/protobuf-java] -->{color}\r\n {color:#14892c} <dependency>{color}\r\n {color:#14892c} <groupId>com.google.protobuf</groupId>{color}\r\n {color:#14892c} <artifactId>protobuf-java</artifactId>{color}\r\n {color:#14892c} <version>${protobuf-java.version}</version>{color}\r\n {color:#14892c} </dependency>{color}{color:#333333}\"{color}\r\n\r\nRick"
            },
            {
                "author_name": "Ricklin",
                "id": "16524674",
                "body": "Dear\u00a0[~aromanenko],\r\n\r\nI have tried running my project with Spark runner (standalone mode) to {color:#d04437}capture\u00a0more data from kafka{color} into each window, in which the settings of driver/master/worker nodes respectively are:\r\n\r\nDriver node (ubuntu8):\r\n\r\nspark-defaults.conf\r\n{quote}spark.driver.memory 10g\r\n spark.executor.memory 2g\r\n spark.executor.instances 4\r\n{quote}\r\nmaster node (ubuntu8):\r\n{quote}export SPARK_MASTER_IP=\"ubuntu8\"\r\n export SPARK_MASTER_WEBUI_PORT=8082\r\n{quote}\r\nThe settings of two worker nodes\u00a0\u00a0(ubuntu8 and ubuntu9) are the same as the master\u00a0node.\r\n||ExecutorID||Worker||Cores||Memory||State||Logs||\r\n|1|ubuntu9|4|2048|KILLED|\u00a0|\r\n|0|ubuntu8|4|2048|KILLED|\u00a0|\r\n\r\n\u00a0\r\n\r\nIn addition, my pipeline is set as:\r\n{quote}Pipeline p = Pipeline.create(options);\r\n {color:#d04437}options.setMaxRecordsPerBatch(1000L);{color}\r\n {color:#d04437}options.setSparkMaster(\"spark://ubuntu8:7077\");{color}\r\n\r\n...\r\n\r\nPCollection<KV<Integer, String>> readData = p.apply(KafkaIO.<Integer, String>read()\r\n .withBootstrapServers(\"ubuntu7:9092\")\r\n .withTopic(\"kafkasink\")\r\n .withKeyDeserializer(IntegerDeserializer.class)\r\n .withValueDeserializer(StringDeserializer.class) \r\n .withoutMetadata());\r\n\r\n...\r\n\r\np.run().waitUntilFinish();\r\n{quote}\r\nand uses the following command line to run project:\r\n\r\n./spark-submit --class com.itri.beam.StarterPipeline --master spark://ubuntu8:7077 /root/beamkafkaIO-0.1.jar --runner=SparkRunner\r\n\r\nAfter a while, my program is broken, where this error is\u00a0as shown in\u00a0attachments (error UnboundedDataset.java 81(0) has different number of partitions.JPG)\r\n\r\n\"UnboundedDataset.java:81(0) has different number of partitions from original RDD MapPartitionsRDD[698] at updateStateByKey at SparkGroupAlsoByWindowViaWindowSet.java:612(2)\"\r\n\r\nAlthough only using one work node (ubuntu9), the similar error still\u00a0appears.\r\n\r\n\u00a0\r\n\r\nBest,\r\n\r\nRick\r\n\r\n\u00a0\r\n\r\n\u00a0"
            },
            {
                "author_name": "aromanenko",
                "id": "16550912",
                "body": "[~Ricklin] Thank you for all this provided information. Regarding your questions about windows/triggers I'd suggest address them on user@beam.apache.org mailing list.\r\n\r\nFor your last question about broken pipeline. Could you provide the whole code of your pipeline which reproduces this issue? I'll try to do this on my side.\r\n\r\n"
            },
            {
                "author_name": "Ricklin",
                "id": "16561536",
                "body": "Hi [~aromanenko],\r\n\r\nFor the last question, i only change\u00a0settings of the SparkPipeline in my program, as:\r\n{code:java}\r\nSparkPipelineOptions options = PipelineOptionsFactory.fromArgs(args).\r\n withValidation().as(SparkPipelineOptions.class); \r\n options.setRunner(SparkRunner.class); \r\n Pipeline p = Pipeline.create(options); \r\n options.setMaxRecordsPerBatch(1000L); \r\n\r\n options.setSparkMaster(\"spark://ubuntu8:7077\");\r\n{code}\r\n{code:java}\r\nPCollection<KV<Integer, String>> readData = p.apply(KafkaIO.\r\n<Integer,  String>read()\r\n.withBootstrapServers(\"ubuntu7:9092\") \r\n.withTopic(\"kafkasink\") \r\n.withKeyDeserializer(IntegerDeserializer.class) \r\n.withValueDeserializer(StringDeserializer.class) \r\n//.withMaxNumRecords(500000) \r\n.withoutMetadata());{code}\r\n{code:java}\r\n...\r\n...\r\n...\r\np.run().waitUntilFinish();{code}\r\n, and then i perform the following command line:\r\n{noformat}\r\nmvn compile exec:java -Dexec.mainClass=com.itri.beam.StarterPipeline -Pspark2-runner -Dexec.args=\"--runner=SparkRunner\"{noformat}\r\nThere is the error:\r\n\r\n\u00a0\r\n{panel:title=The error is}\r\n[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.6.0:java (default-cli) on project beamkafkaIO: An exception occured while executing the Java class. org.apache.spark.SparkException: Checkpoint RDD has a different number of partitions from original RDD. Original RDD [ID: 321, num of partitions: 1]; Checkpoint RDD [ID: 324, num of partitions: 0]. -> [Help 1]\r\n{panel}\r\nThanks\r\n\r\nRick\r\n\r\n\u00a0"
            },
            {
                "author_name": "Ricklin",
                "id": "16561540",
                "body": "By the way, my configuration setting of kafka broker is:\r\n\r\n\u00a0\r\n{code:java}\r\n/kafka_broker/bin/kafka-producer-perf-test.sh \\\r\n--num-records 10000000 \\\r\n--record-size 100 \\\r\n--topic kafkasink \\\r\n--throughput 10000 \\\r\n--producer-props acks=0 bootstrap.servers=ubuntu7:9092 batch.size=1000{code}\r\nThe display of kafka\u00a0broker\u00a0on console is as:\r\n\r\n...\r\n\r\n49992 records sent,{color:#d04437} 9998.4 records/sec{color} (0.95 MB/sec), 1.0 ms avg latency, 146.0 max latency.\r\n 50040 records sent, {color:#d04437}10008.0 records/sec{color} (0.95 MB/sec), 0.2 ms avg latency, 5.0 m ax latency.\r\n 50019 records sent, {color:#d04437}10001.8 records/sec{color} (0.95 MB/sec), 0.2 ms avg latency, 1.0 m ax latency.\r\n 50011 records sent, {color:#d04437}10002.2 records/sec{color} (0.95 MB/sec), 0.2 ms avg latency, 3.0 m ax latency.\r\n 50020 records sent, {color:#d04437}10002.0 records/sec{color} (0.95 MB/sec), 0.2 ms avg latency, 1.0 m ax latency.\r\n\r\n...\r\n\r\nRick\r\n\r\n\u00a0\r\n\r\n\u00a0"
            },
            {
                "author_name": "aromanenko",
                "id": "16576039",
                "body": "[~Ricklin] Unfortunately, I can't reproduce your issue on my side, both pipelines works as expected with latest stable Beam (2.6.0). Perhaps, this error  was caused by your environment settings. "
            }
        ],
        "comments_predictions": [
            [
                3658424,
                "BEAM-4632",
                "Hi [~aromanenko], I am assigning this to you. Since it is works with `BoundedSource` wrapper when\u00a0withMaxNumRecords (1000) is set, it is likely a issue between Beam unbounded sources and streaming Spark. I don't think I can get to this this week. Please assign it to onwers or Spark-runner if appropriate..",
                {
                    "property": {
                        "confidence": 0.005035645328462124,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005577316973358393,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01766435243189335,
                        "prediction": false
                    }
                }
            ],
            [
                3658427,
                "BEAM-4632",
                "Seems that it works in streaming mode only when I run a pipeline with {{waitUntilFinish()}}. Otherwise, it just stops after running. So, probably it's an issue with SparkRunner, I'll investigate it.\r\n\r\n[~Ricklin] Could you run your pipeline with {{p.run().waitUntilFinish();}} to check if it works for you?",
                {
                    "property": {
                        "confidence": 0.0053906310349702835,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008314186707139015,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0099529679864645,
                        "prediction": false
                    }
                }
            ],
            [
                3658428,
                "BEAM-4632",
                "Dear all,\r\n\r\nThanks very much for your attention to this problem.\r\n\r\n\u00a0\r\n\r\nHi [~aromanenko],\r\n\r\nYes, this project have been changed *beam.version*\u00a0*from\u00a02.5.0-SNAPSHOT\u00a0 to 2.4.0*\u00a0and\u00a0*spark2.jackson.version from\u00a02.9.5 to\u00a0 2.8.9*\u00a0to run my project (updated on my Github).\u00a0\r\n\r\nWhen running my pipeline with\u00a0p.run().waitUntilFinish() for StarterPipeline.java program,{color:#d04437} *KafkaIO can be on streaming mode (spark runner with local[4])*.{color}\r\n\r\nThe output of my pipeline is to write the amount of data into the PostgreSQL (raw_c42a25f4bd3d74429dbeb6162e60e5c7/kafkabeamdata) each second, as follows:\r\n{quote}{color:#205081}countData.apply(JdbcIO.<KV<String, Long>>write(){color}\r\n {color:#205081} .withDataSourceConfiguration(JdbcIO.DataSourceConfiguration.create({color}\r\n {color:#205081} \"org.postgresql.Driver\",{color}\r\n {color:#205081} \"jdbc:postgresql://ubuntu7:5432/raw_c42a25f4bd3d74429dbeb6162e60e5c7\"){color}\r\n {color:#205081} .withUsername(\"postgres\"){color}\r\n {color:#205081} .withPassword(\"postgres\")){color}\r\n {color:#205081} .withStatement(\"insert into kafkabeamdata (count) values(?)\"){color}\r\n {color:#205081} .withPreparedStatementSetter(new JdbcIO.PreparedStatementSetter<KV<String, Long>>() {{color}\r\n {color:#205081} @Override{color}\r\n {color:#205081} public void setParameters(KV<String, Long> element, PreparedStatement query){color}\r\n {color:#205081} throws SQLException {{color}\r\n {color:#205081} double count = element.getValue().doubleValue();{color}\r\n {color:#205081} query.setDouble(1, count);{color}\r\n {color:#205081} }{color}\r\n {color:#205081} }));{color}\r\n{quote}\r\nThe\u00a0following figure shows that the amount of data can be wrote into the DB,as:\r\n\r\n!DB_table_kafkabeamdata_count.JPG!\r\n\r\nIn the above table, we can see many zero values (count), and that means there is no data in most windows with the applied window/triggering/Watermark:\r\n{quote}\".apply(Window.<KV<Integer, String>>into(FixedWindows.of(Duration.standardSeconds(1)))\r\n .triggering(AfterWatermark.pastEndOfWindow()\r\n .withLateFirings(AfterProcessingTime.pastFirstElementInPane().plusDelayOf(Duration.ZERO)))\r\n .withAllowedLateness(Duration.ZERO)\r\n .discardingFiredPanes())\".\r\n{quote}\r\nIn this project, I hope that the count of data can mostly be equal than the amount of data generated in kafka producer. For example,\u00a0the figure shows when using setting \"kafkaIO.Read.withMaxNumRecords(500000)\" in the pipeline, as:\r\n\r\n!.withMaxNumRecords(500000).JPG!\r\n\r\n{color:#d04437}The table shows that there is a expected quantity of streaming\u00a0data in each window.{color}\r\n\r\n{color:#d04437}If I would like to realize the situation on a streaming mode, {color}\r\n\r\n{color:#d04437}what can i do related settings for spark runner (set standalone mode), spark pipeline (set MaxRecordsPerBatch), and kafkaIO.Read ?{color}\r\n\r\n\u00a0\r\n\r\nOn the other hand, there is another error:\r\n\r\n\"Caused by: java.lang.ClassNotFoundException: com.google.protobuf.GeneratedMessageV3\"\r\n\r\nas shown in\u00a0attachments\r\n\r\n!the error GeneratedMessageV3.JPG|width=1156,height=249!\r\n\r\nFor dealing with this error, I have added the required dependency (added on my Github), as:\r\n\r\n\"{color:#14892c}<protobuf-java.version>3.4.0</protobuf-java.version>{color}\r\n\r\n{color:#14892c}<!-- [https://mvnrepository.com/artifact/com.google.protobuf/protobuf-java] -->{color}\r\n {color:#14892c} <dependency>{color}\r\n {color:#14892c} <groupId>com.google.protobuf</groupId>{color}\r\n {color:#14892c} <artifactId>protobuf-java</artifactId>{color}\r\n {color:#14892c} <version>${protobuf-java.version}</version>{color}\r\n {color:#14892c} </dependency>{color}{color:#333333}\"{color}\r\n\r\nRick",
                {
                    "property": {
                        "confidence": 0.006225020159035921,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01723107323050499,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007082716561853886,
                        "prediction": false
                    }
                }
            ],
            [
                3658429,
                "BEAM-4632",
                "Dear\u00a0[~aromanenko],\r\n\r\nI have tried running my project with Spark runner (standalone mode) to {color:#d04437}capture\u00a0more data from kafka{color} into each window, in which the settings of driver/master/worker nodes respectively are:\r\n\r\nDriver node (ubuntu8):\r\n\r\nspark-defaults.conf\r\n{quote}spark.driver.memory 10g\r\n spark.executor.memory 2g\r\n spark.executor.instances 4\r\n{quote}\r\nmaster node (ubuntu8):\r\n{quote}export SPARK_MASTER_IP=\"ubuntu8\"\r\n export SPARK_MASTER_WEBUI_PORT=8082\r\n{quote}\r\nThe settings of two worker nodes\u00a0\u00a0(ubuntu8 and ubuntu9) are the same as the master\u00a0node.\r\n||ExecutorID||Worker||Cores||Memory||State||Logs||\r\n|1|ubuntu9|4|2048|KILLED|\u00a0|\r\n|0|ubuntu8|4|2048|KILLED|\u00a0|\r\n\r\n\u00a0\r\n\r\nIn addition, my pipeline is set as:\r\n{quote}Pipeline p = Pipeline.create(options);\r\n {color:#d04437}options.setMaxRecordsPerBatch(1000L);{color}\r\n {color:#d04437}options.setSparkMaster(\"spark://ubuntu8:7077\");{color}\r\n\r\n...\r\n\r\nPCollection<KV<Integer, String>> readData = p.apply(KafkaIO.<Integer, String>read()\r\n .withBootstrapServers(\"ubuntu7:9092\")\r\n .withTopic(\"kafkasink\")\r\n .withKeyDeserializer(IntegerDeserializer.class)\r\n .withValueDeserializer(StringDeserializer.class) \r\n .withoutMetadata());\r\n\r\n...\r\n\r\np.run().waitUntilFinish();\r\n{quote}\r\nand uses the following command line to run project:\r\n\r\n./spark-submit --class com.itri.beam.StarterPipeline --master spark://ubuntu8:7077 /root/beamkafkaIO-0.1.jar --runner=SparkRunner\r\n\r\nAfter a while, my program is broken, where this error is\u00a0as shown in\u00a0attachments (error UnboundedDataset.java 81(0) has different number of partitions.JPG)\r\n\r\n\"UnboundedDataset.java:81(0) has different number of partitions from original RDD MapPartitionsRDD[698] at updateStateByKey at SparkGroupAlsoByWindowViaWindowSet.java:612(2)\"\r\n\r\nAlthough only using one work node (ubuntu9), the similar error still\u00a0appears.\r\n\r\n\u00a0\r\n\r\nBest,\r\n\r\nRick\r\n\r\n\u00a0\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.0033667071256786585,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01569347456097603,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01807972975075245,
                        "prediction": false
                    }
                }
            ],
            [
                3658430,
                "BEAM-4632",
                "[~Ricklin] Thank you for all this provided information. Regarding your questions about windows/triggers I'd suggest address them on user@beam.apache.org mailing list.\r\n\r\nFor your last question about broken pipeline. Could you provide the whole code of your pipeline which reproduces this issue? I'll try to do this on my side.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.0034113212022930384,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0077649252489209175,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03573973849415779,
                        "prediction": false
                    }
                }
            ],
            [
                3658431,
                "BEAM-4632",
                "Hi [~aromanenko],\r\n\r\nFor the last question, i only change\u00a0settings of the SparkPipeline in my program, as:\r\n{code:java}\r\nSparkPipelineOptions options = PipelineOptionsFactory.fromArgs(args).\r\n withValidation().as(SparkPipelineOptions.class); \r\n options.setRunner(SparkRunner.class); \r\n Pipeline p = Pipeline.create(options); \r\n options.setMaxRecordsPerBatch(1000L); \r\n\r\n options.setSparkMaster(\"spark://ubuntu8:7077\");\r\n{code}\r\n{code:java}\r\nPCollection<KV<Integer, String>> readData = p.apply(KafkaIO.\r\n<Integer,  String>read()\r\n.withBootstrapServers(\"ubuntu7:9092\") \r\n.withTopic(\"kafkasink\") \r\n.withKeyDeserializer(IntegerDeserializer.class) \r\n.withValueDeserializer(StringDeserializer.class) \r\n//.withMaxNumRecords(500000) \r\n.withoutMetadata());{code}\r\n{code:java}\r\n...\r\n...\r\n...\r\np.run().waitUntilFinish();{code}\r\n, and then i perform the following command line:\r\n{noformat}\r\nmvn compile exec:java -Dexec.mainClass=com.itri.beam.StarterPipeline -Pspark2-runner -Dexec.args=\"--runner=SparkRunner\"{noformat}\r\nThere is the error:\r\n\r\n\u00a0\r\n{panel:title=The error is}\r\n[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.6.0:java (default-cli) on project beamkafkaIO: An exception occured while executing the Java class. org.apache.spark.SparkException: Checkpoint RDD has a different number of partitions from original RDD. Original RDD [ID: 321, num of partitions: 1]; Checkpoint RDD [ID: 324, num of partitions: 0]. -> [Help 1]\r\n{panel}\r\nThanks\r\n\r\nRick\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.00595784280449152,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012257787398993969,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006726221647113562,
                        "prediction": false
                    }
                }
            ],
            [
                3658432,
                "BEAM-4632",
                "By the way, my configuration setting of kafka broker is:\r\n\r\n\u00a0\r\n{code:java}\r\n/kafka_broker/bin/kafka-producer-perf-test.sh \\\r\n--num-records 10000000 \\\r\n--record-size 100 \\\r\n--topic kafkasink \\\r\n--throughput 10000 \\\r\n--producer-props acks=0 bootstrap.servers=ubuntu7:9092 batch.size=1000{code}\r\nThe display of kafka\u00a0broker\u00a0on console is as:\r\n\r\n...\r\n\r\n49992 records sent,{color:#d04437} 9998.4 records/sec{color} (0.95 MB/sec), 1.0 ms avg latency, 146.0 max latency.\r\n 50040 records sent, {color:#d04437}10008.0 records/sec{color} (0.95 MB/sec), 0.2 ms avg latency, 5.0 m ax latency.\r\n 50019 records sent, {color:#d04437}10001.8 records/sec{color} (0.95 MB/sec), 0.2 ms avg latency, 1.0 m ax latency.\r\n 50011 records sent, {color:#d04437}10002.2 records/sec{color} (0.95 MB/sec), 0.2 ms avg latency, 3.0 m ax latency.\r\n 50020 records sent, {color:#d04437}10002.0 records/sec{color} (0.95 MB/sec), 0.2 ms avg latency, 1.0 m ax latency.\r\n\r\n...\r\n\r\nRick\r\n\r\n\u00a0\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.004584814887493849,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00616619735956192,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04381086677312851,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d376f4d395ee221859b7",
        "key": "YARN-5006",
        "id": "12963418",
        "description": "Client submit a job, this job add 10000 file into DistributedCache. when the job is submitted, ResourceManager sotre ApplicationStateData into zk. ApplicationStateData  is exceed the limit size of znode. RM exit 1.   \n\nThe related code in RMStateStore.java :\n{code}\n  private static class StoreAppTransition\n      implements SingleArcTransition<RMStateStore, RMStateStoreEvent> {\n    @Override\n    public void transition(RMStateStore store, RMStateStoreEvent event) {\n      if (!(event instanceof RMStateStoreAppEvent)) {\n        // should never happen\n        LOG.error(\"Illegal event type: \" + event.getClass());\n        return;\n      }\n      ApplicationState appState = ((RMStateStoreAppEvent) event).getAppState();\n      ApplicationId appId = appState.getAppId();\n      ApplicationStateData appStateData = ApplicationStateData\n          .newInstance(appState);\n      LOG.info(\"Storing info for app: \" + appId);\n      try {  \n        store.storeApplicationStateInternal(appId, appStateData);  //store the appStateData\n        store.notifyApplication(new RMAppEvent(appId,\n               RMAppEventType.APP_NEW_SAVED));\n      } catch (Exception e) {\n        LOG.error(\"Error storing app: \" + appId, e);\n        store.notifyStoreOperationFailed(e);   //handle fail event, system exit \n      }\n    };\n  }\n{code}\n\nThe Exception log:\n{code}\n ...\n2016-04-20 11:26:35,732 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore AsyncDispatcher event handler: Maxed out ZK retries. Giving up!\n\n2016-04-20 11:26:35,732 ERROR org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore AsyncDispatcher event handler: Error storing app: application_1461061795989_17671\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n\n   ...\n2016-04-20 11:26:45,613 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager AsyncDispatcher event handler: Received a org.apache.hadoop.yarn.server.resourcemanager.RMFatalEvent of type STATE_STORE_OP_FAILED. Cause:\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore\n.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n2016-04-20 11:26:45,615 INFO org.apache.hadoop.util.ExitUtil AsyncDispatcher event handler: Exiting with status 1\n2016-04-20 11:26:45,622 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager Thread[Thread-17,5,main]: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\n2016-04-20 11:26:45,623 INFO org.mortbay.log Thread-1: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@10.0.0.1:9088\n2016-04-20 11:26:45,623 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager Thread[Thread-21,5,main]: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\n2016-04-20 11:26:45,624 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager Thread[Thread-19,5,main]: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted\n2016-04-20 11:26:45,724 INFO org.apache.hadoop.ipc.Server Thread-1: Stopping server on 9033\n2016-04-20 11:26:45,725 INFO org.apache.hadoop.ipc.Server IPC Server listener on 9033: Stopping IPC Server listener on 9033\n2016-04-20 11:26:45,725 INFO org.apache.hadoop.ha.ActiveStandbyElector Thread-1: Yielding from election\n2016-04-20 11:26:45,725 INFO org.apache.hadoop.ipc.Server IPC Server Responder: Stopping IPC Server Responder\n2016-04-20 11:26:45,725 INFO org.apache.hadoop.ha.ActiveStandbyElector Thread-1: Deleting bread-crumb of active node...\n2016-04-20 11:26:45,729 INFO org.apache.zookeeper.ZooKeeper Thread-1: Session: 0x2504c1df9409094 closed\n2016-04-20 11:26:45,729 WARN org.apache.hadoop.ha.ActiveStandbyElector main-EventThread: Ignoring stale result from old client with sessionId 0x2504c1df9409094\n2016-04-20 11:26:45,729 INFO org.apache.zookeeper.ClientCnxn main-EventThread: EventThread shut down\n\n{code}\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.007173355668783188
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.013873351737856865
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005272145848721266
                }
            }
        },
        "comments": [
            {
                "author_name": "dongtingting8877@163.com",
                "id": "15261748",
                "body": "```sh\n2016-04-20 11:26:45,613 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager AsyncDispatcher event handler: Received a org.apache.hadoop.yarn.server.resourc\nemanager.RMFatalEvent of type STATE_STORE_OP_FAILED. Cause:\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore\n.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n\n```"
            },
            {
                "author_name": "rohithsharma",
                "id": "15261870",
                "body": "IIUC, this is same as YARN-2962. Can you check and close this issue if it is same?"
            },
            {
                "author_name": "dongtingting8877@163.com",
                "id": "15261871",
                "body": "Our opinion about fixing this bug is  that we want to add the limit of ApplicationStateData  datasize  at RMStateStore do StoreAppTransition . if datasize  of ApplicationStateData is exceed the limit, RM reject the application. Later we will submit the patch."
            },
            {
                "author_name": "dongtingting8877@163.com",
                "id": "15262086",
                "body": "I do not think my issue is same as YARN-2962, because YARN-2962 talks about limit the number of znodes under a znode, but my issue talks about limit the datasize of Appstatedata which will be storing in zk ."
            },
            {
                "author_name": "rohithsharma",
                "id": "15263499",
                "body": "Ah..! In the [YARN-2962-comment|https://issues.apache.org/jira/browse/YARN-2962?focusedCommentId=14247916&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14247916], Rakesh explained 2 reasons where ZK client go into toss. I hope you are talking about 1st case whereas YARN-2962 handles 2nd case."
            },
            {
                "author_name": "templedf",
                "id": "15283009",
                "body": "You should also see if YARN-4958 would help resolve the issue.  We're misusing ZK a bit as a data store, and YARN-4958 attempts to reduce the level of abuse. :)"
            },
            {
                "author_name": "ozawa",
                "id": "15283261",
                "body": "{quote}\nOur opinion about fixing this bug is that we want to add the limit of ApplicationStateData datasize at RMStateStore do StoreAppTransition .\n{quote}\n\n{quote}\nYou should also see if YARN-4958 would help resolve the issue. We're misusing ZK a bit as a data store, and YARN-4958 attempts to reduce the level of abuse. \n{quote}\n\nBoth of your opinions can be done in parallel and are worth fixing. Another workaround is to use compression."
            },
            {
                "author_name": "bperroud",
                "id": "15381372",
                "body": "The same behaviour occurs when a user submit a job with a jobname of 1+MB. While I appreciate that this is clearly a bug in user job submission code, the RM should protect itself against this sort of hard failure.\nFor instance if a user is using legitimately [LzoDistributedIndexer|https://github.com/twitter/hadoop-lzo/blob/master/src/main/java/com/hadoop/compression/lzo/DistributedLzoIndexer.java#L88] which lists as jobname all the files passed to index, he might shutdown the entire cluster.\n\nSo I'm wondering if the RMStateStore shouldn't have a way to reject a job submission when something is going wrong (for instance 10K+ files in DistributedCache or 1+MB jobname, both generating a znode payload > allowed limit)."
            },
            {
                "author_name": "imstefanlee",
                "id": "15607596",
                "body": "hi,how about the progress of this patch?"
            },
            {
                "author_name": "templedf",
                "id": "15626100",
                "body": "[~dongtingting], any progress on this patch?  I think we're all in agreement that this is a useful fix."
            },
            {
                "author_name": "bibinchundatt",
                "id": "15984874",
                "body": "[~luhuichun]\n\nAny progress on this patch? Hoping the implementation is not started yet. Assigning to my name. Will be adding limit as part of this jira. YARN-3935 and YARN-6426 (progress available) is available for compression. \n\n"
            },
            {
                "author_name": "templedf",
                "id": "16003712",
                "body": "Thanks for the patch, [~bibinchundatt].  A few comments:\n* {{RM_ZK_NUM_ZNODE_SIZE_LIMIT}} would be clearer as {{RM_ZK_ZNODE_SIZE_LIMIT_BYTES}}.  Even better, could we make it generic? {{RM_APP_DATA_SIZE_LIMIT_BYTES}}\n* I don't think the {{isRejectApp()}} method makes it clearer; just inline the _instanceof_.\n* {{StoreLimitException}} needs javadoc to explain what it should be used for.\n* {{super(\"RMStateStore not limit reached\");}} could use a clearer message, like: \"Application <appId> exceeds the maximum allowed size for application data. See yarn.resourcemanager.whatever.max-data-size.bytes.\"  Same goes for the message in {{storeApplicationStateInternal()}}.\n* Please add javadoc for the new methods in {{RMAppEvent}}.\n* Please add some additional unit tests to cover the new behavior."
            },
            {
                "author_name": "bibinchundatt",
                "id": "16010711",
                "body": "[~templedf]\nThank  you for review comments.\nAttaching patch handling review comments"
            },
            {
                "author_name": "hadoopqa",
                "id": "16010933",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 23s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 24s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 43s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m 12s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  9m 12s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 56s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 3 new + 400 unchanged - 2 fixed = 403 total (was 402) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 20s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 52s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 35s{color} | {color:red} hadoop-yarn-api in the patch failed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 39m 32s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 99m 39s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.yarn.conf.TestYarnConfigurationFields |\n|   | hadoop.yarn.server.resourcemanager.TestRMRestart |\n|   | hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | YARN-5006 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12868092/YARN-5006.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux a44daa646f3d 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / c48f297 |\n| Default Java | 1.8.0_121 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/15927/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/15927/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/15927/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/15927/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/15927/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/15927/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "imstefanlee",
                "id": "16019128",
                "body": "thanks for this jira, i have a doubt that why \"add 10000 file into DistributedCache\" can due to *ApplicationStateData*  exceed *1M*.  IMO, *ApplicationStateData*  contains _startTime, user, ApplicationSubmissionContext, state ,diagnostics and finishTime_,  they are all small except *diagnostics*, in my scenario, a failed  spark applicaiton has *4M* info of *diagnostics*,when it update info to ZK, the *ApplicationStateData*  exceed *1M*.  then  RM lost connection with ZK,  so i think it is important to fix the size of  *diagnostics*  when \n operate  *updateApplicationAttemptStateInternal* and *updateApplicationStateInternal*  in *ZKRMStateStore*, am i wrong with this question?[~dongtingting8877@163.com] [~templedf] [~bibinchundatt]"
            },
            {
                "author_name": "bibinchundatt",
                "id": "16019319",
                "body": "Hi [~imstefanlee] , Does YARN-6125 solve your issue?? Or looking for some implementation similar to YARN-6125"
            },
            {
                "author_name": "imstefanlee",
                "id": "16021078",
                "body": "[~bibinchundatt] thanks, but  why  \"add 10000 file into DistributedCache\" can due to *ApplicationStateData* exceed *1M*?"
            },
            {
                "author_name": "bibinchundatt",
                "id": "16021154",
                "body": "[~imstefanlee]\nAim of jira is to protect RM from ApplicationStateData size is more than the Limit of ZK node. \n{quote}\nAdd 10000 file into DistributedCache\n{quote}\nwe can consider as way to simulate the issue. \n"
            },
            {
                "author_name": "Naganarasimha",
                "id": "16047505",
                "body": "Thanks [~bibinchundatt],\nOverall the approach and the patch looks fine except for these following nits :\n# Please add the configuration in the {{yarn-default.xml}} and also capture that it needs to be in sync with zookeeper jute buffer, else though it passes here it will fail again at the zookeeper end. I think {{TestYarnConfigurationFields}} is failing for the same reason.\n# {{StoreLimitException}} documentation refers to only \" exceeds limit for ZK RM state store\" it should be any statestore. as we just catch in RMStatestore and hence can be thrown by any store.\n# ZKRMStateStore ln no 751: please add the appid information in the log, so that it can be traced which app was creating the problem. I would prefer have configuration size too in this log.\n# RMAppEvent  ln no 51:  {{storeApp}} is not signifying properly, would prefer doStoreAppInfo and may be a comment mentioning in the state store"
            },
            {
                "author_name": "bibinchundatt",
                "id": "16049001",
                "body": "Thank you [~naganarasimha_gr@apache.org] for review comments.\nAttaching patch after handling all review comments"
            },
            {
                "author_name": "hadoopqa",
                "id": "16049089",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m  4s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 16s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 51s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  5s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common in trunk has 1 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 27s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 25s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  5m 10s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  5m 10s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 53s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 3 new + 391 unchanged - 2 fixed = 394 total (was 393) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 47s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 35s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 33s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 24s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 39m 13s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 97m  4s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.yarn.server.resourcemanager.TestRMRestart |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | YARN-5006 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12872953/YARN-5006.003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 57811cff345b 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 6ed54f3 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/16184/artifact/patchprocess/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common-warnings.html |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/16184/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/16184/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/16184/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/16184/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "Naganarasimha",
                "id": "16049863",
                "body": "hi [~bibinchundatt],\nJust few nits before we can go in\n# checkstyle issues reported\n# RMAppEvent.java ln no 39 and 51, i think  we can have the variable name also in sync.\n\nAlso Findbugs is not related to the current patch, it should have been taken care in YARN-6517 (i have pinged the there) which has been missed somehow. Test case failures too not related to this patch."
            },
            {
                "author_name": "bibinchundatt",
                "id": "16050491",
                "body": "Uploaded updated patch handling checkstyle"
            },
            {
                "author_name": "hadoopqa",
                "id": "16050598",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 32s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 40s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 51s{color} | {color:green} trunk passed {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  2s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common in trunk has 1 extant Findbugs warnings. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 27s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 10s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  5m  5s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  5m  5s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 57s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 1 new + 391 unchanged - 2 fixed = 392 total (was 393) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 49s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 33s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 23s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 32s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 25s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 39m 48s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 95m 43s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSAppStarvation |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | YARN-5006 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12873121/YARN-5006.004.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 12b222d26cb4 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 315f077 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/16187/artifact/patchprocess/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common-warnings.html |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/16187/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/16187/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/16187/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/16187/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "Naganarasimha",
                "id": "16050888",
                "body": "Thanks [~bibinchundatt], Latest patch LGTM, if no one has any more concerns will commit the patch tomorrow."
            },
            {
                "author_name": "templedf",
                "id": "16052449",
                "body": "Thanks for the patch, [~bibinchundatt].  A couple of final little nits:\n\n* Please add spaces after the periods in the description in {yarn-defaults.xml}}\n* {{RMAppEvent.dostoreAppInfo}} should be camel case or maybe just drop the \"do\"\n* Javadoc for {{RMAppEvent.doStoreAppInfo()}} would be helpful since the naming isn't entirely obvious\n* In {{TestAppRejDispatcher.handle()}}, can we just combine the nested _ifs_ into one?"
            },
            {
                "author_name": "bibinchundatt",
                "id": "16057403",
                "body": "Attaching patch after handling comments "
            },
            {
                "author_name": "hadoopqa",
                "id": "16057586",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 59s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 38s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 51s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 19s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 37s{color} | {color:green} trunk passed {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 32s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  5m 20s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  5m 20s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 54s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 1 new + 391 unchanged - 2 fixed = 392 total (was 393) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 48s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch 5 line(s) with tabs. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 33s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 33s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 24s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 39m 13s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 99m 37s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:14b5c93 |\n| JIRA Issue | YARN-5006 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12873860/YARN-5006.005.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux c4348bd407b2 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 5db3f98 |\n| Default Java | 1.8.0_131 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/16211/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/16211/artifact/patchprocess/whitespace-tabs.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/16211/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/16211/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "Naganarasimha",
                "id": "16057887",
                "body": "Thanks [~bibinchundatt] latest patch seems to correct all the open points. I think its good to go. If no more comments then will commit the patch later."
            },
            {
                "author_name": "hudson",
                "id": "16060341",
                "body": "SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #11912 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/11912/])\nYARN-5006. ResourceManager quit due to ApplicationStateData exceed the (naganarasimha_gr: rev 740204b2926f49ea70596c6059582ce409fbdd90)\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/resources/yarn-default.xml\n* (add) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/StoreLimitException.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/RMStateStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/ZKRMStateStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppEvent.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/TestZKRMStateStore.java\n"
            },
            {
                "author_name": "Naganarasimha",
                "id": "16060355",
                "body": "[~bibinchundatt] there seems to be compilation problem for branch-2 on cherry pick. Can you please check and upload patch for branch -2"
            },
            {
                "author_name": "bibinchundatt",
                "id": "16060788",
                "body": "Attaching branch-2 patch"
            },
            {
                "author_name": "hadoopqa",
                "id": "16060958",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 39s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 26s{color} | {color:red} root in branch-2 failed. {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m  3s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 14s{color} | {color:green} branch-2 passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} branch-2 passed {color} |\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 22s{color} | {color:red} hadoop-yarn-server-resourcemanager in branch-2 failed. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-server-resourcemanager in branch-2 failed. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  3s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} branch-2 passed with JDK v1.7.0_131 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 12s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 36s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 13s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m 13s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 36s{color} | {color:green} the patch passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m 36s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 49s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 1 new + 386 unchanged - 2 fixed = 387 total (was 388) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  1s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch 5 line(s) with tabs. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 54s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 17s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 24s{color} | {color:green} the patch passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 28s{color} | {color:green} hadoop-yarn-api in the patch passed with JDK v1.7.0_131. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 23s{color} | {color:green} hadoop-yarn-common in the patch passed with JDK v1.7.0_131. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 40m 50s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed with JDK v1.7.0_131. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}128m 17s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_131 Failed junit tests | hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore |\n|   | hadoop.yarn.server.resourcemanager.TestRMAdminService |\n| JDK v1.7.0_131 Failed junit tests | hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore |\n|   | hadoop.yarn.server.resourcemanager.metrics.TestSystemMetricsPublisher |\n|   | hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler |\n|   | hadoop.yarn.server.resourcemanager.TestRMRestart |\n|   | hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5e40efe |\n| JIRA Issue | YARN-5006 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12874250/YARN-5006-branch-2.005.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux cde84193ca8d 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / f9f6ef8 |\n| Default Java | 1.7.0_131 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_131 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_131 |\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/16227/artifact/patchprocess/branch-mvninstall-root.txt |\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/16227/artifact/patchprocess/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| findbugs | v3.0.0 |\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/16227/artifact/patchprocess/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/16227/artifact/patchprocess/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/16227/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/16227/artifact/patchprocess/whitespace-tabs.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/16227/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager-jdk1.7.0_131.txt |\n| JDK v1.7.0_131  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/16227/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/16227/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16061404",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 23s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 28s{color} | {color:red} root in branch-2 failed. {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 58s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m  5s{color} | {color:green} branch-2 passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 37s{color} | {color:green} branch-2 passed {color} |\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-server-resourcemanager in branch-2 failed. {color} |\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 16s{color} | {color:red} hadoop-yarn-server-resourcemanager in branch-2 failed. {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 52s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  7s{color} | {color:green} branch-2 passed with JDK v1.7.0_131 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 28s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 43s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m  7s{color} | {color:green} the patch passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m  7s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 41s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 1 new + 386 unchanged - 2 fixed = 387 total (was 388) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 35s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch 5 line(s) with tabs. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  0s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m  4s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  5s{color} | {color:green} the patch passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 28s{color} | {color:green} hadoop-yarn-api in the patch passed with JDK v1.7.0_131. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 34s{color} | {color:green} hadoop-yarn-common in the patch passed with JDK v1.7.0_131. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 40m 58s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed with JDK v1.7.0_131. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}119m 19s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_131 Failed junit tests | hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore |\n| JDK v1.7.0_131 Failed junit tests | hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore |\n|   | hadoop.yarn.server.resourcemanager.monitor.TestSchedulingMonitor |\n|   | hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler |\n|   | hadoop.yarn.server.resourcemanager.TestRMRestart |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5e40efe |\n| JIRA Issue | YARN-5006 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12874250/YARN-5006-branch-2.005.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux 2f8e06080b4d 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / 4c6184b |\n| Default Java | 1.7.0_131 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_131 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_131 |\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/16234/artifact/patchprocess/branch-mvninstall-root.txt |\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/16234/artifact/patchprocess/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| findbugs | v3.0.0 |\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/16234/artifact/patchprocess/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/16234/artifact/patchprocess/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/16234/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/16234/artifact/patchprocess/whitespace-tabs.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/16234/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager-jdk1.7.0_131.txt |\n| JDK v1.7.0_131  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/16234/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/16234/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "bibinchundatt",
                "id": "16061757",
                "body": "Branch-2 failure is due to HADOOP-14146. Have triggered build again"
            },
            {
                "author_name": "hadoopqa",
                "id": "16061805",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 55s{color} | {color:blue} Maven dependency ordering for branch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 57s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 56s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 32s{color} | {color:green} branch-2 passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 47s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 49s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 47s{color} | {color:green} branch-2 passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  6s{color} | {color:green} branch-2 passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 18s{color} | {color:green} branch-2 passed with JDK v1.7.0_131 {color} |\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 12s{color} | {color:blue} Maven dependency ordering for patch {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 21s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 20s{color} | {color:green} the patch passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 44s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn: The patch generated 1 new + 386 unchanged - 2 fixed = 387 total (was 388) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 36s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch 5 line(s) with tabs. {color} |\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  0s{color} | {color:green} The patch has no ill-formed XML file. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 34s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 13s{color} | {color:green} the patch passed with JDK v1.8.0_131 {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 19s{color} | {color:green} the patch passed with JDK v1.7.0_131 {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 27s{color} | {color:green} hadoop-yarn-api in the patch passed with JDK v1.7.0_131. {color} |\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 24s{color} | {color:green} hadoop-yarn-common in the patch passed with JDK v1.7.0_131. {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 58m 21s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed with JDK v1.7.0_131. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}151m 57s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| JDK v1.8.0_131 Failed junit tests | hadoop.yarn.server.resourcemanager.TestRMRestart |\n| JDK v1.7.0_131 Failed junit tests | hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler |\n|   | hadoop.yarn.server.resourcemanager.TestRMRestart |\n| JDK v1.7.0_131 Timed out junit tests | org.apache.hadoop.yarn.server.resourcemanager.reservation.TestFairSchedulerPlanFollower |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:5e40efe |\n| JIRA Issue | YARN-5006 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12874250/YARN-5006-branch-2.005.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |\n| uname | Linux be1be2808d9c 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | branch-2 / 4b420e0 |\n| Default Java | 1.7.0_131 |\n| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_131 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_131 |\n| findbugs | v3.0.0 |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/16241/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/16241/artifact/patchprocess/whitespace-tabs.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/16241/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager-jdk1.7.0_131.txt |\n| JDK v1.7.0_131  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/16241/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/16241/console |\n| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "Naganarasimha",
                "id": "16062082",
                "body": "Thanks [~bibinchundatt] for the contribution and additional reviews from [~daniel@cloudera.com],[~imstefanlee], [~bperroud], [~rohithsharma], [~ozawa]. Have committed the patch to branch-2 and trunk. Further if required we can take in other jira for [~ozawa]'s [comment|https://issues.apache.org/jira/browse/YARN-5006?focusedCommentId=15283261&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15283261] where in we can try to compress the data before placing it in statestore"
            },
            {
                "author_name": "templedf",
                "id": "16063202",
                "body": "Thanks for committing, [~Naganarasimha].  I was on vacation. :)\n\nLooks like the spaces after the periods in {{yarn-defaults.xml}} didn't get fixed in the last patch.  I'll file a newbie JIRA to address it."
            },
            {
                "author_name": "Naganarasimha",
                "id": "16064212",
                "body": "Oops Sorry [~daniel@cloudera.com], Actually offline had informed about this to [~bibinchundatt] and he too had told me that he will delete and upload with this correction. some how we missed it. \n??I'll file a newbie JIRA to address it??  : Well addendum patch should have sufficed right ?"
            },
            {
                "author_name": "templedf",
                "id": "16064960",
                "body": "It's such a minor thing that I didn't think it was worth an addendum patch.  There's a community of people who love to do these tiny fixes.  In fact, someone has already claimed the JIRA I filed."
            },
            {
                "author_name": "Naganarasimha",
                "id": "16065090",
                "body": "Yeah saw that, I am fine with it !"
            }
        ],
        "comments_predictions": [
            [
                126388,
                "YARN-5006",
                "```sh\n2016-04-20 11:26:45,613 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager AsyncDispatcher event handler: Received a org.apache.hadoop.yarn.server.resourc\nemanager.RMFatalEvent of type STATE_STORE_OP_FAILED. Cause:\norg.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:931)\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:911)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:936)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$4.run(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1075)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1096)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:933)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doMultiWithRetries(ZKRMStateStore.java:947)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:956)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:626)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:138)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:123)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:806)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore\n.java:860)\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:855)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)\n        at java.lang.Thread.run(Thread.java:724)\n\n```",
                {
                    "property": {
                        "confidence": 0.004767270293086767,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008234146051108837,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013087852858006954,
                        "prediction": false
                    }
                }
            ],
            [
                126390,
                "YARN-5006",
                "Our opinion about fixing this bug is  that we want to add the limit of ApplicationStateData  datasize  at RMStateStore do StoreAppTransition . if datasize  of ApplicationStateData is exceed the limit, RM reject the application. Later we will submit the patch.",
                {
                    "property": {
                        "confidence": 0.004296747501939535,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.02376091480255127,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009435688145458698,
                        "prediction": false
                    }
                }
            ],
            [
                126391,
                "YARN-5006",
                "I do not think my issue is same as YARN-2962, because YARN-2962 talks about limit the number of znodes under a znode, but my issue talks about limit the datasize of Appstatedata which will be storing in zk .",
                {
                    "property": {
                        "confidence": 0.007048350293189287,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004213274456560612,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.09717204421758652,
                        "prediction": false
                    }
                }
            ],
            [
                126392,
                "YARN-5006",
                "Ah..! In the [YARN-2962-comment|https://issues.apache.org/jira/browse/YARN-2962?focusedCommentId=14247916&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14247916], Rakesh explained 2 reasons where ZK client go into toss. I hope you are talking about 1st case whereas YARN-2962 handles 2nd case.",
                {
                    "property": {
                        "confidence": 0.009707160294055939,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0036017922684550285,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.08000075072050095,
                        "prediction": false
                    }
                }
            ],
            [
                126394,
                "YARN-5006",
                "{quote}\nOur opinion about fixing this bug is that we want to add the limit of ApplicationStateData datasize at RMStateStore do StoreAppTransition .\n{quote}\n\n{quote}\nYou should also see if YARN-4958 would help resolve the issue. We're misusing ZK a bit as a data store, and YARN-4958 attempts to reduce the level of abuse. \n{quote}\n\nBoth of your opinions can be done in parallel and are worth fixing. Another workaround is to use compression.",
                {
                    "property": {
                        "confidence": 0.006589584518224001,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01170070469379425,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009596387855708599,
                        "prediction": false
                    }
                }
            ],
            [
                126395,
                "YARN-5006",
                "The same behaviour occurs when a user submit a job with a jobname of 1+MB. While I appreciate that this is clearly a bug in user job submission code, the RM should protect itself against this sort of hard failure.\nFor instance if a user is using legitimately [LzoDistributedIndexer|https://github.com/twitter/hadoop-lzo/blob/master/src/main/java/com/hadoop/compression/lzo/DistributedLzoIndexer.java#L88] which lists as jobname all the files passed to index, he might shutdown the entire cluster.\n\nSo I'm wondering if the RMStateStore shouldn't have a way to reject a job submission when something is going wrong (for instance 10K+ files in DistributedCache or 1+MB jobname, both generating a znode payload > allowed limit).",
                {
                    "property": {
                        "confidence": 0.0059265331365168095,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004756192676723003,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0268841665238142,
                        "prediction": false
                    }
                }
            ],
            [
                126398,
                "YARN-5006",
                "[~luhuichun]\n\nAny progress on this patch? Hoping the implementation is not started yet. Assigning to my name. Will be adding limit as part of this jira. YARN-3935 and YARN-6426 (progress available) is available for compression. \n\n",
                {
                    "property": {
                        "confidence": 0.0038105712737888098,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.020215749740600586,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010201053693890572,
                        "prediction": false
                    }
                }
            ],
            [
                126399,
                "YARN-5006",
                "Thanks for the patch, [~bibinchundatt].  A few comments:\n* {{RM_ZK_NUM_ZNODE_SIZE_LIMIT}} would be clearer as {{RM_ZK_ZNODE_SIZE_LIMIT_BYTES}}.  Even better, could we make it generic? {{RM_APP_DATA_SIZE_LIMIT_BYTES}}\n* I don't think the {{isRejectApp()}} method makes it clearer; just inline the _instanceof_.\n* {{StoreLimitException}} needs javadoc to explain what it should be used for.\n* {{super(\"RMStateStore not limit reached\");}} could use a clearer message, like: \"Application <appId> exceeds the maximum allowed size for application data. See yarn.resourcemanager.whatever.max-data-size.bytes.\"  Same goes for the message in {{storeApplicationStateInternal()}}.\n* Please add javadoc for the new methods in {{RMAppEvent}}.\n* Please add some additional unit tests to cover the new behavior.",
                {
                    "property": {
                        "confidence": 0.005237131845206022,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007753889076411724,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011674465611577034,
                        "prediction": false
                    }
                }
            ],
            [
                126402,
                "YARN-5006",
                "thanks for this jira, i have a doubt that why \"add 10000 file into DistributedCache\" can due to *ApplicationStateData*  exceed *1M*.  IMO, *ApplicationStateData*  contains _startTime, user, ApplicationSubmissionContext, state ,diagnostics and finishTime_,  they are all small except *diagnostics*, in my scenario, a failed  spark applicaiton has *4M* info of *diagnostics*,when it update info to ZK, the *ApplicationStateData*  exceed *1M*.  then  RM lost connection with ZK,  so i think it is important to fix the size of  *diagnostics*  when \n operate  *updateApplicationAttemptStateInternal* and *updateApplicationStateInternal*  in *ZKRMStateStore*, am i wrong with this question?[~dongtingting8877@163.com] [~templedf] [~bibinchundatt]",
                {
                    "property": {
                        "confidence": 0.004886917304247618,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006810276303440332,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01785174012184143,
                        "prediction": false
                    }
                }
            ],
            [
                126405,
                "YARN-5006",
                "[~imstefanlee]\nAim of jira is to protect RM from ApplicationStateData size is more than the Limit of ZK node. \n{quote}\nAdd 10000 file into DistributedCache\n{quote}\nwe can consider as way to simulate the issue. \n",
                {
                    "property": {
                        "confidence": 0.004776825197041035,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005211587529629469,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.025295207276940346,
                        "prediction": false
                    }
                }
            ],
            [
                126406,
                "YARN-5006",
                "Thanks [~bibinchundatt],\nOverall the approach and the patch looks fine except for these following nits :\n# Please add the configuration in the {{yarn-default.xml}} and also capture that it needs to be in sync with zookeeper jute buffer, else though it passes here it will fail again at the zookeeper end. I think {{TestYarnConfigurationFields}} is failing for the same reason.\n# {{StoreLimitException}} documentation refers to only \" exceeds limit for ZK RM state store\" it should be any statestore. as we just catch in RMStatestore and hence can be thrown by any store.\n# ZKRMStateStore ln no 751: please add the appid information in the log, so that it can be traced which app was creating the problem. I would prefer have configuration size too in this log.\n# RMAppEvent  ln no 51:  {{storeApp}} is not signifying properly, would prefer doStoreAppInfo and may be a comment mentioning in the state store",
                {
                    "property": {
                        "confidence": 0.004534607287496328,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008107377216219902,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016004417091608047,
                        "prediction": false
                    }
                }
            ],
            [
                126409,
                "YARN-5006",
                "hi [~bibinchundatt],\nJust few nits before we can go in\n# checkstyle issues reported\n# RMAppEvent.java ln no 39 and 51, i think  we can have the variable name also in sync.\n\nAlso Findbugs is not related to the current patch, it should have been taken care in YARN-6517 (i have pinged the there) which has been missed somehow. Test case failures too not related to this patch.",
                {
                    "property": {
                        "confidence": 0.005650368519127369,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005461180582642555,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.015800459310412407,
                        "prediction": false
                    }
                }
            ],
            [
                126413,
                "YARN-5006",
                "Thanks for the patch, [~bibinchundatt].  A couple of final little nits:\n\n* Please add spaces after the periods in the description in {yarn-defaults.xml}}\n* {{RMAppEvent.dostoreAppInfo}} should be camel case or maybe just drop the \"do\"\n* Javadoc for {{RMAppEvent.doStoreAppInfo()}} would be helpful since the naming isn't entirely obvious\n* In {{TestAppRejDispatcher.handle()}}, can we just combine the nested _ifs_ into one?",
                {
                    "property": {
                        "confidence": 0.005098308902233839,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007411000784486532,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012323064729571342,
                        "prediction": false
                    }
                }
            ],
            [
                126424,
                "YARN-5006",
                "Thanks [~bibinchundatt] for the contribution and additional reviews from [~daniel@cloudera.com],[~imstefanlee], [~bperroud], [~rohithsharma], [~ozawa]. Have committed the patch to branch-2 and trunk. Further if required we can take in other jira for [~ozawa]'s [comment|https://issues.apache.org/jira/browse/YARN-5006?focusedCommentId=15283261&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15283261] where in we can try to compress the data before placing it in statestore",
                {
                    "property": {
                        "confidence": 0.005553091410547495,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00903826393187046,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013899331912398338,
                        "prediction": false
                    }
                }
            ],
            [
                126425,
                "YARN-5006",
                "Thanks for committing, [~Naganarasimha].  I was on vacation. :)\n\nLooks like the spaces after the periods in {{yarn-defaults.xml}} didn't get fixed in the last patch.  I'll file a newbie JIRA to address it.",
                {
                    "property": {
                        "confidence": 0.005632294341921806,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00993449054658413,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.00832658726722002,
                        "prediction": false
                    }
                }
            ],
            [
                126426,
                "YARN-5006",
                "Oops Sorry [~daniel@cloudera.com], Actually offline had informed about this to [~bibinchundatt] and he too had told me that he will delete and upload with this correction. some how we missed it. \n??I'll file a newbie JIRA to address it??  : Well addendum patch should have sufficed right ?",
                {
                    "property": {
                        "confidence": 0.005002308636903763,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012494458816945553,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007679696194827557,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d910f4d395ee2219ea72",
        "key": "SVN-2306",
        "id": "12898691",
        "description": "{noformat:nopanel=true}\nIf your WC has a file with the svn:needs-lock property set and you then switch\nyour WC to a branch where that file does not have that property.  The property\nis removed in the WC but the read-only attribute is not removed from the file.\n\nThis causes problems in Subclipse, and somewhat also TortoiseSVN, since we both\ndecorate files based on the read-only attribute.  In the case of Subclipse, the\npresence of the read-only attribute causes Eclipse to present the user with the\nSubclipse Lock UI -- a good thing.  However, we are then relying on the svn lock\ncommand to remove the read-only attribute, which it doesn't in this case.  It\nwould be nice as a fail-safe if it could do that.\n\nThis should be reproduction recipe.  I did it on Windows, so this may not be\nexactly right.\n\nsvn mkdir -m \"\" url://repos/trunk\nsvn co url://repos/trunk test_wc\ncd testwc\ntouch foo\nsvn add foo\nsvn ci -m \"\"\nsvn copy -m \"\" . url://repos/branch \nsvn propset svn:needs-lock foo\nsvn ci -m \"\"    \nsvn switch url://repos/branch\n\nAt this point, foo will not have the property, but it will be read-only.\n\nAgain, as an additional requuest it would be nice at this point if:\n\nsvn lock foo\n\nWould remove the read-only attribute even though the svn:needs-lock property\ndoes not exist.\n{noformat}",
        "predictions": {},
        "comments": [
            {
                "author_name": "fitz",
                "id": "14921888",
                "body": "{noformat:nopanel=true}\nI'm unable to reproduce this bug.\n\nHere's the shell script I used:\n\n#!/bin/sh\n\n# HEAD of trunk\nSVN=~/svn-work/subversion/subversion/clients/cmdline/svn\n\nrm -rf wc repo\n\nBASEDIR=`pwd`\n\nsvnadmin create $(pwd)/repo\n\nsvn mkdir -m \"\" file://${BASEDIR}/repo/trunk\nsvn co file://${BASEDIR}/repo/trunk wc\ncd wc\ntouch foo\n$SVN add foo\n$SVN ci -m \"\"\nls -l foo\n$SVN copy -m \"\" . file://${BASEDIR}/repo/branch\n$SVN propset svn:needs-lock 1 foo\n$SVN ci -m \"\"    \nls -l foo\n$SVN switch file://${BASEDIR}/repo/branch\nls -l foo\n\n\nThis results in:\n\n./doit.sh \n\nCommitted revision 1.\nChecked out revision 1.\nA         foo\nAdding         foo\nTransmitting file data .\nCommitted revision 2.\n-rw-r--r--    1 fitz     users           0 May 27 13:21 foo\n\nCommitted revision 3.\nproperty 'svn:needs-lock' set on 'foo'\nSending        foo\n\nCommitted revision 4.\n-r--r--r--    1 fitz     users           0 May 27 13:21 foo\n U   foo\nUpdated to revision 4.\n-rw-r--r--    1 fitz     users           0 May 27 13:21 foo\n\n\nNote that the perms were reset.  So maybe this is a win32 bug?  Can someone with\na win32 setup verify?\n{noformat}\n"
            },
            {
                "author_name": "markphip",
                "id": "14921889",
                "body": "{noformat:nopanel=true}\nOK.  I tested with the 1.2 GA on Win32, and I still get the problem,\n\nHere is my script:\n\nset PATH=%PATH%;C:\\svn-win32-1.2.0\\bin\n\nset REPOS=file:///repo\ncd \\\n\nsvnadmin create repo\n\nsvn mkdir -m \"\" %REPOS%/trunk\nsvn co %REPOS%/trunk wc\ncd wc\necho \"creating file\" > foo\nsvn add foo\nsvn ci -m \"\"\nattrib foo\nsvn copy -m \"\" . %REPOS%/branch\nsvn propset svn:needs-lock 1 foo\nsvn ci -m \"\"    \nattrib foo\nsvn switch %REPOS%/branch\nattrib foo\nsvn info foo\n\nAnd here is the output:\n\nC:\\Documents and Settings\\markphip\\Desktop>set PATH=C:\\WINDOWS\\system32;C:\\WINDO\nWS;C:\\WINDOWS\\System32\\Wbem;C:\\PROGRA~1\\IBM\\CLIENT~1;C:\\PROGRA~1\\IBM\\CLIENT~1\\Sh\nared;;C:\\svn-win32-1.2.0\\bin\n\nC:\\Documents and Settings\\markphip\\Desktop>set REPOS=file:///repo\n\nC:\\Documents and Settings\\markphip\\Desktop>cd \\\n\nC:\\>svnadmin create repo\n\nC:\\>svn mkdir -m \"\" file:///repo/trunk\n\nCommitted revision 1.\n\nC:\\>svn co file:///repo/trunk wc\nChecked out revision 1.\n\nC:\\>cd wc\n\nC:\\wc>echo \"creating file\"  1>foo\n\nC:\\wc>svn add foo\nA         foo\n\nC:\\wc>svn ci -m \"\"\nAdding         foo\nTransmitting file data .\nCommitted revision 2.\n\nC:\\wc>attrib foo\nA          C:\\wc\\foo\n\nC:\\wc>svn copy -m \"\" . file:///repo/branch\n\nCommitted revision 3.\n\nC:\\wc>svn propset svn:needs-lock 1 foo\nproperty 'svn:needs-lock' set on 'foo'\n\nC:\\wc>svn ci -m \"\"\nSending        foo\n\nCommitted revision 4.\n\nC:\\wc>attrib foo\nA    R     C:\\wc\\foo\n\nC:\\wc>svn switch file:///repo/branch\n U   foo\nUpdated to revision 4.\n\nC:\\wc>attrib foo\nA    R     C:\\wc\\foo\n\nC:\\wc>svn info foo\nPath: foo\nName: foo\nURL: file:///repo/branch/foo\nRepository UUID: de554f40-0d90-934d-b5df-4692810cc0e9\nRevision: 4\nNode Kind: file\nSchedule: normal\nLast Changed Author: markphip\nLast Changed Rev: 3\nLast Changed Date: 2005-05-27 15:39:47 -0400 (Fri, 27 May 2005)\nText Last Updated: 2005-05-27 15:39:49 -0400 (Fri, 27 May 2005)\nProperties Last Updated: 2005-05-27 15:39:49 -0400 (Fri, 27 May 2005)\nChecksum: 22302679ec952980868aca1812bef4c4\n{noformat}\n"
            },
            {
                "author_name": "ehuelsmann",
                "id": "14921890",
                "body": "{noformat:nopanel=true}\nMoving to 1.3.x since 1.3 will go into soak RSN.\n\n\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921921",
                "body": "Attachment 1_patch.txt has been added with description: A new test for switch_tests.py based on Mark's recipe"
            },
            {
                "author_name": "dlr",
                "id": "14921891",
                "body": "{noformat:nopanel=true}\nCreated an attachment (id=516)\nA new test for switch_tests.py based on Mark's recipe\n\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921892",
                "body": "{noformat:nopanel=true}\nMark, can you give the test case I just uploaded a try on Windows?  It's based\non your recipe, but is passing on my Fedora Core 4 box.  Thanks!\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921922",
                "body": "Attachment 2_patch.txt has been added with description: Correct version of the patch adding a test for this issue"
            },
            {
                "author_name": "dlr",
                "id": "14921893",
                "body": "{noformat:nopanel=true}\nCreated an attachment (id=517)\nCorrect version of the patch adding a test for this issue\n\n{noformat}\n"
            },
            {
                "author_name": "markphip",
                "id": "14921894",
                "body": "{noformat:nopanel=true}\nOK, I got a chance to test this with trunk.  Both my original recipe, and your\ntest fail.  Here is the output of your test.\n\nCMD: svnadmin.exe \"create\" \"svn-test-work\\repositories\\switch_tests-17\"\n\"--bdb-txn-nosync\" \"--fs-type=fsfs\" <TIME = 0.062000>\nCMD: svnadmin.exe dump \"svn-test-work\\local_tmp\\repos\" | svnadmin.exe load\n\"svn-test-work\\repositories\\switch_tests-17\" <TIME = 0.016000>\nCMD: svn.exe \"co\" \"--username\" \"jrandom\" \"--password\" \"rayjandom\"\n\"file:///E:/svn/src-trunk/Release/subversion/tests/clients/cmdline/svn-test-work/repositories/switch_tests-17\"\n\"svn-test-work\\working_copies\\switch_tests-17\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 1.047000>\nCMD: svn.exe \"cp\" \"-m\" \"svn:needs-lock not set\"\n\"file:///E:/svn/src-trunk/Release/subversion/tests/clients/cmdline/svn-test-work/repositories/switch_tests-17/A\"\n\"file:///E:/svn/src-trunk/Release/subversion/tests/clients/cmdline/svn-test-work/repositories/switch_tests-17/A-branch\"\n\"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.062000>\nCMD: svn.exe \"ps\" \"svn:needs-lock\" \"1\"\n\"svn-test-work\\working_copies\\switch_tests-17\\A\\mu\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.063000>\nCMD: svn.exe \"ci\" \"-m\" \"log msg\"\n\"svn-test-work\\working_copies\\switch_tests-17\\A\\mu\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.859000>\nCMD: svn.exe \"status\" \"-v\" \"-u\" \"-q\" \"--username\" \"jrandom\" \"--password\"\n\"rayjandom\" \"svn-test-work\\working_copies\\switch_tests-17\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.078000>\nCMD: svn.exe \"switch\" \"--username\" \"jrandom\" \"--password\" \"rayjandom\"\n\"file:///E:/svn/src-trunk/Release/subversion/tests/clients/cmdline/svn-test-work/repositories/switch_tests-17/A-branch\"\n\"svn-test-work\\working_copies\\switch_tests-17\\A\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.922000>\nCMD: svn.exe \"status\" \"-v\" \"-u\" \"-q\" \"--username\" \"jrandom\" \"--password\"\n\"rayjandom\" \"svn-test-work\\working_copies\\switch_tests-17\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.062000>\nEXCEPTION: Failure: 'svn-test-work\\working_copies\\switch_tests-17\\A\\mu' expected\nto be writable\nFAIL:  switch_tests.py 17: refresh the WC file system read-only attribute \nEND: switch_tests.py\n\n{noformat}\n"
            },
            {
                "author_name": "subversion-importer",
                "id": "14921895",
                "body": "{noformat:nopanel=true}\nThis must be simple.\n{noformat}\n\n\nOriginal comment by *lundblad*"
            },
            {
                "author_name": "subversion-importer",
                "id": "14921896",
                "body": "{noformat:nopanel=true}\nHa! My last comment was premature. I didn't notice it was Windows-specific. I \nchange platform and os to reflect this (I choose Windows XP, but it probably \naffects all Windows versions).\n\nThe problem here is that svn_io_file_rename is careful to keep the read-only \nflag on Windows, and not on Unix. So if the file was read-only before the \nupdate/switch, it will continue to be so afterwards as well. I don't know why \nwe behave like this on Windows.\n\nReassigning from self, since I don't have a Windows testing environment. Some \nWindows developer may want to take this.\n{noformat}\n\n\nOriginal comment by *lundblad*"
            },
            {
                "author_name": "dlr",
                "id": "14921897",
                "body": "{noformat:nopanel=true}\nCommitted the new test case XFail as r17086.  While I believe this test case\npreviously passed on Linux, it no longer passes (since merge of the\nwc-replacements branch, perhaps?).\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921898",
                "body": "{noformat:nopanel=true}\nIn the failure I'm currently seeing on Linux (circa r17089), 'svn ps\nsvn:needs-lock 1' is changing a file from rw to read-only.\n\n'svn up -r REV_BEFORE_LOCK' on a directory containing a locked file (which is\nread-only) is also is not changing a file's permissions from read-only back to rw.\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921899",
                "body": "{noformat:nopanel=true}\nI retract the statement about both 'switch' and 'update' on not working on Linux\n-- perhaps the test is yielding a false-positive?\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921923",
                "body": "Attachment 3_stack.txt has been added with description: Stack showing how this works on Linux"
            },
            {
                "author_name": "dlr",
                "id": "14921900",
                "body": "{noformat:nopanel=true}\nCreated an attachment (id=524)\nStack showing how this works on Linux\n\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921924",
                "body": "Attachment 4_2306.recipe.sh has been added with description: Shell script recipe from Madan"
            },
            {
                "author_name": "dlr",
                "id": "14921901",
                "body": "{noformat:nopanel=true}\nCreated an attachment (id=525)\nShell script recipe from Madan\n\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921902",
                "body": "{noformat:nopanel=true}\nI've confirmed that this test doees in fact work on Linux in our 1.3.x branch.  \nHere's a summary of our test status for this problem:\n\n         +------+------+\n         | 1.2  | 1.3  |\n+--------+------+------+\n| Linux  | pass | fail |\n+--------+------+------+\n|Windows | fail | ???? |\n+--------+------+------+\n\nFurthermore, on trunk, switching trunk -> branch doesn't change the file\npermissions, but subsequently switching branch -> trunk then trunk -> branch\nagain will (!!).\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921903",
                "body": "{noformat:nopanel=true}\nOops, I drew my little TABLE WRONG -- 1.2 is intended to be 1.3, and 1.3 is\nintended to be trunk.\n{noformat}\n"
            },
            {
                "author_name": "ivan",
                "id": "14921904",
                "body": "{noformat:nopanel=true}\nFAIL:  switch_tests.py 17: refresh the WC file system read-only attribute\nSo test keep on failing on Windows with trunk.\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921905",
                "body": "{noformat:nopanel=true}\neh says (paraphrased): We did do translation stuff when merging the\nwc-replacements branch into trunk.  The short cut when no translation is\nnecessary is to copy a file.  If that file is ro, that's copied too.\n\nThis might explain the trunk behavior WRT the switch. \nlibsvn_wc/update_editor.c:install_file() might be relevant.\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921906",
                "body": "{noformat:nopanel=true}\nWhen switching from trunk (which has svn:needs-lock set) to a branch (which does\nnot have the prop set), memory for lock_state is passed into install_file()\n(pointing at garbage).  Then, it's set to svn_wc_notify_lock_state_unchanged by\naccumulate_entry_props().  It's subsequently not changed before being used:\n\n  if (entry_props)\n    SVN_ERR (accumulate_entry_props (log_accum, lock_state,\n                                     adm_access, base_name,\n                                     entry_props, pool));\n  ...\n  else if (*lock_state == svn_wc_notify_lock_state_unlocked)\n    /* If a lock was removed and we didn't update the text contents, we\n       might need to set the file read-only. */\n    SVN_ERR (svn_wc__loggy_maybe_set_readonly (&log_accum, adm_access,\n                                                 base_name, pool));\n\naccumulate_entry_props() would normally set lock_state to\nsvn_wc_notify_lock_state_unlocked if it detected that a lock was removed. \nHowever, SVN_PROP_ENTRY_LOCK_TOKEN is not encountered in the list of WC\nproperties, and thus lock_state remains unchanged from the passed in value:\n\n      if (! strcmp (prop->name, SVN_PROP_ENTRY_LOCK_TOKEN))\n        {\n          SVN_ERR (svn_wc__loggy_delete_lock (&log_accum, adm_access,\n                                              base_name, pool));\n          if (lock_state)\n            *lock_state = svn_wc_notify_lock_state_unlocked;\n          continue;\n        }\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921907",
                "body": "{noformat:nopanel=true}\nI've tracked the Linux portion of this regression in trunk to r16897.\n\nsvn log -r16897\nsvn diff -r16896:16897\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921908",
                "body": "{noformat:nopanel=true}\nRather, I know the regression in trunk on Linux occurs between r16782 (which\nworks) and r16897 (which doesn't work).\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921909",
                "body": "{noformat:nopanel=true}\nOne rather significant difference WRT the regression on Linux appears to be the\npresence of the new version of the resource in the .svn/tmp/test-base/ directory\n(e.g. wc/trunk/.svn/tmp/text-base/file1.svn-base); it's not there for the first\nswitch from trunk to branch when install_file() is called, but is present for\nthe second re-switch from trunk to branch.  Perhaps this has some impact on the\nbehavior of the XML parser callback's invocation of the file_xfer_under_path()\nfunction?\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921910",
                "body": "{noformat:nopanel=true}\nThe WC log files are also getting generated differently between the first and\nsecond runs:\n\n <cp-and-detranslate\n    dest=\".svn/tmp/text-base/file1.svn-base\"\n    name=\"file1\"/>\n+<cp-and-translate\n+   dest=\"file1\"\n+   name=\".svn/tmp/text-base/file1.svn-base\"/>\n\nThe operation triggered by the second <cp-and-translate> overwrites the WC file\nwith the text base of the new resource (which maps to a call to\nsvn_io_copy_file() with with copy_perms=0).  This eventually invokes\nsvn_io_file_rename(), which Peter says drops the read-only file permissions.\n{noformat}\n"
            },
            {
                "author_name": "ehuelsmann",
                "id": "14921911",
                "body": "{noformat:nopanel=true}\nFix committed in r17325.\n\nWhat remains is to create a test case. Setting bite-sized keyword accordingly.\n{noformat}\n"
            },
            {
                "author_name": "ehuelsmann",
                "id": "14921912",
                "body": "{noformat:nopanel=true}\nAfter this mornings automated tests, I found there already *is* a test case for\nthis issue. I unmarked it XFAIL in r17326. Closing this issue.\n{noformat}\n"
            },
            {
                "author_name": "ehuelsmann",
                "id": "14921913",
                "body": "{noformat:nopanel=true}\nHeh. Early - no coffee yet. Really closing.\n{noformat}\n"
            },
            {
                "author_name": "ivan",
                "id": "14921914",
                "body": "{noformat:nopanel=true}\nAt r17326 tests keep failing on Windows:\n\nEXCEPTION: Failure: 'svn-test-work\\working_copies\\switch_tests-17\\A\\mu' expected\nto be writable after being switched to a branch on which its svn:needs-lock\nproperty is not set\nFAIL:  switch_tests.py 17: refresh the WC file system read-only attribute \n\nSo I need to reopen issue?\n{noformat}\n"
            },
            {
                "author_name": "ehuelsmann",
                "id": "14921915",
                "body": "{noformat:nopanel=true}\nTests still failed on some machines (windows only).\n\nZhakov tested the fix committed in r17333 and now the tests pass again. Issue\nreally fixed now.\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921916",
                "body": "{noformat:nopanel=true}\nApparently the fix for this issue wasn't backported to the 1.3.x branch, and\nthus won't be present in 1.3.0.  It's now proposed for backport to 1.3.1.\n\nAdditionally, we have a report of similar troubles on Mac OS 10.4.3:\nhttp://subversion.tigris.org/servlets/ReadMsg?list=dev&msgNo=110197\n{noformat}\n"
            },
            {
                "author_name": "dlr",
                "id": "14921925",
                "body": "Attachment 5_patch.txt has been added with description: Backport of the regression test from trunk to the 1.3.x branch"
            },
            {
                "author_name": "dlr",
                "id": "14921917",
                "body": "{noformat:nopanel=true}\nCreated an attachment (id=536)\nBackport of the regression test from trunk to the 1.3.x branch\n\n{noformat}\n"
            },
            {
                "author_name": "maxb",
                "id": "14921918",
                "body": "{noformat:nopanel=true}\nReset target milestone to 1.3.x after (accidental?) change by dlr.\n\nIt is proposed for backport, after all.\n{noformat}\n"
            },
            {
                "author_name": "subversion-importer",
                "id": "14921919",
                "body": "{noformat:nopanel=true}\nWith Subversion 1.4.2 under Mac OS X 1.4.6:\n\nAt least one test FAILED, checking /usr/local/src/subversion-1.4.2/tests.log\nFAIL:  switch_tests.py 17: refresh the WC file system read-only attribute\n\nLet me know if I can paste anything else that will be useful.\n{noformat}\n\n\nOriginal comment by *jmitchell*"
            },
            {
                "author_name": "subversion-importer",
                "id": "14921920",
                "body": "{noformat:nopanel=true}\nJeff: I bet you're running the tests as root.  Don't do that.\n{noformat}\n\n\nOriginal comment by *malcolm*"
            }
        ],
        "comments_predictions": [
            [
                526006,
                "SVN-2306",
                "{noformat:nopanel=true}\nI'm unable to reproduce this bug.\n\nHere's the shell script I used:\n\n#!/bin/sh\n\n# HEAD of trunk\nSVN=~/svn-work/subversion/subversion/clients/cmdline/svn\n\nrm -rf wc repo\n\nBASEDIR=`pwd`\n\nsvnadmin create $(pwd)/repo\n\nsvn mkdir -m \"\" file://${BASEDIR}/repo/trunk\nsvn co file://${BASEDIR}/repo/trunk wc\ncd wc\ntouch foo\n$SVN add foo\n$SVN ci -m \"\"\nls -l foo\n$SVN copy -m \"\" . file://${BASEDIR}/repo/branch\n$SVN propset svn:needs-lock 1 foo\n$SVN ci -m \"\"    \nls -l foo\n$SVN switch file://${BASEDIR}/repo/branch\nls -l foo\n\n\nThis results in:\n\n./doit.sh \n\nCommitted revision 1.\nChecked out revision 1.\nA         foo\nAdding         foo\nTransmitting file data .\nCommitted revision 2.\n-rw-r--r--    1 fitz     users           0 May 27 13:21 foo\n\nCommitted revision 3.\nproperty 'svn:needs-lock' set on 'foo'\nSending        foo\n\nCommitted revision 4.\n-r--r--r--    1 fitz     users           0 May 27 13:21 foo\n U   foo\nUpdated to revision 4.\n-rw-r--r--    1 fitz     users           0 May 27 13:21 foo\n\n\nNote that the perms were reset.  So maybe this is a win32 bug?  Can someone with\na win32 setup verify?\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.0048094033263623714,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0076019903644919395,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01400662213563919,
                        "prediction": false
                    }
                }
            ],
            [
                526007,
                "SVN-2306",
                "{noformat:nopanel=true}\nOK.  I tested with the 1.2 GA on Win32, and I still get the problem,\n\nHere is my script:\n\nset PATH=%PATH%;C:\\svn-win32-1.2.0\\bin\n\nset REPOS=file:///repo\ncd \\\n\nsvnadmin create repo\n\nsvn mkdir -m \"\" %REPOS%/trunk\nsvn co %REPOS%/trunk wc\ncd wc\necho \"creating file\" > foo\nsvn add foo\nsvn ci -m \"\"\nattrib foo\nsvn copy -m \"\" . %REPOS%/branch\nsvn propset svn:needs-lock 1 foo\nsvn ci -m \"\"    \nattrib foo\nsvn switch %REPOS%/branch\nattrib foo\nsvn info foo\n\nAnd here is the output:\n\nC:\\Documents and Settings\\markphip\\Desktop>set PATH=C:\\WINDOWS\\system32;C:\\WINDO\nWS;C:\\WINDOWS\\System32\\Wbem;C:\\PROGRA~1\\IBM\\CLIENT~1;C:\\PROGRA~1\\IBM\\CLIENT~1\\Sh\nared;;C:\\svn-win32-1.2.0\\bin\n\nC:\\Documents and Settings\\markphip\\Desktop>set REPOS=file:///repo\n\nC:\\Documents and Settings\\markphip\\Desktop>cd \\\n\nC:\\>svnadmin create repo\n\nC:\\>svn mkdir -m \"\" file:///repo/trunk\n\nCommitted revision 1.\n\nC:\\>svn co file:///repo/trunk wc\nChecked out revision 1.\n\nC:\\>cd wc\n\nC:\\wc>echo \"creating file\"  1>foo\n\nC:\\wc>svn add foo\nA         foo\n\nC:\\wc>svn ci -m \"\"\nAdding         foo\nTransmitting file data .\nCommitted revision 2.\n\nC:\\wc>attrib foo\nA          C:\\wc\\foo\n\nC:\\wc>svn copy -m \"\" . file:///repo/branch\n\nCommitted revision 3.\n\nC:\\wc>svn propset svn:needs-lock 1 foo\nproperty 'svn:needs-lock' set on 'foo'\n\nC:\\wc>svn ci -m \"\"\nSending        foo\n\nCommitted revision 4.\n\nC:\\wc>attrib foo\nA    R     C:\\wc\\foo\n\nC:\\wc>svn switch file:///repo/branch\n U   foo\nUpdated to revision 4.\n\nC:\\wc>attrib foo\nA    R     C:\\wc\\foo\n\nC:\\wc>svn info foo\nPath: foo\nName: foo\nURL: file:///repo/branch/foo\nRepository UUID: de554f40-0d90-934d-b5df-4692810cc0e9\nRevision: 4\nNode Kind: file\nSchedule: normal\nLast Changed Author: markphip\nLast Changed Rev: 3\nLast Changed Date: 2005-05-27 15:39:47 -0400 (Fri, 27 May 2005)\nText Last Updated: 2005-05-27 15:39:49 -0400 (Fri, 27 May 2005)\nProperties Last Updated: 2005-05-27 15:39:49 -0400 (Fri, 27 May 2005)\nChecksum: 22302679ec952980868aca1812bef4c4\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.005947321653366089,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004802518058568239,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03423202410340309,
                        "prediction": false
                    }
                }
            ],
            [
                526014,
                "SVN-2306",
                "{noformat:nopanel=true}\nOK, I got a chance to test this with trunk.  Both my original recipe, and your\ntest fail.  Here is the output of your test.\n\nCMD: svnadmin.exe \"create\" \"svn-test-work\\repositories\\switch_tests-17\"\n\"--bdb-txn-nosync\" \"--fs-type=fsfs\" <TIME = 0.062000>\nCMD: svnadmin.exe dump \"svn-test-work\\local_tmp\\repos\" | svnadmin.exe load\n\"svn-test-work\\repositories\\switch_tests-17\" <TIME = 0.016000>\nCMD: svn.exe \"co\" \"--username\" \"jrandom\" \"--password\" \"rayjandom\"\n\"file:///E:/svn/src-trunk/Release/subversion/tests/clients/cmdline/svn-test-work/repositories/switch_tests-17\"\n\"svn-test-work\\working_copies\\switch_tests-17\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 1.047000>\nCMD: svn.exe \"cp\" \"-m\" \"svn:needs-lock not set\"\n\"file:///E:/svn/src-trunk/Release/subversion/tests/clients/cmdline/svn-test-work/repositories/switch_tests-17/A\"\n\"file:///E:/svn/src-trunk/Release/subversion/tests/clients/cmdline/svn-test-work/repositories/switch_tests-17/A-branch\"\n\"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.062000>\nCMD: svn.exe \"ps\" \"svn:needs-lock\" \"1\"\n\"svn-test-work\\working_copies\\switch_tests-17\\A\\mu\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.063000>\nCMD: svn.exe \"ci\" \"-m\" \"log msg\"\n\"svn-test-work\\working_copies\\switch_tests-17\\A\\mu\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.859000>\nCMD: svn.exe \"status\" \"-v\" \"-u\" \"-q\" \"--username\" \"jrandom\" \"--password\"\n\"rayjandom\" \"svn-test-work\\working_copies\\switch_tests-17\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.078000>\nCMD: svn.exe \"switch\" \"--username\" \"jrandom\" \"--password\" \"rayjandom\"\n\"file:///E:/svn/src-trunk/Release/subversion/tests/clients/cmdline/svn-test-work/repositories/switch_tests-17/A-branch\"\n\"svn-test-work\\working_copies\\switch_tests-17\\A\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.922000>\nCMD: svn.exe \"status\" \"-v\" \"-u\" \"-q\" \"--username\" \"jrandom\" \"--password\"\n\"rayjandom\" \"svn-test-work\\working_copies\\switch_tests-17\" \"--config-dir\"\n\"E:\\svn\\src-trunk\\Release\\subversion\\tests\\clients\\cmdline\\svn-test-work\\local_tmp\\config\"\n<TIME = 0.062000>\nEXCEPTION: Failure: 'svn-test-work\\working_copies\\switch_tests-17\\A\\mu' expected\nto be writable\nFAIL:  switch_tests.py 17: refresh the WC file system read-only attribute \nEND: switch_tests.py\n\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.004605347290635109,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008113653399050236,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.020448481664061546,
                        "prediction": false
                    }
                }
            ],
            [
                526016,
                "SVN-2306",
                "{noformat:nopanel=true}\nHa! My last comment was premature. I didn't notice it was Windows-specific. I \nchange platform and os to reflect this (I choose Windows XP, but it probably \naffects all Windows versions).\n\nThe problem here is that svn_io_file_rename is careful to keep the read-only \nflag on Windows, and not on Unix. So if the file was read-only before the \nupdate/switch, it will continue to be so afterwards as well. I don't know why \nwe behave like this on Windows.\n\nReassigning from self, since I don't have a Windows testing environment. Some \nWindows developer may want to take this.\n{noformat}\n\n\nOriginal comment by *lundblad*",
                {
                    "property": {
                        "confidence": 0.0048587871715426445,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011925570666790009,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007900482974946499,
                        "prediction": false
                    }
                }
            ],
            [
                526017,
                "SVN-2306",
                "{noformat:nopanel=true}\nCommitted the new test case XFail as r17086.  While I believe this test case\npreviously passed on Linux, it no longer passes (since merge of the\nwc-replacements branch, perhaps?).\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.0048046838492155075,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007410804275423288,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013964643701910973,
                        "prediction": false
                    }
                }
            ],
            [
                526018,
                "SVN-2306",
                "{noformat:nopanel=true}\nIn the failure I'm currently seeing on Linux (circa r17089), 'svn ps\nsvn:needs-lock 1' is changing a file from rw to read-only.\n\n'svn up -r REV_BEFORE_LOCK' on a directory containing a locked file (which is\nread-only) is also is not changing a file's permissions from read-only back to rw.\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.006440143566578627,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011332448571920395,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006903285626322031,
                        "prediction": false
                    }
                }
            ],
            [
                526024,
                "SVN-2306",
                "{noformat:nopanel=true}\nI've confirmed that this test doees in fact work on Linux in our 1.3.x branch.  \nHere's a summary of our test status for this problem:\n\n         +------+------+\n         | 1.2  | 1.3  |\n+--------+------+------+\n| Linux  | pass | fail |\n+--------+------+------+\n|Windows | fail | ???? |\n+--------+------+------+\n\nFurthermore, on trunk, switching trunk -> branch doesn't change the file\npermissions, but subsequently switching branch -> trunk then trunk -> branch\nagain will (!!).\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.005272723734378815,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009002096951007843,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009538614191114902,
                        "prediction": false
                    }
                }
            ],
            [
                526027,
                "SVN-2306",
                "{noformat:nopanel=true}\neh says (paraphrased): We did do translation stuff when merging the\nwc-replacements branch into trunk.  The short cut when no translation is\nnecessary is to copy a file.  If that file is ro, that's copied too.\n\nThis might explain the trunk behavior WRT the switch. \nlibsvn_wc/update_editor.c:install_file() might be relevant.\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.004893948789685965,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0052374606020748615,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.021674592047929764,
                        "prediction": false
                    }
                }
            ],
            [
                526028,
                "SVN-2306",
                "{noformat:nopanel=true}\nWhen switching from trunk (which has svn:needs-lock set) to a branch (which does\nnot have the prop set), memory for lock_state is passed into install_file()\n(pointing at garbage).  Then, it's set to svn_wc_notify_lock_state_unchanged by\naccumulate_entry_props().  It's subsequently not changed before being used:\n\n  if (entry_props)\n    SVN_ERR (accumulate_entry_props (log_accum, lock_state,\n                                     adm_access, base_name,\n                                     entry_props, pool));\n  ...\n  else if (*lock_state == svn_wc_notify_lock_state_unlocked)\n    /* If a lock was removed and we didn't update the text contents, we\n       might need to set the file read-only. */\n    SVN_ERR (svn_wc__loggy_maybe_set_readonly (&log_accum, adm_access,\n                                                 base_name, pool));\n\naccumulate_entry_props() would normally set lock_state to\nsvn_wc_notify_lock_state_unlocked if it detected that a lock was removed. \nHowever, SVN_PROP_ENTRY_LOCK_TOKEN is not encountered in the list of WC\nproperties, and thus lock_state remains unchanged from the passed in value:\n\n      if (! strcmp (prop->name, SVN_PROP_ENTRY_LOCK_TOKEN))\n        {\n          SVN_ERR (svn_wc__loggy_delete_lock (&log_accum, adm_access,\n                                              base_name, pool));\n          if (lock_state)\n            *lock_state = svn_wc_notify_lock_state_unlocked;\n          continue;\n        }\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.005400001537054777,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007078264839947224,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013208066113293171,
                        "prediction": false
                    }
                }
            ],
            [
                526031,
                "SVN-2306",
                "{noformat:nopanel=true}\nOne rather significant difference WRT the regression on Linux appears to be the\npresence of the new version of the resource in the .svn/tmp/test-base/ directory\n(e.g. wc/trunk/.svn/tmp/text-base/file1.svn-base); it's not there for the first\nswitch from trunk to branch when install_file() is called, but is present for\nthe second re-switch from trunk to branch.  Perhaps this has some impact on the\nbehavior of the XML parser callback's invocation of the file_xfer_under_path()\nfunction?\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.005525844171643257,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0056371972896158695,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01433379016816616,
                        "prediction": false
                    }
                }
            ],
            [
                526032,
                "SVN-2306",
                "{noformat:nopanel=true}\nThe WC log files are also getting generated differently between the first and\nsecond runs:\n\n <cp-and-detranslate\n    dest=\".svn/tmp/text-base/file1.svn-base\"\n    name=\"file1\"/>\n+<cp-and-translate\n+   dest=\"file1\"\n+   name=\".svn/tmp/text-base/file1.svn-base\"/>\n\nThe operation triggered by the second <cp-and-translate> overwrites the WC file\nwith the text base of the new resource (which maps to a call to\nsvn_io_copy_file() with with copy_perms=0).  This eventually invokes\nsvn_io_file_rename(), which Peter says drops the read-only file permissions.\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.005141081754118204,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005363463424146175,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018977347761392593,
                        "prediction": false
                    }
                }
            ],
            [
                526036,
                "SVN-2306",
                "{noformat:nopanel=true}\nAt r17326 tests keep failing on Windows:\n\nEXCEPTION: Failure: 'svn-test-work\\working_copies\\switch_tests-17\\A\\mu' expected\nto be writable after being switched to a branch on which its svn:needs-lock\nproperty is not set\nFAIL:  switch_tests.py 17: refresh the WC file system read-only attribute \n\nSo I need to reopen issue?\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.0055136545561254025,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005597521085292101,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016600649803876877,
                        "prediction": false
                    }
                }
            ],
            [
                526038,
                "SVN-2306",
                "{noformat:nopanel=true}\nApparently the fix for this issue wasn't backported to the 1.3.x branch, and\nthus won't be present in 1.3.0.  It's now proposed for backport to 1.3.1.\n\nAdditionally, we have a report of similar troubles on Mac OS 10.4.3:\nhttp://subversion.tigris.org/servlets/ReadMsg?list=dev&msgNo=110197\n{noformat}\n",
                {
                    "property": {
                        "confidence": 0.005248601548373699,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008223958313465118,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010149800218641758,
                        "prediction": false
                    }
                }
            ],
            [
                526042,
                "SVN-2306",
                "{noformat:nopanel=true}\nWith Subversion 1.4.2 under Mac OS X 1.4.6:\n\nAt least one test FAILED, checking /usr/local/src/subversion-1.4.2/tests.log\nFAIL:  switch_tests.py 17: refresh the WC file system read-only attribute\n\nLet me know if I can paste anything else that will be useful.\n{noformat}\n\n\nOriginal comment by *jmitchell*",
                {
                    "property": {
                        "confidence": 0.004789224825799465,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009180333465337753,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010188697837293148,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "6407448acc1994d91233b39d",
        "key": "NIFI-9168",
        "id": "13397304",
        "description": "After install Nifi Registry in Production environment, when we configured Registries entry and tried to start a new version control, we had the below error:\r\n\r\n!image-2021-08-25-13-14-50-981.png!\r\n\r\n\u00a0\r\n\r\nSo, after import the registry keystore in my nifi nodes, as:\r\n\r\n'''\r\n\r\nkeytool -importcert -keystore /opt/nifi/conf/truststore.jks -storepass ***** -file /tmp/nifi-registry.cer -alias nifi-registry\r\n\r\n'''\r\n\r\n\u00a0\r\n\r\nNow, the error is:\r\n\r\n\u00a0\r\n\r\n!image-2021-08-25-13-16-51-916.png!\r\n Error\r\n Unable to obtain listing of buckets: javax.net.ssl.SSLException: readHandshakeRecord\r\n\r\nSome one already had some like this?\r\n\r\n\u00a0\r\n\r\n\u00a0Below, full error log when i try to begin a new control version:\r\n\r\n\u00a0\r\n\r\n'''\r\n\r\n2021-08-25 13:07:09,554 WARN [NiFi Web Server-171] o.a.n.w.a.config.NiFiCoreExceptionMapper org.apache.nifi.web.NiFiCoreException: Unable to obtain listing of buckets: javax.net.ssl.SSLException: readHandshakeRecord. Returning Conflict response.\r\n org.apache.nifi.web.NiFiCoreException: Unable to obtain listing of buckets: javax.net.ssl.SSLException: readHandshakeRecord\r\n at org.apache.nifi.web.dao.impl.FlowRegistryDAO.getBucketsForUser(FlowRegistryDAO.java:80)\r\n at org.apache.nifi.web.StandardNiFiServiceFacade.getBucketsForUser(StandardNiFiServiceFacade.java:2948)\r\n at org.apache.nifi.web.StandardNiFiServiceFacade$$FastClassBySpringCGLIB$$358780e0.invoke(<generated>)\r\n at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\r\n at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:736)\r\n at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\r\n at org.springframework.aop.aspectj.MethodInvocationProceedingJoinPoint.proceed(MethodInvocationProceedingJoinPoint.java:84)\r\n at org.apache.nifi.web.NiFiServiceFacadeLock.proceedWithReadLock(NiFiServiceFacadeLock.java:161)\r\n at org.apache.nifi.web.NiFiServiceFacadeLock.getLock(NiFiServiceFacadeLock.java:120)\r\n at jdk.internal.reflect.GeneratedMethodAccessor111.invoke(Unknown Source)\r\n at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n at java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethodWithGivenArgs(AbstractAspectJAdvice.java:627)\r\n at org.springframework.aop.aspectj.AbstractAspectJAdvice.invokeAdviceMethod(AbstractAspectJAdvice.java:616)\r\n at org.springframework.aop.aspectj.AspectJAroundAdvice.invoke(AspectJAroundAdvice.java:70)\r\n at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\r\n at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92)\r\n at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\r\n at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:671)\r\n at org.apache.nifi.web.StandardNiFiServiceFacade$$EnhancerBySpringCGLIB$$17e08624.getBucketsForUser(<generated>)\r\n at org.apache.nifi.web.api.FlowResource.getBuckets(FlowResource.java:1511)\r\n at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n at java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)\r\n at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)\r\n at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)\r\n at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)\r\n at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)\r\n at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)\r\n at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)\r\n at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)\r\n at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)\r\n at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)\r\n at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)\r\n at org.glassfish.jersey.internal.Errors.process(Errors.java:316)\r\n at org.glassfish.jersey.internal.Errors.process(Errors.java:298)\r\n at org.glassfish.jersey.internal.Errors.process(Errors.java:268)\r\n at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)\r\n at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)\r\n at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)\r\n at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)\r\n at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)\r\n at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)\r\n at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)\r\n at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)\r\n at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)\r\n at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)\r\n at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)\r\n at org.apache.nifi.web.filter.RequestLogger.doFilter(RequestLogger.java:66)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:317)\r\n at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:127)\r\n at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:91)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)\r\n at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:137)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)\r\n at org.apache.nifi.web.security.NiFiAuthenticationFilter.doFilter(NiFiAuthenticationFilter.java:61)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)\r\n at org.apache.nifi.web.security.NiFiAuthenticationFilter.doFilter(NiFiAuthenticationFilter.java:61)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)\r\n at org.apache.nifi.web.security.NiFiAuthenticationFilter.doFilter(NiFiAuthenticationFilter.java:61)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)\r\n at org.apache.nifi.web.security.NiFiAuthenticationFilter.authenticate(NiFiAuthenticationFilter.java:100)\r\n at org.apache.nifi.web.security.NiFiAuthenticationFilter.doFilter(NiFiAuthenticationFilter.java:59)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)\r\n at org.apache.nifi.web.security.NiFiAuthenticationFilter.authenticate(NiFiAuthenticationFilter.java:100)\r\n at org.apache.nifi.web.security.NiFiAuthenticationFilter.doFilter(NiFiAuthenticationFilter.java:59)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)\r\n at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)\r\n at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\r\n at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:331)\r\n at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:214)\r\n at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:177)\r\n at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:347)\r\n at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:263)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.apache.nifi.web.filter.TimerFilter.doFilter(TimerFilter.java:51)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.apache.nifi.web.filter.ExceptionFilter.doFilter(ExceptionFilter.java:46)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.eclipse.jetty.servlets.DoSFilter.doFilterChain(DoSFilter.java:487)\r\n at org.eclipse.jetty.servlets.DoSFilter.doFilter(DoSFilter.java:336)\r\n at org.eclipse.jetty.servlets.DoSFilter.doFilter(DoSFilter.java:301)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.apache.nifi.web.security.headers.StrictTransportSecurityFilter.doFilter(StrictTransportSecurityFilter.java:48)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.apache.nifi.web.security.headers.XContentTypeOptionsFilter.doFilter(XContentTypeOptionsFilter.java:48)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.apache.nifi.web.security.headers.XSSProtectionFilter.doFilter(XSSProtectionFilter.java:48)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.apache.nifi.web.security.headers.ContentSecurityPolicyFilter.doFilter(ContentSecurityPolicyFilter.java:47)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.apache.nifi.web.security.headers.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:48)\r\n at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)\r\n at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)\r\n at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)\r\n at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\r\n at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)\r\n at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\n at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\r\n at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)\r\n at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\r\n at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1435)\r\n at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\r\n at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)\r\n at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)\r\n at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\r\n at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1350)\r\n at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\r\n at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\r\n at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:763)\r\n at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)\r\n at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:59)\r\n at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\r\n at org.eclipse.jetty.server.Server.handle(Server.java:516)\r\n at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)\r\n at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)\r\n at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)\r\n at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:279)\r\n at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\r\n at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\r\n at org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:540)\r\n at org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:395)\r\n at org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:161)\r\n at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\r\n at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\r\n at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\r\n at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\r\n at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\r\n at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\r\n at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:383)\r\n at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:882)\r\n at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1036)\r\n at java.base/java.lang.Thread.run(Thread.java:834)\r\n Caused by: javax.net.ssl.SSLException: readHandshakeRecord\r\n at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(SSLSocketImpl.java:1325)\r\n at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:440)\r\n at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:411)\r\n at java.base/sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:567)\r\n at java.base/sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:197)\r\n at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1592)\r\n at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1520)\r\n at java.base/java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527)\r\n at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:334)\r\n at org.glassfish.jersey.client.internal.HttpUrlConnector._apply(HttpUrlConnector.java:390)\r\n at org.glassfish.jersey.client.internal.HttpUrlConnector.apply(HttpUrlConnector.java:282)\r\n at org.glassfish.jersey.client.ClientRuntime.invoke(ClientRuntime.java:278)\r\n at org.glassfish.jersey.client.JerseyInvocation.lambda$invoke$1(JerseyInvocation.java:767)\r\n at org.glassfish.jersey.internal.Errors.process(Errors.java:316)\r\n at org.glassfish.jersey.internal.Errors.process(Errors.java:298)\r\n at org.glassfish.jersey.internal.Errors.process(Errors.java:229)\r\n at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:414)\r\n at org.glassfish.jersey.client.JerseyInvocation.invoke(JerseyInvocation.java:765)\r\n at org.glassfish.jersey.client.JerseyInvocation$Builder.method(JerseyInvocation.java:428)\r\n at org.glassfish.jersey.client.JerseyInvocation$Builder.get(JerseyInvocation.java:324)\r\n at org.apache.nifi.registry.client.impl.JerseyBucketClient.lambda$getAll$5(JerseyBucketClient.java:143)\r\n at org.apache.nifi.registry.client.impl.AbstractJerseyClient.executeAction(AbstractJerseyClient.java:103)\r\n at org.apache.nifi.registry.client.impl.JerseyBucketClient.getAll(JerseyBucketClient.java:142)\r\n at org.apache.nifi.registry.flow.RestBasedFlowRegistry.getBuckets(RestBasedFlowRegistry.java:143)\r\n at org.apache.nifi.web.dao.impl.FlowRegistryDAO.getBucketsForUser(FlowRegistryDAO.java:75)\r\n ... 144 common frames omitted\r\n Suppressed: java.net.SocketException: Broken pipe (Write failed)\r\n at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)\r\n at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)\r\n at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)\r\n at java.base/sun.security.ssl.SSLSocketOutputRecord.encodeAlert(SSLSocketOutputRecord.java:81)\r\n at java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:380)\r\n at java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:292)\r\n at java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:450)\r\n ... 167 common frames omitted\r\n Caused by: java.net.SocketException: Broken pipe (Write failed)\r\n at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)\r\n at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)\r\n at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)\r\n at java.base/sun.security.ssl.SSLSocketOutputRecord.flush(SSLSocketOutputRecord.java:251)\r\n at java.base/sun.security.ssl.HandshakeOutStream.flush(HandshakeOutStream.java:89)\r\n at java.base/sun.security.ssl.Finished$T13FinishedProducer.onProduceFinished(Finished.java:679)\r\n at java.base/sun.security.ssl.Finished$T13FinishedProducer.produce(Finished.java:658)\r\n at java.base/sun.security.ssl.SSLHandshake.produce(SSLHandshake.java:436)\r\n at java.base/sun.security.ssl.Finished$T13FinishedConsumer.onConsumeFinished(Finished.java:1011)\r\n at java.base/sun.security.ssl.Finished$T13FinishedConsumer.consume(Finished.java:874)\r\n at java.base/sun.security.ssl.SSLHandshake.consume(SSLHandshake.java:392)\r\n at java.base/sun.security.ssl.HandshakeContext.dispatch(HandshakeContext.java:443)\r\n at java.base/sun.security.ssl.HandshakeContext.dispatch(HandshakeContext.java:421)\r\n at java.base/sun.security.ssl.TransportContext.dispatch(TransportContext.java:182)\r\n at java.base/sun.security.ssl.SSLTransport.decode(SSLTransport.java:171)\r\n at java.base/sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1408)\r\n at java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(SSLSocketImpl.java:1314)\r\n ... 168 common frames omitted\r\n\r\n'''\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n---\r\n\r\nAfter update all my nifi nodes operation system, now i got the error:\r\n\r\n\u00a0\r\nError\r\nUnable to obtain listing of buckets: java.net.SocketException: Broken pipe (Write failed)\r\n\r\n!image-2021-08-25-13-50-04-839.png!\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.015627143904566765
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009759832173585892
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004728173837065697
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640744b1fc1b78c3be33b752",
        "key": "FLINK-26784",
        "id": "13434929",
        "description": "https://cwiki.apache.org/confluence/display/FLINK/FLIP-215%3A+Introduce+FlinkSessionJob+CRD+in+the+kubernetes+operator",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009658892638981342
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.023578135296702385
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00370793673209846
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d6caf4d395ee22196706",
        "key": "TINKERPOP-1082",
        "id": "12929572",
        "description": "Right now we have two keys for input to a {{HadoopGraph}}.\n\n* gremlin.hadoop.graphInputFormat\n* gremlin.spark.graphInputRDD\n\nLikewise for output. I have so many if/else checks because both of these can be set that I think we should make one and only one input.\n\n* gremlin.hadoop.graphInputClass\n\nLikewise, for output: gremlin.hadoop.graphOutputClass.\n\nThis will make things so much simpler. However, it will break current implementations (and not backwards compatible).",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.005052190739661455
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009047240018844604
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.017734363675117493
                }
            }
        },
        "comments": [
            {
                "author_name": "okram",
                "id": "15199707",
                "body": "I went with {{gremlin.hadoop.graphReader}} and {{gremlin.hadoop.graphWriter}} as these terms align with the I/O package of graph readers and writers."
            },
            {
                "author_name": "githubbot",
                "id": "15199745",
                "body": "GitHub user okram opened a pull request:\n\n    https://github.com/apache/incubator-tinkerpop/pull/268\n\n    TINKERPOP-1082 & TINKERPOP-1222: Hadoop Configuration Updates\n\n    https://issues.apache.org/jira/browse/TINKERPOP-1082\n    https://issues.apache.org/jira/browse/TINKERPOP-1222\n    \n    We had a very confusing situation with `gremlin.hadoop.graphInputFormat` and `gremlin.spark.graphInputRDD`. Not only did it cause a mess of `[WARN]` messages it was awkward as users had to know that one overrode the other. To make this cleaner, I created a new configuration called `gremlin.hadoop.graphReader` and `gremlin.hadoop.graphWriter` that can either take an `XXXFormat` or an `XXXRDD`. Internally, Spark/Giraph/etc. know how to reason on what is what.\n    \n    Finally, added `gremlin.hadoop.defaultGraphComputer` where users can specify a default `GraphComputer` in their proprties file and if so, `graph.compute()` will no longer throw an exception saying to use `graph.compute(class)`.\n    \n    Both of these changes are backwards compatible where there backwards compatibility is tested via `SparkHadoopGraphProvider` where via a coin-flip, sometimes the old model is used and sometimes the new model is used.\n    \n    Finally, I forgot to add docs on `GraphFilter` and they have been added to this PR.\n    \n    CHANGELOG\n    \n    ```\n    * Added `gremlin.hadoop.defaultGraphComputer` so users can use `graph.compute()` with `HadoopGraph`.\n    * Added `gremlin.hadoop.graphReader` and `gremlin.hadoop.graphWriter` which can handled `XXXFormats` and `XXXRDDs`.\n    * Deprecated `gremlin.hadoop.graphInputFormat`, `gremlin.hadoop.graphOutputFormat`, `gremlin.spark.graphInputRDD`, and `gremlin.spark.graphOuputRDD`.\n    ```\n    \n    UPDATE\n    \n    ```\n    Hadoop Configurations\n    ++++++++++++++++++\n    \n    Note that `gremlin.hadoop.graphInputFormat`, `gremlin.hadoop.graphOutputFormat`, `gremlin.spark.graphInputRDD`, and `gremlin.spark.graphOuputRDD` have all been deprecated. Using them still works, but moving forward, users only need to leverage `gremlin.hadoop.graphReader` and `gremlin.hadoop.graphWriter`. An example properties file snippet is provided below.\n    \n    gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph\n    gremlin.hadoop.graphReader=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoInputFormat\n    gremlin.hadoop.graphWriter=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormat\n    gremlin.hadoop.jarsInDistributedCache=true\n    gremlin.hadoop.defaultGraphComputer=org.apache.tinkerpop.gremlin.spark.process.computer.SparkGraphComputer\n    ```\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/apache/incubator-tinkerpop TINKERPOP-1082\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/incubator-tinkerpop/pull/268.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #268\n    \n----\ncommit 6411d0d4142770f93fb1a188d7e991ed1b4355f3\nAuthor: Marko A. Rodriguez <okrammarko@gmail.com>\nDate:   2016-03-16T22:01:37Z\n\n    gremlin.hadoop.graphReader and gremlin.hadoop.graphWriter are the new configurations replacing gremlin.hadoop.graphInputFormat and spark.graphInputRDD. Now HadoopGraph can handle either RDD or XXXFormats. Cleaner configurations. Backwards compatible. The older keys just map to the new keys inside HadoopConfiguration.\n\ncommit b7f617b383700390128fca53de48f60cda3211fe\nAuthor: Marko A. Rodriguez <okrammarko@gmail.com>\nDate:   2016-03-16T22:26:22Z\n\n    fixed up the conf/.properties to use graphReader/graphWriter. Found more areas where inputFormat/outputFormat was still being used. Tested Giraph and its passing completely now. Need a helper utility that converts any Reader/Writer into an InputFormat or OutputFormat automagically.\n\ncommit 13561b81aa8287c696b8d79befce42f84792f793\nAuthor: Marko A. Rodriguez <okrammarko@gmail.com>\nDate:   2016-03-16T22:49:47Z\n\n    ConfUtil does the dirty work of InputRDD or InputFormat conversion to an InputFormat.\n\ncommit 5f53589b487ab918719315db6047233fb13971ae\nAuthor: Marko A. Rodriguez <okrammarko@gmail.com>\nDate:   2016-03-17T14:42:57Z\n\n    added gremlin.hadoop.defaultGraphComputer which allows users to specify in their properties file which GraphComputer to use by default. This allows providers that only support one Hadoop-based OLAP engine to 'hard set' the implementation so the syntax is cleaner -- graph.compute() vs. graph.compute(GiraphGraphComputer.class). This is backwards compatible. The SparkHadoopGraphProvider has been updated to sometimes use compute() and sometimes use compute(class).\n\ncommit 4a130d9092bc37dac252536280d60158fe75f74c\nAuthor: Marko A. Rodriguez <okrammarko@gmail.com>\nDate:   2016-03-17T15:09:16Z\n\n    updated docs on GraphFilter and graphReader/graphWriter.\n\ncommit 5a9f56d53741c985982d2bb13d3d8f31ffb6dd85\nAuthor: Marko A. Rodriguez <okrammarko@gmail.com>\nDate:   2016-03-17T15:32:04Z\n\n    gremlin.hadoop.graphInputFormat.hasEdges is not gremlin.hadoop.graphReader.hasEdges. Likewise for graphOuputFormat. Backwards compatible.\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "15199996",
                "body": "Github user okram commented on the pull request:\n\n    https://github.com/apache/incubator-tinkerpop/pull/268#issuecomment-197990762\n  \n    Docs have been published: http://tinkerpop.apache.org/docs/3.2.0-SNAPSHOT/reference\n    \n    VOTE +1.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15202163",
                "body": "Github user twilmes commented on the pull request:\n\n    https://github.com/apache/incubator-tinkerpop/pull/268#issuecomment-198541486\n  \n    Good simplification of the config: VOTE +1\n"
            },
            {
                "author_name": "githubbot",
                "id": "15202502",
                "body": "Github user PommeVerte commented on the pull request:\n\n    https://github.com/apache/incubator-tinkerpop/pull/268#issuecomment-198614584\n  \n    This is a good change to have VOTE +1 \n"
            },
            {
                "author_name": "githubbot",
                "id": "15202818",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/incubator-tinkerpop/pull/268\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5eec0f4d395ee221df095",
        "key": "MESOS-422",
        "id": "12639737",
        "description": "When a leading master exits abruptly, it may fatefully restart and think it's the leader.  If particularly unlucky, this could result in a set of masters that are indefinitely unstable.\n\nSequence of events:\n- Master process becomes leader\n- Master process exits, session expiration counter begins\n- Master process restarts, reads leader node contents, and decides it's the leader (based on PID equality)\n- Previous master session expires, node is deleted\n- Master decides a different master is leader, commits suicide\n- Rinse, repeat for newly-created master node\n\nThe salient fact here is that leaders should be concerned with \"did i create the leader node\" (ignoring node data) while clients want to be apprised of leader's node data.\n\nRelevant code:\nhttps://github.com/apache/mesos/blob/trunk/src/detector/detector.cpp#L548\n\nZK leader election recipe, for reference:\nhttp://zookeeper.apache.org/doc/trunk/recipes.html#sc_leaderElection\n\n",
        "predictions": {},
        "comments": [
            {
                "author_name": "chrismattmann",
                "id": "13652777",
                "body": "- guess fix version"
            },
            {
                "author_name": "bmahler",
                "id": "13690567",
                "body": "Assigning to Jiang as he's working on cleaning up the detector / contender logic."
            },
            {
                "author_name": "bmahler",
                "id": "13821632",
                "body": "[~xujyan] have you thought about how we might fix this in the new detector / contender code?"
            },
            {
                "author_name": "xujyan",
                "id": "13821642",
                "body": "[~vinodkone] and I talked about storing protobuf blob with master UUID (along with PID and perhaps hostname, which came up in another discussion) in ZK."
            },
            {
                "author_name": "bmahler",
                "id": "13821652",
                "body": "Have you thought about how to upgrade safely to storing a protobuf instead of a string?"
            },
            {
                "author_name": "wfarner",
                "id": "13821667",
                "body": "Instead of generating your own UUID, can you instead rely on the sequential ID provided by ZooKeeper?  Since your nodes appear to be created with the {{ZOO_SEQUENCE}} flag, you can count on the node name to be unique."
            },
            {
                "author_name": "bmahler",
                "id": "13821711",
                "body": "[~wfarner] I prefer that option since it requires no change to what we store in ZK, we do have this notion in the code (The Group::Membership of the temporary new leader will not match the leading Group::Membership in ZK), but this unfortunately gets lost through the current layers of abstraction since the detection and contending processes were made separate)."
            },
            {
                "author_name": "xujyan",
                "id": "13822826",
                "body": "OK this makes sense, I'll work on this next and propose some refactoring changes to make this work."
            },
            {
                "author_name": "vinodkone",
                "id": "13887338",
                "body": "https://reviews.apache.org/r/17574/"
            },
            {
                "author_name": "vinodkone",
                "id": "13897601",
                "body": "commit 26b156e33f281f5b342daefa0b8c327eb97d6647\nAuthor: Vinod Kone <vinod@twitter.com>\nDate:   Thu Jan 30 14:34:35 2014 -0800\n\n    Updated detector to return MasterInfo instead of PID.\n    \n    Review: https://reviews.apache.org/r/17574\n"
            }
        ],
        "comments_predictions": [
            [
                1401171,
                "MESOS-422",
                "Instead of generating your own UUID, can you instead rely on the sequential ID provided by ZooKeeper?  Since your nodes appear to be created with the {{ZOO_SEQUENCE}} flag, you can count on the node name to be unique.",
                {
                    "property": {
                        "confidence": 0.006533960811793804,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003428354160860181,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.057964976876974106,
                        "prediction": false
                    }
                }
            ],
            [
                1401172,
                "MESOS-422",
                "[~wfarner] I prefer that option since it requires no change to what we store in ZK, we do have this notion in the code (The Group::Membership of the temporary new leader will not match the leading Group::Membership in ZK), but this unfortunately gets lost through the current layers of abstraction since the detection and contending processes were made separate).",
                {
                    "property": {
                        "confidence": 0.01044626347720623,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0034932803828269243,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.32625019550323486,
                        "prediction": false
                    }
                }
            ],
            [
                1401175,
                "MESOS-422",
                "commit 26b156e33f281f5b342daefa0b8c327eb97d6647\nAuthor: Vinod Kone <vinod@twitter.com>\nDate:   Thu Jan 30 14:34:35 2014 -0800\n\n    Updated detector to return MasterInfo instead of PID.\n    \n    Review: https://reviews.apache.org/r/17574\n",
                {
                    "property": {
                        "confidence": 0.005165677051991224,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006579631473869085,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01569073274731636,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d874f4d395ee2219c88c",
        "key": "TAJO-219",
        "id": "12671492",
        "description": "We have to update HiveQLAnalyzer for concat expression.\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.4246707558631897
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.013868615962564945
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0040817707777023315
                }
            }
        },
        "comments": [
            {
                "author_name": "blrunner",
                "id": "13949629",
                "body": "We need to consider maintaining HiveQLAnalyzer."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e327f4d395ee221beb73",
        "key": "QPID-2147",
        "id": "12438193",
        "description": "THIS IS NO BUG, SINCE I DIDN'T READ THE INSTALLATION INSTRUCTIONS CAREFULLY ENOUGH! As you can see from my environment description, I used the wrong versions of Xerces-C and XQilla. With Xerces-C 2.8.0 (I couldn't find the 2.7.0 here: http://www.apache.org/dist/xerces/c/2/sources/) and XQilla 2.2.0 everything works fine.\n\nHello,\n\nI recently tried to compile the C++ broker and client (http://www.apache.org/dist/qpid/0.5/qpid-cpp-0.5.tar.gz) and got the following error (see below). The same issue arrises when trying to compile the latest SVN revision r825362. From this commit log http://www.mail-archive.com/commits@qpid.apache.org/msg00925.html it seems that the lines causing trouble have been in the repo for quite some time (Feb 27 2009). Am I doing something wrong? I manually downloaded, compiled and installed xerces-c and xqilla. All the other required packages were taken from the Ubuntu repository.\n\nThis is the function causing trouble:\n\nbool XmlExchange::matches(Query& query, Deliverable& msg, const qpid::framing::FieldTable* args, bool parse_message_content) \n{\n  string msgContent;\n\n  try {\n      QPID_LOG(trace, \"matches: query is [\" << UTF8(query->getQueryText()) << \"]\");\n\n      boost::scoped_ptr<DynamicContext> context(query->createDynamicContext());\n      if (!context.get()) {\n          throw InternalErrorException(QPID_MSG(\"Query context looks munged ...\"));\n      }\n\n      if (parse_message_content) {\n\n          msg.getMessage().getFrames().getContent(msgContent);\n\n          QPID_LOG(trace, \"matches: message content is [\" << msgContent << \"]\");\n\n          XERCES_CPP_NAMESPACE::MemBufInputSource xml((const XMLByte*) msgContent.c_str(), \n                                                      msgContent.length(), \"input\" );\n\n\t// This will parse the document using either Xerces or FastXDM, depending\n\t// on your XQilla configuration. FastXDM can be as much as 10x faster.\n\t\n          Sequence seq(context->parseDocument(xml));\n\n          if(!seq.isEmpty() && seq.first()->isNode()) {\n              context->setContextItem(seq.first());\n              context->setContextPosition(1);\n              context->setContextSize(1);\n          }\n      }\n\n      if (args) {\n          FieldTable::ValueMap::const_iterator v = args->begin();\n          for(; v != args->end(); ++v) {\n              // ### TODO: Do types properly\n              if (v->second->convertsTo<std::string>()) {\n                  QPID_LOG(trace, \"XmlExchange, external variable: \" << v->first << \" = \" << v->second->getData().getString().c_str());\n                  Item::Ptr value = context->getItemFactory()->createString(X(v->second->getData().getString().c_str()), context.get());\n                  context->setExternalVariable(X(v->first.c_str()), value);\n              }\n          }\n      }\n\n      Result result = query->execute(context.get());\n      return result->getEffectiveBooleanValue(context.get(), 0);\n  }\n  catch (XQException& e) {\n      QPID_LOG(warning, \"Could not parse XML content (or message headers):\" << msgContent);\n  }\n  catch (...) {\n      QPID_LOG(warning, \"Unexpected error routing message: \" << msgContent);\n  }\n  return 0;\n}\n\nThanks in advance\nKonrad\n\nkleine@dyn-111:/home/kleine/qpidc-0.5$ make\nMaking all in managementgen\nmake[1]: Entering directory `/home/kleine/qpidc-0.5/managementgen'\nmake[1]: Nothing to be done for `all'.\nmake[1]: Leaving directory `/home/kleine/qpidc-0.5/managementgen'\nMaking all in etc\nmake[1]: Entering directory `/home/kleine/qpidc-0.5/etc'\nmake[1]: Nothing to be done for `all'.\nmake[1]: Leaving directory `/home/kleine/qpidc-0.5/etc'\nMaking all in src\nmake[1]: Entering directory `/home/kleine/qpidc-0.5/src'\nmake  all-recursive\nmake[2]: Entering directory `/home/kleine/qpidc-0.5/src'\nMaking all in .\nmake[3]: Entering directory `/home/kleine/qpidc-0.5/src'\ndepbase=`echo qpid/xml/XmlExchange.lo | sed 's|[^/]*$|.deps/&|;s|\\.lo$||'`;\\\n\t/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -Igen -I./gen   -Werror -pedantic -Wall -Wextra -Wno-shadow -Wpointer-arith -Wcast-qual -Wcast-align -Wno-long-long -Wvolatile-register-var -Winvalid-pch -Wno-system-headers -Woverloaded-virtual -g -O2 -MT qpid/xml/XmlExchange.lo -MD -MP -MF $depbase.Tpo -c -o qpid/xml/XmlExchange.lo qpid/xml/XmlExchange.cpp &&\\\n\tmv -f $depbase.Tpo $depbase.Plo\n g++ -DHAVE_CONFIG_H -I. -Igen -I./gen -Werror -pedantic -Wall -Wextra -Wno-shadow -Wpointer-arith -Wcast-qual -Wcast-align -Wno-long-long -Wvolatile-register-var -Winvalid-pch -Wno-system-headers -Woverloaded-virtual -g -O2 -MT qpid/xml/XmlExchange.lo -MD -MP -MF qpid/xml/.deps/XmlExchange.Tpo -c qpid/xml/XmlExchange.cpp  -fPIC -DPIC -o qpid/xml/.libs/XmlExchange.o\nqpid/xml/XmlExchange.cpp: In member function 'bool qpid::broker::XmlExchange::matches(boost::shared_ptr<XQQuery>&, qpid::broker::Deliverable&, const qpid::framing::FieldTable*, bool)':\nqpid/xml/XmlExchange.cpp:182: error: 'class ResultImpl' has no member named 'getEffectiveBooleanValue'\nmake[3]: *** [qpid/xml/XmlExchange.lo] Error 1\nmake[3]: Leaving directory `/home/kleine/qpidc-0.5/src'\nmake[2]: *** [all-recursive] Error 1\nmake[2]: Leaving directory `/home/kleine/qpidc-0.5/src'\nmake[1]: *** [all] Error 2\nmake[1]: Leaving directory `/home/kleine/qpidc-0.5/src'\nmake: *** [all-recursive] Error 1\n\n\n",
        "predictions": {},
        "comments": [
            {
                "author_name": "konrad",
                "id": "12766061",
                "body": "THIS IS NO BUG, SINCE I DIDN'T READ THE INSTALLATION INSTRUCTIONS CAREFULLY ENOUGH! As you can see from my environment description, I used the wrong versions of Xerces-C and XQilla. With Xerces-C 2.8.0 (I couldn't find the 2.7.0 here: http://www.apache.org/dist/xerces/c/2/sources/) and XQilla 2.2.0 everything works fine."
            },
            {
                "author_name": "konrad",
                "id": "12766062",
                "body": "No times is needed to fix this non-bug."
            },
            {
                "author_name": "konrad",
                "id": "12766063",
                "body": "THIS IS NO BUG, SINCE I DIDN'T READ THE INSTALLATION INSTRUCTIONS CAREFULLY ENOUGH! As you can see from my environment description, I used the wrong versions of Xerces-C and XQilla. With Xerces-C 2.8.0 (I couldn't find the 2.7.0 here: http://www.apache.org/dist/xerces/c/2/sources/) and XQilla 2.2.0 everything works fine. "
            }
        ],
        "comments_predictions": [
            [
                875111,
                "QPID-2147",
                "THIS IS NO BUG, SINCE I DIDN'T READ THE INSTALLATION INSTRUCTIONS CAREFULLY ENOUGH! As you can see from my environment description, I used the wrong versions of Xerces-C and XQilla. With Xerces-C 2.8.0 (I couldn't find the 2.7.0 here: http://www.apache.org/dist/xerces/c/2/sources/) and XQilla 2.2.0 everything works fine.",
                {
                    "property": {
                        "confidence": 0.00394268287345767,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03036396950483322,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007006243336945772,
                        "prediction": false
                    }
                }
            ],
            [
                875113,
                "QPID-2147",
                "THIS IS NO BUG, SINCE I DIDN'T READ THE INSTALLATION INSTRUCTIONS CAREFULLY ENOUGH! As you can see from my environment description, I used the wrong versions of Xerces-C and XQilla. With Xerces-C 2.8.0 (I couldn't find the 2.7.0 here: http://www.apache.org/dist/xerces/c/2/sources/) and XQilla 2.2.0 everything works fine. ",
                {
                    "property": {
                        "confidence": 0.00394268287345767,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03036396950483322,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007006243336945772,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5e9f5f4d395ee221d2f7e",
        "key": "NIFI-2156",
        "id": "12985788",
        "description": "This processor would use a DatabaseConnectionPool controller service, call getTables(), and if the (optional, defaulting-to-false) property \"Include Row Count\" is set, then a \"SELECT COUNT(1) from table\" would be issued to the database. The table catalog, schema, name, type, remarks (and its count if specified) will be included as attributes in a zero-content flow file.\n\nIt will also use State Management to only list tables once. If new tables are added (and the processor is running), then the new tables' flow files will be generated. Changing any property that could affect the list of returned tables (such as the DB Connection, catalog, schema pattern, table name pattern, or table types) will reset the state and all tables will be fetched using the new criteria. The state can also be manually cleared using the standard Clear State link on the View State dialog (available on the processor's context menu)",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.011727106757462025
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.5670427680015564
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008575920015573502
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "15357544",
                "body": "GitHub user mattyb149 opened a pull request:\n\n    https://github.com/apache/nifi/pull/599\n\n    NIFI-2156: Add ListDatabaseTables processor\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/mattyb149/nifi NIFI-2156\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/nifi/pull/599.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #599\n    \n----\ncommit 81db08532a0939f7108cf9cd0d641f897e024d79\nAuthor: Matt Burgess <mattyb149@apache.org>\nDate:   2016-06-30T17:49:41Z\n\n    NIFI-2156: Add ListDatabaseTables processor\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "15357918",
                "body": "Github user pvillard31 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/599#discussion_r69216929\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/test/java/org/apache/nifi/processors/standard/TestListDatabaseTables.java ---\n    @@ -0,0 +1,168 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.nifi.controller.AbstractControllerService;\n    +import org.apache.nifi.dbcp.DBCPService;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.util.MockFlowFile;\n    +import org.apache.nifi.util.TestRunner;\n    +import org.apache.nifi.util.TestRunners;\n    +import org.apache.nifi.util.file.FileUtils;\n    +import org.junit.AfterClass;\n    +import org.junit.Before;\n    +import org.junit.BeforeClass;\n    +import org.junit.Test;\n    +\n    +import java.io.File;\n    +import java.io.IOException;\n    +import java.sql.Connection;\n    +import java.sql.DriverManager;\n    +import java.sql.SQLException;\n    +import java.sql.SQLNonTransientConnectionException;\n    +import java.sql.Statement;\n    +import java.util.HashMap;\n    +import java.util.List;\n    +import java.util.Map;\n    +\n    +import static org.junit.Assert.assertEquals;\n    +\n    +\n    +/**\n    + * Unit tests for ListDatabaseTables processor.\n    + */\n    +public class TestListDatabaseTables {\n    --- End diff --\n    \n    I am not familiar with Derby but would it be possible to also test catalog/schema aspects?\n"
            },
            {
                "author_name": "githubbot",
                "id": "15357922",
                "body": "Github user pvillard31 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/599#discussion_r69217243\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -0,0 +1,306 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.nifi.annotation.behavior.InputRequirement;\n    +import org.apache.nifi.annotation.behavior.Stateful;\n    +import org.apache.nifi.annotation.behavior.TriggerSerially;\n    +import org.apache.nifi.annotation.behavior.WritesAttribute;\n    +import org.apache.nifi.annotation.behavior.WritesAttributes;\n    +import org.apache.nifi.annotation.documentation.CapabilityDescription;\n    +import org.apache.nifi.annotation.documentation.Tags;\n    +import org.apache.nifi.annotation.lifecycle.OnScheduled;\n    +import org.apache.nifi.components.PropertyDescriptor;\n    +import org.apache.nifi.components.Validator;\n    +import org.apache.nifi.components.state.Scope;\n    +import org.apache.nifi.components.state.StateManager;\n    +import org.apache.nifi.components.state.StateMap;\n    +import org.apache.nifi.dbcp.DBCPService;\n    +import org.apache.nifi.flowfile.FlowFile;\n    +import org.apache.nifi.logging.ComponentLog;\n    +import org.apache.nifi.processor.AbstractProcessor;\n    +import org.apache.nifi.processor.ProcessContext;\n    +import org.apache.nifi.processor.ProcessSession;\n    +import org.apache.nifi.processor.Relationship;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.util.StringUtils;\n    +\n    +import java.io.IOException;\n    +import java.sql.Connection;\n    +import java.sql.DatabaseMetaData;\n    +import java.sql.ResultSet;\n    +import java.sql.SQLException;\n    +import java.sql.Statement;\n    +import java.util.ArrayList;\n    +import java.util.Collections;\n    +import java.util.HashMap;\n    +import java.util.HashSet;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +import java.util.stream.Collectors;\n    +import java.util.stream.Stream;\n    +\n    +/**\n    + * A processor to retrieve a list of tables (and their metadata) from a database connection\n    + */\n    +@TriggerSerially\n    +@InputRequirement(InputRequirement.Requirement.INPUT_FORBIDDEN)\n    +@Tags({\"sql\", \"list\", \"jdbc\", \"table\", \"database\"})\n    +@CapabilityDescription(\"Generates a set of flow files, each containing attributes corresponding to metadata about a table from a database connection.\")\n    +@WritesAttributes({\n    +        @WritesAttribute(attribute = \"db.table.name\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.catalog\", description = \"Contains the name of the catalog to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.schema\", description = \"Contains the name of the schema to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.fullname\", description = \"Contains the fully-qualifed table name (possibly including catalog, schema, etc.)\"),\n    +        @WritesAttribute(attribute = \"db.table.type\",\n    +                description = \"Contains the type of the database table from the connection. Typical types are \\\"TABLE\\\", \\\"VIEW\\\", \\\"SYSTEM TABLE\\\", \"\n    +                        + \"\\\"GLOBAL TEMPORARY\\\", \\\"LOCAL TEMPORARY\\\", \\\"ALIAS\\\", \\\"SYNONYM\\\"\"),\n    +        @WritesAttribute(attribute = \"db.table.remarks\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.count\", description = \"Contains the number of rows in the table\")\n    +})\n    +@Stateful(scopes = {Scope.LOCAL}, description = \"After performing a listing of tables, the timestamp of the query is stored. \"\n    +        + \"This allows the Processor to not re-list tables the next time that the Processor is run. Changing any of the processor properties will \"\n    +        + \"indicate that the processor should reset state and thus re-list the tables using the new configuration.\")\n    +public class ListDatabaseTables extends AbstractProcessor {\n    +\n    +    // Attribute names\n    +    public static final String DB_TABLE_NAME = \"db.table.name\";\n    +    public static final String DB_TABLE_CATALOG = \"db.table.catalog\";\n    +    public static final String DB_TABLE_SCHEMA = \"db.table.schema\";\n    +    public static final String DB_TABLE_FULLNAME = \"db.table.name\";\n    +    public static final String DB_TABLE_TYPE = \"db.table.type\";\n    +    public static final String DB_TABLE_REMARKS = \"db.table.remarks\";\n    +    public static final String DB_TABLE_COUNT = \"db.table.count\";\n    +\n    +    // Relationships\n    +    public static final Relationship REL_SUCCESS = new Relationship.Builder()\n    +            .name(\"success\")\n    +            .description(\"All FlowFiles that are received are routed to success\")\n    +            .build();\n    +\n    +    // Property descriptors\n    +    public static final PropertyDescriptor DBCP_SERVICE = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-db-connection\")\n    +            .displayName(\"Database Connection Pooling Service\")\n    +            .description(\"The Controller Service that is used to obtain connection to database\")\n    +            .required(true)\n    +            .identifiesControllerService(DBCPService.class)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor CATALOG = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-catalog\")\n    +            .displayName(\"Catalog\")\n    +            .description(\"The name of a catalog from which to list database tables. The name must match the catalog name as it is stored in the database. \"\n    +                    + \"If the property is not set, the catalog name will not be used to narrow the search for tables. If the property is set to an empty string, \"\n    +                    + \"tables without a catalog will be listed.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor SCHEMA_PATTERN = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-schema-pattern\")\n    +            .displayName(\"Schema Pattern\")\n    +            .description(\"A pattern for matching schemas in the database. Within a pattern, \\\"%\\\" means match any substring of 0 or more characters, \"\n    +                    + \"and \\\"_\\\" means match any one character. The pattern must match the schema name as it is stored in the database. \"\n    +                    + \"If the property is not set, the schema name will not be used to narrow the search for tables. If the property is set to an empty string, \"\n    +                    + \"tables without a schema will be listed.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor TABLE_NAME_PATTERN = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-name-pattern\")\n    +            .displayName(\"Table Name Pattern\")\n    +            .description(\"A pattern for matching tables in the database. Within a pattern, \\\"%\\\" means match any substring of 0 or more characters, \"\n    +                    + \"and \\\"_\\\" means match any one character. The pattern must match the table name as it is stored in the database. \"\n    +                    + \"If the property is not set, all tables will be retrieved.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor TABLE_TYPES = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-types\")\n    +            .displayName(\"Table Types\")\n    +            .description(\"A comma-separated list of table types to include. For example, some databases support TABLE and VIEW types. If the property is not set, \"\n    +                    + \"tables of all types will be returned.\")\n    +            .required(false)\n    +            .defaultValue(\"TABLE\")\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor INCLUDE_COUNT = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-include-count\")\n    +            .displayName(\"Include Count\")\n    +            .description(\"Whether to include the table's row count as a flow file attribute. This affects performance as a database query will be generated \"\n    +                    + \"for each table in the retrieved list.\")\n    +            .required(true)\n    +            .allowableValues(\"true\", \"false\")\n    +            .defaultValue(\"false\")\n    +            .build();\n    +\n    +    private static final List<PropertyDescriptor> propertyDescriptors;\n    +    private static final Set<Relationship> relationships;\n    +\n    +    private boolean resetState = false;\n    +\n    +    /*\n    +     * Will ensure that the list of property descriptors is build only once.\n    +     * Will also create a Set of relationships\n    +     */\n    +    static {\n    +        List<PropertyDescriptor> _propertyDescriptors = new ArrayList<>();\n    +        _propertyDescriptors.add(DBCP_SERVICE);\n    +        _propertyDescriptors.add(CATALOG);\n    +        _propertyDescriptors.add(SCHEMA_PATTERN);\n    +        _propertyDescriptors.add(TABLE_NAME_PATTERN);\n    +        _propertyDescriptors.add(TABLE_TYPES);\n    +        _propertyDescriptors.add(INCLUDE_COUNT);\n    +        propertyDescriptors = Collections.unmodifiableList(_propertyDescriptors);\n    +\n    +        Set<Relationship> _relationships = new HashSet<>();\n    +        _relationships.add(REL_SUCCESS);\n    +        relationships = Collections.unmodifiableSet(_relationships);\n    +    }\n    +\n    +    @Override\n    +    protected List<PropertyDescriptor> getSupportedPropertyDescriptors() {\n    +        return propertyDescriptors;\n    +    }\n    +\n    +    @Override\n    +    public Set<Relationship> getRelationships() {\n    +        return relationships;\n    +    }\n    +\n    +    @OnScheduled\n    +    public void setup(ProcessContext context) {\n    +        try {\n    +            if (resetState) {\n    +                context.getStateManager().clear(getScope());\n    +                resetState = false;\n    +            }\n    +        } catch (IOException ioe) {\n    +            throw new ProcessException(ioe);\n    +        }\n    +    }\n    +\n    +    @Override\n    +    public void onTrigger(ProcessContext context, ProcessSession session) throws ProcessException {\n    +        final ComponentLog logger = getLogger();\n    +        final DBCPService dbcpService = context.getProperty(DBCP_SERVICE).asControllerService(DBCPService.class);\n    +        final String catalog = context.getProperty(CATALOG).getValue();\n    +        final String schemaPattern = context.getProperty(SCHEMA_PATTERN).getValue();\n    +        final String tableNamePattern = context.getProperty(TABLE_NAME_PATTERN).getValue();\n    +        final String[] tableTypes = context.getProperty(TABLE_TYPES).isSet()\n    +                ? context.getProperty(TABLE_TYPES).getValue().split(\"\\\\s*,\\\\s*\")\n    +                : null;\n    +        final boolean includeCount = context.getProperty(INCLUDE_COUNT).asBoolean();\n    +\n    +        final StateManager stateManager = context.getStateManager();\n    +        final StateMap stateMap;\n    +        final Map<String, String> stateMapProperties;\n    +        try {\n    +            stateMap = stateManager.getState(getScope());\n    +            stateMapProperties = new HashMap<>(stateMap.toMap());\n    +        } catch (IOException ioe) {\n    +            throw new ProcessException(ioe);\n    +        }\n    +\n    +        try (final Connection con = dbcpService.getConnection()) {\n    +\n    +            DatabaseMetaData dbMetaData = con.getMetaData();\n    +            ResultSet rs = dbMetaData.getTables(catalog, schemaPattern, tableNamePattern, tableTypes);\n    +            while (rs.next()) {\n    +                final String tableCatalog = rs.getString(1);\n    +                final String tableSchema = rs.getString(2);\n    +                final String tableName = rs.getString(3);\n    +                final String tableType = rs.getString(4);\n    +                final String tableRemarks = rs.getString(5);\n    +\n    +                // Build fully-qualified name\n    +                String fqn = Stream.of(tableCatalog, tableSchema, tableName)\n    +                        .filter(segment -> !StringUtils.isEmpty(segment))\n    +                        .collect(Collectors.joining(\".\"));\n    +\n    +                String fqTableName = stateMap.get(fqn);\n    +                if (fqTableName == null) {\n    +                    FlowFile flowFile = session.create();\n    +                    logger.info(\"Found {}: {}\", new Object[]{tableType, fqn});\n    +                    if (includeCount) {\n    +                        try (Statement st = con.createStatement()) {\n    +                            final String countQuery = \"SELECT COUNT(1) FROM \" + fqn;\n    +\n    +                            logger.debug(\"Executing query: {}\", new Object[]{countQuery});\n    +                            ResultSet countResult = st.executeQuery(countQuery);\n    +                            if (countResult.next()) {\n    +                                flowFile = session.putAttribute(flowFile, DB_TABLE_COUNT, Long.toString(countResult.getLong(1)));\n    +                            }\n    +                        } catch (SQLException se) {\n    +                            logger.error(\"Couldn't get row count for {}\", new Object[]{fqn});\n    +                            session.remove(flowFile);\n    +                            continue;\n    +                        }\n    +                    }\n    +                    if (tableCatalog != null) {\n    +                        flowFile = session.putAttribute(flowFile, DB_TABLE_CATALOG, tableCatalog);\n    +                    }\n    +                    if (tableSchema != null) {\n    +                        flowFile = session.putAttribute(flowFile, DB_TABLE_SCHEMA, tableSchema);\n    +                    }\n    +                    flowFile = session.putAttribute(flowFile, DB_TABLE_NAME, tableName);\n    +                    flowFile = session.putAttribute(flowFile, DB_TABLE_FULLNAME, fqn);\n    +                    flowFile = session.putAttribute(flowFile, DB_TABLE_TYPE, tableType);\n    +                    if (tableRemarks != null) {\n    +                        flowFile = session.putAttribute(flowFile, DB_TABLE_REMARKS, tableRemarks);\n    +                    }\n    +\n    +                    String transitUri;\n    +                    try {\n    +                        transitUri = dbMetaData.getURL();\n    +                    } catch (SQLException sqle) {\n    +                        transitUri = \"<unknown>\";\n    +                    }\n    +                    session.getProvenanceReporter().receive(flowFile, transitUri);\n    +                    session.transfer(flowFile, REL_SUCCESS);\n    +                    stateMapProperties.put(fqn, Long.toString(System.currentTimeMillis()));\n    +                }\n    +            }\n    +            stateManager.replace(stateMap, stateMapProperties, getScope());\n    +\n    +        } catch (final SQLException | IOException e) {\n    +            throw new ProcessException(e);\n    +        }\n    +    }\n    +\n    +    @Override\n    +    public void onPropertyModified(PropertyDescriptor descriptor, String oldValue, String newValue) {\n    +        super.onPropertyModified(descriptor, oldValue, newValue);\n    +        // If any of the properties that define the retrieved list have changed, then reset the state\n    +        if (DBCP_SERVICE.equals(descriptor)\n    +                || CATALOG.equals(descriptor)\n    +                || SCHEMA_PATTERN.equals(descriptor)\n    +                || TABLE_NAME_PATTERN.equals(descriptor)\n    +                || TABLE_TYPES.equals(descriptor)) {\n    +            resetState = true;\n    +        }\n    +    }\n    +\n    +    private Scope getScope() {\n    +        return Scope.LOCAL;\n    --- End diff --\n    \n    Out of curiosity, wouldn't be better to have something like:\n    ````java\n    private static final Scope SCOPE = Scope.LOCAL;\n    ````\n    at the beginning of the class instead of this method?\n"
            },
            {
                "author_name": "githubbot",
                "id": "15357999",
                "body": "Github user mattyb149 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/599#discussion_r69224117\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/test/java/org/apache/nifi/processors/standard/TestListDatabaseTables.java ---\n    @@ -0,0 +1,168 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.nifi.controller.AbstractControllerService;\n    +import org.apache.nifi.dbcp.DBCPService;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.util.MockFlowFile;\n    +import org.apache.nifi.util.TestRunner;\n    +import org.apache.nifi.util.TestRunners;\n    +import org.apache.nifi.util.file.FileUtils;\n    +import org.junit.AfterClass;\n    +import org.junit.Before;\n    +import org.junit.BeforeClass;\n    +import org.junit.Test;\n    +\n    +import java.io.File;\n    +import java.io.IOException;\n    +import java.sql.Connection;\n    +import java.sql.DriverManager;\n    +import java.sql.SQLException;\n    +import java.sql.SQLNonTransientConnectionException;\n    +import java.sql.Statement;\n    +import java.util.HashMap;\n    +import java.util.List;\n    +import java.util.Map;\n    +\n    +import static org.junit.Assert.assertEquals;\n    +\n    +\n    +/**\n    + * Unit tests for ListDatabaseTables processor.\n    + */\n    +public class TestListDatabaseTables {\n    --- End diff --\n    \n    Good point will check. The terminology is often DB-specific and inconsistent, for example if I don't include a database on a MySQL connection, the catalog is required, but if I do, it should be blank.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15358001",
                "body": "Github user mattyb149 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/599#discussion_r69224252\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -0,0 +1,306 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.nifi.annotation.behavior.InputRequirement;\n    +import org.apache.nifi.annotation.behavior.Stateful;\n    +import org.apache.nifi.annotation.behavior.TriggerSerially;\n    +import org.apache.nifi.annotation.behavior.WritesAttribute;\n    +import org.apache.nifi.annotation.behavior.WritesAttributes;\n    +import org.apache.nifi.annotation.documentation.CapabilityDescription;\n    +import org.apache.nifi.annotation.documentation.Tags;\n    +import org.apache.nifi.annotation.lifecycle.OnScheduled;\n    +import org.apache.nifi.components.PropertyDescriptor;\n    +import org.apache.nifi.components.Validator;\n    +import org.apache.nifi.components.state.Scope;\n    +import org.apache.nifi.components.state.StateManager;\n    +import org.apache.nifi.components.state.StateMap;\n    +import org.apache.nifi.dbcp.DBCPService;\n    +import org.apache.nifi.flowfile.FlowFile;\n    +import org.apache.nifi.logging.ComponentLog;\n    +import org.apache.nifi.processor.AbstractProcessor;\n    +import org.apache.nifi.processor.ProcessContext;\n    +import org.apache.nifi.processor.ProcessSession;\n    +import org.apache.nifi.processor.Relationship;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.util.StringUtils;\n    +\n    +import java.io.IOException;\n    +import java.sql.Connection;\n    +import java.sql.DatabaseMetaData;\n    +import java.sql.ResultSet;\n    +import java.sql.SQLException;\n    +import java.sql.Statement;\n    +import java.util.ArrayList;\n    +import java.util.Collections;\n    +import java.util.HashMap;\n    +import java.util.HashSet;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +import java.util.stream.Collectors;\n    +import java.util.stream.Stream;\n    +\n    +/**\n    + * A processor to retrieve a list of tables (and their metadata) from a database connection\n    + */\n    +@TriggerSerially\n    +@InputRequirement(InputRequirement.Requirement.INPUT_FORBIDDEN)\n    +@Tags({\"sql\", \"list\", \"jdbc\", \"table\", \"database\"})\n    +@CapabilityDescription(\"Generates a set of flow files, each containing attributes corresponding to metadata about a table from a database connection.\")\n    +@WritesAttributes({\n    +        @WritesAttribute(attribute = \"db.table.name\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.catalog\", description = \"Contains the name of the catalog to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.schema\", description = \"Contains the name of the schema to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.fullname\", description = \"Contains the fully-qualifed table name (possibly including catalog, schema, etc.)\"),\n    +        @WritesAttribute(attribute = \"db.table.type\",\n    +                description = \"Contains the type of the database table from the connection. Typical types are \\\"TABLE\\\", \\\"VIEW\\\", \\\"SYSTEM TABLE\\\", \"\n    +                        + \"\\\"GLOBAL TEMPORARY\\\", \\\"LOCAL TEMPORARY\\\", \\\"ALIAS\\\", \\\"SYNONYM\\\"\"),\n    +        @WritesAttribute(attribute = \"db.table.remarks\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.count\", description = \"Contains the number of rows in the table\")\n    +})\n    +@Stateful(scopes = {Scope.LOCAL}, description = \"After performing a listing of tables, the timestamp of the query is stored. \"\n    +        + \"This allows the Processor to not re-list tables the next time that the Processor is run. Changing any of the processor properties will \"\n    +        + \"indicate that the processor should reset state and thus re-list the tables using the new configuration.\")\n    +public class ListDatabaseTables extends AbstractProcessor {\n    +\n    +    // Attribute names\n    +    public static final String DB_TABLE_NAME = \"db.table.name\";\n    +    public static final String DB_TABLE_CATALOG = \"db.table.catalog\";\n    +    public static final String DB_TABLE_SCHEMA = \"db.table.schema\";\n    +    public static final String DB_TABLE_FULLNAME = \"db.table.name\";\n    +    public static final String DB_TABLE_TYPE = \"db.table.type\";\n    +    public static final String DB_TABLE_REMARKS = \"db.table.remarks\";\n    +    public static final String DB_TABLE_COUNT = \"db.table.count\";\n    +\n    +    // Relationships\n    +    public static final Relationship REL_SUCCESS = new Relationship.Builder()\n    +            .name(\"success\")\n    +            .description(\"All FlowFiles that are received are routed to success\")\n    +            .build();\n    +\n    +    // Property descriptors\n    +    public static final PropertyDescriptor DBCP_SERVICE = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-db-connection\")\n    +            .displayName(\"Database Connection Pooling Service\")\n    +            .description(\"The Controller Service that is used to obtain connection to database\")\n    +            .required(true)\n    +            .identifiesControllerService(DBCPService.class)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor CATALOG = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-catalog\")\n    +            .displayName(\"Catalog\")\n    +            .description(\"The name of a catalog from which to list database tables. The name must match the catalog name as it is stored in the database. \"\n    +                    + \"If the property is not set, the catalog name will not be used to narrow the search for tables. If the property is set to an empty string, \"\n    +                    + \"tables without a catalog will be listed.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor SCHEMA_PATTERN = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-schema-pattern\")\n    +            .displayName(\"Schema Pattern\")\n    +            .description(\"A pattern for matching schemas in the database. Within a pattern, \\\"%\\\" means match any substring of 0 or more characters, \"\n    +                    + \"and \\\"_\\\" means match any one character. The pattern must match the schema name as it is stored in the database. \"\n    +                    + \"If the property is not set, the schema name will not be used to narrow the search for tables. If the property is set to an empty string, \"\n    +                    + \"tables without a schema will be listed.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor TABLE_NAME_PATTERN = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-name-pattern\")\n    +            .displayName(\"Table Name Pattern\")\n    +            .description(\"A pattern for matching tables in the database. Within a pattern, \\\"%\\\" means match any substring of 0 or more characters, \"\n    +                    + \"and \\\"_\\\" means match any one character. The pattern must match the table name as it is stored in the database. \"\n    +                    + \"If the property is not set, all tables will be retrieved.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor TABLE_TYPES = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-types\")\n    +            .displayName(\"Table Types\")\n    +            .description(\"A comma-separated list of table types to include. For example, some databases support TABLE and VIEW types. If the property is not set, \"\n    +                    + \"tables of all types will be returned.\")\n    +            .required(false)\n    +            .defaultValue(\"TABLE\")\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor INCLUDE_COUNT = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-include-count\")\n    +            .displayName(\"Include Count\")\n    +            .description(\"Whether to include the table's row count as a flow file attribute. This affects performance as a database query will be generated \"\n    +                    + \"for each table in the retrieved list.\")\n    +            .required(true)\n    +            .allowableValues(\"true\", \"false\")\n    +            .defaultValue(\"false\")\n    +            .build();\n    +\n    +    private static final List<PropertyDescriptor> propertyDescriptors;\n    +    private static final Set<Relationship> relationships;\n    +\n    +    private boolean resetState = false;\n    +\n    +    /*\n    +     * Will ensure that the list of property descriptors is build only once.\n    +     * Will also create a Set of relationships\n    +     */\n    +    static {\n    +        List<PropertyDescriptor> _propertyDescriptors = new ArrayList<>();\n    +        _propertyDescriptors.add(DBCP_SERVICE);\n    +        _propertyDescriptors.add(CATALOG);\n    +        _propertyDescriptors.add(SCHEMA_PATTERN);\n    +        _propertyDescriptors.add(TABLE_NAME_PATTERN);\n    +        _propertyDescriptors.add(TABLE_TYPES);\n    +        _propertyDescriptors.add(INCLUDE_COUNT);\n    +        propertyDescriptors = Collections.unmodifiableList(_propertyDescriptors);\n    +\n    +        Set<Relationship> _relationships = new HashSet<>();\n    +        _relationships.add(REL_SUCCESS);\n    +        relationships = Collections.unmodifiableSet(_relationships);\n    +    }\n    +\n    +    @Override\n    +    protected List<PropertyDescriptor> getSupportedPropertyDescriptors() {\n    +        return propertyDescriptors;\n    +    }\n    +\n    +    @Override\n    +    public Set<Relationship> getRelationships() {\n    +        return relationships;\n    +    }\n    +\n    +    @OnScheduled\n    +    public void setup(ProcessContext context) {\n    +        try {\n    +            if (resetState) {\n    +                context.getStateManager().clear(getScope());\n    +                resetState = false;\n    +            }\n    +        } catch (IOException ioe) {\n    +            throw new ProcessException(ioe);\n    +        }\n    +    }\n    +\n    +    @Override\n    +    public void onTrigger(ProcessContext context, ProcessSession session) throws ProcessException {\n    +        final ComponentLog logger = getLogger();\n    +        final DBCPService dbcpService = context.getProperty(DBCP_SERVICE).asControllerService(DBCPService.class);\n    +        final String catalog = context.getProperty(CATALOG).getValue();\n    +        final String schemaPattern = context.getProperty(SCHEMA_PATTERN).getValue();\n    +        final String tableNamePattern = context.getProperty(TABLE_NAME_PATTERN).getValue();\n    +        final String[] tableTypes = context.getProperty(TABLE_TYPES).isSet()\n    +                ? context.getProperty(TABLE_TYPES).getValue().split(\"\\\\s*,\\\\s*\")\n    +                : null;\n    +        final boolean includeCount = context.getProperty(INCLUDE_COUNT).asBoolean();\n    +\n    +        final StateManager stateManager = context.getStateManager();\n    +        final StateMap stateMap;\n    +        final Map<String, String> stateMapProperties;\n    +        try {\n    +            stateMap = stateManager.getState(getScope());\n    +            stateMapProperties = new HashMap<>(stateMap.toMap());\n    +        } catch (IOException ioe) {\n    +            throw new ProcessException(ioe);\n    +        }\n    +\n    +        try (final Connection con = dbcpService.getConnection()) {\n    +\n    +            DatabaseMetaData dbMetaData = con.getMetaData();\n    +            ResultSet rs = dbMetaData.getTables(catalog, schemaPattern, tableNamePattern, tableTypes);\n    +            while (rs.next()) {\n    +                final String tableCatalog = rs.getString(1);\n    +                final String tableSchema = rs.getString(2);\n    +                final String tableName = rs.getString(3);\n    +                final String tableType = rs.getString(4);\n    +                final String tableRemarks = rs.getString(5);\n    +\n    +                // Build fully-qualified name\n    +                String fqn = Stream.of(tableCatalog, tableSchema, tableName)\n    +                        .filter(segment -> !StringUtils.isEmpty(segment))\n    +                        .collect(Collectors.joining(\".\"));\n    +\n    +                String fqTableName = stateMap.get(fqn);\n    +                if (fqTableName == null) {\n    +                    FlowFile flowFile = session.create();\n    +                    logger.info(\"Found {}: {}\", new Object[]{tableType, fqn});\n    +                    if (includeCount) {\n    +                        try (Statement st = con.createStatement()) {\n    +                            final String countQuery = \"SELECT COUNT(1) FROM \" + fqn;\n    +\n    +                            logger.debug(\"Executing query: {}\", new Object[]{countQuery});\n    +                            ResultSet countResult = st.executeQuery(countQuery);\n    +                            if (countResult.next()) {\n    +                                flowFile = session.putAttribute(flowFile, DB_TABLE_COUNT, Long.toString(countResult.getLong(1)));\n    +                            }\n    +                        } catch (SQLException se) {\n    +                            logger.error(\"Couldn't get row count for {}\", new Object[]{fqn});\n    +                            session.remove(flowFile);\n    +                            continue;\n    +                        }\n    +                    }\n    +                    if (tableCatalog != null) {\n    +                        flowFile = session.putAttribute(flowFile, DB_TABLE_CATALOG, tableCatalog);\n    +                    }\n    +                    if (tableSchema != null) {\n    +                        flowFile = session.putAttribute(flowFile, DB_TABLE_SCHEMA, tableSchema);\n    +                    }\n    +                    flowFile = session.putAttribute(flowFile, DB_TABLE_NAME, tableName);\n    +                    flowFile = session.putAttribute(flowFile, DB_TABLE_FULLNAME, fqn);\n    +                    flowFile = session.putAttribute(flowFile, DB_TABLE_TYPE, tableType);\n    +                    if (tableRemarks != null) {\n    +                        flowFile = session.putAttribute(flowFile, DB_TABLE_REMARKS, tableRemarks);\n    +                    }\n    +\n    +                    String transitUri;\n    +                    try {\n    +                        transitUri = dbMetaData.getURL();\n    +                    } catch (SQLException sqle) {\n    +                        transitUri = \"<unknown>\";\n    +                    }\n    +                    session.getProvenanceReporter().receive(flowFile, transitUri);\n    +                    session.transfer(flowFile, REL_SUCCESS);\n    +                    stateMapProperties.put(fqn, Long.toString(System.currentTimeMillis()));\n    +                }\n    +            }\n    +            stateManager.replace(stateMap, stateMapProperties, getScope());\n    +\n    +        } catch (final SQLException | IOException e) {\n    +            throw new ProcessException(e);\n    +        }\n    +    }\n    +\n    +    @Override\n    +    public void onPropertyModified(PropertyDescriptor descriptor, String oldValue, String newValue) {\n    +        super.onPropertyModified(descriptor, oldValue, newValue);\n    +        // If any of the properties that define the retrieved list have changed, then reset the state\n    +        if (DBCP_SERVICE.equals(descriptor)\n    +                || CATALOG.equals(descriptor)\n    +                || SCHEMA_PATTERN.equals(descriptor)\n    +                || TABLE_NAME_PATTERN.equals(descriptor)\n    +                || TABLE_TYPES.equals(descriptor)) {\n    +            resetState = true;\n    +        }\n    +    }\n    +\n    +    private Scope getScope() {\n    +        return Scope.LOCAL;\n    --- End diff --\n    \n    Yes I put it as a method early in development in case I needed logic or dependency injection. Can change that at this point :)\n"
            },
            {
                "author_name": "githubbot",
                "id": "15365555",
                "body": "Github user mattyb149 closed the pull request at:\n\n    https://github.com/apache/nifi/pull/599\n"
            },
            {
                "author_name": "githubbot",
                "id": "15375265",
                "body": "GitHub user mattyb149 opened a pull request:\n\n    https://github.com/apache/nifi/pull/642\n\n    NIFI-2156: Add ListDatabaseTables processor\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/mattyb149/nifi NIFI-2156\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/nifi/pull/642.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #642\n    \n----\ncommit b33817d90cee0514deb4c9bd71b57852e0d8b02e\nAuthor: Matt Burgess <mattyb149@apache.org>\nDate:   2016-07-07T02:34:37Z\n\n    NIFI-2156: Add ListDatabaseTables processor\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "15381559",
                "body": "Github user JPercivall commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71091290\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -0,0 +1,304 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.nifi.annotation.behavior.InputRequirement;\n    +import org.apache.nifi.annotation.behavior.Stateful;\n    +import org.apache.nifi.annotation.behavior.TriggerSerially;\n    +import org.apache.nifi.annotation.behavior.WritesAttribute;\n    +import org.apache.nifi.annotation.behavior.WritesAttributes;\n    +import org.apache.nifi.annotation.documentation.CapabilityDescription;\n    +import org.apache.nifi.annotation.documentation.Tags;\n    +import org.apache.nifi.annotation.lifecycle.OnScheduled;\n    +import org.apache.nifi.components.PropertyDescriptor;\n    +import org.apache.nifi.components.Validator;\n    +import org.apache.nifi.components.state.Scope;\n    +import org.apache.nifi.components.state.StateManager;\n    +import org.apache.nifi.components.state.StateMap;\n    +import org.apache.nifi.dbcp.DBCPService;\n    +import org.apache.nifi.flowfile.FlowFile;\n    +import org.apache.nifi.logging.ComponentLog;\n    +import org.apache.nifi.processor.AbstractProcessor;\n    +import org.apache.nifi.processor.ProcessContext;\n    +import org.apache.nifi.processor.ProcessSession;\n    +import org.apache.nifi.processor.Relationship;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.util.StringUtils;\n    +\n    +import java.io.IOException;\n    +import java.sql.Connection;\n    +import java.sql.DatabaseMetaData;\n    +import java.sql.ResultSet;\n    +import java.sql.SQLException;\n    +import java.sql.Statement;\n    +import java.util.ArrayList;\n    +import java.util.Collections;\n    +import java.util.HashMap;\n    +import java.util.HashSet;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +import java.util.stream.Collectors;\n    +import java.util.stream.Stream;\n    +\n    +/**\n    + * A processor to retrieve a list of tables (and their metadata) from a database connection\n    + */\n    +@TriggerSerially\n    +@InputRequirement(InputRequirement.Requirement.INPUT_FORBIDDEN)\n    +@Tags({\"sql\", \"list\", \"jdbc\", \"table\", \"database\"})\n    +@CapabilityDescription(\"Generates a set of flow files, each containing attributes corresponding to metadata about a table from a database connection.\")\n    +@WritesAttributes({\n    +        @WritesAttribute(attribute = \"db.table.name\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.catalog\", description = \"Contains the name of the catalog to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.schema\", description = \"Contains the name of the schema to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.fullname\", description = \"Contains the fully-qualifed table name (possibly including catalog, schema, etc.)\"),\n    +        @WritesAttribute(attribute = \"db.table.type\",\n    +                description = \"Contains the type of the database table from the connection. Typical types are \\\"TABLE\\\", \\\"VIEW\\\", \\\"SYSTEM TABLE\\\", \"\n    +                        + \"\\\"GLOBAL TEMPORARY\\\", \\\"LOCAL TEMPORARY\\\", \\\"ALIAS\\\", \\\"SYNONYM\\\"\"),\n    +        @WritesAttribute(attribute = \"db.table.remarks\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.count\", description = \"Contains the number of rows in the table\")\n    +})\n    +@Stateful(scopes = {Scope.LOCAL}, description = \"After performing a listing of tables, the timestamp of the query is stored. \"\n    --- End diff --\n    \n    Shouldn't this be \"cluster\"? That way when primary node changes it will keep the same listing of tables\n"
            },
            {
                "author_name": "githubbot",
                "id": "15381560",
                "body": "Github user JPercivall commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71091358\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -0,0 +1,304 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.nifi.annotation.behavior.InputRequirement;\n    +import org.apache.nifi.annotation.behavior.Stateful;\n    +import org.apache.nifi.annotation.behavior.TriggerSerially;\n    +import org.apache.nifi.annotation.behavior.WritesAttribute;\n    +import org.apache.nifi.annotation.behavior.WritesAttributes;\n    +import org.apache.nifi.annotation.documentation.CapabilityDescription;\n    +import org.apache.nifi.annotation.documentation.Tags;\n    +import org.apache.nifi.annotation.lifecycle.OnScheduled;\n    +import org.apache.nifi.components.PropertyDescriptor;\n    +import org.apache.nifi.components.Validator;\n    +import org.apache.nifi.components.state.Scope;\n    +import org.apache.nifi.components.state.StateManager;\n    +import org.apache.nifi.components.state.StateMap;\n    +import org.apache.nifi.dbcp.DBCPService;\n    +import org.apache.nifi.flowfile.FlowFile;\n    +import org.apache.nifi.logging.ComponentLog;\n    +import org.apache.nifi.processor.AbstractProcessor;\n    +import org.apache.nifi.processor.ProcessContext;\n    +import org.apache.nifi.processor.ProcessSession;\n    +import org.apache.nifi.processor.Relationship;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.util.StringUtils;\n    +\n    +import java.io.IOException;\n    +import java.sql.Connection;\n    +import java.sql.DatabaseMetaData;\n    +import java.sql.ResultSet;\n    +import java.sql.SQLException;\n    +import java.sql.Statement;\n    +import java.util.ArrayList;\n    +import java.util.Collections;\n    +import java.util.HashMap;\n    +import java.util.HashSet;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +import java.util.stream.Collectors;\n    +import java.util.stream.Stream;\n    +\n    +/**\n    + * A processor to retrieve a list of tables (and their metadata) from a database connection\n    + */\n    +@TriggerSerially\n    +@InputRequirement(InputRequirement.Requirement.INPUT_FORBIDDEN)\n    +@Tags({\"sql\", \"list\", \"jdbc\", \"table\", \"database\"})\n    +@CapabilityDescription(\"Generates a set of flow files, each containing attributes corresponding to metadata about a table from a database connection.\")\n    +@WritesAttributes({\n    +        @WritesAttribute(attribute = \"db.table.name\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.catalog\", description = \"Contains the name of the catalog to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.schema\", description = \"Contains the name of the schema to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.fullname\", description = \"Contains the fully-qualifed table name (possibly including catalog, schema, etc.)\"),\n    +        @WritesAttribute(attribute = \"db.table.type\",\n    +                description = \"Contains the type of the database table from the connection. Typical types are \\\"TABLE\\\", \\\"VIEW\\\", \\\"SYSTEM TABLE\\\", \"\n    +                        + \"\\\"GLOBAL TEMPORARY\\\", \\\"LOCAL TEMPORARY\\\", \\\"ALIAS\\\", \\\"SYNONYM\\\"\"),\n    +        @WritesAttribute(attribute = \"db.table.remarks\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.count\", description = \"Contains the number of rows in the table\")\n    +})\n    +@Stateful(scopes = {Scope.LOCAL}, description = \"After performing a listing of tables, the timestamp of the query is stored. \"\n    +        + \"This allows the Processor to not re-list tables the next time that the Processor is run. Changing any of the processor properties will \"\n    +        + \"indicate that the processor should reset state and thus re-list the tables using the new configuration. This processor is meant to be \"\n    +        + \"run on the primary node only.\")\n    +public class ListDatabaseTables extends AbstractProcessor {\n    +\n    +    // Attribute names\n    +    public static final String DB_TABLE_NAME = \"db.table.name\";\n    +    public static final String DB_TABLE_CATALOG = \"db.table.catalog\";\n    +    public static final String DB_TABLE_SCHEMA = \"db.table.schema\";\n    +    public static final String DB_TABLE_FULLNAME = \"db.table.fullname\";\n    +    public static final String DB_TABLE_TYPE = \"db.table.type\";\n    +    public static final String DB_TABLE_REMARKS = \"db.table.remarks\";\n    +    public static final String DB_TABLE_COUNT = \"db.table.count\";\n    +\n    +    // Relationships\n    +    public static final Relationship REL_SUCCESS = new Relationship.Builder()\n    +            .name(\"success\")\n    +            .description(\"All FlowFiles that are received are routed to success\")\n    +            .build();\n    +\n    +    // Property descriptors\n    +    public static final PropertyDescriptor DBCP_SERVICE = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-db-connection\")\n    +            .displayName(\"Database Connection Pooling Service\")\n    +            .description(\"The Controller Service that is used to obtain connection to database\")\n    +            .required(true)\n    +            .identifiesControllerService(DBCPService.class)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor CATALOG = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-catalog\")\n    +            .displayName(\"Catalog\")\n    +            .description(\"The name of a catalog from which to list database tables. The name must match the catalog name as it is stored in the database. \"\n    +                    + \"If the property is not set, the catalog name will not be used to narrow the search for tables. If the property is set to an empty string, \"\n    +                    + \"tables without a catalog will be listed.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor SCHEMA_PATTERN = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-schema-pattern\")\n    +            .displayName(\"Schema Pattern\")\n    +            .description(\"A pattern for matching schemas in the database. Within a pattern, \\\"%\\\" means match any substring of 0 or more characters, \"\n    +                    + \"and \\\"_\\\" means match any one character. The pattern must match the schema name as it is stored in the database. \"\n    +                    + \"If the property is not set, the schema name will not be used to narrow the search for tables. If the property is set to an empty string, \"\n    +                    + \"tables without a schema will be listed.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor TABLE_NAME_PATTERN = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-name-pattern\")\n    +            .displayName(\"Table Name Pattern\")\n    +            .description(\"A pattern for matching tables in the database. Within a pattern, \\\"%\\\" means match any substring of 0 or more characters, \"\n    +                    + \"and \\\"_\\\" means match any one character. The pattern must match the table name as it is stored in the database. \"\n    +                    + \"If the property is not set, all tables will be retrieved.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor TABLE_TYPES = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-types\")\n    +            .displayName(\"Table Types\")\n    +            .description(\"A comma-separated list of table types to include. For example, some databases support TABLE and VIEW types. If the property is not set, \"\n    +                    + \"tables of all types will be returned.\")\n    +            .required(false)\n    +            .defaultValue(\"TABLE\")\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor INCLUDE_COUNT = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-include-count\")\n    +            .displayName(\"Include Count\")\n    +            .description(\"Whether to include the table's row count as a flow file attribute. This affects performance as a database query will be generated \"\n    +                    + \"for each table in the retrieved list.\")\n    +            .required(true)\n    +            .allowableValues(\"true\", \"false\")\n    +            .defaultValue(\"false\")\n    +            .build();\n    +\n    +    private static final List<PropertyDescriptor> propertyDescriptors;\n    +    private static final Set<Relationship> relationships;\n    +\n    +    private boolean resetState = false;\n    +\n    +    /*\n    +     * Will ensure that the list of property descriptors is build only once.\n    +     * Will also create a Set of relationships\n    +     */\n    +    static {\n    +        List<PropertyDescriptor> _propertyDescriptors = new ArrayList<>();\n    +        _propertyDescriptors.add(DBCP_SERVICE);\n    +        _propertyDescriptors.add(CATALOG);\n    +        _propertyDescriptors.add(SCHEMA_PATTERN);\n    +        _propertyDescriptors.add(TABLE_NAME_PATTERN);\n    +        _propertyDescriptors.add(TABLE_TYPES);\n    +        _propertyDescriptors.add(INCLUDE_COUNT);\n    +        propertyDescriptors = Collections.unmodifiableList(_propertyDescriptors);\n    +\n    +        Set<Relationship> _relationships = new HashSet<>();\n    +        _relationships.add(REL_SUCCESS);\n    +        relationships = Collections.unmodifiableSet(_relationships);\n    +    }\n    +\n    +    @Override\n    +    protected List<PropertyDescriptor> getSupportedPropertyDescriptors() {\n    +        return propertyDescriptors;\n    +    }\n    +\n    +    @Override\n    +    public Set<Relationship> getRelationships() {\n    +        return relationships;\n    +    }\n    +\n    +    @OnScheduled\n    +    public void setup(ProcessContext context) {\n    +        try {\n    +            if (resetState) {\n    +                context.getStateManager().clear(Scope.LOCAL);\n    +                resetState = false;\n    +            }\n    +        } catch (IOException ioe) {\n    +            throw new ProcessException(ioe);\n    +        }\n    +    }\n    +\n    +    @Override\n    +    public void onTrigger(ProcessContext context, ProcessSession session) throws ProcessException {\n    +        final ComponentLog logger = getLogger();\n    +        final DBCPService dbcpService = context.getProperty(DBCP_SERVICE).asControllerService(DBCPService.class);\n    +        final String catalog = context.getProperty(CATALOG).getValue();\n    +        final String schemaPattern = context.getProperty(SCHEMA_PATTERN).getValue();\n    +        final String tableNamePattern = context.getProperty(TABLE_NAME_PATTERN).getValue();\n    +        final String[] tableTypes = context.getProperty(TABLE_TYPES).isSet()\n    +                ? context.getProperty(TABLE_TYPES).getValue().split(\"\\\\s*,\\\\s*\")\n    +                : null;\n    +        final boolean includeCount = context.getProperty(INCLUDE_COUNT).asBoolean();\n    +\n    +        final StateManager stateManager = context.getStateManager();\n    +        final StateMap stateMap;\n    +        final Map<String, String> stateMapProperties;\n    +        try {\n    +            stateMap = stateManager.getState(Scope.LOCAL);\n    +            stateMapProperties = new HashMap<>(stateMap.toMap());\n    +        } catch (IOException ioe) {\n    +            throw new ProcessException(ioe);\n    +        }\n    +\n    +        try (final Connection con = dbcpService.getConnection()) {\n    +\n    +            DatabaseMetaData dbMetaData = con.getMetaData();\n    +            ResultSet rs = dbMetaData.getTables(catalog, schemaPattern, tableNamePattern, tableTypes);\n    +            while (rs.next()) {\n    +                final String tableCatalog = rs.getString(1);\n    +                final String tableSchema = rs.getString(2);\n    +                final String tableName = rs.getString(3);\n    +                final String tableType = rs.getString(4);\n    +                final String tableRemarks = rs.getString(5);\n    +\n    +                // Build fully-qualified name\n    +                String fqn = Stream.of(tableCatalog, tableSchema, tableName)\n    +                        .filter(segment -> !StringUtils.isEmpty(segment))\n    +                        .collect(Collectors.joining(\".\"));\n    +\n    +                String fqTableName = stateMap.get(fqn);\n    +                if (fqTableName == null) {\n    +                    FlowFile flowFile = session.create();\n    +                    logger.info(\"Found {}: {}\", new Object[]{tableType, fqn});\n    +                    if (includeCount) {\n    +                        try (Statement st = con.createStatement()) {\n    +                            final String countQuery = \"SELECT COUNT(1) FROM \" + fqn;\n    +\n    +                            logger.debug(\"Executing query: {}\", new Object[]{countQuery});\n    +                            ResultSet countResult = st.executeQuery(countQuery);\n    +                            if (countResult.next()) {\n    +                                flowFile = session.putAttribute(flowFile, DB_TABLE_COUNT, Long.toString(countResult.getLong(1)));\n    +                            }\n    +                        } catch (SQLException se) {\n    +                            logger.error(\"Couldn't get row count for {}\", new Object[]{fqn});\n    +                            session.remove(flowFile);\n    --- End diff --\n    \n    Wouldn't removing a flowfile essentially skip what ever information would've been in that row, leading to data loss?\n"
            },
            {
                "author_name": "githubbot",
                "id": "15381570",
                "body": "Github user mattyb149 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71091826\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -0,0 +1,304 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.nifi.annotation.behavior.InputRequirement;\n    +import org.apache.nifi.annotation.behavior.Stateful;\n    +import org.apache.nifi.annotation.behavior.TriggerSerially;\n    +import org.apache.nifi.annotation.behavior.WritesAttribute;\n    +import org.apache.nifi.annotation.behavior.WritesAttributes;\n    +import org.apache.nifi.annotation.documentation.CapabilityDescription;\n    +import org.apache.nifi.annotation.documentation.Tags;\n    +import org.apache.nifi.annotation.lifecycle.OnScheduled;\n    +import org.apache.nifi.components.PropertyDescriptor;\n    +import org.apache.nifi.components.Validator;\n    +import org.apache.nifi.components.state.Scope;\n    +import org.apache.nifi.components.state.StateManager;\n    +import org.apache.nifi.components.state.StateMap;\n    +import org.apache.nifi.dbcp.DBCPService;\n    +import org.apache.nifi.flowfile.FlowFile;\n    +import org.apache.nifi.logging.ComponentLog;\n    +import org.apache.nifi.processor.AbstractProcessor;\n    +import org.apache.nifi.processor.ProcessContext;\n    +import org.apache.nifi.processor.ProcessSession;\n    +import org.apache.nifi.processor.Relationship;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.util.StringUtils;\n    +\n    +import java.io.IOException;\n    +import java.sql.Connection;\n    +import java.sql.DatabaseMetaData;\n    +import java.sql.ResultSet;\n    +import java.sql.SQLException;\n    +import java.sql.Statement;\n    +import java.util.ArrayList;\n    +import java.util.Collections;\n    +import java.util.HashMap;\n    +import java.util.HashSet;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +import java.util.stream.Collectors;\n    +import java.util.stream.Stream;\n    +\n    +/**\n    + * A processor to retrieve a list of tables (and their metadata) from a database connection\n    + */\n    +@TriggerSerially\n    +@InputRequirement(InputRequirement.Requirement.INPUT_FORBIDDEN)\n    +@Tags({\"sql\", \"list\", \"jdbc\", \"table\", \"database\"})\n    +@CapabilityDescription(\"Generates a set of flow files, each containing attributes corresponding to metadata about a table from a database connection.\")\n    +@WritesAttributes({\n    +        @WritesAttribute(attribute = \"db.table.name\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.catalog\", description = \"Contains the name of the catalog to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.schema\", description = \"Contains the name of the schema to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.fullname\", description = \"Contains the fully-qualifed table name (possibly including catalog, schema, etc.)\"),\n    +        @WritesAttribute(attribute = \"db.table.type\",\n    +                description = \"Contains the type of the database table from the connection. Typical types are \\\"TABLE\\\", \\\"VIEW\\\", \\\"SYSTEM TABLE\\\", \"\n    +                        + \"\\\"GLOBAL TEMPORARY\\\", \\\"LOCAL TEMPORARY\\\", \\\"ALIAS\\\", \\\"SYNONYM\\\"\"),\n    +        @WritesAttribute(attribute = \"db.table.remarks\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.count\", description = \"Contains the number of rows in the table\")\n    +})\n    +@Stateful(scopes = {Scope.LOCAL}, description = \"After performing a listing of tables, the timestamp of the query is stored. \"\n    --- End diff --\n    \n    Wasn't sure about that but makes sense to me :) will change to cluster.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15381598",
                "body": "Github user mattyb149 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71093459\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -0,0 +1,304 @@\n    +/*\n    + * Licensed to the Apache Software Foundation (ASF) under one or more\n    + * contributor license agreements.  See the NOTICE file distributed with\n    + * this work for additional information regarding copyright ownership.\n    + * The ASF licenses this file to You under the Apache License, Version 2.0\n    + * (the \"License\"); you may not use this file except in compliance with\n    + * the License.  You may obtain a copy of the License at\n    + *\n    + *     http://www.apache.org/licenses/LICENSE-2.0\n    + *\n    + * Unless required by applicable law or agreed to in writing, software\n    + * distributed under the License is distributed on an \"AS IS\" BASIS,\n    + * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    + * See the License for the specific language governing permissions and\n    + * limitations under the License.\n    + */\n    +package org.apache.nifi.processors.standard;\n    +\n    +import org.apache.nifi.annotation.behavior.InputRequirement;\n    +import org.apache.nifi.annotation.behavior.Stateful;\n    +import org.apache.nifi.annotation.behavior.TriggerSerially;\n    +import org.apache.nifi.annotation.behavior.WritesAttribute;\n    +import org.apache.nifi.annotation.behavior.WritesAttributes;\n    +import org.apache.nifi.annotation.documentation.CapabilityDescription;\n    +import org.apache.nifi.annotation.documentation.Tags;\n    +import org.apache.nifi.annotation.lifecycle.OnScheduled;\n    +import org.apache.nifi.components.PropertyDescriptor;\n    +import org.apache.nifi.components.Validator;\n    +import org.apache.nifi.components.state.Scope;\n    +import org.apache.nifi.components.state.StateManager;\n    +import org.apache.nifi.components.state.StateMap;\n    +import org.apache.nifi.dbcp.DBCPService;\n    +import org.apache.nifi.flowfile.FlowFile;\n    +import org.apache.nifi.logging.ComponentLog;\n    +import org.apache.nifi.processor.AbstractProcessor;\n    +import org.apache.nifi.processor.ProcessContext;\n    +import org.apache.nifi.processor.ProcessSession;\n    +import org.apache.nifi.processor.Relationship;\n    +import org.apache.nifi.processor.exception.ProcessException;\n    +import org.apache.nifi.util.StringUtils;\n    +\n    +import java.io.IOException;\n    +import java.sql.Connection;\n    +import java.sql.DatabaseMetaData;\n    +import java.sql.ResultSet;\n    +import java.sql.SQLException;\n    +import java.sql.Statement;\n    +import java.util.ArrayList;\n    +import java.util.Collections;\n    +import java.util.HashMap;\n    +import java.util.HashSet;\n    +import java.util.List;\n    +import java.util.Map;\n    +import java.util.Set;\n    +import java.util.stream.Collectors;\n    +import java.util.stream.Stream;\n    +\n    +/**\n    + * A processor to retrieve a list of tables (and their metadata) from a database connection\n    + */\n    +@TriggerSerially\n    +@InputRequirement(InputRequirement.Requirement.INPUT_FORBIDDEN)\n    +@Tags({\"sql\", \"list\", \"jdbc\", \"table\", \"database\"})\n    +@CapabilityDescription(\"Generates a set of flow files, each containing attributes corresponding to metadata about a table from a database connection.\")\n    +@WritesAttributes({\n    +        @WritesAttribute(attribute = \"db.table.name\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.catalog\", description = \"Contains the name of the catalog to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.schema\", description = \"Contains the name of the schema to which the table belongs (may be null)\"),\n    +        @WritesAttribute(attribute = \"db.table.fullname\", description = \"Contains the fully-qualifed table name (possibly including catalog, schema, etc.)\"),\n    +        @WritesAttribute(attribute = \"db.table.type\",\n    +                description = \"Contains the type of the database table from the connection. Typical types are \\\"TABLE\\\", \\\"VIEW\\\", \\\"SYSTEM TABLE\\\", \"\n    +                        + \"\\\"GLOBAL TEMPORARY\\\", \\\"LOCAL TEMPORARY\\\", \\\"ALIAS\\\", \\\"SYNONYM\\\"\"),\n    +        @WritesAttribute(attribute = \"db.table.remarks\", description = \"Contains the name of a database table from the connection\"),\n    +        @WritesAttribute(attribute = \"db.table.count\", description = \"Contains the number of rows in the table\")\n    +})\n    +@Stateful(scopes = {Scope.LOCAL}, description = \"After performing a listing of tables, the timestamp of the query is stored. \"\n    +        + \"This allows the Processor to not re-list tables the next time that the Processor is run. Changing any of the processor properties will \"\n    +        + \"indicate that the processor should reset state and thus re-list the tables using the new configuration. This processor is meant to be \"\n    +        + \"run on the primary node only.\")\n    +public class ListDatabaseTables extends AbstractProcessor {\n    +\n    +    // Attribute names\n    +    public static final String DB_TABLE_NAME = \"db.table.name\";\n    +    public static final String DB_TABLE_CATALOG = \"db.table.catalog\";\n    +    public static final String DB_TABLE_SCHEMA = \"db.table.schema\";\n    +    public static final String DB_TABLE_FULLNAME = \"db.table.fullname\";\n    +    public static final String DB_TABLE_TYPE = \"db.table.type\";\n    +    public static final String DB_TABLE_REMARKS = \"db.table.remarks\";\n    +    public static final String DB_TABLE_COUNT = \"db.table.count\";\n    +\n    +    // Relationships\n    +    public static final Relationship REL_SUCCESS = new Relationship.Builder()\n    +            .name(\"success\")\n    +            .description(\"All FlowFiles that are received are routed to success\")\n    +            .build();\n    +\n    +    // Property descriptors\n    +    public static final PropertyDescriptor DBCP_SERVICE = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-db-connection\")\n    +            .displayName(\"Database Connection Pooling Service\")\n    +            .description(\"The Controller Service that is used to obtain connection to database\")\n    +            .required(true)\n    +            .identifiesControllerService(DBCPService.class)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor CATALOG = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-catalog\")\n    +            .displayName(\"Catalog\")\n    +            .description(\"The name of a catalog from which to list database tables. The name must match the catalog name as it is stored in the database. \"\n    +                    + \"If the property is not set, the catalog name will not be used to narrow the search for tables. If the property is set to an empty string, \"\n    +                    + \"tables without a catalog will be listed.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor SCHEMA_PATTERN = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-schema-pattern\")\n    +            .displayName(\"Schema Pattern\")\n    +            .description(\"A pattern for matching schemas in the database. Within a pattern, \\\"%\\\" means match any substring of 0 or more characters, \"\n    +                    + \"and \\\"_\\\" means match any one character. The pattern must match the schema name as it is stored in the database. \"\n    +                    + \"If the property is not set, the schema name will not be used to narrow the search for tables. If the property is set to an empty string, \"\n    +                    + \"tables without a schema will be listed.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor TABLE_NAME_PATTERN = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-name-pattern\")\n    +            .displayName(\"Table Name Pattern\")\n    +            .description(\"A pattern for matching tables in the database. Within a pattern, \\\"%\\\" means match any substring of 0 or more characters, \"\n    +                    + \"and \\\"_\\\" means match any one character. The pattern must match the table name as it is stored in the database. \"\n    +                    + \"If the property is not set, all tables will be retrieved.\")\n    +            .required(false)\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor TABLE_TYPES = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-tables-types\")\n    +            .displayName(\"Table Types\")\n    +            .description(\"A comma-separated list of table types to include. For example, some databases support TABLE and VIEW types. If the property is not set, \"\n    +                    + \"tables of all types will be returned.\")\n    +            .required(false)\n    +            .defaultValue(\"TABLE\")\n    +            .addValidator(Validator.VALID)\n    +            .build();\n    +\n    +    public static final PropertyDescriptor INCLUDE_COUNT = new PropertyDescriptor.Builder()\n    +            .name(\"list-db-include-count\")\n    +            .displayName(\"Include Count\")\n    +            .description(\"Whether to include the table's row count as a flow file attribute. This affects performance as a database query will be generated \"\n    +                    + \"for each table in the retrieved list.\")\n    +            .required(true)\n    +            .allowableValues(\"true\", \"false\")\n    +            .defaultValue(\"false\")\n    +            .build();\n    +\n    +    private static final List<PropertyDescriptor> propertyDescriptors;\n    +    private static final Set<Relationship> relationships;\n    +\n    +    private boolean resetState = false;\n    +\n    +    /*\n    +     * Will ensure that the list of property descriptors is build only once.\n    +     * Will also create a Set of relationships\n    +     */\n    +    static {\n    +        List<PropertyDescriptor> _propertyDescriptors = new ArrayList<>();\n    +        _propertyDescriptors.add(DBCP_SERVICE);\n    +        _propertyDescriptors.add(CATALOG);\n    +        _propertyDescriptors.add(SCHEMA_PATTERN);\n    +        _propertyDescriptors.add(TABLE_NAME_PATTERN);\n    +        _propertyDescriptors.add(TABLE_TYPES);\n    +        _propertyDescriptors.add(INCLUDE_COUNT);\n    +        propertyDescriptors = Collections.unmodifiableList(_propertyDescriptors);\n    +\n    +        Set<Relationship> _relationships = new HashSet<>();\n    +        _relationships.add(REL_SUCCESS);\n    +        relationships = Collections.unmodifiableSet(_relationships);\n    +    }\n    +\n    +    @Override\n    +    protected List<PropertyDescriptor> getSupportedPropertyDescriptors() {\n    +        return propertyDescriptors;\n    +    }\n    +\n    +    @Override\n    +    public Set<Relationship> getRelationships() {\n    +        return relationships;\n    +    }\n    +\n    +    @OnScheduled\n    +    public void setup(ProcessContext context) {\n    +        try {\n    +            if (resetState) {\n    +                context.getStateManager().clear(Scope.LOCAL);\n    +                resetState = false;\n    +            }\n    +        } catch (IOException ioe) {\n    +            throw new ProcessException(ioe);\n    +        }\n    +    }\n    +\n    +    @Override\n    +    public void onTrigger(ProcessContext context, ProcessSession session) throws ProcessException {\n    +        final ComponentLog logger = getLogger();\n    +        final DBCPService dbcpService = context.getProperty(DBCP_SERVICE).asControllerService(DBCPService.class);\n    +        final String catalog = context.getProperty(CATALOG).getValue();\n    +        final String schemaPattern = context.getProperty(SCHEMA_PATTERN).getValue();\n    +        final String tableNamePattern = context.getProperty(TABLE_NAME_PATTERN).getValue();\n    +        final String[] tableTypes = context.getProperty(TABLE_TYPES).isSet()\n    +                ? context.getProperty(TABLE_TYPES).getValue().split(\"\\\\s*,\\\\s*\")\n    +                : null;\n    +        final boolean includeCount = context.getProperty(INCLUDE_COUNT).asBoolean();\n    +\n    +        final StateManager stateManager = context.getStateManager();\n    +        final StateMap stateMap;\n    +        final Map<String, String> stateMapProperties;\n    +        try {\n    +            stateMap = stateManager.getState(Scope.LOCAL);\n    +            stateMapProperties = new HashMap<>(stateMap.toMap());\n    +        } catch (IOException ioe) {\n    +            throw new ProcessException(ioe);\n    +        }\n    +\n    +        try (final Connection con = dbcpService.getConnection()) {\n    +\n    +            DatabaseMetaData dbMetaData = con.getMetaData();\n    +            ResultSet rs = dbMetaData.getTables(catalog, schemaPattern, tableNamePattern, tableTypes);\n    +            while (rs.next()) {\n    +                final String tableCatalog = rs.getString(1);\n    +                final String tableSchema = rs.getString(2);\n    +                final String tableName = rs.getString(3);\n    +                final String tableType = rs.getString(4);\n    +                final String tableRemarks = rs.getString(5);\n    +\n    +                // Build fully-qualified name\n    +                String fqn = Stream.of(tableCatalog, tableSchema, tableName)\n    +                        .filter(segment -> !StringUtils.isEmpty(segment))\n    +                        .collect(Collectors.joining(\".\"));\n    +\n    +                String fqTableName = stateMap.get(fqn);\n    +                if (fqTableName == null) {\n    +                    FlowFile flowFile = session.create();\n    +                    logger.info(\"Found {}: {}\", new Object[]{tableType, fqn});\n    +                    if (includeCount) {\n    +                        try (Statement st = con.createStatement()) {\n    +                            final String countQuery = \"SELECT COUNT(1) FROM \" + fqn;\n    +\n    +                            logger.debug(\"Executing query: {}\", new Object[]{countQuery});\n    +                            ResultSet countResult = st.executeQuery(countQuery);\n    +                            if (countResult.next()) {\n    +                                flowFile = session.putAttribute(flowFile, DB_TABLE_COUNT, Long.toString(countResult.getLong(1)));\n    +                            }\n    +                        } catch (SQLException se) {\n    +                            logger.error(\"Couldn't get row count for {}\", new Object[]{fqn});\n    +                            session.remove(flowFile);\n    --- End diff --\n    \n    It's a data generator, so not sure what counts as data loss. I could add a \"failure\" relationship but I didn't see any precedence for transferring newly-created flowfiles.\n    If you mean that an error getting the count shouldn't prevent the flow file (minus the count) from being transferred, then yeah I can make that change. Just wasn't sure from a UX perspective if they want a count and can't get one, should the flow file be transferred?\n"
            },
            {
                "author_name": "githubbot",
                "id": "15382368",
                "body": "Github user JPercivall commented on the issue:\n\n    https://github.com/apache/nifi/pull/642\n  \n    Alright, after giving it some time and a cup of coffee I realize how off I was at first, lol. This processor reaches out to the DB asking for the tables. Then for each table that isn't already stored in state it creates a flowfile. If the processor is configured to give the count, it needs to send a SQL query asking for it. If that query fails it will remove the flowfile it created and continue onto the next table. If successful, the FQN of the table will then be added to state (after queuing it to transfer).\n    \n    That realization makes my comment about data loss void (was afraid it would get stored in state after un-successfully getting the count). \n    \n    One new comment, would a user want to set an expiration for tables in state? That way they could get updates on the count of a table every X seconds/minutes. In it's current form it will get the table once but never again. You're already storing the timestamp as the value so it should be an easy addition.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15382703",
                "body": "Github user mattyb149 commented on the issue:\n\n    https://github.com/apache/nifi/pull/642\n  \n    Yes, at one point I had a \"Refresh Interval\" property but I think that was in another branch, will restore it. Also, currently any change to properties will reset the state (since the tables fetched may have changed), I'm thinking of taking that part out. The Refresh Interval would cause all tables to be re-fetched, and/or the user could always manually clear state. What do you think?\n"
            },
            {
                "author_name": "githubbot",
                "id": "15383192",
                "body": "Github user JPercivall commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71242383\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -211,17 +213,37 @@ public void onTrigger(ProcessContext context, ProcessSession session) throws Pro\n                     ? context.getProperty(TABLE_TYPES).getValue().split(\"\\\\s*,\\\\s*\")\n                     : null;\n             final boolean includeCount = context.getProperty(INCLUDE_COUNT).asBoolean();\n    +        final long refreshInterval = context.getProperty(REFRESH_INTERVAL).asTimePeriod(TimeUnit.MILLISECONDS);\n     \n             final StateManager stateManager = context.getStateManager();\n             final StateMap stateMap;\n             final Map<String, String> stateMapProperties;\n             try {\n    -            stateMap = stateManager.getState(Scope.LOCAL);\n    +            stateMap = stateManager.getState(Scope.CLUSTER);\n                 stateMapProperties = new HashMap<>(stateMap.toMap());\n             } catch (IOException ioe) {\n                 throw new ProcessException(ioe);\n             }\n     \n    +        try {\n    +            // Refresh state if the interval has elapsed\n    +            long lastRefreshed = -1;\n    +            final long currentTime = System.currentTimeMillis();\n    +            String lastTimestamp = stateMapProperties.get(this.getIdentifier());\n    +            if (!StringUtils.isEmpty(lastTimestamp)) {\n    +                lastRefreshed = Long.parseLong(lastTimestamp);\n    +            }\n    +            if (lastRefreshed > 0 && refreshInterval > 0 && currentTime >= (lastRefreshed + refreshInterval)) {\n    +                stateManager.clear(Scope.CLUSTER);\n    +                stateMapProperties.clear();\n    --- End diff --\n    \n    Why clear all the properties at once and not just have an expiration time that applies to each table? Where if you have it set to 5 minutes, the processor will end up reporting the count of the table every minutes (while it still exists). You already store the timestamp under the FQN.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15383281",
                "body": "Github user mattyb149 commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71249117\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -211,17 +213,37 @@ public void onTrigger(ProcessContext context, ProcessSession session) throws Pro\n                     ? context.getProperty(TABLE_TYPES).getValue().split(\"\\\\s*,\\\\s*\")\n                     : null;\n             final boolean includeCount = context.getProperty(INCLUDE_COUNT).asBoolean();\n    +        final long refreshInterval = context.getProperty(REFRESH_INTERVAL).asTimePeriod(TimeUnit.MILLISECONDS);\n     \n             final StateManager stateManager = context.getStateManager();\n             final StateMap stateMap;\n             final Map<String, String> stateMapProperties;\n             try {\n    -            stateMap = stateManager.getState(Scope.LOCAL);\n    +            stateMap = stateManager.getState(Scope.CLUSTER);\n                 stateMapProperties = new HashMap<>(stateMap.toMap());\n             } catch (IOException ioe) {\n                 throw new ProcessException(ioe);\n             }\n     \n    +        try {\n    +            // Refresh state if the interval has elapsed\n    +            long lastRefreshed = -1;\n    +            final long currentTime = System.currentTimeMillis();\n    +            String lastTimestamp = stateMapProperties.get(this.getIdentifier());\n    +            if (!StringUtils.isEmpty(lastTimestamp)) {\n    +                lastRefreshed = Long.parseLong(lastTimestamp);\n    +            }\n    +            if (lastRefreshed > 0 && refreshInterval > 0 && currentTime >= (lastRefreshed + refreshInterval)) {\n    +                stateManager.clear(Scope.CLUSTER);\n    +                stateMapProperties.clear();\n    --- End diff --\n    \n    Good point, will add.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15384205",
                "body": "Github user JPercivall commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71347101\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -260,8 +241,27 @@ public void onTrigger(ProcessContext context, ProcessSession session) throws Pro\n                             .filter(segment -> !StringUtils.isEmpty(segment))\n                             .collect(Collectors.joining(\".\"));\n     \n    -                String fqTableName = stateMapProperties.get(fqn);\n    -                if (fqTableName == null) {\n    +                String lastTimestampForTable = stateMapProperties.get(fqn);\n    +                boolean refreshTable = true;\n    +                try {\n    +                    // Refresh state if the interval has elapsed\n    +                    long lastRefreshed = -1;\n    +                    final long currentTime = System.currentTimeMillis();\n    +                    if (!StringUtils.isEmpty(lastTimestampForTable)) {\n    +                        lastRefreshed = Long.parseLong(lastTimestampForTable);\n    +                    }\n    +                    if (lastRefreshed == -1 || (refreshInterval > 0 && currentTime >= (lastRefreshed + refreshInterval))) {\n    +                        stateMapProperties.remove(lastTimestampForTable);\n    +                    } else {\n    +                        refreshTable = false;\n    +                    }\n    +                } catch (final NumberFormatException nfe) {\n    +                    getLogger().error(\"Failed to retrieve observed last table fetches from the State Manager. Will not perform \"\n    --- End diff --\n    \n    This exception really *shouldn't* happen since we are setting the long ourselves but if it does it will fail entirely until state is cleared by the user. In addition to returning and yielding, it should probably clear the offending state entry (and log in the error message that this is hapenning and the ramifications). This will at least give the processor a chance to continue working if it every reaches this state. \n"
            },
            {
                "author_name": "githubbot",
                "id": "15384214",
                "body": "Github user JPercivall commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71348259\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -304,7 +304,6 @@ public void onTrigger(ProcessContext context, ProcessSession session) throws Pro\n                     }\n                 }\n                 // Update the last time the processor finished successfully\n    --- End diff --\n    \n    I believe this can be removed\n"
            },
            {
                "author_name": "githubbot",
                "id": "15384452",
                "body": "Github user JPercivall commented on a diff in the pull request:\n\n    https://github.com/apache/nifi/pull/642#discussion_r71372009\n  \n    --- Diff: nifi-nar-bundles/nifi-standard-bundle/nifi-standard-processors/src/main/java/org/apache/nifi/processors/standard/ListDatabaseTables.java ---\n    @@ -303,8 +303,8 @@ public void onTrigger(ProcessContext context, ProcessSession session) throws Pro\n                         stateMapProperties.put(fqn, Long.toString(System.currentTimeMillis()));\n                     }\n                 }\n    -            // Update the last time the processor finished successfully\n    -            stateManager.replace(stateMap, stateMapProperties, Scope.CLUSTER);\n    +            // Update the timestamps for listed tables\n    +            stateManager.setState(stateMapProperties, Scope.CLUSTER);\n    --- End diff --\n    \n    I would not change this to setState. It will overwrite anything that is in State. If someone does end up running clustered and not primary Node it will blow it away without warnings. \n    \n    Instead just check if the prior map version was -1 and do a set instead of replace.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15384506",
                "body": "Github user JPercivall commented on the issue:\n\n    https://github.com/apache/nifi/pull/642\n  \n    +1\n    \n    Visually verified code and any comments were addressed. Ran a contrib check build and verified functionality in a standalone cluster hitting a MySQL DB. Thanks @mattyb149, I will squash and merge\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15384530",
                "body": "Commit f1ba2403265b7f8b170862039212c341bb9e352c in nifi's branch refs/heads/master from [~mattyb149]\n[ https://git-wip-us.apache.org/repos/asf?p=nifi.git;h=f1ba240 ]\n\nNIFI-2156: Add ListDatabaseTables processor\n\nThis closes #642\n\nSigned-off-by: jpercivall <joepercivall@yahoo.com>\n"
            },
            {
                "author_name": "githubbot",
                "id": "15384531",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/nifi/pull/642\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640753bc46426b37b1b85e6e",
        "key": "CLOUDSTACK-9164",
        "id": "12921620",
        "description": "At least with recent Firefox-Browsers using the Consoleproxy results in Firefox Quicksearch when typing slash ( / ).\nFurthermore, using a shell via Consoleproxy shows typical typing patterns like slash,tab,return to get autocompetion of files.\nOne has to be very attentive not to get into the Quicksearch ( / ), moving to the ctrl-alt-del (tab) and reboot the VM without confirmation (return).\n\nThe external lilnk points to a patch for ajaxviewer.js, mitigation that issue.\n\nSorry for not cloning the project on github so far.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.17060503363609314
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008390171453356743
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006090439856052399
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5dc7af4d395ee221aa2d7",
        "key": "SPARK-12708",
        "id": "12928575",
        "description": null,
        "predictions": {},
        "comments": [
            {
                "author_name": "apachespark",
                "id": "15088898",
                "body": "User 'yoshidakuy' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/10663"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d62e56f4d395ee2226e493",
        "key": "AMBARI-18476",
        "id": "13008034",
        "description": "AMBARI-12263 adds support for PAM as authentication mechanism for accessing Ambari UI/REST. \n\nSince a new column group_type has been added for groups, the UI will display labels for group type and enable/disable group delete/add member functionality based on the group_type instead of the ldap_group flag.\nThe user_type will be used to determine if the user can be deleted or if the user's password can be changed.\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.07279904931783676
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.44907116889953613
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.04648379608988762
                }
            }
        },
        "comments": [
            {
                "author_name": "hadoopqa",
                "id": "15535223",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12830952/AMBARI-18476.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in ambari-admin.\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/8771//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/8771//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "sangeetar",
                "id": "15542806",
                "body": "Updated patch that includes new file that was added as part of these changes."
            },
            {
                "author_name": "hadoopqa",
                "id": "15542922",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12831340/AMBARI-18476.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in ambari-admin.\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/8789//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/8789//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hkropp",
                "id": "15611604",
                "body": "This seems not enough, or am I missing something?"
            },
            {
                "author_name": "sangeetar",
                "id": "15612194",
                "body": "Can you clarify what you mean by that?"
            },
            {
                "author_name": "sangeetar",
                "id": "15630899",
                "body": "Final patch that was updated in the review request"
            },
            {
                "author_name": "sangeetar",
                "id": "15630905",
                "body": "Hi Henning, I had missed updating the patch in the jira when I updated the review request. The final patch was attached in the review. This has all the necessary changes."
            },
            {
                "author_name": "hadoopqa",
                "id": "15631062",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12836688/AMBARI-18476.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/9110//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "15636486",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12837078/AMBARI-18476.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in ambari-admin.\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/9137//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/9137//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "sangeetar",
                "id": "15669489",
                "body": "patch for 2.5"
            },
            {
                "author_name": "hadoopqa",
                "id": "15669499",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12839118/AMBARI-18476_2.5patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/9294//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "dili",
                "id": "15671202",
                "body": "Pushed to trunk as https://git-wip-us.apache.org/repos/asf?p=ambari.git;a=commit;h=745d1057b04f1ecf8a089d437e49a1ef672c2090\nPushed to branch 2.5 as  https://git-wip-us.apache.org/repos/asf?p=ambari.git;a=commit;h=31caa528ff07c8cb1f58ff355fc4c82c3cf7fdf3\n"
            },
            {
                "author_name": "hudson",
                "id": "15671296",
                "body": "FAILURE: Integrated in Jenkins build Ambari-branch-2.5 #342 (See [https://builds.apache.org/job/Ambari-branch-2.5/342/])\nAMBARI-18476: Ambari UI changes to support PAM authentication (Sangeeta (dili: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=31caa528ff07c8cb1f58ff355fc4c82c3cf7fdf3])\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/views/groups/list.html\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/views/users/show.html\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/controllers/groups/GroupsListCtrl.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/views/groups/edit.html\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/controllers/users/UsersShowCtrl.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/i18n.config.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/services/Group.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/index.html\n* (add) ambari-admin/src/main/resources/ui/admin-web/app/scripts/services/GroupConstants.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/controllers/groups/GroupsEditCtrl.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/services/UserConstants.js\n"
            },
            {
                "author_name": "dili",
                "id": "15671317",
                "body": "Following unit tests failed, none is related to the ambari admin view code change from this JIRA.\nTest Result (12 failures / +1)\norg.apache.ambari.server.controller.metrics.JMXPropertyProviderTest.testJMXPropertyProviderAsAdministrator\norg.apache.ambari.server.state.svccomphost.ServiceComponentHostTest.testStaleConfigs\norg.apache.ambari.server.controller.internal.StackDefinedPropertyProviderTest.testStackDefinedPropertyProviderAsClusterAdministrator\norg.apache.ambari.server.controller.internal.StackDefinedPropertyProviderTest.testStackDefinedPropertyProviderAsAdministrator\norg.apache.ambari.server.controller.internal.StackDefinedPropertyProviderTest.testStackDefinedPropertyProviderAsServiceAdministrator\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testRestMetricsPropertyProviderAsClusterAdministrator\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testRestMetricsPropertyProviderAsAdministrator\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testRestMetricsPropertyProviderAsServiceAdministrator\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testRestMetricsPropertyProviderAsViewUser\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testResolvePort\norg.apache.ambari.server.state.ServicePropertiesTest.validatePropertySchemaOfServiceXMLs\norg.apache.ambari.server.upgrade.UpgradeCatalog250Test.testExecuteDMLUpdates"
            },
            {
                "author_name": "hudson",
                "id": "15672164",
                "body": "ABORTED: Integrated in Jenkins build Ambari-trunk-Commit #6030 (See [https://builds.apache.org/job/Ambari-trunk-Commit/6030/])\nAMBARI-18476: Ambari UI changes to support PAM authentication (Sangeeta (dili: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=745d1057b04f1ecf8a089d437e49a1ef672c2090])\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/index.html\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/services/Group.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/views/groups/edit.html\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/i18n.config.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/controllers/groups/GroupsListCtrl.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/services/UserConstants.js\n* (add) ambari-admin/src/main/resources/ui/admin-web/app/scripts/services/GroupConstants.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/views/groups/list.html\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/controllers/users/UsersShowCtrl.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/scripts/controllers/groups/GroupsEditCtrl.js\n* (edit) ambari-admin/src/main/resources/ui/admin-web/app/views/users/show.html\n"
            }
        ],
        "comments_predictions": [
            [
                3841491,
                "AMBARI-18476",
                "Pushed to trunk as https://git-wip-us.apache.org/repos/asf?p=ambari.git;a=commit;h=745d1057b04f1ecf8a089d437e49a1ef672c2090\nPushed to branch 2.5 as  https://git-wip-us.apache.org/repos/asf?p=ambari.git;a=commit;h=31caa528ff07c8cb1f58ff355fc4c82c3cf7fdf3\n",
                {
                    "property": {
                        "confidence": 0.0061405799351632595,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00482699740678072,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0188400000333786,
                        "prediction": false
                    }
                }
            ],
            [
                3841493,
                "AMBARI-18476",
                "Following unit tests failed, none is related to the ambari admin view code change from this JIRA.\nTest Result (12 failures / +1)\norg.apache.ambari.server.controller.metrics.JMXPropertyProviderTest.testJMXPropertyProviderAsAdministrator\norg.apache.ambari.server.state.svccomphost.ServiceComponentHostTest.testStaleConfigs\norg.apache.ambari.server.controller.internal.StackDefinedPropertyProviderTest.testStackDefinedPropertyProviderAsClusterAdministrator\norg.apache.ambari.server.controller.internal.StackDefinedPropertyProviderTest.testStackDefinedPropertyProviderAsAdministrator\norg.apache.ambari.server.controller.internal.StackDefinedPropertyProviderTest.testStackDefinedPropertyProviderAsServiceAdministrator\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testRestMetricsPropertyProviderAsClusterAdministrator\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testRestMetricsPropertyProviderAsAdministrator\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testRestMetricsPropertyProviderAsServiceAdministrator\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testRestMetricsPropertyProviderAsViewUser\norg.apache.ambari.server.controller.metrics.RestMetricsPropertyProviderTest.testResolvePort\norg.apache.ambari.server.state.ServicePropertiesTest.validatePropertySchemaOfServiceXMLs\norg.apache.ambari.server.upgrade.UpgradeCatalog250Test.testExecuteDMLUpdates",
                {
                    "property": {
                        "confidence": 0.004478008020669222,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009602084755897522,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011223454028367996,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5ff9bf4d395ee22207838",
        "key": "HIVE-16370",
        "id": "13061425",
        "description": "I was attempting to create hive tables over some partitioned Avro files. It seems the void data type (Avro null) is not supported on partitioned tables (i could not replicate the bug on an un-partitioned table).\n\n---------------\n\ni managed to replicate the bug on two different hive versions.\n\nHive 1.1.0-cdh5.10.0\nHive 2.1.1-amzn-0\n----------------\n\nhow to replicate (avro tools are required to create the avro files):\n\n$ wget http://mirror.serversupportforum.de/apache/avro/avro-1.8.1/java/avro-tools-1.8.1.jar\n\n$ mkdir /tmp/avro\n$ mkdir /tmp/avro/null\n$ echo \"{ \\\n  \\\"type\\\" : \\\"record\\\", \\\n  \\\"name\\\" : \\\"null_failure\\\", \\\n  \\\"namespace\\\" : \\\"org.apache.avro.null_failure\\\", \\\n  \\\"doc\\\":\\\"the purpose of this schema is to replicate the hive avro null failure\\\", \\\n  \\\"fields\\\" : [{\\\"name\\\":\\\"one\\\", \\\"type\\\":\\\"null\\\",\\\"default\\\":null}] \\\n} \" > /tmp/avro/null/schema.avsc\n$ echo \"{\\\"one\\\":null}\" > /tmp/avro/null/data.json\n$ java -jar avro-tools-1.8.1.jar fromjson --schema-file /tmp/avro/null/schema.avsc /tmp/avro/null/data.json > /tmp/avro/null/data.avro\n\n$ hdfs dfs -mkdir /tmp/avro\n$ hdfs dfs -mkdir /tmp/avro/null\n$ hdfs dfs -mkdir /tmp/avro/null/schema\n$ hdfs dfs -mkdir /tmp/avro/null/data\n$ hdfs dfs -mkdir /tmp/avro/null/data/foo=bar\n$ hdfs dfs -copyFromLocal /tmp/avro/null/schema.avsc /tmp/avro/null/schema/schema.avsc\n$ hdfs dfs -copyFromLocal /tmp/avro/null/data.avro /tmp/avro/null/data/foo=bar/data.avro\n\n$ hive \n\n\nhive> CREATE EXTERNAL TABLE avro_null\nPARTITIONED BY (foo string)\n  ROW FORMAT SERDE\n  'org.apache.hadoop.hive.serde2.avro.AvroSerDe'\n  STORED as INPUTFORMAT\n  'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'\n  OUTPUTFORMAT\n  'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'\nLOCATION\n'/tmp/avro/null/data/'\n  TBLPROPERTIES (\n    'avro.schema.url'='/tmp/avro/null/schema/schema.avsc')\n;\n\n\n\nOK\nTime taken: 3.127 seconds\n\n\n\nhive> msck repair table avro_null;\nOK\nPartitions not in metastore:\tavro_null:foo=bar\nRepair: Added partition to metastore avro_null:foo=bar\nTime taken: 0.712 seconds, Fetched: 2 row(s)\n\n\n\nhive> select * from avro_null;\nFAILED: RuntimeException org.apache.hadoop.hive.ql.metadata.HiveException: Failed with exception Hive internal error inside isAssignableFromSettablePrimitiveOI void not supported yet.java.lang.RuntimeException: Hive internal error inside isAssignableFromSettablePrimitiveOI void not supported yet.\n\n\nhive> select foo, count(1)  from avro_null group by foo;\n\nOK\nbar\t1\nTime taken: 29.806 seconds, Fetched: 1 row(s)\n\n\n\n\n\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.052977144718170166
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.00765587342903018
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.003748555202037096
                }
            }
        },
        "comments": [
            {
                "author_name": "asears",
                "id": "16083316",
                "body": "This is something that can be handled in Avro by unioning the null type with another type in the avro file.\n\n[http://apache-avro.679487.n3.nabble.com/Support-for-null-in-String-primitive-types-td4025659.html]\n\nObjectInspectorUtils.java might be updated to handle \"void\" primitive category as it does in other cases."
            },
            {
                "author_name": "afan",
                "id": "16603942",
                "body": "Hi [~iamwrong], Do you still work on this one? Do you mind I can take this? Besides, do you see the issue for current master branch? I was wondering if the issue only happens to recursive schema?"
            },
            {
                "author_name": "hiveqa",
                "id": "16605724",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12938604/HIVE-16370.01-branch-1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 95 failed/errored test(s), 9121 tests executed\n*Failed tests:*\n{noformat}\nTestHs2HooksWithMiniKdc - did not produce a TEST-*.xml file (likely timed out) (batchId=452)\nTestJdbcWithMiniKdc - did not produce a TEST-*.xml file (likely timed out) (batchId=449)\nTestJdbcWithMiniKdcCookie - did not produce a TEST-*.xml file (likely timed out) (batchId=448)\nTestJdbcWithMiniKdcSQLAuthBinary - did not produce a TEST-*.xml file (likely timed out) (batchId=446)\nTestJdbcWithMiniKdcSQLAuthHttp - did not produce a TEST-*.xml file (likely timed out) (batchId=451)\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=202)\n\t[multi_insert_mixed.q,smb_mapjoin_4.q,timestamp_comparison.q,join_cond_pushdown_3.q,insert1.q,union_remove_10.q,mapreduce2.q,bucketmapjoin_negative.q,udf_in_file.q,skewjoinopt5.q,auto_join12.q,skewjoin.q,vector_count_distinct.q,smb_mapjoin_3.q,stats10.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=205)\n\t[auto_join30.q,union_remove_1.q,ppd_outer_join2.q,date_udf.q,join16.q,smb_mapjoin_13.q,bucketmapjoin7.q,smb_mapjoin_18.q,join19.q,metadata_only_queries.q,union6.q,cbo_subq_in.q,vectorization_part.q,groupby3_map_multi_distinct.q,vectorized_timestamp_funcs.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=206)\n\t[bucketmapjoin12.q,auto_join10.q,ptf_rcfile.q,join20.q,vector_elt.q,multi_insert.q,groupby_rollup1.q,ppd_join5.q,join_filters_overlap.q,vector_string_concat.q,join_empty.q,smb_mapjoin_6.q,auto_sortmerge_join_12.q,groupby_bigdata.q,innerjoin.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=207)\n\t[tez_joins_explain.q,input17.q,ppd_gby_join.q,vectorized_rcfile_columnar.q,ppd_join.q,join_cond_pushdown_1.q,union_remove_6_subq.q,timestamp_3.q,load_dyn_part6.q,load_dyn_part9.q,multi_insert_gby2.q,vectorization_11.q,avro_compression_enabled_native.q,stats_noscan_2.q,transform1.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=211)\n\t[escape_distributeby1.q,join9.q,groupby2.q,vectorization_pushdown.q,union_date.q,join_cond_pushdown_unqual3.q,join8.q,sample10.q,ppd_outer_join3.q,cross_product_check_1.q,statsfs.q,auto_sortmerge_join_2.q,auto_join_stats.q,input_part2.q,groupby_multi_single_reducer3.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=215)\n\t[ppd_join4.q,load_dyn_part2.q,smb_mapjoin_7.q,vectorization_5.q,smb_mapjoin_2.q,ppd_join_filter.q,column_access_stats.q,stats0.q,vector_between_in.q,vectorized_string_funcs.q,vectorization_1.q,bucket_map_join_2.q,temp_table_join1.q,vectorized_case.q,stats_noscan_1.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=217)\n\t[stats12.q,groupby4.q,union_top_level.q,groupby10.q,subquery_in.q,mapjoin_filter_on_outerjoin.q,stats14.q,auto_sortmerge_join_4.q,limit_partition_metadataonly.q,load_dyn_part4.q,union3.q,smb_mapjoin_14.q,groupby3_noskew_multi_distinct.q,stats18.q,union_remove_21.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=221)\n\t[table_access_keys_stats.q,bucketmapjoin11.q,union_remove_9.q,mergejoins_mixed.q,join_nullsafe.q,stats8.q,auto_join28.q,skewjoinopt14.q,union17.q,vectorized_shufflejoin.q,groupby8_noskew.q,auto_sortmerge_join_10.q,groupby11.q,skewjoinopt11.q,load_dyn_part11.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=222)\n\t[script_pipe.q,auto_join24.q,ptf_seqfile.q,union_remove_23.q,filter_join_breaktask.q,parallel_join0.q,join_thrift.q,vectorized_mapjoin.q,groupby8.q,union4.q,auto_join5.q,smb_mapjoin_20.q,groupby_multi_insert_common_distinct.q,join6.q,union_remove_16.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=227)\n\t[join36.q,union_remove_15.q,smb_mapjoin_10.q,bucket_map_join_tez1.q,temp_table.q,union_remove_13.q,auto_join8.q,auto_join6.q,auto_join0.q,vectorization_17.q,auto_join_stats2.q,skewjoin_union_remove_1.q,union16.q,auto_join32.q,union_remove_20.q]\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_acid_globallimit (batchId=45)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_acid_mapjoin (batchId=16)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_table (batchId=32)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_drop_database_removes_partition_dirs (batchId=98)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_drop_table_removes_partition_dirs (batchId=132)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization (batchId=81)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization_acid (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explain_dependency (batchId=64)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explain_dependency2 (batchId=109)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby10 (batchId=95)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby11 (batchId=111)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8 (batchId=114)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ivyDownload (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join0 (batchId=90)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_json_serde1 (batchId=53)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_11 (batchId=28)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_12 (batchId=76)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_13 (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_2 (batchId=18)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_4 (batchId=23)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_5 (batchId=58)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_6 (batchId=49)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_8 (batchId=111)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_9 (batchId=128)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_outer_join_ppr (batchId=30)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parallel_join0 (batchId=114)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_plan_json (batchId=101)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_selectDistinctStar (batchId=116)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_semijoin5 (batchId=24)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_str_to_map (batchId=97)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_multiinsert (batchId=128)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_notin_having (batchId=76)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_temp_table_gb1 (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_collect_set_2 (batchId=103)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_sort_array (batchId=99)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_fast_stats (batchId=78)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_cast_constant (batchId=13)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_string_decimal (batchId=4)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_udf1 (batchId=89)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_windowing (batchId=82)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_drop_partition (batchId=438)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join1 (batchId=453)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join4 (batchId=453)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join5 (batchId=453)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning (batchId=176)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_1 (batchId=177)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_2 (batchId=186)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_groupby2 (batchId=181)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_join0 (batchId=184)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_selectDistinctStar (batchId=187)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_stats_only_null (batchId=175)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_smb_empty (batchId=177)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_union_fast_stats (batchId=182)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant (batchId=170)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_dynamic_partition_pruning (batchId=176)\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_groupby2 (batchId=144)\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_index_bitmap_auto (batchId=139)\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx_cbo_2 (batchId=148)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import (batchId=154)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_invalid_values (batchId=154)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_right_side_join (batchId=154)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_dynamic_rdd_cache (batchId=214)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby1 (batchId=199)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_complex_types_multi_single_reducer (batchId=228)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_list_bucket_dml_2 (batchId=196)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats9 (batchId=203)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_only_null (batchId=204)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_multiinsert (batchId=226)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_cast_constant (batchId=196)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_13 (batchId=212)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_short_regress (batchId=212)\norg.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=381)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testSplitGenFailure (batchId=595)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testLocksInSubquery (batchId=728)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=270)\norg.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.testSparkQuery (batchId=416)\norg.apache.hive.jdbc.TestSSL.testSSLVersion (batchId=409)\norg.apache.hive.minikdc.TestHiveAuthFactory.testStartTokenManagerForDBTokenStore (batchId=450)\norg.apache.hive.minikdc.TestHiveAuthFactory.testStartTokenManagerForMemoryTokenStore (batchId=450)\norg.apache.hive.minikdc.TestMiniHiveKdc.testLogin (batchId=447)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/13622/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/13622/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-13622/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 95 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12938604 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16606612",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12938721/HIVE-16370.01-branch-1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 94 failed/errored test(s), 9121 tests executed\n*Failed tests:*\n{noformat}\nTestHs2HooksWithMiniKdc - did not produce a TEST-*.xml file (likely timed out) (batchId=452)\nTestJdbcWithMiniKdc - did not produce a TEST-*.xml file (likely timed out) (batchId=449)\nTestJdbcWithMiniKdcCookie - did not produce a TEST-*.xml file (likely timed out) (batchId=448)\nTestJdbcWithMiniKdcSQLAuthBinary - did not produce a TEST-*.xml file (likely timed out) (batchId=446)\nTestJdbcWithMiniKdcSQLAuthHttp - did not produce a TEST-*.xml file (likely timed out) (batchId=451)\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=202)\n\t[multi_insert_mixed.q,smb_mapjoin_4.q,timestamp_comparison.q,join_cond_pushdown_3.q,insert1.q,union_remove_10.q,mapreduce2.q,bucketmapjoin_negative.q,udf_in_file.q,skewjoinopt5.q,auto_join12.q,skewjoin.q,vector_count_distinct.q,smb_mapjoin_3.q,stats10.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=205)\n\t[auto_join30.q,union_remove_1.q,ppd_outer_join2.q,date_udf.q,join16.q,smb_mapjoin_13.q,bucketmapjoin7.q,smb_mapjoin_18.q,join19.q,metadata_only_queries.q,union6.q,cbo_subq_in.q,vectorization_part.q,groupby3_map_multi_distinct.q,vectorized_timestamp_funcs.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=206)\n\t[bucketmapjoin12.q,auto_join10.q,ptf_rcfile.q,join20.q,vector_elt.q,multi_insert.q,groupby_rollup1.q,ppd_join5.q,join_filters_overlap.q,vector_string_concat.q,join_empty.q,smb_mapjoin_6.q,auto_sortmerge_join_12.q,groupby_bigdata.q,innerjoin.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=207)\n\t[tez_joins_explain.q,input17.q,ppd_gby_join.q,vectorized_rcfile_columnar.q,ppd_join.q,join_cond_pushdown_1.q,union_remove_6_subq.q,timestamp_3.q,load_dyn_part6.q,load_dyn_part9.q,multi_insert_gby2.q,vectorization_11.q,avro_compression_enabled_native.q,stats_noscan_2.q,transform1.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=211)\n\t[escape_distributeby1.q,join9.q,groupby2.q,vectorization_pushdown.q,union_date.q,join_cond_pushdown_unqual3.q,join8.q,sample10.q,ppd_outer_join3.q,cross_product_check_1.q,statsfs.q,auto_sortmerge_join_2.q,auto_join_stats.q,input_part2.q,groupby_multi_single_reducer3.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=215)\n\t[ppd_join4.q,load_dyn_part2.q,smb_mapjoin_7.q,vectorization_5.q,smb_mapjoin_2.q,ppd_join_filter.q,column_access_stats.q,stats0.q,vector_between_in.q,vectorized_string_funcs.q,vectorization_1.q,bucket_map_join_2.q,temp_table_join1.q,vectorized_case.q,stats_noscan_1.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=217)\n\t[stats12.q,groupby4.q,union_top_level.q,groupby10.q,subquery_in.q,mapjoin_filter_on_outerjoin.q,stats14.q,auto_sortmerge_join_4.q,limit_partition_metadataonly.q,load_dyn_part4.q,union3.q,smb_mapjoin_14.q,groupby3_noskew_multi_distinct.q,stats18.q,union_remove_21.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=221)\n\t[table_access_keys_stats.q,bucketmapjoin11.q,union_remove_9.q,mergejoins_mixed.q,join_nullsafe.q,stats8.q,auto_join28.q,skewjoinopt14.q,union17.q,vectorized_shufflejoin.q,groupby8_noskew.q,auto_sortmerge_join_10.q,groupby11.q,skewjoinopt11.q,load_dyn_part11.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=222)\n\t[script_pipe.q,auto_join24.q,ptf_seqfile.q,union_remove_23.q,filter_join_breaktask.q,parallel_join0.q,join_thrift.q,vectorized_mapjoin.q,groupby8.q,union4.q,auto_join5.q,smb_mapjoin_20.q,groupby_multi_insert_common_distinct.q,join6.q,union_remove_16.q]\nTestSparkCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=227)\n\t[join36.q,union_remove_15.q,smb_mapjoin_10.q,bucket_map_join_tez1.q,temp_table.q,union_remove_13.q,auto_join8.q,auto_join6.q,auto_join0.q,vectorization_17.q,auto_join_stats2.q,skewjoin_union_remove_1.q,union16.q,auto_join32.q,union_remove_20.q]\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_acid_globallimit (batchId=45)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_acid_mapjoin (batchId=16)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_annotate_stats_table (batchId=32)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_drop_database_removes_partition_dirs (batchId=98)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_drop_table_removes_partition_dirs (batchId=132)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization (batchId=81)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_dynpart_sort_optimization_acid (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explain_dependency (batchId=64)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_explain_dependency2 (batchId=109)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby10 (batchId=95)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby11 (batchId=111)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_groupby8 (batchId=114)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_ivyDownload (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_join0 (batchId=90)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_json_serde1 (batchId=53)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_11 (batchId=28)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_12 (batchId=76)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_13 (batchId=38)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_2 (batchId=18)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_4 (batchId=23)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_5 (batchId=58)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_6 (batchId=49)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_8 (batchId=111)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_list_bucket_dml_9 (batchId=128)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_outer_join_ppr (batchId=30)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_parallel_join0 (batchId=114)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_plan_json (batchId=101)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_selectDistinctStar (batchId=116)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_semijoin5 (batchId=24)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_str_to_map (batchId=97)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_multiinsert (batchId=128)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_subquery_notin_having (batchId=76)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_temp_table_gb1 (batchId=50)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udaf_collect_set_2 (batchId=103)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_udf_sort_array (batchId=99)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_union_fast_stats (batchId=78)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_cast_constant (batchId=13)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_string_decimal (batchId=4)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_vector_udf1 (batchId=89)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver_windowing (batchId=82)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver_encryption_drop_partition (batchId=438)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join1 (batchId=453)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join4 (batchId=453)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver_vector_outer_join5 (batchId=453)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_dynamic_partition_pruning (batchId=176)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_1 (batchId=177)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_explainuser_2 (batchId=186)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_groupby2 (batchId=181)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_join0 (batchId=184)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_selectDistinctStar (batchId=187)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_stats_only_null (batchId=175)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_tez_smb_empty (batchId=177)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_union_fast_stats (batchId=182)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vector_cast_constant (batchId=170)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver_vectorized_dynamic_partition_pruning (batchId=176)\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_groupby2 (batchId=144)\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_index_bitmap_auto (batchId=139)\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_ql_rewrite_gbtoidx_cbo_2 (batchId=148)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_authorization_uri_import (batchId=154)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_columnstats_partlvl_invalid_values (batchId=154)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testNegativeCliDriver_right_side_join (batchId=154)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_dynamic_rdd_cache (batchId=214)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby1 (batchId=199)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_groupby_complex_types_multi_single_reducer (batchId=228)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_list_bucket_dml_2 (batchId=196)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats9 (batchId=203)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_stats_only_null (batchId=204)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_subquery_multiinsert (batchId=226)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vector_cast_constant (batchId=196)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_13 (batchId=212)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver_vectorization_short_regress (batchId=212)\norg.apache.hadoop.hive.ql.TestMTQueries.testMTQueries1 (batchId=381)\norg.apache.hadoop.hive.ql.io.orc.TestInputOutputFormat.testSplitGenFailure (batchId=595)\norg.apache.hadoop.hive.ql.lockmgr.TestDbTxnManager2.testLocksInSubquery (batchId=728)\norg.apache.hive.hcatalog.api.TestHCatClient.testTableSchemaPropagation (batchId=270)\norg.apache.hive.jdbc.TestSSL.testSSLVersion (batchId=409)\norg.apache.hive.minikdc.TestHiveAuthFactory.testStartTokenManagerForDBTokenStore (batchId=450)\norg.apache.hive.minikdc.TestHiveAuthFactory.testStartTokenManagerForMemoryTokenStore (batchId=450)\norg.apache.hive.minikdc.TestMiniHiveKdc.testLogin (batchId=447)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/13633/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/13633/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-13633/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 94 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12938721 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16608009",
                "body": "| (/) *{color:green}+1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  9m 13s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 20s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 18s{color} | {color:green} master passed {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 44s{color} | {color:blue} serde in master has 195 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 16s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 14s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 13m 28s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-13662/dev-support/hive-personality.sh |\r\n| git revision | master / b1a917c |\r\n| Default Java | 1.8.0_111 |\r\n| findbugs | v3.0.0 |\r\n| modules | C: serde U: serde |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-13662/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hiveqa",
                "id": "16608022",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12938881/HIVE-16370.1.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 2 failed/errored test(s), 14930 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.ql.exec.spark.TestSparkSessionTimeout.testMultiSessionSparkSessionTimeout (batchId=245)\norg.apache.hadoop.hive.ql.exec.spark.TestSparkSessionTimeout.testMultiSparkSessionTimeout (batchId=245)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/13662/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/13662/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-13662/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 2 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12938881 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16608976",
                "body": "| (/) *{color:green}+1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 42s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 16s{color} | {color:green} master passed {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 40s{color} | {color:blue} serde in master has 195 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 17s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 14s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 12m 57s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-13693/dev-support/hive-personality.sh |\r\n| git revision | master / ff98a30 |\r\n| Default Java | 1.8.0_111 |\r\n| findbugs | v3.0.0 |\r\n| modules | C: serde U: serde |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-13693/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hiveqa",
                "id": "16609081",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12939029/HIVE-16370.2.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 14930 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hive.jdbc.miniHS2.TestHs2ConnectionMetricsBinary.testOpenConnectionMetrics (batchId=255)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/13693/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/13693/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-13693/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 1 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12939029 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16609711",
                "body": "| (/) *{color:green}+1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  1s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 20s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 18s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 17s{color} | {color:green} master passed {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 43s{color} | {color:blue} serde in master has 195 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 16s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 13s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 12m 39s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.36-1+deb8u1 (2016-09-03) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-13703/dev-support/hive-personality.sh |\r\n| git revision | master / afb61ae |\r\n| Default Java | 1.8.0_111 |\r\n| findbugs | v3.0.0 |\r\n| modules | C: serde U: serde |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-13703/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hiveqa",
                "id": "16609783",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12939124/HIVE-16370.2.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 14931 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.ql.TestTxnCommands.testMergeOnTezEdges (batchId=315)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/13703/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/13703/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-13703/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 1 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12939124 - PreCommit-HIVE-Build"
            }
        ],
        "comments_predictions": [
            [
                1925822,
                "HIVE-16370",
                "This is something that can be handled in Avro by unioning the null type with another type in the avro file.\n\n[http://apache-avro.679487.n3.nabble.com/Support-for-null-in-String-primitive-types-td4025659.html]\n\nObjectInspectorUtils.java might be updated to handle \"void\" primitive category as it does in other cases.",
                {
                    "property": {
                        "confidence": 0.004216236528009176,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009351772256195545,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01509527675807476,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "64074465e12046200a33af9c",
        "key": "BEAM-10959",
        "id": "13329070",
        "description": "Currently there is a race where a BundleProcessor doesn't exist until another thread picks up the task and inserts into the active set. This allows for split/progress calls to happen and error out with \"Unknown process bundle instruction X\".\r\n\r\nSince the control stream is ordered, we can guarantee that an uninitialized BundleProcessor exists that can respond to this really early split/progress calls.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.003453456098213792
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.04241795465350151
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006357268895953894
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d3edf4d395ee22186239",
        "key": "YARN-2757",
        "id": "12750941",
        "description": "pontential NPE in checkNodeLabelExpression of SchedulerUtils for nodeLabels.\nsince we check the nodeLabels null at \n{code}\n        if (!str.trim().isEmpty()\n            && (nodeLabels == null || !nodeLabels.contains(str.trim()))) {\n          return false;\n        }\n{code}\nWe should also check nodeLabels null at \n{code}\n      if (!nodeLabels.isEmpty()) {\n        return false;\n      }\n{code}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006105346605181694
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.015166840516030788
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005054530221968889
                }
            }
        },
        "comments": [
            {
                "author_name": "hadoopqa",
                "id": "14186207",
                "body": "{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12677472/YARN-2757.000.patch\n  against trunk revision 00b4e44.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-YARN-Build/5593//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-YARN-Build/5593//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "leftnoteasy",
                "id": "14187131",
                "body": "[~zxu], This method is invoked by RMNodeLabelsManager#getLabelsOnNode, and that method will never return null, so I changed priority of this issue to minor, please boost it if you don't agree. "
            },
            {
                "author_name": "zxu",
                "id": "14187672",
                "body": "Hi [~leftnoteasy],\n\nthanks to review the patch. I agree to change the priority to minor.\nI just want to make sure the code is consistent either both check the null pointer or both don't check the null pointer.\n\nzhihai"
            },
            {
                "author_name": "hadoopqa",
                "id": "14524982",
                "body": "\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12677472/YARN-2757.000.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / f1a152c |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/7635/console |\n\n\nThis message was automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "14525006",
                "body": "\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12677472/YARN-2757.000.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / f1a152c |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/7643/console |\n\n\nThis message was automatically generated."
            },
            {
                "author_name": "jianhe",
                "id": "14527560",
                "body": "This code has been changed a lot. Close as invalid."
            }
        ],
        "comments_predictions": [
            [
                162150,
                "YARN-2757",
                "Hi [~leftnoteasy],\n\nthanks to review the patch. I agree to change the priority to minor.\nI just want to make sure the code is consistent either both check the null pointer or both don't check the null pointer.\n\nzhihai",
                {
                    "property": {
                        "confidence": 0.004345590714365244,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010505888611078262,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011468039825558662,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d376f4d395ee22185784",
        "key": "YARN-5579",
        "id": "13001138",
        "description": "I found the following in Resourcemanager log when I tried to figure out why application got stuck in NEW_SAVING state.\r\n\r\n{code}\r\n2016-08-29 18:14:23,486 INFO  recovery.ZKRMStateStore (ZKRMStateStore.java:runWithRetries(1242)) - Maxed out ZK retries. Giving up!\r\n2016-08-29 18:14:23,486 ERROR recovery.RMStateStore (RMStateStore.java:transition(205)) - Error storing app: application_1470517915158_0001\r\norg.apache.zookeeper.KeeperException$AuthFailedException: KeeperErrorCode = AuthFailed\r\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:123)\r\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:935)\r\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:915)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$5.run(ZKRMStateStore.java:998)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$5.run(ZKRMStateStore.java:995)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1174)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1207)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doStoreMultiWithRetries(ZKRMStateStore.java:995)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doStoreMultiWithRetries(ZKRMStateStore.java:1009)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createWithRetries(ZKRMStateStore.java:1042)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.storeApplicationStateInternal(ZKRMStateStore.java:639)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:201)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$StoreAppTransition.transition(RMStateStore.java:183)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)\r\n        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore.handleStoreEvent(RMStateStore.java:955)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:1036)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler.handle(RMStateStore.java:1031)\r\n        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)\r\n        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)\r\n        at java.lang.Thread.run(Thread.java:745)\r\n2016-08-29 18:14:23,486 ERROR recovery.RMStateStore (RMStateStore.java:notifyStoreOperationFailedInternal(987)) - State store operation failed\r\norg.apache.zookeeper.KeeperException$AuthFailedException: KeeperErrorCode = AuthFailed\r\n        at org.apache.zookeeper.KeeperException.create(KeeperException.java:123)\r\n        at org.apache.zookeeper.ZooKeeper.multiInternal(ZooKeeper.java:935)\r\n        at org.apache.zookeeper.ZooKeeper.multi(ZooKeeper.java:915)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$5.run(ZKRMStateStore.java:998)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$5.run(ZKRMStateStore.java:995)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithCheck(ZKRMStateStore.java:1174)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore$ZKAction.runWithRetries(ZKRMStateStore.java:1207)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doStoreMultiWithRetries(ZKRMStateStore.java:995)\r\n        at org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.doStoreMultiWithRetries(ZKRMStateStore.java:1009)\r\n{code}\r\nResourcemanager should surface the above error prominently.\r\n\r\nLikely subsequent application submission would encounter the same error.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0074137053452432156
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.012821503914892673
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005005422979593277
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d61bfdf4d395ee22248338",
        "key": "CLIMATE-853",
        "id": "12997131",
        "description": "When we build the documentation we can observe that sphinx drops the function _convert_times_to_datetime() while building the documentation and this function does not appear in the documentation. \n\nThe reason for the failure according to me could be that sphinx does not load any function that starts with underscore in its automodule docstrings. I will send a patch for this.  \n",
        "predictions": {},
        "comments": [
            {
                "author_name": "githubbot",
                "id": "15424960",
                "body": "GitHub user Omkar20895 opened a pull request:\n\n    https://github.com/apache/climate/pull/395\n\n    CLIMATE-853 Fixing broken documentation in dap.py and making it PEP8 \u2026\n\n    \u2026compliant\n    \n    - This PR addresses issue CLIMATE-853.\n    - I have removed '_' in the function '_current_times_to_date', I have removed this because sphinx does not load any function that starts with underscore in its automodule docstrings, hopefully this should fix it. \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/Omkar20895/climate master\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/climate/pull/395.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #395\n    \n----\ncommit 83c19de75b0976e0b06a0a6c8b171ea4bb901ce9\nAuthor: Omkar20895 <omkarreddy2008@gmail.com>\nDate:   2016-08-17T17:20:22Z\n\n    CLIMATE-853 Fixing broken documentation in dap.py and making it PEP8 compliant\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "15424961",
                "body": "Github user OCWJenkins commented on the issue:\n\n    https://github.com/apache/climate/pull/395\n  \n     Merged build triggered. Test Failed.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15427827",
                "body": "Github user lewismc commented on the issue:\n\n    https://github.com/apache/climate/pull/395\n  \n    This PR is broken @Omkar20895 please fix. If this is part of GSoC (which it is) then please clean it up.\n    The fixes are simple.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15428226",
                "body": "Github user Omkar20895 commented on the issue:\n\n    https://github.com/apache/climate/pull/395\n  \n    @lewismc this PR was opened way before @jarifibrahim fixed the tests and hence travis-ci build failed then, I have asked @jarifibrahim to cross check it in his local machine, after his 'GO' I will merge this PR. Thanks.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15428244",
                "body": "Github user jarifibrahim commented on the issue:\n\n    https://github.com/apache/climate/pull/395\n  \n    The doc build works fine on my machine. Please rebase and then merge.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15428287",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/climate/pull/395\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e9f5f4d395ee221d42cd",
        "key": "NETBEANS-3777",
        "id": "13282655",
        "description": "Issue from users list: [https://lists.apache.org/thread.html/rfb7e6e37c5dc26d2de7ccab12be89c8825ed477a6d886252f136e211%40%3Cusers.netbeans.apache.org%3E]\r\n\r\nFor artefact:  org.springframework:spring-framework-bom no jar are present on maven central.\r\nonly pom and txt.\r\nFixing by using pom as type",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0419401116669178
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.018963366746902466
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006602241192013025
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5debaf4d395ee221b13ce",
        "key": "SMXCOMP-336",
        "id": "12490537",
        "description": "I have a sender bean and a receiver bean, both configured using <bean:endpoint ... bean=\"#...\".  The problem is that the PreDestroy method is being called after every MessageExchange is finished.\n\nAccording to the documentation:\n\nAttention: The Bean Endpoint schema allows to set a Bean or a Bean Name. The Bean will create a single instance of the POJO per endpoint whereas the Bean Name will create an instance per request (message exchange).\n\nI have in my xbean.xml:\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<beans xmlns:bean=\"http://servicemix.apache.org/bean/1.0\"\n       xmlns:example=\"http://servicemix.apache.org/example\">\n\n  <bean:endpoint service=\"example:sender\" endpoint=\"senderEndpoint\" bean=\"#sender\"/>\n  <bean:endpoint service=\"example:receiver\" endpoint=\"receiverEndpoint\" bean=\"#receiver\"/>\n\n  <bean id=\"sender\" class=\"example.Sender\">\n    <property name=\"target\" value=\"example:receiver\"/>\n  </bean>\n  \n  <bean id=\"receiver\" class=\"example.Receiver\">\n  </bean>\n\n</beans>\n\nThe receiver simply implements MessageExchangeListener.\n\nThe PostConstruct and PreDestroy only gets called once on the sender\nThe PostConstruct only gets called once on the receiver\nHowever, the PreDestroy gets called on the receiver for each request.\n\nI noticed in BeanEndpoint, there is the following method:\n\nprotected void checkEndOfRequest(Request request, Object corId) {\n        if (request.getExchange().getStatus() != ExchangeStatus.ACTIVE) {\n            ReflectionUtils.callLifecycleMethod(request.getBean(), PreDestroy.class);\n            //request.setBean(null);\n            //request.setExchange(null);\n            requests.remove(corId);\n        }\n    }\n\nIt doesn't look like this class pays any attention to whether the bean is supposed to be a single instance of an instance-per-request, which is probably the cause of the problem.\n\n\nIf you need me to attach an example, please let me know.\n",
        "predictions": {},
        "comments": [
            {
                "author_name": "gnodet",
                "id": "12961672",
                "body": "Do you think you could fix the issue and provide a patch for it ?"
            },
            {
                "author_name": "rbohn",
                "id": "12961694",
                "body": "I have attached the patch.  The patch was derived from the 3.2.1 tag."
            },
            {
                "author_name": "rbohn",
                "id": "12961591",
                "body": "Any word on when this patch will be incorporated into ServiceMix?"
            },
            {
                "author_name": "tpounds",
                "id": "12961798",
                "body": "We were experiencing the same issue until we applied the patch supplied by Ryan Bohn to our local build. Thanks!"
            },
            {
                "author_name": "gnodet",
                "id": "12961796",
                "body": "Sending        servicemix-bean/src/main/java/org/apache/servicemix/bean/BeanEndpoint.java\nTransmitting file data .\nCommitted revision 641067.\n\nSending        servicemix-bean/src/main/java/org/apache/servicemix/bean/BeanEndpoint.java\nTransmitting file data .\nCommitted revision 641068."
            }
        ],
        "comments_predictions": [
            [
                716228,
                "SMXCOMP-336",
                "Sending        servicemix-bean/src/main/java/org/apache/servicemix/bean/BeanEndpoint.java\nTransmitting file data .\nCommitted revision 641067.\n\nSending        servicemix-bean/src/main/java/org/apache/servicemix/bean/BeanEndpoint.java\nTransmitting file data .\nCommitted revision 641068.",
                {
                    "property": {
                        "confidence": 0.0028648816514760256,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.02044312097132206,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.025010960176587105,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d376f4d395ee22185115",
        "key": "YARN-7243",
        "id": "13104189",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.08090269565582275
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.03191276639699936
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.024771979078650475
                }
            }
        },
        "comments": [
            {
                "author_name": "Cyl",
                "id": "16176019",
                "body": "Add patch001."
            },
            {
                "author_name": "Cyl",
                "id": "16176102",
                "body": "In the below code:\n{code:title=FairSchedulerEventLog.java}\n      synchronized void log(String eventType, Object... params) {\n    try {\n      if (logDisabled)\n        return;\n      StringBuffer buffer = new StringBuffer();\n      buffer.append(eventType);\n      for (Object param: params) {\n        buffer.append(\"\\t\");\n        buffer.append(param);\n      }\n      String message = buffer.toString();\n      Logger logger = Logger.getLogger(getClass());\n      appender.append(new LoggingEvent(\"\", logger, Level.INFO, message, null));\n    } catch (Exception e) {\n      LOG.error(\"Failed to append to fair scheduler event log\", e);\n      logDisabled = true;\n    }\n  }\n{code}\nThe variable \"logger\"  in method LoggingEvent is an object of org.apache.log4j.Category. I don't know how to deal with it, so I just leave it unchanged.\n\nAlso, org.apache.log4j.LogManager is used in testRM.java and many other UT files. I leave them unchanged, too! "
            },
            {
                "author_name": "Cyl",
                "id": "16176107",
                "body": "Submit patch002 to remove the trailing whitespace in YARN-7247.001.patch:2002 "
            },
            {
                "author_name": "hadoopqa",
                "id": "16176149",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 59s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 54 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 33m 38s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 16s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  0s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 37s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  5s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m 28s{color} | {color:green} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager generated 0 new + 8 unchanged - 5 fixed = 8 total (was 13) {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 15s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager: The patch generated 13 new + 3602 unchanged - 27 fixed = 3615 total (was 3629) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 58s{color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 57s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 62m 37s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black}124m  8s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.yarn.server.resourcemanager.ahs.TestRMApplicationHistoryWriter |\n|   | hadoop.yarn.server.resourcemanager.scheduler.capacity.TestIncreaseAllocationExpirer |\n|   | hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerResizing |\n|   | hadoop.yarn.server.resourcemanager.monitor.TestSchedulingMonitor |\n|   | hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation |\n| Timed out junit tests | org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA |\n|   | org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestApplicationLifetimeMonitor |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | YARN-7243 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888449/YARN-7243.001.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 03fd86e723b9 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / c71d137 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/17586/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/17586/artifact/patchprocess/whitespace-eol.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/17586/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/17586/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/17586/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16176189",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 13s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 54 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 38s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 34s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 19s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 36s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 21s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 32s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 31s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 31s{color} | {color:green} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager generated 0 new + 8 unchanged - 5 fixed = 8 total (was 13) {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 51s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager: The patch generated 13 new + 3600 unchanged - 27 fixed = 3613 total (was 3627) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 31s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 46m 45s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 69m 11s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | YARN-7243 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888461/YARN-7243.002.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux bad02f3159ef 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / c71d137 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/17587/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/17587/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/17587/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/17587/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "Cyl",
                "id": "16178252",
                "body": "Submit patch003! Fix some checkstyles.\nI leave the \n{code}\nName 'LOG' must match pattern '^[a-z][a-zA-Z0-9]*$'.\n{code}\nunchanged..."
            },
            {
                "author_name": "hadoopqa",
                "id": "16178276",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |\n|| || || || {color:brown} Prechecks {color} ||\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 54 new or modified test files. {color} |\n|| || || || {color:brown} trunk Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 28s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 34s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 12s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} |\n|| || || || {color:brown} Patch Compile Tests {color} ||\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 39s{color} | {color:green} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager generated 0 new + 8 unchanged - 5 fixed = 8 total (was 13) {color} |\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 10s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager: The patch generated 9 new + 3592 unchanged - 26 fixed = 3601 total (was 3618) {color} |\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 18s{color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 22s{color} | {color:green} the patch passed {color} |\n|| || || || {color:brown} Other Tests {color} ||\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 45m 17s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 14s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 74m 15s{color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed junit tests | hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker |  Image:yetus/hadoop:71bbb86 |\n| JIRA Issue | YARN-7243 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12888746/YARN-7243.003.patch |\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |\n| uname | Linux 4d95ff36d7c4 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\n| git revision | trunk / 415e5a1 |\n| Default Java | 1.8.0_144 |\n| findbugs | v3.1.0-RC1 |\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/17612/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/17612/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/17612/testReport/ |\n| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager |\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/17612/console |\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "aajisaka",
                "id": "16190866",
                "body": "Thanks [~Cyl] for the work! The usages of LogManager in tests can be replaced as follows:\n{code}\n+    GenericTestUtils.setRootLogLevel(Level.DEBUG);\n-    org.apache.log4j.Logger rootLogger = LogManager.getRootLogger();\n-    rootLogger.setLevel(Level.DEBUG);\n{code}\nIn FairSchedulerEventLog.java, I'm okay with leave it unchanged because this class is strongly depends on Log4J1 implementation. We need to remove or update this when updating from Log4J1 to Log4J2."
            },
            {
                "author_name": "Cyl",
                "id": "16196739",
                "body": "Thanks [~ajisakaa] for the review! And thanks for the hint for dealing with logManager. Also, the solution can be found in HADOOP-14549, sorry for did not catching that!\r\nWill submit a patch soon!"
            },
            {
                "author_name": "Cyl",
                "id": "16196908",
                "body": "Submit patch004"
            },
            {
                "author_name": "Cyl",
                "id": "16196915",
                "body": "I move the below code:\r\n{code:title=TestCapacitySchedulerPerf.java}\r\n     for (Enumeration<?> loggers = LogManager.getCurrentLoggers();\r\n         loggers.hasMoreElements(); )  {\r\n      Logger logger = (Logger) loggers.nextElement();\r\n      logger.setLevel(Level.WARN);\r\n    }\r\n{code}\r\nto GenericTestUtils.java\r\n{code:title=GenericTestUtils.java}\r\n     public static void setCurrentLoggersLogLevel(org.slf4j.event.Level level) {\r\n    for (Enumeration<?> loggers = LogManager.getCurrentLoggers();\r\n         loggers.hasMoreElements(); )  {\r\n      Logger logger = (Logger) loggers.nextElement();\r\n      logger.setLevel(Level.toLevel(level.toString()));\r\n    }\r\n  }\r\n{code}\r\n\r\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16197178",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 63 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 46s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m  1s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 28s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 52s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 47s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 12s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 35s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 23s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m  4s{color} | {color:green} root generated 0 new + 1266 unchanged - 5 fixed = 1266 total (was 1271) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 58s{color} | {color:orange} root: The patch generated 11 new + 3747 unchanged - 29 fixed = 3758 total (was 3776) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 28s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 46s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 46m  1s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}167m 32s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.resourcemanager.ahs.TestRMApplicationHistoryWriter |\r\n|   | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler |\r\n|   | hadoop.yarn.server.resourcemanager.TestApplicationMasterService |\r\n|   | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSAppAttempt |\r\n|   | hadoop.yarn.server.resourcemanager.TestWorkPreservingRMRestart |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:71bbb86 |\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12891049/YARN-7243.004.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 119739ede143 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 6d6ca4c |\r\n| Default Java | 1.8.0_144 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/17823/artifact/patchprocess/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/17823/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/17823/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/17823/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "Cyl",
                "id": "16210725",
                "body": "Sumbit patch005, the UTs are passed locally on my computer."
            },
            {
                "author_name": "hadoopqa",
                "id": "16210730",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} docker {color} | {color:red}  0m 11s{color} | {color:red} Docker failed to build yetus/hadoop:0de40f0. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893007/YARN-7243.005.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/18024/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16212092",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  6s{color} | {color:red} YARN-7243 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893157/YARN-7243.005.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/18043/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "Cyl",
                "id": "16212190",
                "body": "Submit patch006!"
            },
            {
                "author_name": "hadoopqa",
                "id": "16212400",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 65 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m  4s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 30s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 56s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m  6s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 34s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 36s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 25s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 25s{color} | {color:green} root generated 0 new + 1251 unchanged - 5 fixed = 1251 total (was 1256) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  3m  6s{color} | {color:orange} root: The patch generated 12 new + 3751 unchanged - 29 fixed = 3763 total (was 3780) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  5s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 15s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 49s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m 21s{color} | {color:red} hadoop-common in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 45m 59s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}155m 54s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.net.TestDNS |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:ca8ddc6 |\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893180/YARN-7243.006.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 3352e1a1b639 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 4afd308 |\r\n| Default Java | 1.8.0_131 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/18048/artifact/patchprocess/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/18048/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/18048/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/18048/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16212657",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} docker {color} | {color:red}  8m 39s{color} | {color:red} Docker failed to build yetus/hadoop:ca8ddc6. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893180/YARN-7243.006.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/18051/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16212922",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 18m 38s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  1s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 65 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 36s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 52s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m  9s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 52s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 50s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m  9s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 31s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 31s{color} | {color:green} root generated 0 new + 1251 unchanged - 5 fixed = 1251 total (was 1256) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 57s{color} | {color:orange} root: The patch generated 12 new + 3750 unchanged - 29 fixed = 3762 total (was 3779) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 27s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 31s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 47s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 50m 17s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 39s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}174m 12s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSLeafQueue |\r\n|   | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler |\r\n| Timed out junit tests | org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker |  Image:yetus/hadoop:ca8ddc6 |\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893180/YARN-7243.006.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux c2649948c163 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 1f4cdf1 |\r\n| Default Java | 1.8.0_131 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/18054/artifact/patchprocess/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/18054/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/18054/testReport/ |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/18054/console |\r\n| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "giovanni.fumarola",
                "id": "16505303",
                "body": "Any update on this one?"
            },
            {
                "author_name": "genericqa",
                "id": "16505320",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  8s{color} | {color:red} YARN-7243 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893180/YARN-7243.006.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/20982/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "prabhujoseph",
                "id": "16780866",
                "body": "[~Cyl] If you are okay, i will work on this."
            },
            {
                "author_name": "hadoopqa",
                "id": "16780871",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  9s{color} | {color:red} YARN-7243 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893180/YARN-7243.006.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/23595/console |\r\n| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16782406",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 24s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 76 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m  5s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 50s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 21m 48s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  4m 56s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 23s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m 51s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 37s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 27s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 54s{color} | {color:green} root generated 0 new + 1487 unchanged - 5 fixed = 1487 total (was 1492) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  4m 18s{color} | {color:orange} root: The patch generated 19 new + 3982 unchanged - 33 fixed = 4001 total (was 4015) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  8s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 13s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 29s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 34s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 33s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 81m 36s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 41s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}200m 15s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.resourcemanager.metrics.TestSystemMetricsPublisherForV2 |\r\n|   | hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12960869/YARN-7243-007.patch |\r\n| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux 61ad4476f8a7 4.4.0-138-generic #164~14.04.1-Ubuntu SMP Fri Oct 5 08:56:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / bc6fe7a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_191 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/23609/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/23609/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/23609/testReport/ |\r\n| Max. process+thread count | 1351 (vs. ulimit of 10000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/23609/console |\r\n| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "prabhujoseph",
                "id": "16782456",
                "body": "[~Cyl] Assigning to me."
            },
            {
                "author_name": "hadoopqa",
                "id": "16782523",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 29s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 76 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 25s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m  4s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 12s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  4m 28s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 50s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 36s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 21s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 32s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m 23s{color} | {color:green} root generated 0 new + 1487 unchanged - 5 fixed = 1487 total (was 1492) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  4m 18s{color} | {color:orange} root: The patch generated 2 new + 3915 unchanged - 100 fixed = 3917 total (was 4015) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 10s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 26s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 38s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 50s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 90m 28s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 43s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}203m 39s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.resourcemanager.metrics.TestSystemMetricsPublisherForV2 |\r\n|   | hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12960886/YARN-7243-008.patch |\r\n| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux db56f4209413 4.4.0-138-generic #164~14.04.1-Ubuntu SMP Fri Oct 5 08:56:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / fe6b2b2 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_191 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/23611/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/23611/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/23611/testReport/ |\r\n| Max. process+thread count | 1391 (vs. ulimit of 10000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/23611/console |\r\n| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "prabhujoseph",
                "id": "16782608",
                "body": "[~ajisakaa] [~cheersyang] Can you review the latest patch for moving logging api's to slf4j in yarn-server-resourcemanager. Failures testcases are not related and handled as part of YARN-9338."
            },
            {
                "author_name": "aajisaka",
                "id": "16783112",
                "body": "Thanks [~prabhujoseph] for rebasing. Two comments:\r\n\r\nIn ResourceTrackerService.java, {{LOG.error(errorMessage.toString(), ex.toString());}} should be {{LOG.error(errorMessage.toString(), ex);}}.\r\n\r\nIn PreemptableResourceCalculator.java,\r\n{code}\r\nif (LOG.isDebugEnabled()) {\r\n  LOG.debug(qT.toString());\r\n}\r\n{code}\r\ncan be simplified to {{LOG.debug(\"{}\", qT);}}. There is a similar code in NodeAttributesManagerImpl.java L205, it can be fixed as well."
            },
            {
                "author_name": "hadoopqa",
                "id": "16783347",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 30s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 76 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m  4s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 55s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 16s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  4m 20s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 11s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 33s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 10s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 38s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 30s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 34s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 34s{color} | {color:green} root generated 0 new + 1483 unchanged - 5 fixed = 1483 total (was 1488) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  4m 14s{color} | {color:orange} root: The patch generated 2 new + 3915 unchanged - 100 fixed = 3917 total (was 4015) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m  6s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 30s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 29s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 42s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 42s{color} | {color:green} hadoop-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 83m 36s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 58s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}196m  9s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.resourcemanager.metrics.TestSystemMetricsPublisherForV2 |\r\n|   | hadoop.yarn.server.resourcemanager.metrics.TestCombinedSystemMetricsPublisher |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12960965/YARN-7243-009.patch |\r\n| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |\r\n| uname | Linux e0ab300d1c09 4.4.0-138-generic #164~14.04.1-Ubuntu SMP Fri Oct 5 08:56:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / bd8d299 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_191 |\r\n| findbugs | v3.1.0-RC1 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/23618/artifact/out/diff-checkstyle-root.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/23618/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/23618/testReport/ |\r\n| Max. process+thread count | 1391 (vs. ulimit of 10000) |\r\n| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/23618/console |\r\n| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "aajisaka",
                "id": "16784083",
                "body": "+1 for 009 patch. Thanks [~prabhujoseph] for the update."
            },
            {
                "author_name": "aajisaka",
                "id": "16784094",
                "body": "Committed this to trunk. Thanks [~prabhujoseph] and [~Cyl]!"
            },
            {
                "author_name": "hudson",
                "id": "16784104",
                "body": "SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #16123 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/16123/])\nYARN-7243. Moving logging APIs over to slf4j in (aajisaka: rev e40e2d6ad5cbe782c3a067229270738b501ed27e)\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/nodelabels/FileSystemNodeAttributeStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/FifoIntraQueuePreemptionPlugin.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/applicationsmanager/TestAMLaunchFailure.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/allocator/AbstractContainerAllocator.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/Task.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestApplicationLimits.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/RMWebAppUtil.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/IntraQueueCandidatesSelector.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestLeafQueue.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestApplicationACLs.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerNode.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/AMSProcessingChain.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/volume/csi/lifecycle/VolumeImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/policy/AbstractComparatorOrderingPolicy.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/YarnConfigurationStoreFactory.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/CuratorBasedElectorService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAppManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestQueueCapacities.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/placement/UserGroupMappingPlacementRule.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerPerf.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/resource/DynamicResourceConfiguration.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestApplicationMasterLauncher.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ActiveStandbyElectorBasedElectorService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/TestResourceUsage.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAutoQueueCreation.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/security/TestDelegationTokenRenewer.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicyMockFramework.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/applicationsmanager/TestASMStateMachine.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/activities/ActivitiesManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/LeafQueue.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestClientRMTokens.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/placement/LocalityAppPlacementAllocator.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterServiceTestBase.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ReservedContainerCandidatesSelector.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMHAForNodeLabels.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/VisitedResourceRequestTracker.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/AdminService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/TestReservationInputValidator.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSPreemptionThread.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestWorkPreservingUnmanagedAM.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/activities/ActivitiesLogger.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestApplicationMasterServiceWithFS.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSSchedulerNode.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestUtils.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/RMWebApp.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/TestRMAppAttemptTransitions.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/TestRMAppTransitions.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/PlacementConstraintManagerService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmcontainer/RMContainerImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AbstractCSQueue.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestAMAuthorization.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerAppUtils.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/TestZKRMStateStoreZKClientConnections.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerAutoCreatedQueueBase.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestSchedulingPolicy.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/ZKRMStateStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/TestZKConfigurationStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/NodeManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/ZKConfigurationStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/FairSharePolicy.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesSchedulerActivities.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ApplicationMasterService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacitySchedulerQueueManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/ParentQueue.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/QueueManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMContextImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMActiveServiceContext.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacityScheduler.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesNodeLabels.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestQueueParsing.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/placement/SingleConstraintAppPlacementAllocator.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/MutableCSConfigurationProvider.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/RMContainerTokenSecretManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/OpportunisticContainerAllocatorAMService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/placement/AppNameMappingPlacementRule.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/resource/ResourceProfilesManagerImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/resourcetracker/TestNMExpiry.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/MockRM.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/FifoCandidatesSelector.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/QueuePlacementRule.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/amlauncher/ApplicationMasterLauncher.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/security/TestRMDelegationTokens.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/NMTokenSecretManagerInRM.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/MockAM.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/amlauncher/AMLauncher.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/policies/FifoPolicy.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/placement/PlacementManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/TestApplicationLifetimeMonitor.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/dao/NodeAllocationInfo.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/nodelabels/NodeLabelsUtils.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMRestart.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptMetrics.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/ClusterNodeTracker.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestApplicationMasterServiceInterceptor.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/TestZKRMStateStorePerf.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/blacklist/SimpleBlacklistManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/nodelabels/NodeAttributesManagerImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/TestFSRMStateStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/AppPriorityACLsManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ClientRMService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMAuditLogger.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestSignalContainer.java\n* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/GenericTestUtils.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/UsersManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ResourceTrackerService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/AppPriorityACLConfigurationParser.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/ProportionalCapacityPreemptionPolicy.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/records/impl/pb/ApplicationAttemptStateDataPBImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestAppManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/common/fica/FiCaSchedulerApp.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/Application.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/activities/NodeAllocation.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/nodelabels/RMDelegatedNodeLabelsUpdater.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMServerUtils.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacitySchedulerConfiguration.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/dao/AppAllocationInfo.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSParentQueue.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRM.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestKillApplicationWithRMHA.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/allocator/RegularContainerAllocator.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/AMRMTokenSecretManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/metrics/TimelineServiceV1Publisher.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/FileSystemRMStateStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestResourceManagerMXBean.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AppSchedulingInfo.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/security/TestAMRMTokens.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/RMStateStoreFactory.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestClientRMService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/TestLeveldbConfigurationStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerMultiNodes.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestLeaderElectorService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/DelegationTokenRenewer.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerUtils.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/LeveldbRMStateStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/PreemptableResourceCalculator.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/RMStateStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/SchedulingMonitor.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/metrics/TimelineServiceV2Publisher.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestContainerResourceUsage.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMHA.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/RMDelegationTokenSecretManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/MaxRunningAppsEnforcer.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/NavBlock.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/dao/ActivitiesInfo.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestReservations.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/RMStateStoreTestBase.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/TestZKRMStateStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestRMEmbeddedElector.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/TestNodesListManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestSubmitApplicationWithRMHA.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMNMInfo.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/reservation/planning/SimpleCapacityReplanner.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/DefaultAMSProcessor.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fifo/TestFifoScheduler.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/AllocationFileLoaderService.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNodeImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/FSSchedulerConfigurationStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/distributed/NodeQueueLoadMonitor.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/DeSelectFields.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSLeafQueue.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestParentQueue.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestResourceManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/TestFairSchedulerConfiguration.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/RMAppLogAggregationStatusBlock.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestQueueMappings.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/timelineservice/RMTimelineCollectorManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/ConfigurationMutationACLPolicyFactory.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/ACLsTestBase.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestCapacitySchedulerDynamicBehavior.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/ahs/RMApplicationHistoryWriter.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/volume/csi/VolumeManagerImpl.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/ActiveUsersManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestContainerResizing.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/RMCriticalThreadUncaughtExceptionHandler.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/placement/PlacementFactory.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/placement/MultiNodeSortingManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/QueueStateManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/TestSchedulerUtils.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/TestPlacementProcessor.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/capacity/QueuePriorityContainerCandidateSelector.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/common/fica/FiCaSchedulerNode.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairSchedulerConfiguration.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/activities/AllocationActivity.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/QueueACLsManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestWorkPreservingRMRestart.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/policy/CompoundComparator.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/DecommissioningNodesWatcher.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/applicationsmanager/TestApplicationMasterExpiry.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestChildQueueOrder.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fifo/FifoAppAttempt.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/TestApplicationCleanup.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/dao/AppActivitiesInfo.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/monitor/SchedulingMonitorManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/PlacementConstraintsUtil.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fifo/FifoScheduler.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/rmapp/monitor/RMAppLifetimeMonitor.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/YarnConfigurationStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSAppAttempt.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FSQueue.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/recovery/RMStateStoreUtils.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/conf/LeveldbConfigurationStore.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/placement/MultiNodeSorter.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerApplicationAttempt.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/NodesListManager.java\n* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/TestContainerAllocation.java\n"
            },
            {
                "author_name": "prabhujoseph",
                "id": "16784106",
                "body": "Thanks [~ajisakaa]!"
            },
            {
                "author_name": "aajisaka",
                "id": "16948144",
                "body": "Created https://github.com/apache/hadoop/pull/1634 to backport this to branch-3.2."
            },
            {
                "author_name": "aajisaka",
                "id": "16948248",
                "body": "Backported to branch-3.2."
            }
        ],
        "comments_predictions": [
            [
                99196,
                "YARN-7243",
                "In the below code:\n{code:title=FairSchedulerEventLog.java}\n      synchronized void log(String eventType, Object... params) {\n    try {\n      if (logDisabled)\n        return;\n      StringBuffer buffer = new StringBuffer();\n      buffer.append(eventType);\n      for (Object param: params) {\n        buffer.append(\"\\t\");\n        buffer.append(param);\n      }\n      String message = buffer.toString();\n      Logger logger = Logger.getLogger(getClass());\n      appender.append(new LoggingEvent(\"\", logger, Level.INFO, message, null));\n    } catch (Exception e) {\n      LOG.error(\"Failed to append to fair scheduler event log\", e);\n      logDisabled = true;\n    }\n  }\n{code}\nThe variable \"logger\"  in method LoggingEvent is an object of org.apache.log4j.Category. I don't know how to deal with it, so I just leave it unchanged.\n\nAlso, org.apache.log4j.LogManager is used in testRM.java and many other UT files. I leave them unchanged, too! ",
                {
                    "property": {
                        "confidence": 0.005349732469767332,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006441778969019651,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012878681533038616,
                        "prediction": false
                    }
                }
            ],
            [
                99202,
                "YARN-7243",
                "Thanks [~Cyl] for the work! The usages of LogManager in tests can be replaced as follows:\n{code}\n+    GenericTestUtils.setRootLogLevel(Level.DEBUG);\n-    org.apache.log4j.Logger rootLogger = LogManager.getRootLogger();\n-    rootLogger.setLevel(Level.DEBUG);\n{code}\nIn FairSchedulerEventLog.java, I'm okay with leave it unchanged because this class is strongly depends on Log4J1 implementation. We need to remove or update this when updating from Log4J1 to Log4J2.",
                {
                    "property": {
                        "confidence": 0.004552197176963091,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009792023338377476,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010459679178893566,
                        "prediction": false
                    }
                }
            ],
            [
                99205,
                "YARN-7243",
                "I move the below code:\r\n{code:title=TestCapacitySchedulerPerf.java}\r\n     for (Enumeration<?> loggers = LogManager.getCurrentLoggers();\r\n         loggers.hasMoreElements(); )  {\r\n      Logger logger = (Logger) loggers.nextElement();\r\n      logger.setLevel(Level.WARN);\r\n    }\r\n{code}\r\nto GenericTestUtils.java\r\n{code:title=GenericTestUtils.java}\r\n     public static void setCurrentLoggersLogLevel(org.slf4j.event.Level level) {\r\n    for (Enumeration<?> loggers = LogManager.getCurrentLoggers();\r\n         loggers.hasMoreElements(); )  {\r\n      Logger logger = (Logger) loggers.nextElement();\r\n      logger.setLevel(Level.toLevel(level.toString()));\r\n    }\r\n  }\r\n{code}\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.005897573195397854,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005714659579098225,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016476163640618324,
                        "prediction": false
                    }
                }
            ],
            [
                99215,
                "YARN-7243",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  8s{color} | {color:red} YARN-7243 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | YARN-7243 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893180/YARN-7243.006.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/20982/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004887979477643967,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006575926672667265,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02545979991555214,
                        "prediction": false
                    }
                }
            ],
            [
                99222,
                "YARN-7243",
                "Thanks [~prabhujoseph] for rebasing. Two comments:\r\n\r\nIn ResourceTrackerService.java, {{LOG.error(errorMessage.toString(), ex.toString());}} should be {{LOG.error(errorMessage.toString(), ex);}}.\r\n\r\nIn PreemptableResourceCalculator.java,\r\n{code}\r\nif (LOG.isDebugEnabled()) {\r\n  LOG.debug(qT.toString());\r\n}\r\n{code}\r\ncan be simplified to {{LOG.debug(\"{}\", qT);}}. There is a similar code in NodeAttributesManagerImpl.java L205, it can be fixed as well.",
                {
                    "property": {
                        "confidence": 0.00521569000557065,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008556094020605087,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010323655791580677,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d60f9ff4d395ee2222a1c2",
        "key": "FLINK-11564",
        "id": "13214669",
        "description": "\r\nTranslate \"How To Contribute\" page into Chinese.\r\n\r\nThe markdown file is located in: flink-web/how-to-contribute.zh.md\r\nThe url link is: https://flink.apache.org/zh/how-to-contribute.html\r\n\r\nPlease adjust the links in the page to Chinese pages when translating. \r\n\r\n\r\n\r\n\r\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.06367506831884384
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.011852484196424484
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.003003902966156602
                }
            }
        },
        "comments": [
            {
                "author_name": "jark",
                "id": "16772773",
                "body": "Fixed in flink-web:\u00a0bf1374cf5cf7ebe6c5bebc5b79d4208a74e0b409"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f286f4d395ee221e7d62",
        "key": "LOG4J2-360",
        "id": "12664181",
        "description": "AppenderRef and ErrorRef should also be allowed as appender-ref and error-ref since many users are used to that since that is what Log4j 1 and Logback do.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014844844117760658
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.010441863909363747
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.003825008636340499
                }
            }
        },
        "comments": [
            {
                "author_name": "rgoers",
                "id": "13742963",
                "body": "Patch to add PluginAliases annotation."
            },
            {
                "author_name": "ggregory",
                "id": "13747502",
                "body": "Ralph, can this issue be resolved now?"
            },
            {
                "author_name": "rgoers",
                "id": "13747632",
                "body": "Fixed in revision 1515465."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d618eff4d395ee2224180c",
        "key": "DAFFODIL-405",
        "id": "13113823",
        "description": null,
        "predictions": {},
        "comments": [
            {
                "author_name": "mbeckerle",
                "id": "16229370",
                "body": "Memo summarizing features needed was sent."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d602f3f4d395ee22210b5d",
        "key": "HDDS-1389",
        "id": "13226205",
        "description": "This test failure is caused by HDDS-1207, as we use the same ChillModeHandler thread for waitTime sleep. Because of that, this is causing a test failure.\r\n\r\n\u00a0\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.013036094605922699
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006026297342032194
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006079694721847773
                }
            }
        },
        "comments": [
            {
                "author_name": "bharat",
                "id": "16811084",
                "body": "I have committed this to the trunk."
            },
            {
                "author_name": "hudson",
                "id": "16811271",
                "body": "FAILURE: Integrated in Jenkins build Hadoop-trunk-Commit #16355 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/16355/])\nHDDS-1389. Fix testSCMChillModeRestrictedOp. (#696) (bharat: rev 5750bb94edc98436723975e2f84c38f513e59bef)\n* (edit) hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/chillmode/ChillModeHandler.java\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d60432f4d395ee22211418",
        "key": "HBASE-26442",
        "id": "13411135",
        "description": "{noformat}\r\n[INFO] --- maven-surefire-plugin:2.22.2:test (default-test) @ hbase-server ---\r\n[INFO] \r\n[INFO] -------------------------------------------------------\r\n[INFO]  T E S T S\r\n[INFO] -------------------------------------------------------\r\n[INFO] Running org.apache.hadoop.hbase.replication.TestReplicationEndpoint\r\n[ERROR] Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 20.978 s <<< FAILURE! - in org.apache.hadoop.hbase.replication.TestReplicationEndpoint\r\n[ERROR] org.apache.hadoop.hbase.replication.TestReplicationEndpoint  Time elapsed: 3.921 s  <<< FAILURE!\r\njava.lang.AssertionError\r\n\tat org.junit.Assert.fail(Assert.java:86)\r\n\tat org.junit.Assert.assertTrue(Assert.java:41)\r\n\tat org.junit.Assert.assertTrue(Assert.java:52)\r\n\tat org.apache.hadoop.hbase.replication.TestReplicationEndpoint.tearDownAfterClass(TestReplicationEndpoint.java:88)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\r\n\tat org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)\r\n\tat org.junit.runners.ParentRunner.run(ParentRunner.java:363)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)\r\n\tat org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)\r\n\tat org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)\r\n\r\n[INFO] \r\n[INFO] Results:\r\n[INFO] \r\n[ERROR] Failures: \r\n[ERROR]   TestReplicationEndpoint.tearDownAfterClass:88\r\n[INFO] \r\n[ERROR] Tests run: 2, Failures: 1, Errors: 0, Skipped: 0\r\n{noformat}\r\n\r\nIt fails if testInterClusterReplication is run alone but succeeds (depending on the order of test it ran) as a test suite.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.01574763096868992
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006287101190537214
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00600050063803792
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d376f4d395ee221852a1",
        "key": "YARN-6843",
        "id": "13088460",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006246007978916168
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008446377702057362
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.016787497326731682
                }
            }
        },
        "comments": [
            {
                "author_name": "haibochen",
                "id": "16129677",
                "body": "Unit tests will be added as part of YARN-6672"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "6407469bcc191512f881ddc9",
        "key": "SPARK-41335",
        "id": "13507397",
        "description": null,
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d61297f4d395ee2223102d",
        "key": "FLEX-18666",
        "id": "12579540",
        "description": null,
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13351549",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-20483\nOriginal Reporter: doug_eui\nOriginal Resolution: Fixed\nNumber of votes: 0\nResolved by: jszeto\nreporter: doug_eui"
            },
            {
                "author_name": "adobejira",
                "id": "13351550",
                "body": "created: 2009-04-04 09:23:04.000\nresolved: 2009-07-27 17:32:45.315\nupdated: 2009-07-27 17:32:45.000"
            },
            {
                "author_name": "adobejira",
                "id": "13351551",
                "body": "On 2009-04-28 23:50:38.764 laupark commented:\nFor review\nOn 2009-07-27 17:32:45.312 jszeto commented:\nPatch submitted in revision 8844"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "64074665dc5b3e8de781d8ba",
        "key": "HOP-4044",
        "id": "13470343",
        "description": "Happens with CONCATENATE and ISBLANK, maybe more ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008433066308498383
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.015400370582938194
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004455770365893841
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d60433f4d395ee2221356c",
        "key": "HBASE-17731",
        "id": "13048229",
        "description": "When average latency is less than one millisecond the LoadTestTool tool reports a latency of 0. Better to report a fraction out to a couple of decimal points. \n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.038902461528778076
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.00394166074693203
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.018795328214764595
                }
            }
        },
        "comments": [
            {
                "author_name": "apurtell",
                "id": "15895341",
                "body": "Trivial patch"
            },
            {
                "author_name": "hadoopqa",
                "id": "15895473",
                "body": "| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 15s {color} | {color:blue} Docker mode activated. {color} |\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green} 0m 0s {color} | {color:green} Patch does not have any anti-patterns. {color} |\n| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 47s {color} | {color:green} master passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 34s {color} | {color:green} master passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 40s {color} | {color:green} master passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} master passed {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 38s {color} | {color:green} master passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 25s {color} | {color:green} master passed {color} |\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 34s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 34s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 40s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 24m 38s {color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 or 3.0.0-alpha2. {color} |\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 41s {color} | {color:green} the patch passed {color} |\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 24s {color} | {color:green} the patch passed {color} |\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 94m 19s {color} | {color:red} hbase-server in the patch failed. {color} |\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 16s {color} | {color:green} The patch does not generate ASF License warnings. {color} |\n| {color:black}{color} | {color:black} {color} | {color:black} 130m 15s {color} | {color:black} {color} |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Timed out junit tests | org.apache.hadoop.hbase.regionserver.compactions.TestFIFOCompactionPolicy |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Docker | Client=1.12.3 Server=1.12.3 Image:yetus/hbase:8d52d23 |\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12856017/HBASE-17731.patch |\n| JIRA Issue | HBASE-17731 |\n| Optional Tests |  asflicense  javac  javadoc  unit  findbugs  hadoopcheck  hbaseanti  checkstyle  compile  |\n| uname | Linux 4e34fbe52cae 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\n| Build tool | maven |\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh |\n| git revision | master / 404a288 |\n| Default Java | 1.8.0_121 |\n| findbugs | v3.0.0 |\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/5946/artifact/patchprocess/patch-unit-hbase-server.txt |\n| unit test logs |  https://builds.apache.org/job/PreCommit-HBASE-Build/5946/artifact/patchprocess/patch-unit-hbase-server.txt |\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/5946/testReport/ |\n| modules | C: hbase-server U: hbase-server |\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/5946/console |\n| Powered by | Apache Yetus 0.3.0   http://yetus.apache.org |\n\n\nThis message was automatically generated.\n\n"
            },
            {
                "author_name": "apurtell",
                "id": "15895943",
                "body": "Unless objection, going to commit trivial patch on Monday\n"
            },
            {
                "author_name": "anoop.hbase",
                "id": "15902434",
                "body": "+1."
            },
            {
                "author_name": "apurtell",
                "id": "15904180",
                "body": "Thanks Anoop. Committed"
            },
            {
                "author_name": "hudson",
                "id": "15904426",
                "body": "SUCCESS: Integrated in Jenkins build HBase-Trunk_matrix #2644 (See [https://builds.apache.org/job/HBase-Trunk_matrix/2644/])\nHBASE-17731 Fractional latency reporting in MultiThreadedAction (apurtell: rev 7da0feea8dd4236b520bf48b2a84c52bf2910e56)\n* (edit) hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedAction.java\n"
            },
            {
                "author_name": "hudson",
                "id": "16720750",
                "body": "SUCCESS: Integrated in Jenkins build HBase-1.3-IT #509 (See [https://builds.apache.org/job/HBase-1.3-IT/509/])\nHBASE-17731 Fractional latency reporting in MultiThreadedAction (apurtell: rev 286ade8155e5c198feef83bbd5fcc4f00a3d7796)\n* (edit) hbase-server/src/test/java/org/apache/hadoop/hbase/util/MultiThreadedAction.java\n"
            },
            {
                "author_name": "hudson",
                "id": "16721137",
                "body": "Results for branch branch-1.3\n\t[build #576 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/branch-1.3/576/]: (x) *{color:red}-1 overall{color}*\n----\ndetails (if available):\n\n(/) {color:green}+1 general checks{color}\n-- For more information [see general report|https://builds.apache.org/job/HBase%20Nightly/job/branch-1.3/576//General_Nightly_Build_Report/]\n\n\n(/) {color:green}+1 jdk7 checks{color}\n-- For more information [see jdk7 report|https://builds.apache.org/job/HBase%20Nightly/job/branch-1.3/576//JDK7_Nightly_Build_Report/]\n\n\n(x) {color:red}-1 jdk8 hadoop2 checks{color}\n-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-1.3/576//JDK8_Nightly_Build_Report_(Hadoop2)/]\n\n\n\n\n(/) {color:green}+1 source release artifact{color}\n-- See build output for details.\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640743e0b840a77c40d2b437",
        "key": "ARROW-3846",
        "id": "13199734",
        "description": "I started briefly looking at this. As an initial matter, our FindLLVM.cmake is inadequate. There's one (BSD-licensed) we can pull in from the LLVM-based D compiler: https://github.com/ldc-developers/ldc/blob/master/cmake/Modules/FindLLVM.cmake. If someone can point out another one, I can take a look. ",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5eaeaf4d395ee221d45c7",
        "key": "NETBEANS-2983",
        "id": "13250744",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.12515157461166382
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01133318617939949
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00390704395249486
                }
            }
        },
        "comments": [
            {
                "author_name": "lkishalmi",
                "id": "16907095",
                "body": "The description of NETBEANS-2963 is full of bloat, that makes it even hard to remove, so I've created a new issue and going to close that one. Next time please attach files instead of copy + paste content."
            },
            {
                "author_name": "lkishalmi",
                "id": "16954201",
                "body": "Neither a ProjectClassPathModifierImplementation nor a ProjectClassPathExtender can be implemented as they supposed to modify the project files. The current implementation treats the Gradle project as read-only.\r\nThough this issue probably can be solved without that support."
            },
            {
                "author_name": "lkishalmi",
                "id": "16976076",
                "body": "Well, well it is one of the ugly copy and paste bugs. It happens as for non-modular projects the Gradle support returned the Compile classpath instead of the runtime one."
            },
            {
                "author_name": "lkishalmi",
                "id": "16976078",
                "body": "BTW Thanks for reporting this one! It might have caused problems somewhere else as well."
            },
            {
                "author_name": "grandinj",
                "id": "17028886",
                "body": "Noting that this bug also makes the forms designer unable to edit a form, when that form includes other components from the current gradle sub-project"
            }
        ],
        "comments_predictions": [
            [
                1265609,
                "NETBEANS-2983",
                "The description of NETBEANS-2963 is full of bloat, that makes it even hard to remove, so I've created a new issue and going to close that one. Next time please attach files instead of copy + paste content.",
                {
                    "property": {
                        "confidence": 0.003718410851433873,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011502547189593315,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01634395308792591,
                        "prediction": false
                    }
                }
            ],
            [
                1265610,
                "NETBEANS-2983",
                "Neither a ProjectClassPathModifierImplementation nor a ProjectClassPathExtender can be implemented as they supposed to modify the project files. The current implementation treats the Gradle project as read-only.\r\nThough this issue probably can be solved without that support.",
                {
                    "property": {
                        "confidence": 0.004348269663751125,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005710619036108255,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.030428634956479073,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5f741f4d395ee221f4b31",
        "key": "JCLOUDS-511",
        "id": "12703168",
        "description": "For example, uk feature has the following definition:\n{code:xml}\n<feature name='jclouds-rackspace-cloudblockstorage-uk' description='Racksapce Cloud Block Storage UK' version='${project.version}' resolver='(obr)'>\n  <feature version='${project.version}'>jclouds-api-openstack-cinder</feature>\n  <feature version='${project.version}'>jclouds-api-rackspace-cloudidentity</feature>\n  <bundle>mvn:org.apache.jclouds.provider/rackspace-cloudblockstorage-uk/${jclouds.version}</bundle>\n</feature>\n{code}\nand {{jclouds-api-rackspace-cloudidentity}}:\n{code:xml}\n<feature name=\"jclouds-api-rackspace-cloudidentity\" description=\"Rackspace Cloud Identity API\" version=\"${project.version}\" resolver=\"(obr)\">\n  <feature version='${project.version}'>jclouds-compute</feature>\n  <feature version='${project.version}'>jclouds-api-openstack-keystone</feature>\n  <bundle dependency='true'>mvn:org.apache.jclouds.api/rackspace-cloudidentity/${jclouds.version}</bundle>\n</feature>\n{code}\n\nHowever, with current Karaf there's no way the bundle \"mvn:org.apache.jclouds.api/rackspace-cloudidentity/${jclouds.version}\" will get installed. Bundles with {dependency=\"true\"} are taken into account only during resolution of other bundles from the same feature - not of the _upper_ feature which uses other features. In other words - {{<bundle dependency=\"true\" />}} doesn't _bubble up_.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012372429482638836
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01313791610300541
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0035763923078775406
                }
            }
        },
        "comments": [
            {
                "author_name": "ggrzybek",
                "id": "13944914",
                "body": "Patch included with correct definition of {{jclouds-api-rackspace-cloudidentity}} Karaf feature."
            },
            {
                "author_name": "everett-toews",
                "id": "13945252",
                "body": "Hi [~ggrzybek],\n\nWould you like to try submitting this patch via our GitHub workflow outlined in [How to Contribute|http://wiki.apache.org/jclouds/How%20to%20Contribute]?\n\nThat's our normal workflow and it gives your patch more visibility. If you need help with it, you can find us in IRC at #jclouds on freenode.\n\nThanks"
            },
            {
                "author_name": "ggrzybek",
                "id": "13945278",
                "body": "Sorry. that's what I usually do ;)\nHere it is: https://github.com/jclouds/jclouds-karaf/pull/40"
            },
            {
                "author_name": "jira-bot",
                "id": "13954442",
                "body": "Commit b21a33582b6265ba3f47882beb9da420b8ab8b86 in jclouds-karaf's branch refs/heads/master from [~ggrzybek]\n[ https://git-wip-us.apache.org/repos/asf?p=jclouds-karaf.git;h=b21a335 ]\n\nJCLOUDS-511: Correcting features with dependency-only bundles\n"
            },
            {
                "author_name": "ggrzybek",
                "id": "13955095",
                "body": "Could we backport it to {{1.7.x}} branch?"
            },
            {
                "author_name": "jira-bot",
                "id": "13955201",
                "body": "Commit a7422966616abcad3c72cc78b521b07ee10d828b in jclouds-karaf's branch refs/heads/JCLOUDS-511-1.7.x from [~ggrzybek]\n[ https://git-wip-us.apache.org/repos/asf?p=jclouds-karaf.git;h=a742296 ]\n\nJCLOUDS-511: Correcting features with dependency-only bundles\n"
            },
            {
                "author_name": "andrewp",
                "id": "13955230",
                "body": "1.7.x backport PR: https://github.com/jclouds/jclouds-karaf/pull/41"
            },
            {
                "author_name": "jira-bot",
                "id": "13957223",
                "body": "Commit 866aaa921593e936cb66db8ca9a0125daa389798 in jclouds-karaf's branch refs/heads/JCLOUDS-511-1.7.x from [~ggrzybek]\n[ https://git-wip-us.apache.org/repos/asf?p=jclouds-karaf.git;h=866aaa9 ]\n\nJCLOUDS-511: Correcting features with dependency-only bundles\n"
            },
            {
                "author_name": "jira-bot",
                "id": "13957567",
                "body": "Commit cabe956be0cb99151ba27a0e109bc580881b60cf in jclouds-karaf's branch refs/heads/1.7.x from [~ggrzybek]\n[ https://git-wip-us.apache.org/repos/asf?p=jclouds-karaf.git;h=cabe956 ]\n\nJCLOUDS-511: Correcting features with dependency-only bundles\n"
            }
        ],
        "comments_predictions": [
            [
                1739039,
                "JCLOUDS-511",
                "Hi [~ggrzybek],\n\nWould you like to try submitting this patch via our GitHub workflow outlined in [How to Contribute|http://wiki.apache.org/jclouds/How%20to%20Contribute]?\n\nThat's our normal workflow and it gives your patch more visibility. If you need help with it, you can find us in IRC at #jclouds on freenode.\n\nThanks",
                {
                    "property": {
                        "confidence": 0.00412962818518281,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006700263824313879,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.024215297773480415,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5e742f4d395ee221cc87c",
        "key": "OFBIZ-3182",
        "id": "12440301",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.5836364030838013
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.017474541440606117
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008506158366799355
                }
            }
        },
        "comments": [
            {
                "author_name": "jleroux",
                "id": "12776692",
                "body": "Thanks Andr\u00e9,\n\nYour patch is in trunk at r835103  \n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d6055df4d395ee2221616c",
        "key": "HBASE-6432",
        "id": "12599576",
        "description": "ClusterId is normally set into the passed conf during instantiation of an HTable class. In the case of a HRegionServer this is bypassed and set to \"default\" since getMaster() since it uses HBaseRPC to create the proxy directly and bypasses the class which retrieves and sets the correct clusterId. \n\nThis becomes a problem with clients (ie within a coprocessor) using delegation tokens for authentication. Since the token's service will be the correct clusterId and while the TokenSelector is looking for one with service \"default\".",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.005215747281908989
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.023968052119016647
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00495422538369894
                }
            }
        },
        "comments": [
            {
                "author_name": "toffer",
                "id": "13418921",
                "body": "a patch for 0.94 to get feedback on the approach. Things changed significant enough in trunk to need a separate patch. I'm hoping to get this backported to 0.94 since it is needed for security."
            },
            {
                "author_name": "apurtell",
                "id": "13419263",
                "body": "Seems reasonable and low risk to pull the ID from ZooKeeper."
            },
            {
                "author_name": "apurtell",
                "id": "13419271",
                "body": "However, the master is responsible for publishing the cluster ID to ZooKeeper. If on a fresh install the regionservers are started first, then they won't find the ID up in ZK until the master comes up. I think this should be a Chore that retries until the ID is found then exits."
            },
            {
                "author_name": "toffer",
                "id": "13445091",
                "body": "[~apurtell] I was working on adding the blocking logic this morning.  Looking at the way the master starts up it looks like it sets the clusterId before changing cluster status to up. And the HRegionServer already has blocking logic until clusterStatus is set to up. We can add the retrieval of the clusterId after this step. Is that a fair assumption to make? "
            },
            {
                "author_name": "toffer",
                "id": "13446147",
                "body": "Here's patch of what I described. Let me know if this is ok and I'll come up with an 0.94 patch."
            },
            {
                "author_name": "hadoopqa",
                "id": "13446208",
                "body": "-1 overall.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12543304/HBASE-6432.patch\n  against trunk revision .\n\n    +1 @author.  The patch does not contain any @author tags.\n\n    +1 tests included.  The patch appears to include 2 new or modified tests.\n\n    +1 hadoop2.0.  The patch compiles against the hadoop 2.0 profile.\n\n    -1 javadoc.  The javadoc tool appears to have generated 110 warning messages.\n\n    -1 javac.  The applied patch generated 5 javac compiler warnings (more than the trunk's current 4 warnings).\n\n    -1 findbugs.  The patch appears to introduce 11 new Findbugs (version 1.3.9) warnings.\n\n    +1 release audit.  The applied patch does not increase the total number of release audit warnings.\n\n     -1 core tests.  The patch failed these unit tests:\n                       org.apache.hadoop.hbase.replication.TestReplication\n                  org.apache.hadoop.hbase.coprocessor.TestRegionServerCoprocessorExceptionWithAbort\n\nTest results: https://builds.apache.org/job/PreCommit-HBASE-Build/2754//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/2754//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop2-compat.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/2754//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/2754//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/2754//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/2754//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html\nConsole output: https://builds.apache.org/job/PreCommit-HBASE-Build/2754//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "stack",
                "id": "13450427",
                "body": "Committed trunk and 0.94 patch.  Thanks Francis."
            },
            {
                "author_name": "hudson",
                "id": "13450462",
                "body": "Integrated in HBase-TRUNK #3314 (See [https://builds.apache.org/job/HBase-TRUNK/3314/])\n    HBASE-6432 HRegionServer doesn't properly set clusterId in conf (Revision 1381905)\n\n     Result = FAILURE\nstack : \nFiles : \n* /hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n* /hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestClusterId.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13450471",
                "body": "Integrated in HBase-0.94 #453 (See [https://builds.apache.org/job/HBase-0.94/453/])\n    HBASE-6432 HRegionServer doesn't properly set clusterId in conf (Revision 1381907)\n\n     Result = FAILURE\nstack : \nFiles : \n* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13450539",
                "body": "Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #164 (See [https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/164/])\n    HBASE-6432 HRegionServer doesn't properly set clusterId in conf (Revision 1381905)\n\n     Result = FAILURE\nstack : \nFiles : \n* /hbase/trunk/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n* /hbase/trunk/hbase-server/src/test/java/org/apache/hadoop/hbase/regionserver/TestClusterId.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13455036",
                "body": "Integrated in HBase-0.94-security #52 (See [https://builds.apache.org/job/HBase-0.94-security/52/])\n    HBASE-6432 HRegionServer doesn't properly set clusterId in conf (Revision 1381907)\n\n     Result = SUCCESS\nstack : \nFiles : \n* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13469889",
                "body": "Integrated in HBase-0.94-security-on-Hadoop-23 #8 (See [https://builds.apache.org/job/HBase-0.94-security-on-Hadoop-23/8/])\n    HBASE-6432 HRegionServer doesn't properly set clusterId in conf (Revision 1381907)\n\n     Result = FAILURE\nstack : \nFiles : \n* /hbase/branches/0.94/src/main/java/org/apache/hadoop/hbase/regionserver/HRegionServer.java\n"
            },
            {
                "author_name": "stack",
                "id": "13624646",
                "body": "Fix up after bulk move overwrote some 0.94.2 fix versions w/ 0.95.0 (Noticed by Lars Hofhansl)"
            }
        ],
        "comments_predictions": [
            [
                2433013,
                "HBASE-6432",
                "However, the master is responsible for publishing the cluster ID to ZooKeeper. If on a fresh install the regionservers are started first, then they won't find the ID up in ZK until the master comes up. I think this should be a Chore that retries until the ID is found then exits.",
                {
                    "property": {
                        "confidence": 0.005685281939804554,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004868336953222752,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0315229631960392,
                        "prediction": false
                    }
                }
            ],
            [
                2433014,
                "HBASE-6432",
                "[~apurtell] I was working on adding the blocking logic this morning.  Looking at the way the master starts up it looks like it sets the clusterId before changing cluster status to up. And the HRegionServer already has blocking logic until clusterStatus is set to up. We can add the retrieval of the clusterId after this step. Is that a fair assumption to make? ",
                {
                    "property": {
                        "confidence": 0.0064802272245287895,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004199393093585968,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023084238171577454,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d617d5f4d395ee2223e0cf",
        "key": "DIR-141",
        "id": "13582",
        "description": "Rewrite of realm code (DIR-14) calls for rewrite of XML front-end.",
        "predictions": {},
        "comments": [
            {
                "author_name": "vtence",
                "id": "16285",
                "body": "Work will be done in sandbox and the new realm stuff wil move at once when this is done."
            },
            {
                "author_name": "vtence",
                "id": "19593",
                "body": "Implemented basic front-end in sandbox."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d617d5f4d395ee2223eec7",
        "key": "DERBY-3846",
        "id": "12402887",
        "description": "The \"Messages libraries\" section of the Derby Developer's Guide says that Derby \"supports\" a number of locales:\n\n    * derbyLocale_de_DE.jar German\n    * derbyLocale_es.jar - Spanish\n    * derbyLocale_fr.jar - French\n    * derbyLocale_it.jar - Italian\n    * derbyLocale_ja_JP.jar - Japanese\n    * derbyLocale_ko_KR.jar - Korean\n    * derbyLocale_pt_BR.jar - Brazilian Portuguese\n    * derbyLocale_zh_CN.jar - Simplified Chinese\n    * derbyLocale_zh_TW.jar - Traditional Chinese\n\nIn fact, in addition to these locales, Derby provides localizations for some others (see http://wiki.apache.org/db-derby/LocalizingDerbyMessages):\n\n    * derbyLocale_cs.jar - Czech\n    * derbyLocale_hu.jar - Hungarian\n    * derbyLocale_pl.jar - Polish (except for sysinfo)\n    * derbyLocale_ru.jar - Russian\n\nThe term \"supports\" may overdescribe the situation. Effort has been put into keeping some of these localizations up-to-date, although I don't think that any systematic effort has been put into verifying that any of our non-English locales are really current. Some locales have not been updated recently. Here's the list of locales which received fresh localizations in 10.4 (see http://issues.apache.org/jira/browse/DERBY-3804):\n\nGerman\nSpanish\nFrench\nItalian\nJapanese\nKorean\nTraditional and Simplified Chinese \n\nThis means that the Developer's Guide is claiming that Derby \"supports\" Portuguese, even though it's clear that those localizations are drifting out of sync with the English messages.\n\nWe should correct the \"Message libraries\" section:\n\n1) We should decide what we mean by \"supports\". This term could mean\n \n  a) Derby provides SOME localized messages for the locale or\n  b) The localizations are being actively maintained\n\n2) Based on what how we resolve (1), we should add or subtract locales from the list in \"Message libraries\"\n\nMy gut feeling is that we should list all of the locales for which we provide localizations and this section should note that some locales are maintained better than others.\n\n\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014876948669552803
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.03547219932079315
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008799705654382706
                }
            }
        },
        "comments": [
            {
                "author_name": "djd",
                "id": "12624910",
                "body": "Not sure the claim can be made that some localizations are better maintained than others, in an open source project past maintenance is no guarantee of future maintenance. Really an incorrect or missing translation in any provided locale is just a bug, and there may or may not be interest from someone in fixing it, much like any other bug."
            },
            {
                "author_name": "rhillegas",
                "id": "12624928",
                "body": "Thanks for the quick response, Dan. That sounds like a vote for (1a) but with a caution that we should remain silent about the variable bug counts across localizations."
            },
            {
                "author_name": "chaase3",
                "id": "12711360",
                "body": "I gather that the solution is to keep this simple and just add the new locale jars to the list without adding any caveats. I'll file a patch based on this assumption unless I hear otherwise."
            },
            {
                "author_name": "rhillegas",
                "id": "12711606",
                "body": "Thanks, Kim. That sounds good to me."
            },
            {
                "author_name": "chaase3",
                "id": "12711632",
                "body": "Thanks, Rick, for the go-ahead. I'm attaching DERBY-3846.diff and the resulting cdevin38113.html. I made one little font tweak in addition to adding the file names. I thought of trying to resolve the other font inconsistencies but decided to keep it simple."
            },
            {
                "author_name": "rhillegas",
                "id": "12711641",
                "body": "Thanks, Kim. Looks good. I wonder if we should not mention the sysinfo defect in the Polish localizations. Many of the other localizations have drifted out-of-sync with the English versions and, in my opinion, those skews are more significant than the missing Polish variants for sysinfo. "
            },
            {
                "author_name": "chaase3",
                "id": "12711652",
                "body": "Thanks -- that makes sense, Rick. Attaching a revised patch (DERBY-3846-2.diff) and output file."
            },
            {
                "author_name": "rhillegas",
                "id": "12711655",
                "body": "Thanks, Kim. +1"
            },
            {
                "author_name": "chaase3",
                "id": "12711705",
                "body": "Thanks, Rick!\n\nCommitted patch DERBY-3846-2.diff to documentation trunk at revision 777181. \nMerged to 10.5 branch at revision 777186."
            },
            {
                "author_name": "rhillegas",
                "id": "12711736",
                "body": "Confirmed that changes appear in trunk docs. Closing."
            }
        ],
        "comments_predictions": [
            [
                3217903,
                "DERBY-3846",
                "Not sure the claim can be made that some localizations are better maintained than others, in an open source project past maintenance is no guarantee of future maintenance. Really an incorrect or missing translation in any provided locale is just a bug, and there may or may not be interest from someone in fixing it, much like any other bug.",
                {
                    "property": {
                        "confidence": 0.004949918948113918,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.02393110655248165,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006200322415679693,
                        "prediction": false
                    }
                }
            ],
            [
                3217907,
                "DERBY-3846",
                "Thanks, Rick, for the go-ahead. I'm attaching DERBY-3846.diff and the resulting cdevin38113.html. I made one little font tweak in addition to adding the file names. I thought of trying to resolve the other font inconsistencies but decided to keep it simple.",
                {
                    "property": {
                        "confidence": 0.005383993033319712,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006904266308993101,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01311612967401743,
                        "prediction": false
                    }
                }
            ],
            [
                3217908,
                "DERBY-3846",
                "Thanks, Kim. Looks good. I wonder if we should not mention the sysinfo defect in the Polish localizations. Many of the other localizations have drifted out-of-sync with the English versions and, in my opinion, those skews are more significant than the missing Polish variants for sysinfo. ",
                {
                    "property": {
                        "confidence": 0.004986748564988375,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.04591841250658035,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010839181020855904,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d63154f4d395ee222764cc",
        "key": "ACCUMULO-1568",
        "id": "12657485",
        "description": "I have not seen this issue, but its something I thought of.  Assume the following happens.\n\n * iterators I1 ... I10 are configured to Table T1 at time 1\n * iterators NI1 ... NI10 are configured to Table T1 at time 2\n * compaction is reading iterator config and reads I1 ... I5  and NI4 ... NI9, a combination of the two iterator configurations w/o NI10, this could be really bad.\n\nSeems like this could be solved by use of Zookeeper transactions.   The Accumulo API will need to change to allow setting many iterators or config settings at once.\n \n\n ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.004303120542317629
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.04287121072411537
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005339800380170345
                }
            }
        },
        "comments": [
            {
                "author_name": "vines",
                "id": "13707116",
                "body": "I think zookeeper transactions are used for writes, not reads, but I could be mistaken. This helps to mitigate this possibility, but I don't think it would prevent a client from having a partial view.\n\nHowever, if we're concerned about partial views, then this could more easily be accomplished by changing the way we store the iterators in zookeeper, but that has it's own issues. If we flatten all iterators and settings to a single znode we can guarantee everything is in sync, but then there's the race condition in the read/modify/write, but that can be handled by stat versions."
            },
            {
                "author_name": "kturner",
                "id": "13707246",
                "body": "bq. I think zookeeper transactions are used for writes, not reads, but I could be mistaken. \n\nI think you are right.  org.apache.zookeeper.Op only has write operations.   So the API does not seem to provide a way to batch read operations for atomic reads.\n\n\nbq.  If we flatten all iterators and settings to a single znode we can guarantee everything is in sync, but then there's the race condition in the read/modify/write, but that can be handled by stat versions.\n\nI think thats the way to go.  No need to limit it to iterator settings.  Put all per table config in a single node, all system config in a single node, and all namepace config in a single node.   This could allow cleaning up of other potential problems.  For example there is currently a race condition with setting locality groups.  If that method is called concurrently, I think it could corrupt the config.  Using stat versions and all config in a single node would offer a way to fix this.\n"
            },
            {
                "author_name": "vines",
                "id": "13707266",
                "body": "I'm a fan of that and it would make my curator migrations a lot easier. However, I'm wondering if there's a reason [~ecn] did it this way in the first place."
            },
            {
                "author_name": "ecn",
                "id": "13707275",
                "body": "I don't remember a good reason, but I barely remember writing the LG configuration code."
            },
            {
                "author_name": "vines",
                "id": "13707294",
                "body": "Alright, I guess I'll be adding some migration code to the master to handle this changeover then as well. Make sense to put it there?"
            },
            {
                "author_name": "kturner",
                "id": "13707582",
                "body": "[~vines], when I first implemented per-table config I arbitrarily decided to put each config entry in a zookeeper node.  Later this convention was followed for system config stored in zookeeper.  [~shickey] is currently working on storing namespace configs in zookeeper.\n\nThe master did have some upgrade code in place for upgrading zookeeper.   If I remember correctly, it writes something after the zookeeper upgrade has run successfully.  Should the master die in the middle, it will just run the code again."
            },
            {
                "author_name": "vines",
                "id": "13783095",
                "body": "Did the namespace configs get wrapped? I'll work on this, but I don't want to make merging that code a PITA."
            },
            {
                "author_name": "ctubbsii",
                "id": "13788667",
                "body": "I've been keeping the namespace code up-to-date (rebase, not running tests). See comment on ACCUMULO-802 for the link to the latest. Due to unforeseeable interruptions, I've not been able to complete reviewing and testing it, in order to feel comfortable enough to merge it in. It might help if you or somebody else could review the code, and make any necessary contributions to it to ensure it is stable enough to merge in."
            },
            {
                "author_name": "ctubbsii",
                "id": "17217800",
                "body": "Duplicated by https://github.com/apache/accumulo/issues/1454"
            }
        ],
        "comments_predictions": [
            [
                3955746,
                "ACCUMULO-1568",
                "I think zookeeper transactions are used for writes, not reads, but I could be mistaken. This helps to mitigate this possibility, but I don't think it would prevent a client from having a partial view.\n\nHowever, if we're concerned about partial views, then this could more easily be accomplished by changing the way we store the iterators in zookeeper, but that has it's own issues. If we flatten all iterators and settings to a single znode we can guarantee everything is in sync, but then there's the race condition in the read/modify/write, but that can be handled by stat versions.",
                {
                    "property": {
                        "confidence": 0.08957810699939728,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002076387871056795,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.7074633240699768,
                        "prediction": true
                    }
                }
            ],
            [
                3955747,
                "ACCUMULO-1568",
                "bq. I think zookeeper transactions are used for writes, not reads, but I could be mistaken. \n\nI think you are right.  org.apache.zookeeper.Op only has write operations.   So the API does not seem to provide a way to batch read operations for atomic reads.\n\n\nbq.  If we flatten all iterators and settings to a single znode we can guarantee everything is in sync, but then there's the race condition in the read/modify/write, but that can be handled by stat versions.\n\nI think thats the way to go.  No need to limit it to iterator settings.  Put all per table config in a single node, all system config in a single node, and all namepace config in a single node.   This could allow cleaning up of other potential problems.  For example there is currently a race condition with setting locality groups.  If that method is called concurrently, I think it could corrupt the config.  Using stat versions and all config in a single node would offer a way to fix this.\n",
                {
                    "property": {
                        "confidence": 0.0054174549877643585,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0060880305245518684,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.09885227680206299,
                        "prediction": false
                    }
                }
            ],
            [
                3955751,
                "ACCUMULO-1568",
                "[~vines], when I first implemented per-table config I arbitrarily decided to put each config entry in a zookeeper node.  Later this convention was followed for system config stored in zookeeper.  [~shickey] is currently working on storing namespace configs in zookeeper.\n\nThe master did have some upgrade code in place for upgrading zookeeper.   If I remember correctly, it writes something after the zookeeper upgrade has run successfully.  Should the master die in the middle, it will just run the code again.",
                {
                    "property": {
                        "confidence": 0.003482795087620616,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007766669616103172,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.06936084479093552,
                        "prediction": false
                    }
                }
            ],
            [
                3955753,
                "ACCUMULO-1568",
                "I've been keeping the namespace code up-to-date (rebase, not running tests). See comment on ACCUMULO-802 for the link to the latest. Due to unforeseeable interruptions, I've not been able to complete reviewing and testing it, in order to feel comfortable enough to merge it in. It might help if you or somebody else could review the code, and make any necessary contributions to it to ensure it is stable enough to merge in.",
                {
                    "property": {
                        "confidence": 0.006845573429018259,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0052942377515137196,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01531845424324274,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5e3fef4d395ee221c2f61",
        "key": "PHOENIX-3255",
        "id": "13003624",
        "description": "We need to improve test coverage for TIMESTAMP. See PHOENIX-2946 for issues found when comparing TIMESTAMP with DATE.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.022105850279331207
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006914344150573015
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008735968731343746
                }
            }
        },
        "comments": [
            {
                "author_name": "jamestaylor",
                "id": "15474344",
                "body": "Attaching patch on behalf of [~kliew]."
            },
            {
                "author_name": "hudson",
                "id": "15474875",
                "body": "FAILURE: Integrated in Jenkins build Phoenix-master #1385 (See [https://builds.apache.org/job/Phoenix-master/1385/])\nPHOENIX-3255 Increase test coverage for TIMESTAMP (Kevin Liew) (jamestaylor: rev d94d57183501526cff6fc1c5d1475e487c9c4653)\n* (edit) phoenix-core/src/it/java/org/apache/phoenix/end2end/DateTimeIT.java\n"
            },
            {
                "author_name": "hudson",
                "id": "15474963",
                "body": "SUCCESS: Integrated in Jenkins build Phoenix-4.8-HBase-1.2 #11 (See [https://builds.apache.org/job/Phoenix-4.8-HBase-1.2/11/])\nPHOENIX-3255 Increase test coverage for TIMESTAMP (Kevin Liew) (jamestaylor: rev 3516993b1d254670aadb7f99855d1a5dce9b078e)\n* (edit) phoenix-core/src/it/java/org/apache/phoenix/end2end/DateTimeIT.java\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d5c5f4d395ee22191b58",
        "key": "TS-3217",
        "id": "12758787",
        "description": "When compiling traffic server with --enable-debug using TSHttpTxnRedirectUrlSet causes failed assertions.\n\nHere's a simple example plugin replicating the behavior:\n\nhttps://gist.github.com/biilmann/d9a877bb353224ff19de\n\nThis causes the following assertion to fail:\n\nFATAL: HttpSM.cc:2467: failed assert `server_entry == NULL`\n\nThe patch for TS-3140 solves this, but leads to another assertion fail:\n\nDEBUG: (http) [0] State Transition: SM_ACTION_API_OS_DNS -> SM_ACTION_CACHE_ISSUE_WRITE\nFATAL: HttpSM.cc:7108: failed assert `cache_sm.cache_write_vc == NULL`\n\n",
        "predictions": {},
        "comments": [
            {
                "author_name": "zwoop",
                "id": "14251178",
                "body": "This seems pretty serious. E.g. the escalation plugin uses the same API."
            },
            {
                "author_name": "shinrich",
                "id": "14281131",
                "body": "Linking this bug to TS-3140 since we'll be applying a single fix to both. Chose TS-3140 to use for the tracking.\n\nIn addition, we're fixing another resource assertion with POST redirects."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e023f4d395ee221b501f",
        "key": "SLING-2712",
        "id": "12628871",
        "description": "I have a {{Resource}} which has a property named {{releaseMonth}} which is of type {{long}}; then I have a simple {{NumberFormat}}\n\n{code}\nNumberFormat numberFormat = new DecimalFormat(\"00\");\n{code}\n\nIf I try to execute, in a JSP, the following code, to cast the {{releaseMonth}} property to the primitive {{long.class}}:\n\n{code}\n<%= numberFormat.format(properties.get(\"releaseMonth\", long.class)) %>\n{code}\n\nIt throws an exception:\n\n{code}\nCaused by: java.lang.IllegalArgumentException: Cannot format given\nObject as a Number\nat java.text.DecimalFormat.format(DecimalFormat.java:486)\nat java.text.Format.format(Format.java:140)\nat \norg.apache.jsp.apps.gtunes.album.html_jsp._jspService(html_jsp.java:171)\nat \norg.apache.sling.scripting.jsp.jasper.runtime.HttpJspBase.service(HttpJspB\nase.java:70)\nat javax.servlet.http.HttpServlet.service(HttpServlet.java:820)\nat \norg.apache.sling.scripting.jsp.jasper.servlet.JspServletWrapper.service(Js\npServletWrapper.java:502)\n... 68 more\n{code}\n\nIf I use instead the primitive wrapper {{Long.class}}\n\n{code}\n<%= numberFormat.format(properties.get(\"releaseMonth\", Long.class)) %>\n{code}\n\neverything works fine.\n\nLooks like that\n\n{code}\nproperties.get(\"\", long.class)\n{code}\n\ngets {{NULL}} back",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.025077015161514282
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.010091911070048809
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0034794905222952366
                }
            }
        },
        "comments": [
            {
                "author_name": "alexander.klimetschek",
                "id": "13560588",
                "body": "That's as designed. I didn't know you could do \"long.class\" or \"int.class\"...."
            },
            {
                "author_name": "cziegeler",
                "id": "13560596",
                "body": "I think we can easily support the primitive types - of course, as the method returns an object, the wrapper object is returned, so\nproperties.get(\"name\", Long.class) would return the same object as properties.get(\"name\", long.class)\n"
            },
            {
                "author_name": "fmeschbe",
                "id": "13560753",
                "body": "Maybe supporting the primitive types may help, but ....\n\n* The boxed type will always be returned which does *not* match the requested type (unless the generics support also assumes autoboxing when deriving the result type from the parameter type).\n\n* More importantly: Requesting a primitive type and auto-unboxing the result may result in a NullPointerException: The get method is specified to return null if the the property does not exist. Auto-unboxing does no null-check (it cannot because it does not know how to handle) and thus runs straight into the NullPointerException.\n\nI thus, in the interest of clarity and stability, suggest to not implement this \"feature\" but instead enhance the JavaDoc to clearly state that primitive types are not supported as type parameters and that instead the respective boxed type should be used."
            },
            {
                "author_name": "alexander.klimetschek",
                "id": "13561027",
                "body": "+1 to Felix' proposal."
            },
            {
                "author_name": "cziegeler",
                "id": "13561501",
                "body": "Right, good idea - I was a little bit worried about the fact that a get(\"name\", long.class) returns a Long as well and the NPE when a value is not available is really something to avoid.\nI'll changed the title of this issue to update the javadocs."
            },
            {
                "author_name": "bdelacretaz",
                "id": "13561516",
                "body": "IMO, as we agree on not supporting primitive types (which makes sense), the method should throw an IllegalArgumentException when such a type is passed in, to avoid surprises."
            },
            {
                "author_name": "cziegeler",
                "id": "13561545",
                "body": "Not sure if we have to throw a special exception, you either get a NPE or a ClassCastException - I think an IAE is as surprising as an NPE :)"
            },
            {
                "author_name": "bdelacretaz",
                "id": "13561553",
                "body": "throw new IllegalArgumentException(\"Conversions to primitive types are not supported, cannot convert to \" + whateverTypeWasAskedFor) \n\nis certainly more transparent than a vague NPE that happens later in the caller..."
            },
            {
                "author_name": "cziegeler",
                "id": "13561557",
                "body": "But throwing an IAE is a contract change - and the NPE happens right away when null is tried to auto-unbox"
            },
            {
                "author_name": "alexander.klimetschek",
                "id": "13561592",
                "body": "I agree with Bertrand. Throwing an IAE is not a contract change as it's not a checked exception."
            },
            {
                "author_name": "fmeschbe",
                "id": "13562721",
                "body": "Yes, throwing violates the contract. In fact null is not only returned if the property does not exist, it is also returned if the property cannot be converted to the requested type. So the second case applies here (impossible conversion) and null must be returned.\n\nHmm, maybe we should also clarify this one: null is returned if conversion to the requested type is not possible."
            },
            {
                "author_name": "cziegeler",
                "id": "13562746",
                "body": "From the javadocs: Return named value converted to type T or <code>null</code> if non existing or can't be converted.\nSo I think we're good :) I've updated the javadocs that primitve types are not supported."
            },
            {
                "author_name": "fmeschbe",
                "id": "13563684",
                "body": "While it may be disputable whether throwing IAE is a contract change or not, in this case it is because the contract says: return null if conversion is not possible."
            },
            {
                "author_name": "alexander.klimetschek",
                "id": "13563831",
                "body": "Yep, I agreed silently, returning null instead of throwing IAE makes total sense."
            }
        ],
        "comments_predictions": [
            [
                749823,
                "SLING-2712",
                "I think we can easily support the primitive types - of course, as the method returns an object, the wrapper object is returned, so\nproperties.get(\"name\", Long.class) would return the same object as properties.get(\"name\", long.class)\n",
                {
                    "property": {
                        "confidence": 0.005275950767099857,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005245689768344164,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023729873821139336,
                        "prediction": false
                    }
                }
            ],
            [
                749824,
                "SLING-2712",
                "Maybe supporting the primitive types may help, but ....\n\n* The boxed type will always be returned which does *not* match the requested type (unless the generics support also assumes autoboxing when deriving the result type from the parameter type).\n\n* More importantly: Requesting a primitive type and auto-unboxing the result may result in a NullPointerException: The get method is specified to return null if the the property does not exist. Auto-unboxing does no null-check (it cannot because it does not know how to handle) and thus runs straight into the NullPointerException.\n\nI thus, in the interest of clarity and stability, suggest to not implement this \"feature\" but instead enhance the JavaDoc to clearly state that primitive types are not supported as type parameters and that instead the respective boxed type should be used.",
                {
                    "property": {
                        "confidence": 0.008199324831366539,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0039123715832829475,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.25915348529815674,
                        "prediction": false
                    }
                }
            ],
            [
                749826,
                "SLING-2712",
                "Right, good idea - I was a little bit worried about the fact that a get(\"name\", long.class) returns a Long as well and the NPE when a value is not available is really something to avoid.\nI'll changed the title of this issue to update the javadocs.",
                {
                    "property": {
                        "confidence": 0.004336214158684015,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.014766312204301357,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009062528610229492,
                        "prediction": false
                    }
                }
            ],
            [
                749829,
                "SLING-2712",
                "throw new IllegalArgumentException(\"Conversions to primitive types are not supported, cannot convert to \" + whateverTypeWasAskedFor) \n\nis certainly more transparent than a vague NPE that happens later in the caller...",
                {
                    "property": {
                        "confidence": 0.006289842538535595,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005890607833862305,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014052992686629295,
                        "prediction": false
                    }
                }
            ],
            [
                749832,
                "SLING-2712",
                "Yes, throwing violates the contract. In fact null is not only returned if the property does not exist, it is also returned if the property cannot be converted to the requested type. So the second case applies here (impossible conversion) and null must be returned.\n\nHmm, maybe we should also clarify this one: null is returned if conversion to the requested type is not possible.",
                {
                    "property": {
                        "confidence": 0.008375945501029491,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0033588299993425608,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03283867612481117,
                        "prediction": false
                    }
                }
            ],
            [
                749833,
                "SLING-2712",
                "From the javadocs: Return named value converted to type T or <code>null</code> if non existing or can't be converted.\nSo I think we're good :) I've updated the javadocs that primitve types are not supported.",
                {
                    "property": {
                        "confidence": 0.004804850090295076,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00942259468138218,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010297700762748718,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d61395f4d395ee22233bb6",
        "key": "FLEX-7520",
        "id": "12568393",
        "description": "This bug was imported from another system and requires review from a project committer before some of the details can be marked public. For more information about historical bugs, please read: [Why are some bugs missing information?|https://bugs.adobe.com/confluence/display/ADOBE/Why+are+some+bugs+missing+information]\n\nYou can request a review of this bug report by sending an e-mail to: [Request Public Review for This Bug|mailto:jira_support@adobe.com?subject=Bug%20Review%20Request%20-%20SDK-7565&amp;body=Please%20review%20this%20historical%20bug%20report%20and%20consider%20making%20additional%20information%20public.%20%20I%20understand%20that%20my%20request%20(including%20this%20e-mail)%20may%20be%20included%20as%20part%20of%20the%20public%20history%20in%20the%20bug%20comments.%0D%0A%0D%0AAdditional Information: ]\n\nPlease be sure to include the bug number in your request.",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13318745",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-7565\nOriginal Reporter: dsubrama\nOriginal Resolution: Fixed\nNeeds Release Note: No\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nResolved by: mjethani\nSeverity: Incorrectly Functioning\nreporter: dsubrama"
            },
            {
                "author_name": "adobejira",
                "id": "13318746",
                "body": "created: 2006-05-09 10:13:02.000\nresolved: 2007-06-04 10:08:32.196\nupdated: 2011-05-10 14:26:52.000"
            },
            {
                "author_name": "adobejira",
                "id": "13318747",
                "body": "On 2007-05-12 15:01:26.187 customware commented:\nMove from BugDB issue number 170140\nOn 2007-05-12 15:01:26.187 customware commented:\nMilestone ID = 703\nMilestone = GMC_Flex2.0 \nBuild ID = 18637\nBuild = 138547_Flex\nFix Build ID = 18689\nFix Build = 138783_Flex"
            }
        ],
        "comments_predictions": [
            [
                3039269,
                "FLEX-7520",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-7565\nOriginal Reporter: dsubrama\nOriginal Resolution: Fixed\nNeeds Release Note: No\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nResolved by: mjethani\nSeverity: Incorrectly Functioning\nreporter: dsubrama",
                {
                    "property": {
                        "confidence": 0.003915582317858934,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03850063681602478,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01742871105670929,
                        "prediction": false
                    }
                }
            ],
            [
                3039271,
                "FLEX-7520",
                "On 2007-05-12 15:01:26.187 customware commented:\nMove from BugDB issue number 170140\nOn 2007-05-12 15:01:26.187 customware commented:\nMilestone ID = 703\nMilestone = GMC_Flex2.0 \nBuild ID = 18637\nBuild = 138547_Flex\nFix Build ID = 18689\nFix Build = 138783_Flex",
                {
                    "property": {
                        "confidence": 0.0036360130179673433,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012494323775172234,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01413060910999775,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5fc52f4d395ee22201705",
        "key": "IGNITE-4929",
        "id": "13062345",
        "description": "One phase tx for invoke may fail in this scenario:\n- backup did not rebalanced partition yet\n- in this case primary sends on backup new value instead of entry processor, in this case on backup we loose information about value calculated by entry processor\n- primary fails before it receives response from backup, client sends 'check' request on backup to get return value, but return value on backup does not contain expected invoke result\n\nAdded test IgniteOnePhaseCommitInvokeTest.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.003990780562162399
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.019940270110964775
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007770911790430546
                }
            }
        },
        "comments": [
            {
                "author_name": "sboikov",
                "id": "15976238",
                "body": "When execute tx on changing topology we already send old value available on primary to all backups, so this old value can be used on backups to execute 'invoke'. So I got rid of code in GridDhtTxPrepareFuture sending to backups computed value instead of entry processors."
            }
        ],
        "comments_predictions": [
            [
                1850001,
                "IGNITE-4929",
                "When execute tx on changing topology we already send old value available on primary to all backups, so this old value can be used on backups to execute 'invoke'. So I got rid of code in GridDhtTxPrepareFuture sending to backups computed value instead of entry processors.",
                {
                    "property": {
                        "confidence": 0.007883241400122643,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0034817613195627928,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04627033323049545,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5e3fef4d395ee221c268d",
        "key": "PHOENIX-5525",
        "id": "13262070",
        "description": "Is Apache Phoenix compatible with Java 11(Open JDK)? When we are starting our application service we could see the below error in case of JDK11, which is not occuring in JDK 8.\r\n\r\n*2019-10-11 08:27:11.376 WARN [PlanService,,,] 1524 \u2014 [ main] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'phoenixEntityManager' defined in class path resource [/PhoenixDataSource.class]: Invocation of init method failed; nested exception is org.hibernate.service.spi.ServiceException: Unable to create requested service [org.hibernate.engine.jdbc.env.spi.JdbcEnvironment]*\r\n\r\n\u00a0\r\n\r\n*Caused by: org.hibernate.boot.registry.selector.spi.StrategySelectionException: Unable to resolve name [com.ruesga.phoenix.dialect.PhoenixDialect] as strategy\u00a0[org.hibernate.dialect.Dialect]*\r\n\r\nFull application log is attached in the ticket.\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.8817129135131836
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01661611720919609
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.01884402707219124
                }
            }
        },
        "comments": [
            {
                "author_name": "larsh",
                "id": "16950726",
                "body": "Hi [~armeggaddon] , please ask this on the mailing lists.\r\n\r\nThere are no classes in your stack traces that are shipped by the Phoenix project."
            },
            {
                "author_name": "armeggaddon",
                "id": "16950732",
                "body": "Hi Lars, Thanks for the comment. We are receiving this Unable to resolve name [com.ruesga.phoenix.dialect.PhoenixDialect]. Still it has nothing to do with Phoenix. Also, could you please let me know the mailing list?"
            }
        ],
        "comments_predictions": [
            [
                938866,
                "PHOENIX-5525",
                "Hi Lars, Thanks for the comment. We are receiving this Unable to resolve name [com.ruesga.phoenix.dialect.PhoenixDialect]. Still it has nothing to do with Phoenix. Also, could you please let me know the mailing list?",
                {
                    "property": {
                        "confidence": 0.004977123811841011,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.033364925533533096,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007000808138400316,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d60433f4d395ee222134f3",
        "key": "HBASE-17852",
        "id": "13060154",
        "description": "Design approach rollback-via-snapshot implemented in this ticket:\r\n\r\n# Before backup create/delete/merge starts we take a snapshot of the backup meta-table (backup system table). This procedure is lightweight because meta table is small, usually should fit a single region.\r\n# When operation fails on a server side, we handle this failure by cleaning up partial data in backup destination, followed by restoring backup meta-table from a snapshot. \r\n# When operation fails on a client side (abnormal termination, for example), next time user will try create/merge/delete he(she) will see error message, that system is in inconsistent state and repair is required, he(she) will need to run backup repair tool.\r\n# To avoid multiple writers to the backup system table (backup client and BackupObserver's) we introduce small table ONLY to keep listing of bulk loaded files. All backup observers will work only with this new tables. The reason: in case of a failure during backup create/delete/merge/restore, when system performs automatic rollback, some data written by backup observers during failed operation may be lost. This is what we try to avoid.\r\n# Second table keeps only bulk load related references. We do not care about consistency of this table, because bulk load is idempotent operation and can be repeated after failure. Partially written data in second table does not affect on BackupHFileCleaner plugin, because this data (list of bulk loaded files) correspond to a files which have not been loaded yet successfully and, hence - are not visible to the system \r\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012360623106360435
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.9736069440841675
                },
                "property": {
                    "prediction": true,
                    "confidence": 0.9471439719200134
                }
            }
        },
        "comments": [
            {
                "author_name": "vrodionov",
                "id": "16163729",
                "body": "Some notes after initial analysis of implementation of bulk-loaded files support\n\n# RegionObserver coprocessor has pre-commit and post-commit code (kind of Tx), but only on a region level. No Tx support on a table level. This means that if (for some regions), loading files fail, we will be left with a partial data in both: table store physical location and in backup system table. What we need here is Tx support for the whole bulk load operation cluster-wide (prepare, commit). And hooks exposed for custom coprocessor (Master?). \n# What will happen if bulk load operation runs at the same time as  incremental backup? Backup will see partial updates, but it should not.\n# We add files to backup system tables, but I have not found where and when we delete those files. \n"
            },
            {
                "author_name": "vrodionov",
                "id": "16168693",
                "body": "Patch v1"
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16168703",
                "body": "Looks like a new table is introduced.\n\nHow you thought about achieving the same purpose with additional column family in backup table ?\n\nPlease summary design in description."
            },
            {
                "author_name": "elserj",
                "id": "16169471",
                "body": "{quote}\nLooks like a new table is introduced.\n\nHow you thought about achieving the same purpose with additional column family in backup table ?\n{quote}\n\nI had an offline talk with Vlad about this one. He explained that a table-level lock is grabbed which would introduce a deadlock scenario. The introduction of a separate table avoids this problem in that manner."
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16169485",
                "body": "{code}\n+    String coproc = conf.get(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY);\n+    String regionObserverClass = BackupObserver.class.getName();\n{code}\nWhat's the implication of the above change ? Is BackupManager loaded server side ?\n{code}\n+  public static HTableDescriptor getSystemTableForBulkLoadedDataDescriptor(Configuration conf) {\n{code}\ngetSystemTableForBulkLoadedDataDescriptor -> getTableDescriptorForBulkLoadedData\n{code}\n+  public static TableName getTableForBulkLoadedDataName(Configuration conf) {\n{code}\ngetTableForBulkLoadedDataName -> getTableNameForBulkLoadedData\n\n"
            },
            {
                "author_name": "elserj",
                "id": "16170246",
                "body": "{noformat}\n+    String coproc = conf.get(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY);\n+    String regionObserverClass = BackupObserver.class.getName();\n+    conf.set(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY, (coproc == null ? \"\" : coproc + \",\") +\n+        regionObserverClass);\n{noformat}\n\nMaybe {{coproc == null || coproc.isEmpty()}} instead? I'm thinking about the case when coproc is the empty string."
            },
            {
                "author_name": "elserj",
                "id": "16170290",
                "body": "bq. We add files to backup system tables, but I have not found where and when we delete those files.\n\nThis is a follow-on task?\n\nbq. Please summary design in description.\n\nThis would also be helpful. An updated description with your new findings would be great."
            },
            {
                "author_name": "vrodionov",
                "id": "16170818",
                "body": "Unfortunately, we have issue with the current implementation of bulk loading - no distcp support. All file copies are done from a client. This definitely,  does not scale. My bad, somehow I have missed that during the code review. "
            },
            {
                "author_name": "vrodionov",
                "id": "16170822",
                "body": "Reopened HBASE-14417. Working on the fix.\n\nCreated HBASE-18843"
            },
            {
                "author_name": "stack",
                "id": "16175272",
                "body": "Moving out of alpha-4. If it comes in before alpha-4, that'd be great but no critical to the coprocessor-focused release."
            },
            {
                "author_name": "vrodionov",
                "id": "16210357",
                "body": "Patch v2.cc: [~tedyu@apache.org], [~elserj]"
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16210381",
                "body": "Can you put the JIRA in 'Patch Available' state ?"
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16210382",
                "body": "I guess v2 shouldn't be run on top hadoop3 beta1 where 'java.io.IOException: Inconsistent sequence file' appears."
            },
            {
                "author_name": "vrodionov",
                "id": "16210414",
                "body": "{quote}\r\n guess v2 shouldn't be run on top hadoop3 beta1 where 'java.io.IOException: Inconsistent sequence file' appears.\r\n{quote}\r\nYour guess is correct, [~tedyu@apache.org] :)"
            },
            {
                "author_name": "hadoopqa",
                "id": "16210420",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} docker {color} | {color:red}  3m 12s{color} | {color:red} Docker failed to build yetus/hbase:5d60123. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12892947/HBASE-17852-v2.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/9192/console |\r\n| Powered by | Apache Yetus 0.4.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16210497",
                "body": "Can you put patch v1 on review board, followed by patch v2 ?\r\nThis way, it is easier to see the changes."
            },
            {
                "author_name": "vrodionov",
                "id": "16211395",
                "body": "Opened RB:\r\n\r\nhttps://reviews.apache.org/r/63155/"
            },
            {
                "author_name": "vrodionov",
                "id": "16213127",
                "body": "v3. cc: [~tedyu@apache.org]"
            },
            {
                "author_name": "vrodionov",
                "id": "16213230",
                "body": "v4. cc : [~tedyu@apache.org]"
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16213279",
                "body": "Is it possible to add new test case which shows the potential dead lock being solved by the patch ?"
            },
            {
                "author_name": "hadoopqa",
                "id": "16213369",
                "body": "| (/) *{color:green}+1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 20m 10s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 20s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 14s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m  9s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  3m 43s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 25s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 10s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  3m 18s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 33m 26s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 or 3.0.0-alpha4. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 36s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  3s{color} | {color:green} hbase-backup in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m  6s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 79m 33s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:af479c5 |\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893340/HBASE-17852-v4.patch |\r\n| Optional Tests |  asflicense  shadedjars  javac  javadoc  unit  findbugs  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux cc3889cadd5a 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh |\r\n| git revision | master / 89d3b0b |\r\n| Default Java | 1.8.0_141 |\r\n| findbugs | v3.1.0-RC3 |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/9281/testReport/ |\r\n| modules | C: hbase-backup U: hbase-backup |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/9281/console |\r\n| Powered by | Apache Yetus 0.4.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16213498",
                "body": "| (/) *{color:green}+1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 50s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 27s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 18s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 27s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m 41s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 46s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 18s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 18s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 22s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 52s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 56m 33s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 or 3.0.0-alpha4. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 14m 40s{color} | {color:green} hbase-backup in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 17s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 93m  0s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:af479c5 |\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12893340/HBASE-17852-v4.patch |\r\n| Optional Tests |  asflicense  shadedjars  javac  javadoc  unit  findbugs  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 41c0564a0570 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build@2/component/dev-support/hbase-personality.sh |\r\n| git revision | master / 89d3b0b |\r\n| Default Java | 1.8.0_141 |\r\n| findbugs | v3.1.0-RC3 |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/9283/testReport/ |\r\n| modules | C: hbase-backup U: hbase-backup |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/9283/console |\r\n| Powered by | Apache Yetus 0.4.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16213512",
                "body": "{quote}\r\nIs it possible to add new test case which shows the potential dead lock being solved by the patch ?\r\n{quote}\r\n\r\nWhat deadlock are you referring to, [~tedyu@apache.org]?"
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16213524",
                "body": "See comment from Sept 17th:\r\n\r\nhttps://issues.apache.org/jira/browse/HBASE-17852?focusedCommentId=16169471&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16169471"
            },
            {
                "author_name": "vrodionov",
                "id": "16213563",
                "body": "That is not a deadlock - its synchronization mechanism through access serialization. Only one critical operation at a time. "
            },
            {
                "author_name": "elserj",
                "id": "16215541",
                "body": "Comment on RB, but I think this looks fine (one follow-up issue, IMO).\r\n\r\n[~tedyu], do you have any objections? As far as I remember, the existing tests around bulk loaded files should be sufficient to test these changes."
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16215576",
                "body": "No objection from me."
            },
            {
                "author_name": "elserj",
                "id": "16216044",
                "body": "Thanks, Ted.\r\n\r\nFYI, [~stack], will be landing this on in alpha-4 tonight as well if it concerns you at all."
            },
            {
                "author_name": "stack",
                "id": "16216210",
                "body": "Whats going on in here? Is it written up anywhere? Are we implementing our own transaction management as the below comment would suggest?\r\n\r\n{code}\r\nSome notes after initial analysis of implementation of bulk-loaded files support\r\nRegionObserver coprocessor has pre-commit and post-commit code (kind of Tx), but only on a region level. No Tx support on a table level. This means that if (for some regions), loading files fail, we will be left with a partial data in both: table store physical location and in backup system table. What we need here is Tx support for the whole bulk load operation cluster-wide (prepare, commit). And hooks exposed for custom coprocessor (Master?).\r\nWhat will happen if bulk load operation runs at the same time as incremental backup? Backup will see partial updates, but it should not.\r\nWe add files to backup system tables, but I have not found where and when we delete those files.\r\n{code}\r\n\r\nI saw above note but no more since....\r\n\r\nOn looking at the patch, it looks like we have a backup system table and then a whole new table for bulk loaded materials. A whole system table just for bulk loaded files?"
            },
            {
                "author_name": "elserj",
                "id": "16216220",
                "body": "bq. On looking at the patch, it looks like we have a backup system table and then a whole new table for bulk loaded materials. A whole system table just for bulk loaded files?\r\n\r\nYeah, as I recall, Vlad ran into a case where, when trying to make sure that we didn't lose files in incremental backups, we grabbed a table-level lock. Because this lock was on the {{hbase:backup}} table, it introduced a situation where the system deadlocked. By introducing a table which is explicitly tracking the bulk-loaded files, it avoids this deadlock scenario.\r\n\r\nbq. Whats going on in here? Is it written up anywhere? Are we implementing our own transaction management as the below comment would suggest?\r\n\r\nMy understanding is that, functionality-wise, we're not actually changing anything. This is really just automatically deploying the BackupObserver instead of forcing it to be deployed automatically.\r\n\r\nI'm not sure if [~tedyu] has more depth to provide some more context. I do know that Vlad is traveling for familial reasons this week and is likely slow to respond.\r\n\r\n[~stack], would you prefer I hold off and re-tag this for beta-1?"
            },
            {
                "author_name": "yuzhihong@gmail.com",
                "id": "16216236",
                "body": "bq.  Ted Yu has more depth to provide some more context\r\n\r\nUnfortunately I don't. Hence the request for unit test showing the scenario."
            },
            {
                "author_name": "stack",
                "id": "16216239",
                "body": "bq.. stack, would you prefer I hold off and re-tag this for beta-1?\r\n\r\nYeah. Sounds like an RPC from a CP to a remote table. This is problematic (apart from yet-another-system-table though already a backup system table). Presumes remote table always up and ready, already-assigned and recovered ahead of the RPC. We have no means of guaranteeing this (This issue has 'fault-tolerance' in its summary). Thanks."
            },
            {
                "author_name": "stack",
                "id": "16216240",
                "body": "I moved it [~elserj] Thanks."
            },
            {
                "author_name": "elserj",
                "id": "16216263",
                "body": "Sure thing, boss. Not a problem.\r\n\r\nThanks for the book-keeping"
            },
            {
                "author_name": "elserj",
                "id": "16227068",
                "body": "bq. Yeah, as I recall, Vlad ran into a case where, when trying to make sure that we didn't lose files in incremental backups, we grabbed a table-level lock. Because this lock was on the hbase:backup table, it introduced a situation where the system deadlocked. By introducing a table which is explicitly tracking the bulk-loaded files, it avoids this deadlock scenario.\r\n\r\n[~vrodionov], when you have a moment, could you please describe this problem you ran into for us and the pros/cons on you chose a separate table as the way to work around it?"
            },
            {
                "author_name": "vrodionov",
                "id": "16227162",
                "body": "The issue with a single table (backup:system) arises from that fact that we have multiple independent writers: backup client application and BackupObserver (on each RS). In case of a backup failure we perform table rollback (restore from snapshot), which can result in a loss of  data being written by BackupObserver(s), that is why I introduced separate table to keep track of bulk loaded files."
            },
            {
                "author_name": "vrodionov",
                "id": "16234558",
                "body": "{quote}\r\nYeah. Sounds like an RPC from a CP to a remote table. This is problematic.\r\n{quote}\r\n\r\nThis is what Phoenix does for indexing AFAIK. I am not saying that this is a good idea or approach, but we have no other options "
            },
            {
                "author_name": "apurtell",
                "id": "16234841",
                "body": "bq. This is what Phoenix does for indexing AFAIK\r\nThis has brought down big clusters where I work. I'm not saying don't do it, but whatever depends on cross-server RPC should learn from the Phoenix example:\r\n- Never block on those remote RPCs in critical sections, holding locks, especially if you are running in a RPC handler already\r\n- Don't expect the remote resource to be available\r\n- Fail as quickly as possible and retry/clean up later\r\n\r\nLet me just assume this stuff is handled, but a walk through of what happens when the backup table goes away in different scenarios would be good. \r\n\r\nWe are also going to have these same issues when we migrate replication tracking state away from ZooKeeper into a system table. At some point we have to communicate off server for resilient state tracking, no ways around it. Maybe we can build up some kind of library for cross server RPC. "
            },
            {
                "author_name": "vrodionov",
                "id": "16234847",
                "body": "{quote}\r\nThis has brought down big clusters where I work. I'm not saying don't do it, but whatever depends on cross-server RPC should learn from the Phoenix example:\r\n{quote}\r\n\r\nHeavy writing during index updates what brings down clusters in Phoenix- not cross RS RPC calls. This is not the case for backup - we do not do any heavy writing at all.  Just record file names.\r\n\r\n"
            },
            {
                "author_name": "apurtell",
                "id": "16234850",
                "body": "bq. Heavy writing during index updates what brings down clusters in Phoenix- not cross RS RPC calls.\r\n\r\nYou are wrong. I am right. I was there, you were not. :-) There were implementation bugs and unfortunate/accidental complications that contributed to the problem, but we were brought down by cross RS RPC calls. "
            },
            {
                "author_name": "apurtell",
                "id": "16234859",
                "body": "So my point is, be careful."
            },
            {
                "author_name": "vrodionov",
                "id": "16234895",
                "body": "We do *single* RPC call from one RS (A) to another (B). This RPC call *terminates* at B. I do not see hot this can result in a distributed deadlock."
            },
            {
                "author_name": "elserj",
                "id": "16234903",
                "body": "bq. I do not see hot this can result in a distributed deadlock.\r\n\r\nI think Andrew is just trying to warn about the kind of problem that can be observed with Cross-RS RPCs. It's possible that some lock in one RS might accidentally preclude some other RPC from completing. Or, if one RS executes enough RPCs that saturate the handlers in another RS, we could soft-lock (degrade and appear to be stuck). I don't think he's trying to tell you that he believes there to be a concrete problem that exists in the implementation, just giving context to why \"Cross-RS RPCs\" are oft considered smells and raise the eyebrows they have raised.\r\n\r\nSorry if I'm putting words in your mouth (fingers), Andrew."
            },
            {
                "author_name": "vrodionov",
                "id": "16234908",
                "body": "[~elserj], I just wanted to point out, that, in a current implementation, the code is deadlock - safe. Timeouts are possible, as always in HBase, but this will fail bulk loader (this happens sometimes for other reasons). One can not put a finger on this and say - boooh , bad approach :)"
            },
            {
                "author_name": "vrodionov",
                "id": "16255810",
                "body": "Patch v5. Updated RB:\r\nhttps://reviews.apache.org/r/63155/"
            },
            {
                "author_name": "hadoopqa",
                "id": "16255936",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  9s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 24s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 51s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 28s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 14s{color} | {color:red} hbase-backup: The patch generated 4 new + 69 unchanged - 6 fixed = 73 total (was 75) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 38s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 50m 16s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 2.7.4 or 3.0.0-alpha4. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 13m 33s{color} | {color:green} hbase-backup in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 10s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 79m 22s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:eee3b01 |\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12898036/HBASE-17852-v5.patch |\r\n| Optional Tests |  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 6dd5cd4eb828 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh |\r\n| git revision | master / d8fb10c832 |\r\n| maven | version: Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z) |\r\n| Default Java | 1.8.0_151 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/9869/artifact/patchprocess/diff-checkstyle-hbase-backup.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/9869/testReport/ |\r\n| modules | C: hbase-backup U: hbase-backup |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/9869/console |\r\n| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "stack",
                "id": "16255991",
                "body": "bq. Let me just assume this stuff is handled, but a walk through of what happens when the backup table goes away in different scenarios would be good.\r\n\r\nIs the above answered? (Copied from earlier in this dialog).\r\n\r\n"
            },
            {
                "author_name": "stack",
                "id": "16256071",
                "body": "Looking at patch...\r\n\r\nWhy log two debug lines, one after the other? Logs should be terse. Two lines not needed.\r\n\r\n149\t      LOG.debug(\"Added region procedure manager: \" + regionProcedureClass);\r\n150\t      LOG.debug(\"Added region observer: \" + regionObserverClass);\r\n\r\nbq. The issue with a single table (backup:system) arises from that fact that we have multiple independent writers: backup client application and BackupObserver (on each RS). In case of a backup failure we perform table rollback (restore from snapshot), which can result in a loss of data being written by BackupObserver(s), that is why I introduced separate table to keep track of bulk loaded files.\r\n\r\nI don't understand the above. There is a backup failure, so we restore a snapshot? And an Observer can lose data? And so we introduce a new table just to hold bulk loaded files? I don't get it.\r\n\r\nLooking at comment on the back up bulkLoadTableName data member.... It says \"... * We keep all bulk loaded file references in a separate table\r\n127\t   * because we have to isolate general backup operations: create, merge etc\r\n128\t   * from activity of RegionObserver, which controls process of a bulk loading\r\n129\t   * {@link org.apache.hadoop.hbase.backup.BackupObserver}\"\r\n\r\nHow do general backup ops and bulk loaded files effect each other?\r\n\r\nIn the patch, it is called a ' Backup System table name for bulk loaded files' ... but it is not a system table? Is that so? And this is different from the BackupSystemTable.... which also is not a system table, right?\r\n\r\nBackupSystemTable does a checkSystemTable(); It is checking system tables, or not?\r\n\r\nIn hbase2, we have builders for the below instead...\r\n\r\n\r\n1381\t    HTableDescriptor tableDesc = new HTableDescriptor(getTableNameForBulkLoadedData(conf));\r\n\r\n\r\n\r\n\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16256124",
                "body": "{quote}\r\nHow do general backup ops and bulk loaded files effect each other?\r\n{quote}\r\n\r\nWhen backup fails, we restore backup system table from snapshot. If Observers write to the same table as general backup operation, some data from Observers may be lost when we restore table from snapshot. I thought, I explained that.\r\n\r\nSecond table keeps only bulk load related references. We do not care about consistency of this table, because bulk load is idempotent operation and can be repeated after failure. Partially written data in second table does not affect on BackupHFileCleaner plugin, because this data (list of bulk loaded files) correspond to a files which *have not been loaded yet successfully* and, hence - are not visible to the system\r\n\r\n\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16256126",
                "body": "{quote}\r\nIn the patch, it is called a ' Backup System table name for bulk loaded files' ... but it is not a system table? Is that so? And this is different from the BackupSystemTable.... which also is not a system table, right?\r\nBackupSystemTable does a checkSystemTable(); It is checking system tables, or not?\r\n{quote}\r\n\r\nThey are system from the point of view of a user. checkSystemTable checks backup system table. "
            },
            {
                "author_name": "stack",
                "id": "16256183",
                "body": "bq. When backup fails, we restore backup system table from snapshot.\r\n\r\nWhy would you restore a backup system table from a snapshot when a 'backup' fails? Backups are of user-space tables. How does this impinge on the backup 'system' table?\r\n\r\nbq. If Observers write to the same table as general backup operation, some data from Observers may be lost when we restore table from snapshot. I thought, I explained that.\r\n\r\nWhere?\r\n\r\nIs there a writeup on how this all works? (It is not in the user-guide)\r\n\r\nbq. They are system from the point of view of a user. checkSystemTable checks backup system table.\r\n\r\nThis is going to confuse. 'system' tables have a particular meaning in hbase."
            },
            {
                "author_name": "vrodionov",
                "id": "16256193",
                "body": "{quote}\r\nIs there a writeup on how this all works? (It is not in the user-guide)\r\n{quote}\r\nPlease, refer to a parent ticket for description what we perform in case of a failure\r\nhttps://issues.apache.org/jira/browse/HBASE-15227\r\n\r\nIn a few words, we take backup system table snapshot before backup/merge/delete/ and restore this table from snapshot back\r\nin case if operation fails to restore meta - data consistency in a backup system table"
            },
            {
                "author_name": "stack",
                "id": "16256202",
                "body": "Thanks for the pointer. I'd not read it previous. It does not answer my question though, \"Why would you restore a backup system table from a snapshot when a 'backup' fails? Backups are of user-space tables. How does this impinge on the backup 'system' table?\"\r\n\r\n\"....in case if operation fails to restore meta - data consistency in a backup system table...\"\r\n\r\nYeah, which operation? Which meta? A backup meta? What consistency needs to be maintained in the backup table?"
            },
            {
                "author_name": "vrodionov",
                "id": "16257502",
                "body": "Backup/Delete/Merge operations must be executed in a transactional manner. Backup system table keeps data (meta-data) which allows to run backups and others commands. During backup create, delete or merge, we update backup system table multiple times and do not want these updates to be partial ones (when operation fails), because *it will prevent further backups/deletes/merges after a failure*.\r\n\r\nThat is why we take snapshot of a backup system table and restore this table from snapshot, previously taken, in case of a command (create/delete/merge) failure.\r\n\r\nBy consistency of data I mean - no partial updates should be visible to a user after operation completes (either successfully or not). Partial updates in a backup system tables == corruption of a system table and MUST be avoided. When corruption happens - the only way to restore backup system is to truncate backup system table and re-run all backups in full mode.\r\n\r\n\r\n"
            },
            {
                "author_name": "stack",
                "id": "16257561",
                "body": "bq. That is why we take snapshot of a backup system table and restore this table from snapshot, previously taken, in case of a command (create/delete/merge) failure.\r\n\r\nWas this written up somewhere previously and the design shopped before others with buy-in?\r\n\r\nThe snapshot/restore of a whole system table strikes me as a bunch of moving parts. I have to ask why we got such an extreme? 2PC is tough-enough w/o offlining/restore of whole meta table. During restore, all clients are frozen out or something so they can't pollute the restored version? Restore is not atomic, right? We couldn't have something like a row-per-backup with a success tag if all went well (I've not been following closely -- pardon all the questions).\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16257564",
                "body": "v6 addresses some of the RB comments"
            },
            {
                "author_name": "stack",
                "id": "16257572",
                "body": "bq. v6 addresses some of the RB comments\r\n\r\nWhich comments were addressed?"
            },
            {
                "author_name": "vrodionov",
                "id": "16257580",
                "body": "{quote}\r\nThe snapshot/restore of a whole system table strikes me as a bunch of moving parts. \r\n{quote}\r\n\r\nThat is only one backup system table. \r\n\r\n{quote}\r\nI have to ask why we got such an extreme?\r\n{quote}\r\n\r\nWhat is so extreme here? Snapshot of a system table? I consider this approach much more simple and elegant than \r\nothers?\r\n\r\n{quote}\r\nDuring restore, all clients are frozen out or something so they can't pollute the restored version?\r\n{quote}\r\n\r\nYes. During table restore operation, all clients (of this table) must  be stopped.  In theory, this is not a hard requirement - it is just an advice. But,\r\nwe truncate table, before restore and this, definitely, may affect unexpectedly incoming writes. Any database system, which allows writes to a table during restore of a table? \r\n\r\nStack, if you have doubts in the implementation, I suggest you to go over code and find places where you think the code has issues.\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16257590",
                "body": "{quote}\r\nWhich comments were addressed?\r\n{quote}\r\nYou can find them as fixed on RB:\r\nhttps://reviews.apache.org/r/63155/"
            },
            {
                "author_name": "stack",
                "id": "16257621",
                "body": "My comments above are not in RB. Were they addressed?\r\n\r\nPatches should include description. Helps reviewers and those trying to follow-behind. Yours have none.\r\n\r\nYou don't use the suggested patch-making tool either in-spite of an earlier request.\r\n\r\nSo, the idea to offline a system table and then restore from a snapshot on error with clients 'advised' to stop writing as some-sort of 2PC got buy-in from others? This is 'fault-tolerance'? Is there a write-up somewhere that explains why we have to offline and then restore a whole table (whatever its size) just because a particular op failed and how it is more simple and elegant than other soluntions (what others?), I'd like to read it. Otherwise, I just don't get it (neither will the operator whose cron job failed because backup table was gone when it ran).\r\n\r\nYou suggest I review code. I have been reviewing code. Thats how we got here."
            },
            {
                "author_name": "hadoopqa",
                "id": "16257706",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  2m 25s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 11s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 41s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 18s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  6m  7s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 19s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 36s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 25s{color} | {color:red} hbase-backup: The patch generated 4 new + 69 unchanged - 6 fixed = 73 total (was 75) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  6m 23s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 64m 41s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 2.7.4 or 3.0.0-alpha4. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 13m 16s{color} | {color:green} hbase-backup in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m  9s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}101m 53s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:eee3b01 |\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12898274/HBASE-17852-v6.patch |\r\n| Optional Tests |  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 5973dfc868e3 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh |\r\n| git revision | master / ca74ec7740 |\r\n| maven | version: Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z) |\r\n| Default Java | 1.8.0_151 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/9901/artifact/patchprocess/diff-checkstyle-hbase-backup.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/9901/testReport/ |\r\n| modules | C: hbase-backup U: hbase-backup |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/9901/console |\r\n| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16257729",
                "body": "{quote}\r\nYou suggest I review code. I have been reviewing code. Thats how we got here.\r\n{quote}\r\n\r\nSure, you can start from very beginning, Stack. Go ahead."
            },
            {
                "author_name": "vrodionov",
                "id": "16257737",
                "body": "{quote}\r\nSo, the idea to offline a system table and then restore from a snapshot on error with clients 'advised' to stop writing as some-sort of 2PC got buy-in from others? This is 'fault-tolerance'? Is there a write-up somewhere that explains why we have to offline and then restore a whole table (whatever its size) just because a particular op failed and how it is more simple and elegant than other soluntions (what others?), I'd like to read it. Otherwise, I just don't get it (neither will the operator whose cron job failed because backup table was gone when it ran).\r\n{quote}\r\n\r\nStack, you just out of context right now, but I appreciate you want to spend so much time digging into my code once again. Thanks.\r\nYour are the only one who is objecting snapshot-based approach, but I am still waiting for a single argument why is this bad?\r\n"
            },
            {
                "author_name": "elserj",
                "id": "16257919",
                "body": "bq. This is going to confuse. 'system' tables have a particular meaning in hbase.\r\n\r\nShould be easy enough to rename with your IDE of choice, right Vlad? Avoiding overloading terminology is always a good idea. \"BackupMetadata\" and \"BackupBulkLoadFiles\"? (just pitching ideas)\r\n\r\nbq. The snapshot/restore of a whole system table strikes me as a bunch of moving parts. I have to ask why we got such an extreme? 2PC is tough-enough w/o offlining/restore of whole meta table. During restore, all clients are frozen out or something so they can't pollute the restored version? Restore is not atomic, right? We couldn't have something like a row-per-backup with a success tag if all went well (I've not been following closely \u2013 pardon all the questions).\r\n\r\nStack, are you essentially asking why this isn't implemented on top of ProcV2? I'm trying to read between the lines but am not sure if I'm inventing something that isn't there. There are definitely areas of the code in which the acknowledgement has already been made about a better implementation can be done. For example, clients _are_ \"frozen out\" right now from concurrent operations (a nod that backups, merges, and restores could be done concurrently). I think at this point, it would be more productive if we can say more \"there is something implicitly broken with this approach\" instead of \"there is a more elegant implementation to be had\". I don't think anyone is arguing against that.\r\n\r\nYes, rolling back the entire backup \"system\" table is overkill (for what may sometimes be deleting a single row/column -- the ACTIVE_SNAPSHOT as mentioned in the parent) and would take much longer that it could necessarily need to.\r\n\r\nbq. You suggest I review code. I have been reviewing code. Thats how we got here.\r\n\r\nAnd thank you for that. I know your intentions are good. We're all ultimately working towards a common goal here.\r\n\r\nbq. Sure, you can start from very beginning, Stack. Go ahead.\r\n\r\nThis isn't helpful and, likely, directly harmful :\\"
            },
            {
                "author_name": "elserj",
                "id": "16257920",
                "body": "{code}\r\nIn hbase2, we have builders for the below instead...\r\n\r\n1381 HTableDescriptor tableDesc = new HTableDescriptor(getTableNameForBulkLoadedData(conf));\r\n{code}\r\n\r\nI had left a similar comment on RB. This was fixed in v6 (patchset 5 on RB). I think the majority of other changes were suggestions I had left on RB -- have not explicitly checked, just going off of the \"issues\" being resolved."
            },
            {
                "author_name": "stack",
                "id": "16257930",
                "body": "bq. Stack, are you essentially asking why this isn't implemented on top of ProcV2?\r\nbq.  I think at this point, it would be more productive if we can say more \"there is something implicitly broken with this approach\" instead of \"there is a more elegant implementation to be had\".\r\n\r\nI am not asking for any particular implementation, to be clear. I'm just trying to understand and am having trouble digesting full restore of a meta table whatever the size or traffic on error. It strikes me as whack (You seem to at least agree it 'overkill'). There seems to be no write-up on the approach here ahead of piecemeal code drops (w/o overarching description of what all is entailed) so only way to figure it as best as I can ascertain, is via this really pleasant back and forth w the author.\r\n\r\nVlad, you seem to be doing your utmost to sabotage the delivery of this feature. The sort of answers you give us reviewers is one thing. Will operators who run into issues w/ this feature get the same treatment?\r\n\r\n"
            },
            {
                "author_name": "elserj",
                "id": "16259504",
                "body": "bq. I am not asking for any particular implementation, to be clear. I'm just trying to understand and am having trouble digesting full restore of a meta table whatever the size or traffic on error. It strikes me as whack (You seem to at least agree it 'overkill')\r\n\r\nGot it. To clarify my previous message, by \"overkill\" I only mean \"non-ideal\". As in, there is likely a more complicated solution that could accomplish the same net-effect with less computation+time required. I didn't mean to say that I believed using a snapshot and table-restore is invalid or wrong. My gut reaction is that the number of backups which would need to be retained in the system (e.g. rows in the hbase backup \"system\" table) would have to be quite large to even grow beyond a single region (many thousands to millions). As such, the snapshot restore isn't much more than grabbing the write lock and replacing some one data file and some Region metadata. This is on my list today to investigate confirm.\r\n\r\nTo try to move the conversation forward, I tend to agree with Vlad that I don't seen an inherent problem with the rollback-via-snapshot implementation. Architecturally, Vlad is using the snapshot feature exactly how it was intended to be used (shallow copy and restore of a table).\r\n\r\nbq. the idea to offline a system table and then restore from a snapshot on error with clients 'advised' to stop writing as some-sort of 2PC\r\n\r\nLet's revisit this again: in the parent JIRA issue, Vlad outlined two-cases. 1) Recover from a \"server-side\" failure and 2) recover from client side failure (and, probably, implicitly meant to include un-handled server-side failure conditions too).\r\n\r\nFor #1, clients don't need to do anything special (specifically mentioned on the parent issue). Mutual exclusion is already built in to manage the serialized state in the backup \"system\" table. So, we're just looking at the cost of these steps. Offline+snapshot+online should be one of these rock-solid features of the system.\r\n\r\nFor #2, we're in this situation that you outline. Per the concerns you raised about \"coordination\" (the special handshake, to use another metaphor), this seems mitigate-able via return code of the {{hbase backup}} and a prominent error message in this case. I don't know if either presently exist (Could you comment, [~vrodionov]?).\r\n\r\nBoth of these are predicated on the mutual exclusion of multiple clients at a higher level. Obviously, a finer grain exclusion strategy is desirable for multiple reasons, but, given my current understanding, I don't see any fundamental problem with this approach."
            },
            {
                "author_name": "vrodionov",
                "id": "16259911",
                "body": "{quote}\r\n2) recover from client side failure (and, probably, implicitly meant to include un-handled server-side failure conditions too).\r\n{quote}\r\n\r\nFor 2. we have backup repair tool, client will be asked to run repair tool next time he/she will try to run backup/restore/merge/delete"
            },
            {
                "author_name": "vrodionov",
                "id": "16260212",
                "body": "{quote}\r\nMy gut reaction is that the number of backups which would need to be retained in the system (e.g. rows in the hbase backup \"system\" table) would have to be quite large to even grow beyond a single region (many thousands to millions). As such, the snapshot restore isn't much more than grabbing the write lock and replacing some one data file and some Region metadata. This is on my list today to investigate confirm.\r\n{quote}\r\n\r\nYes, [~elserj], you are right. Backup system table for vast majority of deployments will fit a single region. It is a metadata - not a data. Therefore,  creation of snapshot and restoring from snapshot is a very lightweight operation. That is was a major reason I have chosen rollback-via-snapshot approach. "
            },
            {
                "author_name": "vrodionov",
                "id": "16261396",
                "body": "Patch v7. Renamed BackupSystemTable to BackupMetaTable."
            },
            {
                "author_name": "hadoopqa",
                "id": "16261499",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  9s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 19 new or modified test files. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 32s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 40s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m 26s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 22s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 13s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 31s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 15s{color} | {color:red} hbase-backup: The patch generated 6 new + 187 unchanged - 10 fixed = 193 total (was 197) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 52s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 52m  1s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 2.7.4 or 3.0.0-alpha4. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 59s{color} | {color:green} hbase-backup in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 26s{color} | {color:green} hbase-it in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 80m 52s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:eee3b01 |\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12898716/HBASE-17852-v7.patch |\r\n| Optional Tests |  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 13b57d82c6f1 3.13.0-133-generic #182-Ubuntu SMP Tue Sep 19 15:49:21 UTC 2017 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh |\r\n| git revision | master / 984e0ecfc4 |\r\n| maven | version: Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z) |\r\n| Default Java | 1.8.0_151 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/9952/artifact/patchprocess/diff-checkstyle-hbase-backup.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/9952/testReport/ |\r\n| modules | C: hbase-backup hbase-it U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/9952/console |\r\n| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16261586",
                "body": "v8  some checkstyle fixes"
            },
            {
                "author_name": "hadoopqa",
                "id": "16261687",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 19 new or modified test files. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 11s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 11s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 38s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m  6s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 23s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 17s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 16s{color} | {color:red} hbase-backup: The patch generated 3 new + 179 unchanged - 18 fixed = 182 total (was 197) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 26s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 47m  8s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 2.7.4 or 3.0.0-alpha4. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 10m 28s{color} | {color:green} hbase-backup in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 23s{color} | {color:green} hbase-it in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 18s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 75m 39s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:eee3b01 |\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12898743/HBASE-17852-v8.patch |\r\n| Optional Tests |  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux bd11d8af32a0 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh |\r\n| git revision | master / 3b2b22b5fa |\r\n| maven | version: Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z) |\r\n| Default Java | 1.8.0_151 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/9956/artifact/patchprocess/diff-checkstyle-hbase-backup.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/9956/testReport/ |\r\n| modules | C: hbase-backup hbase-it U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/9956/console |\r\n| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16265492",
                "body": "{quote}\r\nLet me just assume this stuff is handled, but a walk through of what happens when the backup table goes away in different scenarios would be good.\r\nIs the above answered? (Copied from earlier in this dialog).\r\n{quote}\r\n\r\nWhen backup meta table goes away, bulk load will continue because bul load observers do not write to main meta table. When second table (for bulk loaded files) gets offlined - bulk loading fails.\r\n\r\n  "
            },
            {
                "author_name": "stack",
                "id": "16269677",
                "body": "Write-up helps. Some questions.\r\n\r\nbq. When operation fails on a server side, we handle this failure by cleaning up partial data in backup destination, followed by restoring backup meta-table from a snapshot.\r\n\r\nWhy do this? Why not just mark the backup as corrupt and move on? (Why does an incomplete back-up freeze all backups -- which you say above .... I'm trying to understand).\r\n\r\nbq. When operation fails on a client side (abnormal termination, for example), next time user will try create/merge/delete he(she) will see error message, that system is in inconsistent state and repair is required, he(she) will need to run backup repair tool.\r\n\r\nWhat if its a cron job? Does this inability at moving on past failure make it so backup cannot be cron'd?\r\n\r\nbq. To avoid multiple writers to the backup system table (backup client and BackupObserver's) we introduce small table ONLY to keep listing of bulk loaded files.\r\n\r\nIf we weren't snapshotting/restoring the backup table, we wouldn't have to make a separate table to hold bulkloaded files? Is that so? (I'm not asking for a rewrite...).\r\n\r\nbq. Your are the only one who is objecting snapshot-based approach, but I am still waiting for a single argument why is this bad?\r\n\r\nI am asking questions to try and understand what is going on in here. When the response is terse or lean on info, I'm going to ask another question... and so on. As to whether snapshot/restore of the meta backup table is 'bad' or not, I'm still trying to understand why we would go to the extreme of offlining a whole table -- even though rare when in error and then it seems, this offlining is making it so we have to add yet another table just to hold bulk loaded files... Pardon my being slow.\r\n\r\nWhat of my review comments are addressed in latest patch?\r\n\r\nThanks."
            },
            {
                "author_name": "vrodionov",
                "id": "16269733",
                "body": "{quote}\r\nWhat of my review comments are addressed in latest patch?\r\n{quote}\r\n\r\nCan you post your comments on RB, Stack? "
            },
            {
                "author_name": "vrodionov",
                "id": "16269756",
                "body": "{quote}\r\nWhy do this? Why not just mark the backup as corrupt and move on? (Why does an incomplete back-up freeze all backups \u2013 which you say above .... I'm trying to understand).\r\n{quote}\r\n\r\nI have explained this many times already ... Restoring meta table in case of a backup failure is a necessary step to make future backups possible. We write some data during backup create, which is safe only of backup succeeds, such as last WAL roll timestamp per table-per RS. If backup fails, this data becomes corrupt w/o restoring meta table from snapshot.     \r\n\r\n{quote}\r\nWhat if its a cron job? Does this inability at moving on past failure make it so backup cannot be cron'd?\r\n{quote}\r\n\r\nRunning backup repair automatically in case of a  backup failure won't hurt and can be incorporated into cron job\r\n\r\n{quote}\r\nIf we weren't snapshotting/restoring the backup table, we wouldn't have to make a separate table to hold bulkloaded files? Is that so? (I'm not asking for a rewrite...).\r\n{quote}\r\n\r\nYes, correct.\r\n\r\n{quote}\r\nI am asking questions to try and understand what is going on in here. When the response is terse or lean on info, I'm going to ask another question... and so on. As to whether snapshot/restore of the meta backup table is 'bad' or not, I'm still trying to understand why we would go to the extreme of offlining a whole table \u2013 even though rare when in error and then it seems, this offlining is making it so we have to add yet another table just to hold bulk loaded files... Pardon my being slow.\r\n{quote}\r\n\r\nYes, the second table has been added long after the initial implementation was complete as a result of hardening bulk load support feature. You may consider this a s work-around, but it is pretty lightweight work-around. W/o snapshots, we have to make all the changes to meta table fully transactional ones. I think it is much harder.    \r\n\r\n\r\n\r\n\r\n"
            },
            {
                "author_name": "elserj",
                "id": "16271835",
                "body": "{quote}\r\nbq.    Why do this? Why not just mark the backup as corrupt and move on? (Why does an incomplete back-up freeze all backups \u2013 which you say above .... I'm trying to understand).\r\n\r\nI have explained this many times already ... Restoring meta table in case of a backup failure is a necessary step to make future backups possible. We write some data during backup create, which is safe only of backup succeeds, such as last WAL roll timestamp per table-per RS. If backup fails, this data becomes corrupt w/o restoring meta table from snapshot. \r\n{quote}\r\n\r\nThat's the technical explanation for why it is implemented as such, but I think the spirit of the question is more: \"what are the reasons for making this choice and is there something that could be done to make this less painful for users?\"\r\n\r\n{quote}\r\nbq.  What if its a cron job? Does this inability at moving on past failure make it so backup cannot be cron'd?\r\n\r\nRunning backup repair automatically in case of a backup failure won't hurt and can be incorporated into cron job\r\n{quote}\r\n\r\nIf the standard-procedures would be to run a repair blindly, why can't this be encapsulated in BackupDriver? Making the user's life easier is certainly beneficial."
            },
            {
                "author_name": "elserj",
                "id": "16271843",
                "body": "I think the only outstanding code-review comment from [~stack] was consolidation of two log messages into one (other questions were \"why the bulk load backup table\" which I think we better understand now and the use of TableDescriptorBuilder which I had already dinged and Vlad has fixed)."
            },
            {
                "author_name": "vrodionov",
                "id": "16271873",
                "body": "{quote}\r\nf the standard-procedures would be to run a repair blindly, why can't this be encapsulated in BackupDriver? Making the user's life easier is certainly beneficial.\r\n{quote}\r\n\r\nI can add auto-repair mode of execution for create/merge/delete.\r\n\r\nHere it is:\r\nhttps://issues.apache.org/jira/browse/HBASE-19380 (this is for 2.1 release)"
            },
            {
                "author_name": "stack",
                "id": "16271903",
                "body": "bq. Can you post your comments on RB, Stack?\r\n\r\nTraditionally it is the contributors' job keeping the feedback in order and making sure it all addressed whether in JIRA or RB. Not addressing reviewers feedback or dropping it w/o comment is a total no-no.\r\n\r\nbq. I have explained this many times already ... \r\n\r\nYou don't answer the question. You just make asserts that we have to rollback w/o justification other than backups 'become corrupt' or a backup is only 'safe' if it completes? Sounds like it needs to be 'transactional' but you don't describe the transaction (correct me if I'm wrong). I don't get why a completed backup can't just write a completion marker to the backup table. W/o it the backup is corrupt/incomplete and we just move on.\r\n\r\nbq. Running backup repair automatically in case of a backup failure won't hurt and can be incorporated into cron job\r\n\r\nDon't follow. An operator sets up a cron job. Works great for a few days. Then it stops. Operator needs to figure that he has to run a repair. Operator sets up two cron jobs? Or cron probes first for breakage...\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16271978",
                "body": "{quote}\r\nYou don't answer the question\r\n{quote}\r\n\r\nWhat question? What does \"corrupt\" mean? Why do I need to restore meta table? I am afraid, I can't add anything else to my answers above.\r\n\r\n{quote}\r\nDon't follow. An operator sets up a cron job. Works great for a few days. Then it stops. Operator needs to figure that he has to run a repair. Operator sets up two cron jobs? Or cron probes first for breakage...\r\n{quote}\r\n\r\nStops means fails. If cron job fails, operator will need to intervene, read logs, manuals and figure out that repair is required. Not a big deal, imo. We clearly log message, that repair tool has to be run. But for lazy operators I will add auto-repir mode of execution (see above ticket).\r\n\r\nI would like to add that repair will be required very rarely. *Any server-side backup failures are taken care of automatically* - no need to run repair tool. *Backup will be marked as failed in a backup meta table*. Only if client (cron in this case) exits abruptly, only then repair will be required. \r\n\r\nStack, can you be more technical and specific in your questions? The patch is no 8 already. Do you have any code - related questions and comments? If yes, then RB is the right place to put them on."
            },
            {
                "author_name": "vrodionov",
                "id": "16272016",
                "body": "v9. small fix in debug output"
            },
            {
                "author_name": "hadoopqa",
                "id": "16272106",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  2m  9s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 19 new or modified test files. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 25s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 15s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m 41s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 25s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 13s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 43s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 17s{color} | {color:red} hbase-backup: The patch generated 4 new + 179 unchanged - 18 fixed = 183 total (was 197) {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 670 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m 16s{color} | {color:red} The patch 384 line(s) with tabs. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m 17s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 54m 25s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.1 2.6.2 2.6.3 2.6.4 2.6.5 2.7.1 2.7.2 2.7.3 2.7.4 or 3.0.0-alpha4. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 16s{color} | {color:green} hbase-backup in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 28s{color} | {color:green} hbase-it in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 86m 27s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:eee3b01 |\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12899932/HBASE-17852-v9.patch |\r\n| Optional Tests |  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux b272d49628c9 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh |\r\n| git revision | master / abb535eef6 |\r\n| maven | version: Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z) |\r\n| Default Java | 1.8.0_151 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/10128/artifact/patchprocess/diff-checkstyle-hbase-backup.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-HBASE-Build/10128/artifact/patchprocess/whitespace-eol.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-HBASE-Build/10128/artifact/patchprocess/whitespace-tabs.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/10128/testReport/ |\r\n| modules | C: hbase-backup hbase-it U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/10128/console |\r\n| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "stack",
                "id": "16272169",
                "body": "Moving out of beta-1.  I ask questions and get rubbish back.\r\n\r\nContributor has wrong attitude. Operators who'd rather avoid reading logs and having to run repair tools are 'lazy'."
            },
            {
                "author_name": "vrodionov",
                "id": "16273141",
                "body": "My attitude? Nice. Maybe yours? I tried several times to explain you obvious things, but you still not getting them. \r\n\r\n{quote}\r\nask questions and get rubbish back.\r\n{quote}\r\n\r\nYou are not Linus,btw\r\n\r\n"
            },
            {
                "author_name": "mdrob",
                "id": "16273167",
                "body": "[~vrodionov] - I think Josh clarified Stack's question to explain why he posits that you \"didn't answer the question\"\r\n\r\nbq. That's the technical explanation for why it is implemented as such, but I think the spirit of the question is more: \"what are the reasons for making this choice and is there something that could be done to make this less painful for users?\""
            },
            {
                "author_name": "vrodionov",
                "id": "16273329",
                "body": "The reason is the simplicity of the implementation. Is not this obvious? Should I have spent time trying to implement Tx management instead? I doubt. Did I answer original question? I thought that we are technical guys and we need technical answers. It seems that I was wrong. \r\n\r\nUser intervention is required only if user kills backup process or it dies on a client side, for some other reason. All cluster side failures get repaired automatically. I see nothing painful for users here, [~mdrob], especially when I will implement auto-repair feature. This is the question actually, should we do repair automatically or we need to inform user, that there was abnormal failure of a last backup/merge/delete command and user need to run repair.\r\n\r\nDo not we still have *hbck* for this reason? Repair all the s**t which happens periodically in HBase cluster.\r\n\r\nMoving feature out of beta-1 only because someone does not like *attitude of a contributor* means that something is not going well in HBase community.  "
            },
            {
                "author_name": "mdrob",
                "id": "16273371",
                "body": "bq. The reason is the simplicity of the implementation. Is not this obvious?\r\nIt's not obvious, hence the need for clarifying questions. We're all collaborators here, Vlad, not adversaries. I haven't reviewed the code, so in this instance I'm a messenger and attempted mediator.\r\n\r\nbq. Should I have spent time trying to implement Tx management instead?\r\nMaybe!\r\n\r\nbq. Did I answer original question? I thought that we are technical guys and we need technical answers. It seems that I was wrong.\r\nI'm reminded of advice I got early in my software engineer career - it's easy to write code, it's less easy to write correct code, and it is actively hard to know which code to write.\r\n\r\nThe technical answer may have been obvious like you assert, but it's not a complete answer. Understanding how the operators will need to use this feature and how they will interact with it is important in building something that is useful to them.\r\n\r\nbq. User intervention is required only if user kills backup process or it dies on a client side, for some other reason.\r\nThere's lots of reasons that a process might die on the client side. Seems we may disagree on the frequency here.\r\n\r\nbq. Do not we still have hbck for this reason?\r\nSure, we can extend hbck to take care of these failures as well. Does it currently do so? I have no idea. Probably not, given that I don't think hbck works with hbase-2.0 due to AMv2.\r\n\r\nbq. Moving feature out of beta-1 only because someone does not like attitude of a contributor\r\nIt seems like the feature is being moved out because it's incomplete...\r\n\r\nAnd some earlier comments:\r\nbq. But for lazy operators...\r\nLazy operators are the best kind. They are the ones that automate things, the ones that prepare and test for failure so that they don't get called in the middle of the night, the ones that actually make sure that the ship stays sailing.\r\n\r\nbq. The patch is no 8 already\r\nI'm not sure what this is intended to prove. Sometimes I get patches right on the first try, sometimes it takes twenty tries."
            },
            {
                "author_name": "elserj",
                "id": "16273376",
                "body": "bq. Operators who'd rather avoid reading logs and having to run repair tools are 'lazy'.\r\n\r\nbq. Do not we still have hbck for this reason? Repair \\[...\\] which happens periodically in HBase cluster.\r\n\r\nLet me also expand on this: I would consider \"lazy\" as a virtue for operators. The system should automatically handle as much as possible. There's a fundamental difference between what hbck is and what `hbase backup repair` is: HBCK is fixing things that inadvertently happen server-side (hopefully, only around bugs which has since been fixed) whereas hbase-backup are completely client-driven. For example, something as benign as a user ctrl-C'ing a backup because they mis-typed the backup name or table being backed up would cause the backup table to need a repair.\r\n\r\nbq. This is the question actually, should we do repair automatically or we need to inform user, that there was abnormal failure of a last backup/merge/delete command and user need to run repair.\r\n\r\nI was about to write that I thought it was a no-brainer to blindly run a repair as a part of the BackupDriver, but now I wonder about the following:\r\n\r\nTake two administrators running backups, unaware of each other. Admin1 starts a backup on Table1. Before Admin1's backup finishes, Admin2 tries to do a backup on Table2. Could Admin2 preempt/fail Admin1's backup by running a {{hbase backup repair}} while Admin1 is using the system?\r\n\r\nIn other words: does {{hbase backup repair}} have the ability to differentiate between \"user is currently executing a backup\" and \"stale state exists in the table from an aborted/unfinished operation\"?"
            },
            {
                "author_name": "vrodionov",
                "id": "16273399",
                "body": "{quote}\r\nIt seems like the feature is being moved out because it's incomplete...\r\n{quote}\r\nReally, what is missing? Have you read the doc? Everything described in the B&R documentation have been implemented and tested.  I am running integration tests now on a scale, this is probably the last what developer is supposed to do before declaring feature fully complete? We are still at alpha stage, plenty time to harden the feature before beta-1 or 2."
            },
            {
                "author_name": "vrodionov",
                "id": "16273414",
                "body": "{quote}\r\nI'm not sure what this is intended to prove. Sometimes I get patches right on the first try, sometimes it takes twenty tries.\r\n{quote}\r\n\r\nNothing, actually except that when contributor submit a patch he expects comments/questions related to the code of a patch not a generic questions: Why have you chosen this design approach, especially when this approach has been discussed many times with other developers before. It is very hard and time consuming to explain everything from a  very beginning for  a person who wants to participate in a review, but is not familiar with the code. I have two committers on the feature [~tedyu@apache.org] and [~elserj] who have spent a lot of time working on the code. I trust them and although I appreciate help from other developers, I expect them to spend some time digging into the full feature code, before trying to review a particular patch (one of more than 100 already). This requires some commitment. \r\n\r\nAny question on the patch itself? "
            },
            {
                "author_name": "vrodionov",
                "id": "16273426",
                "body": "{quote}\r\nI was about to write that I thought it was a no-brainer to blindly run a repair as a part of the BackupDriver, but now I wonder about the following:\r\nTake two administrators running backups, unaware of each other. Admin1 starts a backup on Table1. Before Admin1's backup finishes, Admin2 tries to do a backup on Table2. Could Admin2 preempt/fail Admin1's backup by running a hbase backup repair while Admin1 is using the system?\r\nIn other words: does hbase backup repair have the ability to differentiate between \"user is currently executing a backup\" and \"stale state exists in the table from an aborted/unfinished operation\"?\r\n{quote}\r\n\r\nAll operations are serialized. Admin 2 will fail and will be waiting until first operation is complete (successfully or not). Multiple parallel backup sessions support is on roadmap for 2.1 release: https://issues.apache.org/jira/browse/HBASE-16391."
            },
            {
                "author_name": "mdrob",
                "id": "16273491",
                "body": "bq. not a generic questions: Why have you chosen this design approach, especially when this approach has been discussed many times with other developers before\r\nCan you point me at a design document that covers this?"
            },
            {
                "author_name": "vrodionov",
                "id": "16273529",
                "body": "The approach described in this JIRA description and in the parent ticket, [~mdrob]."
            },
            {
                "author_name": "mdrob",
                "id": "16273568",
                "body": "Thank you for pointing at the parent ticket, I missed that there was design doc in there.\r\n\r\nI'm worried about our current design choices for future concurrent backup design. Please correct my gaps in understanding here:\r\n\r\nCurrent approach, which is limited to single backup operation involves snapshot the backup state table (what you refer to as backup system table, but I think state is more appropriate term) and then if failure then we restore the state? In future are we going to have multiple tables in backup namespace for each table to be backed up so that we can have concurrent approaches? Otherwise the concurrent backup solution will be a complete rewrite I expect.\r\n\r\nDo backup operations have timeouts? I don't see them in the code, but could be looking at the wrong place."
            },
            {
                "author_name": "vrodionov",
                "id": "16273661",
                "body": "Yes, concurrent backup support will require some code rewrite. Rollback - via -snapshot won't work in this case probably, but this is internal implementation details and they won't affect users - backward compatibility is a must here.\r\n\r\nWe do not have any specific timeouts for backups - only those, low level HBase timeouts for RPC and distributed procedure ops. If they time out - backup fails.  "
            },
            {
                "author_name": "mdrob",
                "id": "16273856",
                "body": "Hmm... I don't think we can publish backup/restore without HBASE-16391 in a 2.0 release. I'd like to have confidence that the feature is rock solid before telling users that it's ok to use, parallel operations seems like a major shortcoming to me.\r\n\r\nMaybe this isn't the right JIRA to discuss this, apologies for stepping into the crossfire here. I left a few comments on the RB, will continue to look after reading more of the general design."
            },
            {
                "author_name": "appy",
                "id": "16273901",
                "body": "Few questions:\r\nPardon me if my high level analysis of design is off. Is following correct description of current design?\r\nStart bulkload from client -> each RS gets its RPC for prepare and then do the actual bulkload --> Internally when bulk load is done,BackupObserver#postBulkLoadHFile writes paths to backup table.\r\nAnd to avoid full backup failures from affecting incremental backups (due to snapshot restore), you are putting bulk loaded paths data in a separate table, right?\r\n\r\n----\r\nThere were concerns above on cross RS rpc to write the paths, I was trying to think of easiest way of avoiding that. How about returning the [map as part of response here|https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java#L2251] and then issue rpc to master from client side. It's easy and safer to retry from client side if remote resource isn't available.\r\nI'd suggest going extra step, an easy one though -  collect all paths on client side and do single put request. That'll give two benefits:\r\n- Will make it transactional incremental backup\r\n- If put fails repeatedly, you can either fail bulk load altogether, or throw error to user telling that these bulk loaded files failed to backup and that only full backup will include them. \r\n\r\n----\r\nWhat happens if during an ongoing backup, i create some backup sets, but then the backup fails? Snapshot restore will remove my backup sets?"
            },
            {
                "author_name": "vrodionov",
                "id": "16273953",
                "body": "{quote}\r\nAnd to avoid full backup failures from affecting incremental backups (due to snapshot restore), you are putting bulk loaded paths data in a separate table, right?\r\n{quote}\r\n\r\nYes, you are right.\r\n\r\n{quote}\r\nWhat happens if during an ongoing backup, i create some backup sets, but then the backup fails? Snapshot restore will remove my backup sets?\r\n{quote}\r\n\r\nYes. Any modifications to backup meta table *during* backup create/merge/delete session, which *fails* will be lost. It is the limitation currently. As a simple workaround, any updates (*backup sets operations only*) to backup meta table can be disabled during these sessions. "
            },
            {
                "author_name": "vrodionov",
                "id": "16273955",
                "body": "{quote}\r\nThere were concerns above on cross RS rpc to write the paths, I was trying to think of easiest way of avoiding that. How about returning the map as part of response here and then issue rpc to master from client side. It's easy and safer to retry from client side if remote resource isn't available.\r\nI'd suggest going extra step, an easy one though - collect all paths on client side and do single put request. That'll give two benefits:\r\nWill make it transactional incremental backup\r\nIf put fails repeatedly, you can either fail bulk load altogether, or throw error to user telling that these bulk loaded files failed to backup and that only full backup will include them.\r\n{quote}\r\n\r\nI will think about this and will get back to you, [~appy] shortly. Thanks, for suggestion."
            },
            {
                "author_name": "mdrob",
                "id": "16273958",
                "body": "When we switch away from restore-via-snapshot and have proper transactions, does that mean this extra table will go away?"
            },
            {
                "author_name": "vrodionov",
                "id": "16274008",
                "body": "{quote}\r\nWhen we switch away from restore-via-snapshot and have proper transactions, does that mean this extra table will go away?\r\n{quote}\r\n\r\nYes, but you need to understand, that proper Tx management is a hard task in this case. It is even harder than classic Tx management. DB Tx got rollbacked automatically in case of a collision (updates to the same record), but we have to merge these updates correctly, because backup sessions always update shared records. Is it worth doing? Only Admin can run backups and what is the use case when Admin starts two sessions in parallel if he can run them serially?"
            },
            {
                "author_name": "elserj",
                "id": "16274659",
                "body": "bq. Hmm... I don't think we can publish backup/restore without HBASE-16391 in a 2.0 release. I'd like to have confidence that the feature is rock solid before telling users that it's ok to use, parallel operations seems like a major shortcoming to me.\r\n\r\nLet's dig in on this some more, [~mdrob]. B&R is much more of an \"administrative function\" as opposed to a \"client feature\". My general expectation would be that, most aggressively, HBase admins (a couple of people) would run incremental backups on the order of \"hours\", e.g. incremental backup every 8 hours . I could see the extremely paranoid wanting to do incremental backups every hour over some collection of tables which _could_ cause issues if we can only execute one backup operation at a time (I'm thinking along the lines of 3 backup sets, incremental backups every hour, merging of those backups every few hours, full backup every day, etc).\r\n\r\nAs such, my opinion differs in that I don't see the lack of concurrent backup operations being a major impediment for \"most\" users. I completely agree with you that there will be some users in which this limitation would be problematic on what they want to use it, but, even for these edge cases, B&R without this would still have value to them. I think getting this feature into the hands of users (with the extremely clear caveats on current implementation) would actually better serve the feature than letting it fester more on JIRA. Thoughts?"
            },
            {
                "author_name": "mdrob",
                "id": "16274700",
                "body": "The problem is that backups and restores cannot occur simultaneously.\r\n\r\nLet's say that we have a hypothetical system set to backup nightly (via cron or some other non-interactive mechanism). While this full system backup is running, some problem is detected with a single table and it is determined that the correct course of action is to restore that table. Given that we base backup and restore operations on snapshots, this should be straightforward - the large backup can continue to run while a restore of the specific table (to the last known good state) is put in place without waiting for the backup to complete.\r\n\r\nThe current options appear to be wait until the backup finishes (maybe ok, depending on sizes/bandwidth/etc...) or cancel the nightly backup (very bad, especially  if we have to do manual cleanup of things). I think the position that I'm slowly arriving to is that we shouldn't be recommending nightly backups at all to folks - this is probably a use case better served by replication and having a wider variety of sinks available instead of only another HBase cluster (HBASE-18846 might help with this?). That said we would still need some kind of bulk restore wrappers. Let me think on this more..."
            },
            {
                "author_name": "mdrob",
                "id": "16274706",
                "body": "bq. because backup sessions always update shared records.\r\nThis sounds like a design flaw.\r\n\r\nbq. what is the use case when Admin starts two sessions in parallel if he can run them serially\r\nCan an admin queue sessions? That would help the user experience quite a bit until we get parallel sessions. (Not that I'm suggesting that this is either necessary or sufficient; I would much rather see effort towards a proper solution rather than temporary workaround after workaround, but queued operations may be useful in other contexts.)"
            },
            {
                "author_name": "vrodionov",
                "id": "16274742",
                "body": "{quote}\r\nThe problem is that backups and restores cannot occur simultaneously.\r\n{quote}\r\nThis is much easier to fix, than concurrent backup sessions support, because restore does not access meta table.  \r\n{quote}\r\nCan an admin queue sessions? That would help the user experience quite a bit until we get parallel sessions. \r\n{quote}\r\nNo, this is client -side operation. Can someone queue *hbck*?\r\n\r\n"
            },
            {
                "author_name": "elserj",
                "id": "16274744",
                "body": "bq. The current options appear to be wait until the backup finishes (maybe ok, depending on sizes/bandwidth/etc...) or cancel the nightly backup (very bad, especially if we have to do manual cleanup of things).\r\n\r\n\"manual cleanup\" is only running the {{hbase backup repair}} command. I don't feel like that is too onerous and goes back to my original feelings (acceptable limitation to get this in the hands of users).\r\n\r\nbq. Can an admin queue sessions? That would help the user experience quite a bit until we get parallel sessions. (Not that I'm suggesting that this is either necessary or sufficient; I would much rather see effort towards a proper solution rather than temporary workaround after workaround, but queued operations may be useful in other contexts.)\r\n\r\nSpecifically, the client does a checkAndPut to specifics coordinates in the backup table and throws an exception when that fails. Remember that backups are client driven (per some design review from a long time ago), so queuing is tough to reason about (we have no \"centralized\" execution system to use). At a glance, it seems pretty straightforward to add some retry/backoff semantics to {{BackupSystemTable#startBackupExclusiveOperation()}}. Isn't exactly a \"queue\", but it would ease the pain you allude to."
            },
            {
                "author_name": "mdrob",
                "id": "16274762",
                "body": "bq. This is much easier to fix, than concurrent backup sessions support, because restore does not access meta table.\r\nRestore doesn't need to update the set of backup files (to remove references to no longer referenced files?) If we backup, add data, incremental backup, add data, restore to first backup, add data, incremental backup this will all work correctly without the Restore having needed to update any backup state? Where do I look for how this works?\r\n\r\nbq. No, this is client -side operation. Can someone queue hbck?\r\nIt's client-side... kind of. We're encouraging folks to automate these operations, comparing to hbck isn't the same.\r\n\r\nbq. \"manual cleanup\" is only running the hbase backup repair command. I don't feel like that is too onerous and goes back to my original feelings (acceptable limitation to get this in the hands of users).\r\nYea, this is probably ok. I thought we still had a pretty hairy situation here.\r\n\r\nbq. Specifically, the client does a checkAndPut to specifics coordinates in the backup table and throws an exception when that fails. Remember that backups are client driven (per some design review from a long time ago), so queuing is tough to reason about (we have no \"centralized\" execution system to use). At a glance, it seems pretty straightforward to add some retry/backoff semantics to BackupSystemTable#startBackupExclusiveOperation(). Isn't exactly a \"queue\", but it would ease the pain you allude to.\r\nYea, retry would be good. File a JIRA?"
            },
            {
                "author_name": "appy",
                "id": "16275107",
                "body": "bq. To try to move the conversation forward, I tend to agree with Vlad that I don't seen an inherent problem with the rollback-via-snapshot implementation\r\n\r\nThe inherent problem with rollback-via-snapshot approach is - one operation is taking \"exclusive lock\" on the backup meta table, and that too in a very weird way.\r\nIt's weird because:\r\n1) It behaves like exclusive lock in certain cases. (We only restore on failure, i.e. exclusion kicks in only on failures. That leads to waterfall of issues mentioned below.)\r\n2) Some other operations on that table are following \"exclusion\" semantics (via locking a row), while others not.\r\n\r\nAs a result of which we see so many problems:\r\n1) Different table for incremental backup data: The problem is not that there's a different table, that's fine, but the reason which led to it.\r\n2) You can't run any other command in parallel! No restores (data loss, services are down, everything is on fire, oh but there's a cron job taking backup, so i can't do zilch!?), no merges, no deletes (prod cluster, running out of space, i have to wait for backup before i can free up space?). That's just absurd.\r\n3) Other successful commands are rolled back silently. If an operator add/remove/delete sets, they are gone if a totally different thing fails!\r\n4) During restore, backup table goes offline, cron job attempts backup and fails.\r\n\r\nOthers:\r\n- And then the issues around cross RS RPC from observer during bulk load. Was the alternative suggested yesterday considered in the design? Was there any alternative that was considered?\r\n- (Ref: Bulk loads) Backups are very important. But more important is user being able to load their data and use it. Preventing user to work with their data by putting backup in load path and failing everything if backup doesn't work is plain wrong. Find a different way to backup bulk load data without affecting core read/write paths.\r\n\r\nSo, I'd say, there are many things implicitly broken with current design.\r\n\r\nStrong -1 on shipping it unless they are fixed."
            },
            {
                "author_name": "vrodionov",
                "id": "16275203",
                "body": "[~appy],\r\n\r\n# Only Admin user can run backups, therefore, there is no need to run multiple backups in parallel. Admin can run them in a single backup command.\r\n# Restore can be run in parallel with other commands. That is artificial limitation and can be removed easily. It means Admin can run backups session and multiple restore sessions in parallel. I personally, do not see or anticipate strong request to allow multiple backup sessions in parallel. I advise you to go through doc and you fill find and easy to work-around parallel sessions by combining them into single one, [~appy]\r\n# There is no issues with cross - RPC in backup case, because RPC call is a single hop and, hence, deadlock - free\r\n# Failure of BackupObserver to record bulk loaded file with result in bulk load failure - yes. *But I do not see an alternative here*, do you? We need to record *all bulk loaded file names and store them persistently before bulk load operation completes*. Do you have an idea, how can this be achieved, w/o failing bulk load itself and w/o touching hbase core code? \r\n\r\nThe only thing I agree here is support for parallel deletes, merges and if we will introduce this support we can easily add multiple backup session support for free.\r\n\r\nI personally, was very impressed by you, guys, you spent so much time looking for design and implementation flaws, when time was running out literally, during this week. Good job. Why haven't you done this couple months before? \r\n\r\nSome of the \"problems\" you described looks kind of artificial:\r\n{quote}\r\n4) During restore, backup table goes offline, cron job attempts backup and fails.\r\n{quote}\r\n\r\nAnd what? Table goes offline? Why would not you or somebody else to spend time and fix this offline regions/tables crap HBase is full of? \r\n\r\n\r\n"
            },
            {
                "author_name": "elserj",
                "id": "16280521",
                "body": "bq. Yea, retry would be good. File a JIRA?\r\n\r\nHBASE-19441. Tagged in the \"Phase 4\" umbrella.\r\n\r\n{quote}\r\nSo, I'd say, there are many things implicitly broken with current design.\r\n\r\nStrong -1 on shipping it unless they are fixed.\r\n{quote}\r\n\r\n[~appy], while I appreciate the keen eye you're applying here, how can we move forward here? I know it's very frustrating for Vlad to have something that he's already built+tested be taken back to the drawing board abruptly. Do you truly feel like this feature is harmful as compared to what the current implementation is?\r\n\r\nI'd prefer to see this land in master, then we take the concept back to the drawing board and, with all of your help, we revisit this and come up with a design and implementation that works for concurrent backup sessions (as Vlad has this on the Phase4 roadmap already)."
            },
            {
                "author_name": "elserj",
                "id": "16324439",
                "body": "bq. I'd prefer to see this land in master, then we take the concept back to the drawing board and, with all of your help, we revisit this and come up with a design and implementation that works for concurrent backup sessions (as Vlad has this on the Phase4 roadmap already).\r\n\r\nPing [~appy]."
            },
            {
                "author_name": "appy",
                "id": "16327774",
                "body": "I'm fine with this landing in master.\r\nI'll try to take a thorough look at the code after 2.0 release (If i miss that, i'll consider myself ineligible for casting any +/- 1).\r\nOf the top of my head, I think the main areas to touch upon are:\r\n- Make backups concurrent\r\n- Use procedure framework: Long-standing request. The procv2 framework has features like locking, queuing operations, etc. Replication is already moving to it. I don't see a reason why backup can't too.\r\n- Can't use CP hooks for incremental backup. Backup should/will become first class feature - more important and critical than Coprocessor.\r\n- There should be some basic access control, if only, limiting everything to ADMIN (like RS group recently did in HBASE-19483)"
            },
            {
                "author_name": "vrodionov",
                "id": "16329466",
                "body": "So, we are returning back to procV2 and tight integration with hbase-server? [~appy], we used to have this before, but had to move everything from hbase-server more than a year ago by request from [~stack]. Therefore, I need [~stack] +1 on this plan before I start working on refactoring again."
            },
            {
                "author_name": "appy",
                "id": "16329494",
                "body": "Replication is doing it, but it's already in hbase-server module so it's definitely not the ideal example. But I think its possible to do procv2 + backup without tight integration with hbase-server i.e. while keeping things in separate module. Won't be surprised if it requires some refactoring/small design improvements in proc2 code itself, but that'll be all for good. Maybe backup module become the poster face for \"Building features with procv2\" and we make replication do the same."
            },
            {
                "author_name": "appy",
                "id": "16329538",
                "body": "Adding more, so the likely dependencies will end up being:\r\nhbase-backup --> hbase-server\r\nhbase-backup --> hbase-procedure\r\n\r\nB&R's functionalities will be implementations of Procedure/StateMachineProcedure and use masterServices.getMasterProcedureExecutor().submitProcedure() to get stuff done. I do see some deps issues, but we can come with solutions. One thing we should definitely try to stay away from is, merging the code back in hbase-server module.\r\nFor now, what do you think are the biggest blockers for making procv2 + backup happen [~vrodionov]? You're right, we should definitely discuss concrete design/problems/solutions before staring with the refactoring. Can help with design review. "
            },
            {
                "author_name": "appy",
                "id": "16329577",
                "body": "I said hbase-backup --> hbase-server above because backup needs snapshot. Our dependencies are in a state of orgy right now, otherwise following would have been perfect shape to be in.\r\n !screenshot-1.png|width=800! \r\n That said, we should still be able to do procv2+backup without having to refactor other modules out of hbase-server."
            },
            {
                "author_name": "hadoopqa",
                "id": "16329597",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  4s{color} | {color:red} HBASE-17852 does not apply to master. Rebase required? Wrong Branch? See https://yetus.apache.org/documentation/0.6.0/precommit-patchnames for help. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887458/HBASE-17852-v1.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/11094/console |\r\n| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16329642",
                "body": "I will rebase patch to the current master. The majority of this code (but not all) went into master in HBASE-19568 btw."
            },
            {
                "author_name": "vrodionov",
                "id": "16329648",
                "body": "{quote}For now, what do you think are the biggest blockers for making procv2 + backup happen\u00a0[~vrodionov]?\r\n{quote}\r\nIf we could do procv2 implementation w/o getting into server <- backup dependency, then no blockers.\u00a0 But this won't be possible, for sure:\r\n\r\n{quote}\r\n - Can't use CP hooks for incremental backup. Backup should/will become first class feature - more important and critical than Coprocessor.\r\n\r\n{quote}\r\n\r\n\u00a0"
            },
            {
                "author_name": "hadoopqa",
                "id": "16329767",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |\r\n| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HBASE-17852 does not apply to master. Rebase required? Wrong Branch? See https://yetus.apache.org/documentation/0.6.0/precommit-patchnames for help. {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887458/HBASE-17852-v1.patch |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/11096/console |\r\n| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "16331092",
                "body": "| (/) *{color:green}+1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  4m 56s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Findbugs executables are not available. {color} |\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 19 new or modified test files. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 26s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 35s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 41s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  6m 27s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 31s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 41s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 20s{color} | {color:green} hbase-backup: The patch generated 0 new + 162 unchanged - 2 fixed = 162 total (was 164) {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} The patch hbase-it passed checkstyle {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  5m 57s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 24m 53s{color} | {color:green} Patch does not cause any errors with Hadoop 2.6.5 2.7.4 or 3.0.0. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 25s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 13m  8s{color} | {color:green} hbase-backup in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 46s{color} | {color:green} hbase-it in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 69m 21s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hbase:eee3b01 |\r\n| JIRA Issue | HBASE-17852 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12906516/HBASE-17852-v10.patch |\r\n| Optional Tests |  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 550f5f3def54 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HBASE-Build/component/dev-support/hbase-personality.sh |\r\n| git revision | master / 09ffbb5b68 |\r\n| maven | version: Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z) |\r\n| Default Java | 1.8.0_151 |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/11117/testReport/ |\r\n| modules | C: hbase-backup hbase-it U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/11117/console |\r\n| Powered by | Apache Yetus 0.6.0   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "elserj",
                "id": "16336001",
                "body": "{quote}I'm fine with this landing in master.\r\n I'll try to take a thorough look at the code after 2.0 release (If i miss that, i'll consider myself ineligible for casting any +/- 1).\r\n{quote}\r\nThanks Appy. Your input is appreciated. I think the direction you're proposing makes sense, but it might be premature to push this forward right now. I've been seeing some funkiness in branch-2 work around procv2. Letting it burn in on branch-2 first is probably a good idea. I'm glad we can help Vlad move forward now and revisit this later.\r\n\r\nI'm +1 on this one. Committing it now to master."
            },
            {
                "author_name": "elserj",
                "id": "16336297",
                "body": "Pushed to master. Thanks for sticking with this, Vlad."
            },
            {
                "author_name": "vrodionov",
                "id": "16338635",
                "body": "[~appy] wrote:\r\n{quote}Of the top of my head, I think the main areas to touch upon are:\r\n - Make backups concurrent\r\n - Use procedure framework: Long-standing request. The procv2 framework has features like locking, queuing operations, etc. Replication is already moving to it. I don't see a reason why backup can't too.\r\n - Can't use CP hooks for incremental backup. Backup should/will become first class feature - more important and critical than Coprocessor.\r\n - There should be some basic access control, if only, limiting everything to ADMIN (like RS group recently did in\u00a0HBASE-19483){quote}\r\nOK,\u00a0\r\nh4. Concurrent backups\r\n\r\nIt is doable, but ...\r\n # Will require transaction management support - it complicates implementations a lot. We will need to provide full isolation of operations and complex conflict resolutions on commit. And rollback?\r\n # Complicates testing, as well - a lot. Imagine all different possible collisions between create, merge, delete sessions\r\n\r\nWhat I suggest is a slightly different approach:\r\n # Make restore operations concurrent\r\n # Implement fair queuing for *create-merge-delete* sessions\r\n # *create-merge-restore* executions will be serialized (one-by-one), but from user's point of view they will run, kind of, in parallel.\u00a0\r\n\r\nYES/NO\r\nh4. Use procedure framework\u00a0\r\n\r\nShort answer - no. I will wait until procv2 becomes more mature and robust. I do not want to build new feature on a foundation of a new feature. Too risky in my opinion. NO\r\nh4. Can't use CP hooks for incremental backup\r\n\r\nCurrently backup lives in a separate module and we would like to keep it there. There is no need for the tight integration of a HBase core and backup and therefore, CP is the only our option here. NO\r\nh4. Access control\r\n\r\nCurrently, only ADMIN can run backups/restore/delete/merge operations, but we do not enforce this explicitly, so we should probably, do the access right check *before* starting critical operation. YES.\r\n\r\n\u00a0\r\n\r\n[~appy], [~elserj] - comments?\r\n\r\n\u00a0"
            },
            {
                "author_name": "appy",
                "id": "16339026",
                "body": "Man....(lightly shaking head side-to-side)...such strong responses when we are trying to scope out needed work/design changes for a better B&R in 2.1. Please work with me here..smile.\r\n\r\nWhy do you believe procv2 is new feature? It's being used for core HBase functionality - create, delete tables, etc since 1.2 release.\r\nWhat would make it mature & robust enough for B&R in your opinion?\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16339615",
                "body": "[~appy] we have fully functional module already, but you suggest rewriting 20%-40% of code.\u00a0 That is why my response is so strong. As for procv2, I have heard a lot from other developers who worked on procv2-related\u00a0 bugs.\u00a0\r\n\r\nBackup is not like table create, truncate, split etc - it is in its own league.\u00a0\r\n\r\n{quote}\r\n\r\nWhat would make it mature & robust enough for B&R in your opinion?\r\n\r\n{quote}\r\n\r\n2-3 years of bug fixing :)\r\n\r\nFor concurrent sessions, as I said already it is doable, but will require a lot of efforts, especially in testing. Can you tell me, why do you think my approach (suggested) is not good enough? In a case when only ADMIN can run operations, what is the use case, where truly concurrent sessions are must?\u00a0\u00a0\r\n\r\n\u00a0"
            },
            {
                "author_name": "appy",
                "id": "16344160",
                "body": "I see only patch v10 in the attached files, and all it's doing is changing name of BackupSystemTable to BackupMetaTable. It's far from what the title says - \"Add Fault Tolerance....\". What am i missing?\r\n\r\n{color:red}Edit: {color} *Please never delete attachments which formed the basis of earlier discussions in a jira*"
            },
            {
                "author_name": "vrodionov",
                "id": "16344163",
                "body": "I will quote myself\r\n\r\n{quote}\r\n\r\nI will rebase patch to the current master. The majority of this code (but not all) went into master in\u00a0HBASE-19568\u00a0btw.\r\n\r\n{quote}"
            },
            {
                "author_name": "appy",
                "id": "16344219",
                "body": "Forget all the design discussion, that's not important anymore.\r\n----\r\nHBASE-19568 had basically everything that was objected in the reviews here, why wasn't it brought to the attention of people who raised objections?  The title/reason of that jira reason doesn't matter.\r\nI see it as a really sly move - going behind community and committed changes which were heavily objected against, by using separate jira.\r\n\r\nPing reviewers of other jira: [~elserj] [~tedyu] \r\nPing [~stack] [~apurtell]"
            },
            {
                "author_name": "vrodionov",
                "id": "16344228",
                "body": "Nope, it turned out that this patch (HBASE-17852) also fixes the issue raised in HBASE-19568, that is why it was committed (with refactoring code stripped down). No conspiracy here.\u00a0 Besides this, I thought that we have agreed on pushing this to the master branch and continue working on a critical changes after that?\u00a0"
            },
            {
                "author_name": "elserj",
                "id": "16344231",
                "body": "{quote}\r\nHBASE-19568 had basically everything that was objected in the reviews here, why wasn't it brought to the attention of people who raised objections? The title/reason of that jira reason doesn't matter.\r\nI see it as a really sly move - going behind community and committed changes which were heavily objected against, by using separate jira.\r\n{quote}\r\n\r\n[~appy], let's take a step back, please. I called this out to your attention -- I was under the impression that, based on your earlier comment ([here|https://issues.apache.org/jira/browse/HBASE-17852?focusedCommentId=16327774&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16327774]) that you were OK of this implementation landing in master as-is.\r\n\r\nHBASE-19568 was used to commit to master (with what I thought was your blessing) while we continue to use this JIRA issue to flesh out design because of all of the discussion that has happened. If I misunderstood you or poorly asked you the question, let's take that over to HBASE-19568 and get a revert in place. There was nothing malicious intending to happen here."
            },
            {
                "author_name": "appy",
                "id": "16344258",
                "body": "bq. Nope, it turned out that this patch (HBASE-17852) also fixes the issue raised in HBASE-19568, that is why it was committed (with refactoring code stripped down).\r\nNot a justification!\r\nDid you not use the patch in this jira to fix HBASE-19568?\r\nWasn't the said patch objected against committing by multiple members of the community?\r\nDid you brought to anyone's attention, who raised the objections (me/stack/andrew/[~mdrob]), the fact that you were committing these changes.\r\n\r\nbq. No conspiracy here.  Besides this, I thought that we have agreed on pushing this to the master branch and continue working on a critical changes after that? \r\nYou really think that'd work? People can match timestamps, you committed 4 days before i even replied back!\r\n"
            },
            {
                "author_name": "appy",
                "id": "16344272",
                "body": "bq. ....There was nothing malicious intending to happen here\r\nI'll can't believe that because I can't believe that\r\n-  he started fixing the other jira from clean slate and somehow mysteriously ended up with exact same diff as was here, and which we all were against.\r\n- he had random urge to delete all previous 9 patches from this jira, but not from phase1 jira HBASE-14030 or phase2 jira HBASE-14123, which both have like 40 patches each\r\n"
            },
            {
                "author_name": "vrodionov",
                "id": "16344287",
                "body": "{quote}\r\n\r\nhe had random urge to delete all previous 9 patches from this jira\r\n\r\n{quote}\r\n\r\nNo conspiracy here as well. I was not able to submit patch v10 due to some Apache Jira issues and had to remove all previous patches to be able to submit v10.\u00a0"
            },
            {
                "author_name": "stack",
                "id": "16344302",
                "body": "{quote}The majority of this code (but not all) went into master in\u00a0HBASE-19568\u00a0btw.\r\n{quote}\r\nThe majority of 'HBASE-17852 Add Fault tolerance to HBASE-14417 (Support bulk loaded files in incremental backup)', a contentious issue, went into another\u00a0commit named 'HBASE-19568\u00a0Restore of HBase table using incremental backup doesn't restore rows from an earlier incremental backup' with no outline of what made it and what did not, and no changeset explaination. There is no release note. The two JIRAs are not even linked.\r\n{quote}Nope, it turned out that this patch (HBASE-17852) also fixes the issue raised in\u00a0HBASE-19568, that is why it was committed (with refactoring code stripped down). No conspiracy here.\u00a0 \u00a0\r\n{quote}\r\nBut hang on, now the patch here on 'fault tolerance' fixes issues over in the 'restore rows' issue,\u00a0-HBASE-19568?-\r\n\r\nI can see how\u00a0[~appy]\u00a0might arrive at his assessment.\r\n\r\nOn the 'declarations', the first offers options free of context or explanation.\r\n\r\nThis one I find interesting:\r\n\r\n\u00a0#\u00a0Use procedure framework:\u00a0 Short answer - no. I will wait until procv2 becomes more mature and robust. I do not want to build new feature on a foundation of a new feature. Too risky in my opinion. NO\r\n\r\n....when we are talking about a hbase3 (possibly) feature and when there is no alternative.\r\n\r\nAnyway, keeping it short.\r\n\r\n\u00a0"
            },
            {
                "author_name": "vrodionov",
                "id": "16344307",
                "body": "{quote}\r\n\r\nWasn't the said patch objected against committing by multiple members of the community?\r\n\r\n{quote}\r\n\r\n\u00a0\r\n\r\nCalm down,\u00a0 [~appy]. We are not doing anything criminal here. The result of these two patches is what you have agreed on personally :\r\n\r\nhttps://issues.apache.org/jira/browse/HBASE-17852?focusedCommentId=16327774&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16327774"
            },
            {
                "author_name": "elserj",
                "id": "16344310",
                "body": "bq. I'll can't believe that because I can't believe that..\n\n [~appy], truly, boss, if you weren't giving your blessing on the fix going into master, say so and I'll revert it when next at a computer. I was operating under the assumption that we had time to address design and not look gift-contribtuion(horses) in the mouth.\n\nThe rest of this is a product of some heavy-handedness about the busted Yetus after the JIRA upgrade.\n\nNot trying to tell you something different than what you think happened, did. Trying to express that I thought you were ok with this plan against master (not branch-2)."
            },
            {
                "author_name": "appy",
                "id": "16344314",
                "body": "Okay, f**k it, I really don't want to waste anymore of my time fighting some fight. It's obvious from events what happened here, and that it shouldn't have - makes me very sad and angry.\r\nI leave its further handling to PMC.\r\nAt the very least, someone lost my basic trust and respect.\r\n\r\n\r\n"
            },
            {
                "author_name": "appy",
                "id": "16344327",
                "body": "Commit date is 12th jan\r\n{noformat}\r\ncommit a5601c8eac6bfcac7d869574547f505d44e49065\r\nAuthor:     Vladimir Rodionov <vrodionov@hortonworks.com>\r\nAuthorDate: Wed Jan 10 16:26:09 2018 -0800\r\nCommit:     Josh Elser <elserj@apache.org>\r\nCommitDate: Fri Jan 12 13:13:17 2018 -0500\r\n\r\n    HBASE-19568: Restore of HBase table using incremental backup doesn't restore rows from an earlier incremental backup\r\n\r\n    Signed-off-by: Josh Elser <elserj@apache.org>\r\n{noformat}\r\n\r\nI did say it was okay to go in master, but that's like 4 days after the commit - 2018-01-16T12:46:19-0800\r\n\r\n{color:red}Edit{color}\r\nBtw, anyone wishing to cross check the diffs.\r\nDiff on this jira that wasn't approved (until 16th) : https://reviews.apache.org/r/63155/diff/5/\r\nDiff on HBASE-19568 which was committed on 12th: https://issues.apache.org/jira/secure/attachment/12905579/HBASE-19568-v4.patch"
            },
            {
                "author_name": "vrodionov",
                "id": "16344341",
                "body": "{quote}\r\n\r\nI did say it was okay to go in master, but that's like 4 days after the commit - 2018-01-16T12:46:19-0800\r\n\r\n{quote}\r\n\r\nOK, there was an issue found during QA testing -\u00a0HBASE-19568. It turned out that HBASE-17852 fixes the issue. Let us say I have had two options:\r\n # Find out which part of HBASE-17852 fixes the issue and create smaller HBASE-19568- specific patch\r\n # Apply HBASE-17852 patch directly (with some refactoring part stripped down)\u00a0 \u00a0 \u00a0\u00a0\r\n  \r\nSo I have chosen the latter one. Reasons: time, time, time. We can revert HBASE-19568 back if there are so many objections. \r\n"
            },
            {
                "author_name": "appy",
                "id": "16344359",
                "body": "If your mental radar doesn't tick-off in loud red alarms between the time of choosing the second approach and getting someone to commit it, that's precisely the reason why i can't trust you.\r\n"
            },
            {
                "author_name": "elserj",
                "id": "16344404",
                "body": "bq. I did say it was okay to go in master, but that's like 4 days after the commit - 2018-01-16T12:46:19-0800\n\nI'm not messing with you, [~appy]. Check the push logs/comments on the other JIRA issue.. I swear to you that I did not push this until after I heard back from you. My guess is that this is due to me using git-am or cherry picking a commit from a local branch."
            },
            {
                "author_name": "elserj",
                "id": "16344407",
                "body": "Also, again, if you want this reverted, please say so."
            },
            {
                "author_name": "elserj",
                "id": "16344416",
                "body": "[~vrodionov] that's also plenty shit-slinging from you too on the matter. Thanks."
            },
            {
                "author_name": "elserj",
                "id": "16344441",
                "body": "bq. I'm not messing with you, Appy. Check the push logs/comments on the other JIRA issue.. I swear to you that I did not push this until after I heard back from you. My guess is that this is due to me using git-am or cherry picking a commit from a local branch.\r\n\r\nMy apologies, Appy. I am wrong. I apparently got impatient and pushed this because there was silence from the Dec 6th mention and the Jan 12th re-ping. My intent was not to squash your opinions, but to avoid being blocked if you were not interested/busy as seemed might be the case.\r\n\r\nIf you have since changed your mind about the reduced patch hitting master, my offer to revert stands. My apologies again for arguing with you while in the wrong."
            },
            {
                "author_name": "appy",
                "id": "16344578",
                "body": "bq. My intent was not to squash your opinions, but to avoid being blocked if you were not interested/busy as seemed might be the case.\r\nThat's reasonable. Sorry for the delay on my part.\r\nLeaving a comment saying the same and that post-hoc reviews would be welcome would have avoided whole situation.\r\nThe only thing that put me off was, finding it out myself, followed by certain tone in certain comments.\r\n\r\n[~elserj] i believe you. Everyone makes mistakes from time-to-time, i'm certain i must have done too. Always happy with \"acknowledge, learn, and move past them\" way. All's good (between us two).\r\n"
            }
        ],
        "comments_predictions": [
            [
                2316975,
                "HBASE-17852",
                "Some notes after initial analysis of implementation of bulk-loaded files support\n\n# RegionObserver coprocessor has pre-commit and post-commit code (kind of Tx), but only on a region level. No Tx support on a table level. This means that if (for some regions), loading files fail, we will be left with a partial data in both: table store physical location and in backup system table. What we need here is Tx support for the whole bulk load operation cluster-wide (prepare, commit). And hooks exposed for custom coprocessor (Master?). \n# What will happen if bulk load operation runs at the same time as  incremental backup? Backup will see partial updates, but it should not.\n# We add files to backup system tables, but I have not found where and when we delete those files. \n",
                {
                    "property": {
                        "confidence": 0.006673133932054043,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008349013514816761,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.11313202232122421,
                        "prediction": false
                    }
                }
            ],
            [
                2316978,
                "HBASE-17852",
                "{quote}\nLooks like a new table is introduced.\n\nHow you thought about achieving the same purpose with additional column family in backup table ?\n{quote}\n\nI had an offline talk with Vlad about this one. He explained that a table-level lock is grabbed which would introduce a deadlock scenario. The introduction of a separate table avoids this problem in that manner.",
                {
                    "property": {
                        "confidence": 0.010892443358898163,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0033956568222492933,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.2500283122062683,
                        "prediction": false
                    }
                }
            ],
            [
                2316979,
                "HBASE-17852",
                "{code}\n+    String coproc = conf.get(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY);\n+    String regionObserverClass = BackupObserver.class.getName();\n{code}\nWhat's the implication of the above change ? Is BackupManager loaded server side ?\n{code}\n+  public static HTableDescriptor getSystemTableForBulkLoadedDataDescriptor(Configuration conf) {\n{code}\ngetSystemTableForBulkLoadedDataDescriptor -> getTableDescriptorForBulkLoadedData\n{code}\n+  public static TableName getTableForBulkLoadedDataName(Configuration conf) {\n{code}\ngetTableForBulkLoadedDataName -> getTableNameForBulkLoadedData\n\n",
                {
                    "property": {
                        "confidence": 0.005483771674335003,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0051269265823066235,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.017919091507792473,
                        "prediction": false
                    }
                }
            ],
            [
                2316980,
                "HBASE-17852",
                "{noformat}\n+    String coproc = conf.get(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY);\n+    String regionObserverClass = BackupObserver.class.getName();\n+    conf.set(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY, (coproc == null ? \"\" : coproc + \",\") +\n+        regionObserverClass);\n{noformat}\n\nMaybe {{coproc == null || coproc.isEmpty()}} instead? I'm thinking about the case when coproc is the empty string.",
                {
                    "property": {
                        "confidence": 0.005612920504063368,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00834839791059494,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.00918667297810316,
                        "prediction": false
                    }
                }
            ],
            [
                2316981,
                "HBASE-17852",
                "bq. We add files to backup system tables, but I have not found where and when we delete those files.\n\nThis is a follow-on task?\n\nbq. Please summary design in description.\n\nThis would also be helpful. An updated description with your new findings would be great.",
                {
                    "property": {
                        "confidence": 0.03470681235194206,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0033816052600741386,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.4842831492424011,
                        "prediction": false
                    }
                }
            ],
            [
                2316982,
                "HBASE-17852",
                "Unfortunately, we have issue with the current implementation of bulk loading - no distcp support. All file copies are done from a client. This definitely,  does not scale. My bad, somehow I have missed that during the code review. ",
                {
                    "property": {
                        "confidence": 0.0047656032256782055,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.025978537276387215,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007564454339444637,
                        "prediction": false
                    }
                }
            ],
            [
                2317000,
                "HBASE-17852",
                "Comment on RB, but I think this looks fine (one follow-up issue, IMO).\r\n\r\n[~tedyu], do you have any objections? As far as I remember, the existing tests around bulk loaded files should be sufficient to test these changes.",
                {
                    "property": {
                        "confidence": 0.00604218989610672,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005465655121952295,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014810031279921532,
                        "prediction": false
                    }
                }
            ],
            [
                2317003,
                "HBASE-17852",
                "Whats going on in here? Is it written up anywhere? Are we implementing our own transaction management as the below comment would suggest?\r\n\r\n{code}\r\nSome notes after initial analysis of implementation of bulk-loaded files support\r\nRegionObserver coprocessor has pre-commit and post-commit code (kind of Tx), but only on a region level. No Tx support on a table level. This means that if (for some regions), loading files fail, we will be left with a partial data in both: table store physical location and in backup system table. What we need here is Tx support for the whole bulk load operation cluster-wide (prepare, commit). And hooks exposed for custom coprocessor (Master?).\r\nWhat will happen if bulk load operation runs at the same time as incremental backup? Backup will see partial updates, but it should not.\r\nWe add files to backup system tables, but I have not found where and when we delete those files.\r\n{code}\r\n\r\nI saw above note but no more since....\r\n\r\nOn looking at the patch, it looks like we have a backup system table and then a whole new table for bulk loaded materials. A whole system table just for bulk loaded files?",
                {
                    "property": {
                        "confidence": 0.005541065242141485,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004859208595007658,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018940236419439316,
                        "prediction": false
                    }
                }
            ],
            [
                2317004,
                "HBASE-17852",
                "bq. On looking at the patch, it looks like we have a backup system table and then a whole new table for bulk loaded materials. A whole system table just for bulk loaded files?\r\n\r\nYeah, as I recall, Vlad ran into a case where, when trying to make sure that we didn't lose files in incremental backups, we grabbed a table-level lock. Because this lock was on the {{hbase:backup}} table, it introduced a situation where the system deadlocked. By introducing a table which is explicitly tracking the bulk-loaded files, it avoids this deadlock scenario.\r\n\r\nbq. Whats going on in here? Is it written up anywhere? Are we implementing our own transaction management as the below comment would suggest?\r\n\r\nMy understanding is that, functionality-wise, we're not actually changing anything. This is really just automatically deploying the BackupObserver instead of forcing it to be deployed automatically.\r\n\r\nI'm not sure if [~tedyu] has more depth to provide some more context. I do know that Vlad is traveling for familial reasons this week and is likely slow to respond.\r\n\r\n[~stack], would you prefer I hold off and re-tag this for beta-1?",
                {
                    "property": {
                        "confidence": 0.019665595144033432,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0029293016996234655,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.5347005724906921,
                        "prediction": true
                    }
                }
            ],
            [
                2317006,
                "HBASE-17852",
                "bq.. stack, would you prefer I hold off and re-tag this for beta-1?\r\n\r\nYeah. Sounds like an RPC from a CP to a remote table. This is problematic (apart from yet-another-system-table though already a backup system table). Presumes remote table always up and ready, already-assigned and recovered ahead of the RPC. We have no means of guaranteeing this (This issue has 'fault-tolerance' in its summary). Thanks.",
                {
                    "property": {
                        "confidence": 0.005007570143789053,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007060350850224495,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02369730919599533,
                        "prediction": false
                    }
                }
            ],
            [
                2317009,
                "HBASE-17852",
                "bq. Yeah, as I recall, Vlad ran into a case where, when trying to make sure that we didn't lose files in incremental backups, we grabbed a table-level lock. Because this lock was on the hbase:backup table, it introduced a situation where the system deadlocked. By introducing a table which is explicitly tracking the bulk-loaded files, it avoids this deadlock scenario.\r\n\r\n[~vrodionov], when you have a moment, could you please describe this problem you ran into for us and the pros/cons on you chose a separate table as the way to work around it?",
                {
                    "property": {
                        "confidence": 0.007464691065251827,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0037042000330984592,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04554688185453415,
                        "prediction": false
                    }
                }
            ],
            [
                2317010,
                "HBASE-17852",
                "The issue with a single table (backup:system) arises from that fact that we have multiple independent writers: backup client application and BackupObserver (on each RS). In case of a backup failure we perform table rollback (restore from snapshot), which can result in a loss of  data being written by BackupObserver(s), that is why I introduced separate table to keep track of bulk loaded files.",
                {
                    "property": {
                        "confidence": 0.012529289349913597,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003423035843297839,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.37144121527671814,
                        "prediction": false
                    }
                }
            ],
            [
                2317011,
                "HBASE-17852",
                "{quote}\r\nYeah. Sounds like an RPC from a CP to a remote table. This is problematic.\r\n{quote}\r\n\r\nThis is what Phoenix does for indexing AFAIK. I am not saying that this is a good idea or approach, but we have no other options ",
                {
                    "property": {
                        "confidence": 0.007104920223355293,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006513930857181549,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012734231539070606,
                        "prediction": false
                    }
                }
            ],
            [
                2317012,
                "HBASE-17852",
                "bq. This is what Phoenix does for indexing AFAIK\r\nThis has brought down big clusters where I work. I'm not saying don't do it, but whatever depends on cross-server RPC should learn from the Phoenix example:\r\n- Never block on those remote RPCs in critical sections, holding locks, especially if you are running in a RPC handler already\r\n- Don't expect the remote resource to be available\r\n- Fail as quickly as possible and retry/clean up later\r\n\r\nLet me just assume this stuff is handled, but a walk through of what happens when the backup table goes away in different scenarios would be good. \r\n\r\nWe are also going to have these same issues when we migrate replication tracking state away from ZooKeeper into a system table. At some point we have to communicate off server for resilient state tracking, no ways around it. Maybe we can build up some kind of library for cross server RPC. ",
                {
                    "property": {
                        "confidence": 0.004827673081308603,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01462352741509676,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.1571607142686844,
                        "prediction": false
                    }
                }
            ],
            [
                2317013,
                "HBASE-17852",
                "{quote}\r\nThis has brought down big clusters where I work. I'm not saying don't do it, but whatever depends on cross-server RPC should learn from the Phoenix example:\r\n{quote}\r\n\r\nHeavy writing during index updates what brings down clusters in Phoenix- not cross RS RPC calls. This is not the case for backup - we do not do any heavy writing at all.  Just record file names.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.003261663718149066,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.014735790900886059,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03356214985251427,
                        "prediction": false
                    }
                }
            ],
            [
                2317014,
                "HBASE-17852",
                "bq. Heavy writing during index updates what brings down clusters in Phoenix- not cross RS RPC calls.\r\n\r\nYou are wrong. I am right. I was there, you were not. :-) There were implementation bugs and unfortunate/accidental complications that contributed to the problem, but we were brought down by cross RS RPC calls. ",
                {
                    "property": {
                        "confidence": 0.006393137853592634,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.023575764149427414,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007348034996539354,
                        "prediction": false
                    }
                }
            ],
            [
                2317017,
                "HBASE-17852",
                "bq. I do not see hot this can result in a distributed deadlock.\r\n\r\nI think Andrew is just trying to warn about the kind of problem that can be observed with Cross-RS RPCs. It's possible that some lock in one RS might accidentally preclude some other RPC from completing. Or, if one RS executes enough RPCs that saturate the handlers in another RS, we could soft-lock (degrade and appear to be stuck). I don't think he's trying to tell you that he believes there to be a concrete problem that exists in the implementation, just giving context to why \"Cross-RS RPCs\" are oft considered smells and raise the eyebrows they have raised.\r\n\r\nSorry if I'm putting words in your mouth (fingers), Andrew.",
                {
                    "property": {
                        "confidence": 0.008950804360210896,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0029600029811263084,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.05434979498386383,
                        "prediction": false
                    }
                }
            ],
            [
                2317018,
                "HBASE-17852",
                "[~elserj], I just wanted to point out, that, in a current implementation, the code is deadlock - safe. Timeouts are possible, as always in HBase, but this will fail bulk loader (this happens sometimes for other reasons). One can not put a finger on this and say - boooh , bad approach :)",
                {
                    "property": {
                        "confidence": 0.005605611950159073,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010585405863821507,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008683999069035053,
                        "prediction": false
                    }
                }
            ],
            [
                2317021,
                "HBASE-17852",
                "bq. Let me just assume this stuff is handled, but a walk through of what happens when the backup table goes away in different scenarios would be good.\r\n\r\nIs the above answered? (Copied from earlier in this dialog).\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.014802435413002968,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002327174646779895,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.10416354984045029,
                        "prediction": false
                    }
                }
            ],
            [
                2317022,
                "HBASE-17852",
                "Looking at patch...\r\n\r\nWhy log two debug lines, one after the other? Logs should be terse. Two lines not needed.\r\n\r\n149\t      LOG.debug(\"Added region procedure manager: \" + regionProcedureClass);\r\n150\t      LOG.debug(\"Added region observer: \" + regionObserverClass);\r\n\r\nbq. The issue with a single table (backup:system) arises from that fact that we have multiple independent writers: backup client application and BackupObserver (on each RS). In case of a backup failure we perform table rollback (restore from snapshot), which can result in a loss of data being written by BackupObserver(s), that is why I introduced separate table to keep track of bulk loaded files.\r\n\r\nI don't understand the above. There is a backup failure, so we restore a snapshot? And an Observer can lose data? And so we introduce a new table just to hold bulk loaded files? I don't get it.\r\n\r\nLooking at comment on the back up bulkLoadTableName data member.... It says \"... * We keep all bulk loaded file references in a separate table\r\n127\t   * because we have to isolate general backup operations: create, merge etc\r\n128\t   * from activity of RegionObserver, which controls process of a bulk loading\r\n129\t   * {@link org.apache.hadoop.hbase.backup.BackupObserver}\"\r\n\r\nHow do general backup ops and bulk loaded files effect each other?\r\n\r\nIn the patch, it is called a ' Backup System table name for bulk loaded files' ... but it is not a system table? Is that so? And this is different from the BackupSystemTable.... which also is not a system table, right?\r\n\r\nBackupSystemTable does a checkSystemTable(); It is checking system tables, or not?\r\n\r\nIn hbase2, we have builders for the below instead...\r\n\r\n\r\n1381\t    HTableDescriptor tableDesc = new HTableDescriptor(getTableNameForBulkLoadedData(conf));\r\n\r\n\r\n\r\n\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.006856345105916262,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0036843609996140003,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.1160622090101242,
                        "prediction": false
                    }
                }
            ],
            [
                2317023,
                "HBASE-17852",
                "{quote}\r\nHow do general backup ops and bulk loaded files effect each other?\r\n{quote}\r\n\r\nWhen backup fails, we restore backup system table from snapshot. If Observers write to the same table as general backup operation, some data from Observers may be lost when we restore table from snapshot. I thought, I explained that.\r\n\r\nSecond table keeps only bulk load related references. We do not care about consistency of this table, because bulk load is idempotent operation and can be repeated after failure. Partially written data in second table does not affect on BackupHFileCleaner plugin, because this data (list of bulk loaded files) correspond to a files which *have not been loaded yet successfully* and, hence - are not visible to the system\r\n\r\n\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.021564431488513947,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003446610178798437,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.49976933002471924,
                        "prediction": false
                    }
                }
            ],
            [
                2317024,
                "HBASE-17852",
                "{quote}\r\nIn the patch, it is called a ' Backup System table name for bulk loaded files' ... but it is not a system table? Is that so? And this is different from the BackupSystemTable.... which also is not a system table, right?\r\nBackupSystemTable does a checkSystemTable(); It is checking system tables, or not?\r\n{quote}\r\n\r\nThey are system from the point of view of a user. checkSystemTable checks backup system table. ",
                {
                    "property": {
                        "confidence": 0.005312285851687193,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004222252871841192,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04201604425907135,
                        "prediction": false
                    }
                }
            ],
            [
                2317025,
                "HBASE-17852",
                "bq. When backup fails, we restore backup system table from snapshot.\r\n\r\nWhy would you restore a backup system table from a snapshot when a 'backup' fails? Backups are of user-space tables. How does this impinge on the backup 'system' table?\r\n\r\nbq. If Observers write to the same table as general backup operation, some data from Observers may be lost when we restore table from snapshot. I thought, I explained that.\r\n\r\nWhere?\r\n\r\nIs there a writeup on how this all works? (It is not in the user-guide)\r\n\r\nbq. They are system from the point of view of a user. checkSystemTable checks backup system table.\r\n\r\nThis is going to confuse. 'system' tables have a particular meaning in hbase.",
                {
                    "property": {
                        "confidence": 0.007411112543195486,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0038542798720300198,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03656098619103432,
                        "prediction": false
                    }
                }
            ],
            [
                2317026,
                "HBASE-17852",
                "{quote}\r\nIs there a writeup on how this all works? (It is not in the user-guide)\r\n{quote}\r\nPlease, refer to a parent ticket for description what we perform in case of a failure\r\nhttps://issues.apache.org/jira/browse/HBASE-15227\r\n\r\nIn a few words, we take backup system table snapshot before backup/merge/delete/ and restore this table from snapshot back\r\nin case if operation fails to restore meta - data consistency in a backup system table",
                {
                    "property": {
                        "confidence": 0.010672631673514843,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0038646759930998087,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.2966434359550476,
                        "prediction": false
                    }
                }
            ],
            [
                2317027,
                "HBASE-17852",
                "Thanks for the pointer. I'd not read it previous. It does not answer my question though, \"Why would you restore a backup system table from a snapshot when a 'backup' fails? Backups are of user-space tables. How does this impinge on the backup 'system' table?\"\r\n\r\n\"....in case if operation fails to restore meta - data consistency in a backup system table...\"\r\n\r\nYeah, which operation? Which meta? A backup meta? What consistency needs to be maintained in the backup table?",
                {
                    "property": {
                        "confidence": 0.007891932502388954,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003247726010158658,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04657427594065666,
                        "prediction": false
                    }
                }
            ],
            [
                2317028,
                "HBASE-17852",
                "Backup/Delete/Merge operations must be executed in a transactional manner. Backup system table keeps data (meta-data) which allows to run backups and others commands. During backup create, delete or merge, we update backup system table multiple times and do not want these updates to be partial ones (when operation fails), because *it will prevent further backups/deletes/merges after a failure*.\r\n\r\nThat is why we take snapshot of a backup system table and restore this table from snapshot, previously taken, in case of a command (create/delete/merge) failure.\r\n\r\nBy consistency of data I mean - no partial updates should be visible to a user after operation completes (either successfully or not). Partial updates in a backup system tables == corruption of a system table and MUST be avoided. When corruption happens - the only way to restore backup system is to truncate backup system table and re-run all backups in full mode.\r\n\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.07412198185920715,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0033578656148165464,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.8036230206489563,
                        "prediction": true
                    }
                }
            ],
            [
                2317029,
                "HBASE-17852",
                "bq. That is why we take snapshot of a backup system table and restore this table from snapshot, previously taken, in case of a command (create/delete/merge) failure.\r\n\r\nWas this written up somewhere previously and the design shopped before others with buy-in?\r\n\r\nThe snapshot/restore of a whole system table strikes me as a bunch of moving parts. I have to ask why we got such an extreme? 2PC is tough-enough w/o offlining/restore of whole meta table. During restore, all clients are frozen out or something so they can't pollute the restored version? Restore is not atomic, right? We couldn't have something like a row-per-backup with a success tag if all went well (I've not been following closely -- pardon all the questions).\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.01077336072921753,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003061485243961215,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.05222856625914574,
                        "prediction": false
                    }
                }
            ],
            [
                2317032,
                "HBASE-17852",
                "{quote}\r\nThe snapshot/restore of a whole system table strikes me as a bunch of moving parts. \r\n{quote}\r\n\r\nThat is only one backup system table. \r\n\r\n{quote}\r\nI have to ask why we got such an extreme?\r\n{quote}\r\n\r\nWhat is so extreme here? Snapshot of a system table? I consider this approach much more simple and elegant than \r\nothers?\r\n\r\n{quote}\r\nDuring restore, all clients are frozen out or something so they can't pollute the restored version?\r\n{quote}\r\n\r\nYes. During table restore operation, all clients (of this table) must  be stopped.  In theory, this is not a hard requirement - it is just an advice. But,\r\nwe truncate table, before restore and this, definitely, may affect unexpectedly incoming writes. Any database system, which allows writes to a table during restore of a table? \r\n\r\nStack, if you have doubts in the implementation, I suggest you to go over code and find places where you think the code has issues.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.019084518775343895,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0021116752177476883,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.22884246706962585,
                        "prediction": false
                    }
                }
            ],
            [
                2317034,
                "HBASE-17852",
                "My comments above are not in RB. Were they addressed?\r\n\r\nPatches should include description. Helps reviewers and those trying to follow-behind. Yours have none.\r\n\r\nYou don't use the suggested patch-making tool either in-spite of an earlier request.\r\n\r\nSo, the idea to offline a system table and then restore from a snapshot on error with clients 'advised' to stop writing as some-sort of 2PC got buy-in from others? This is 'fault-tolerance'? Is there a write-up somewhere that explains why we have to offline and then restore a whole table (whatever its size) just because a particular op failed and how it is more simple and elegant than other soluntions (what others?), I'd like to read it. Otherwise, I just don't get it (neither will the operator whose cron job failed because backup table was gone when it ran).\r\n\r\nYou suggest I review code. I have been reviewing code. Thats how we got here.",
                {
                    "property": {
                        "confidence": 0.0056181661784648895,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006077122408896685,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.017902223393321037,
                        "prediction": false
                    }
                }
            ],
            [
                2317037,
                "HBASE-17852",
                "{quote}\r\nSo, the idea to offline a system table and then restore from a snapshot on error with clients 'advised' to stop writing as some-sort of 2PC got buy-in from others? This is 'fault-tolerance'? Is there a write-up somewhere that explains why we have to offline and then restore a whole table (whatever its size) just because a particular op failed and how it is more simple and elegant than other soluntions (what others?), I'd like to read it. Otherwise, I just don't get it (neither will the operator whose cron job failed because backup table was gone when it ran).\r\n{quote}\r\n\r\nStack, you just out of context right now, but I appreciate you want to spend so much time digging into my code once again. Thanks.\r\nYour are the only one who is objecting snapshot-based approach, but I am still waiting for a single argument why is this bad?\r\n",
                {
                    "property": {
                        "confidence": 0.016255881637334824,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0019996529445052147,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.06916232407093048,
                        "prediction": false
                    }
                }
            ],
            [
                2317038,
                "HBASE-17852",
                "bq. This is going to confuse. 'system' tables have a particular meaning in hbase.\r\n\r\nShould be easy enough to rename with your IDE of choice, right Vlad? Avoiding overloading terminology is always a good idea. \"BackupMetadata\" and \"BackupBulkLoadFiles\"? (just pitching ideas)\r\n\r\nbq. The snapshot/restore of a whole system table strikes me as a bunch of moving parts. I have to ask why we got such an extreme? 2PC is tough-enough w/o offlining/restore of whole meta table. During restore, all clients are frozen out or something so they can't pollute the restored version? Restore is not atomic, right? We couldn't have something like a row-per-backup with a success tag if all went well (I've not been following closely \u2013 pardon all the questions).\r\n\r\nStack, are you essentially asking why this isn't implemented on top of ProcV2? I'm trying to read between the lines but am not sure if I'm inventing something that isn't there. There are definitely areas of the code in which the acknowledgement has already been made about a better implementation can be done. For example, clients _are_ \"frozen out\" right now from concurrent operations (a nod that backups, merges, and restores could be done concurrently). I think at this point, it would be more productive if we can say more \"there is something implicitly broken with this approach\" instead of \"there is a more elegant implementation to be had\". I don't think anyone is arguing against that.\r\n\r\nYes, rolling back the entire backup \"system\" table is overkill (for what may sometimes be deleting a single row/column -- the ACTIVE_SNAPSHOT as mentioned in the parent) and would take much longer that it could necessarily need to.\r\n\r\nbq. You suggest I review code. I have been reviewing code. Thats how we got here.\r\n\r\nAnd thank you for that. I know your intentions are good. We're all ultimately working towards a common goal here.\r\n\r\nbq. Sure, you can start from very beginning, Stack. Go ahead.\r\n\r\nThis isn't helpful and, likely, directly harmful :\\",
                {
                    "property": {
                        "confidence": 0.0051897624507546425,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005213174968957901,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04643488675355911,
                        "prediction": false
                    }
                }
            ],
            [
                2317039,
                "HBASE-17852",
                "{code}\r\nIn hbase2, we have builders for the below instead...\r\n\r\n1381 HTableDescriptor tableDesc = new HTableDescriptor(getTableNameForBulkLoadedData(conf));\r\n{code}\r\n\r\nI had left a similar comment on RB. This was fixed in v6 (patchset 5 on RB). I think the majority of other changes were suggestions I had left on RB -- have not explicitly checked, just going off of the \"issues\" being resolved.",
                {
                    "property": {
                        "confidence": 0.006510370410978794,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004945376422256231,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.015683498233556747,
                        "prediction": false
                    }
                }
            ],
            [
                2317040,
                "HBASE-17852",
                "bq. Stack, are you essentially asking why this isn't implemented on top of ProcV2?\r\nbq.  I think at this point, it would be more productive if we can say more \"there is something implicitly broken with this approach\" instead of \"there is a more elegant implementation to be had\".\r\n\r\nI am not asking for any particular implementation, to be clear. I'm just trying to understand and am having trouble digesting full restore of a meta table whatever the size or traffic on error. It strikes me as whack (You seem to at least agree it 'overkill'). There seems to be no write-up on the approach here ahead of piecemeal code drops (w/o overarching description of what all is entailed) so only way to figure it as best as I can ascertain, is via this really pleasant back and forth w the author.\r\n\r\nVlad, you seem to be doing your utmost to sabotage the delivery of this feature. The sort of answers you give us reviewers is one thing. Will operators who run into issues w/ this feature get the same treatment?\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.01123959943652153,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002440674463286996,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.07996615022420883,
                        "prediction": false
                    }
                }
            ],
            [
                2317041,
                "HBASE-17852",
                "bq. I am not asking for any particular implementation, to be clear. I'm just trying to understand and am having trouble digesting full restore of a meta table whatever the size or traffic on error. It strikes me as whack (You seem to at least agree it 'overkill')\r\n\r\nGot it. To clarify my previous message, by \"overkill\" I only mean \"non-ideal\". As in, there is likely a more complicated solution that could accomplish the same net-effect with less computation+time required. I didn't mean to say that I believed using a snapshot and table-restore is invalid or wrong. My gut reaction is that the number of backups which would need to be retained in the system (e.g. rows in the hbase backup \"system\" table) would have to be quite large to even grow beyond a single region (many thousands to millions). As such, the snapshot restore isn't much more than grabbing the write lock and replacing some one data file and some Region metadata. This is on my list today to investigate confirm.\r\n\r\nTo try to move the conversation forward, I tend to agree with Vlad that I don't seen an inherent problem with the rollback-via-snapshot implementation. Architecturally, Vlad is using the snapshot feature exactly how it was intended to be used (shallow copy and restore of a table).\r\n\r\nbq. the idea to offline a system table and then restore from a snapshot on error with clients 'advised' to stop writing as some-sort of 2PC\r\n\r\nLet's revisit this again: in the parent JIRA issue, Vlad outlined two-cases. 1) Recover from a \"server-side\" failure and 2) recover from client side failure (and, probably, implicitly meant to include un-handled server-side failure conditions too).\r\n\r\nFor #1, clients don't need to do anything special (specifically mentioned on the parent issue). Mutual exclusion is already built in to manage the serialized state in the backup \"system\" table. So, we're just looking at the cost of these steps. Offline+snapshot+online should be one of these rock-solid features of the system.\r\n\r\nFor #2, we're in this situation that you outline. Per the concerns you raised about \"coordination\" (the special handshake, to use another metaphor), this seems mitigate-able via return code of the {{hbase backup}} and a prominent error message in this case. I don't know if either presently exist (Could you comment, [~vrodionov]?).\r\n\r\nBoth of these are predicated on the mutual exclusion of multiple clients at a higher level. Obviously, a finer grain exclusion strategy is desirable for multiple reasons, but, given my current understanding, I don't see any fundamental problem with this approach.",
                {
                    "property": {
                        "confidence": 0.04023338854312897,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.001806971849873662,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.44305098056793213,
                        "prediction": false
                    }
                }
            ],
            [
                2317042,
                "HBASE-17852",
                "{quote}\r\n2) recover from client side failure (and, probably, implicitly meant to include un-handled server-side failure conditions too).\r\n{quote}\r\n\r\nFor 2. we have backup repair tool, client will be asked to run repair tool next time he/she will try to run backup/restore/merge/delete",
                {
                    "property": {
                        "confidence": 0.01871088147163391,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00201656436547637,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.17050908505916595,
                        "prediction": false
                    }
                }
            ],
            [
                2317043,
                "HBASE-17852",
                "{quote}\r\nMy gut reaction is that the number of backups which would need to be retained in the system (e.g. rows in the hbase backup \"system\" table) would have to be quite large to even grow beyond a single region (many thousands to millions). As such, the snapshot restore isn't much more than grabbing the write lock and replacing some one data file and some Region metadata. This is on my list today to investigate confirm.\r\n{quote}\r\n\r\nYes, [~elserj], you are right. Backup system table for vast majority of deployments will fit a single region. It is a metadata - not a data. Therefore,  creation of snapshot and restoring from snapshot is a very lightweight operation. That is was a major reason I have chosen rollback-via-snapshot approach. ",
                {
                    "property": {
                        "confidence": 0.11433359235525131,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0034933181013911963,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.3481055796146393,
                        "prediction": false
                    }
                }
            ],
            [
                2317048,
                "HBASE-17852",
                "{quote}\r\nLet me just assume this stuff is handled, but a walk through of what happens when the backup table goes away in different scenarios would be good.\r\nIs the above answered? (Copied from earlier in this dialog).\r\n{quote}\r\n\r\nWhen backup meta table goes away, bulk load will continue because bul load observers do not write to main meta table. When second table (for bulk loaded files) gets offlined - bulk loading fails.\r\n\r\n  ",
                {
                    "property": {
                        "confidence": 0.01748534105718136,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00220675440505147,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.23210559785366058,
                        "prediction": false
                    }
                }
            ],
            [
                2317049,
                "HBASE-17852",
                "Write-up helps. Some questions.\r\n\r\nbq. When operation fails on a server side, we handle this failure by cleaning up partial data in backup destination, followed by restoring backup meta-table from a snapshot.\r\n\r\nWhy do this? Why not just mark the backup as corrupt and move on? (Why does an incomplete back-up freeze all backups -- which you say above .... I'm trying to understand).\r\n\r\nbq. When operation fails on a client side (abnormal termination, for example), next time user will try create/merge/delete he(she) will see error message, that system is in inconsistent state and repair is required, he(she) will need to run backup repair tool.\r\n\r\nWhat if its a cron job? Does this inability at moving on past failure make it so backup cannot be cron'd?\r\n\r\nbq. To avoid multiple writers to the backup system table (backup client and BackupObserver's) we introduce small table ONLY to keep listing of bulk loaded files.\r\n\r\nIf we weren't snapshotting/restoring the backup table, we wouldn't have to make a separate table to hold bulkloaded files? Is that so? (I'm not asking for a rewrite...).\r\n\r\nbq. Your are the only one who is objecting snapshot-based approach, but I am still waiting for a single argument why is this bad?\r\n\r\nI am asking questions to try and understand what is going on in here. When the response is terse or lean on info, I'm going to ask another question... and so on. As to whether snapshot/restore of the meta backup table is 'bad' or not, I'm still trying to understand why we would go to the extreme of offlining a whole table -- even though rare when in error and then it seems, this offlining is making it so we have to add yet another table just to hold bulk loaded files... Pardon my being slow.\r\n\r\nWhat of my review comments are addressed in latest patch?\r\n\r\nThanks.",
                {
                    "property": {
                        "confidence": 0.010273686610162258,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002696035197004676,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.08459555357694626,
                        "prediction": false
                    }
                }
            ],
            [
                2317051,
                "HBASE-17852",
                "{quote}\r\nWhy do this? Why not just mark the backup as corrupt and move on? (Why does an incomplete back-up freeze all backups \u2013 which you say above .... I'm trying to understand).\r\n{quote}\r\n\r\nI have explained this many times already ... Restoring meta table in case of a backup failure is a necessary step to make future backups possible. We write some data during backup create, which is safe only of backup succeeds, such as last WAL roll timestamp per table-per RS. If backup fails, this data becomes corrupt w/o restoring meta table from snapshot.     \r\n\r\n{quote}\r\nWhat if its a cron job? Does this inability at moving on past failure make it so backup cannot be cron'd?\r\n{quote}\r\n\r\nRunning backup repair automatically in case of a  backup failure won't hurt and can be incorporated into cron job\r\n\r\n{quote}\r\nIf we weren't snapshotting/restoring the backup table, we wouldn't have to make a separate table to hold bulkloaded files? Is that so? (I'm not asking for a rewrite...).\r\n{quote}\r\n\r\nYes, correct.\r\n\r\n{quote}\r\nI am asking questions to try and understand what is going on in here. When the response is terse or lean on info, I'm going to ask another question... and so on. As to whether snapshot/restore of the meta backup table is 'bad' or not, I'm still trying to understand why we would go to the extreme of offlining a whole table \u2013 even though rare when in error and then it seems, this offlining is making it so we have to add yet another table just to hold bulk loaded files... Pardon my being slow.\r\n{quote}\r\n\r\nYes, the second table has been added long after the initial implementation was complete as a result of hardening bulk load support feature. You may consider this a s work-around, but it is pretty lightweight work-around. W/o snapshots, we have to make all the changes to meta table fully transactional ones. I think it is much harder.    \r\n\r\n\r\n\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.12754209339618683,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00348385120742023,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.8793134689331055,
                        "prediction": true
                    }
                }
            ],
            [
                2317052,
                "HBASE-17852",
                "{quote}\r\nbq.    Why do this? Why not just mark the backup as corrupt and move on? (Why does an incomplete back-up freeze all backups \u2013 which you say above .... I'm trying to understand).\r\n\r\nI have explained this many times already ... Restoring meta table in case of a backup failure is a necessary step to make future backups possible. We write some data during backup create, which is safe only of backup succeeds, such as last WAL roll timestamp per table-per RS. If backup fails, this data becomes corrupt w/o restoring meta table from snapshot. \r\n{quote}\r\n\r\nThat's the technical explanation for why it is implemented as such, but I think the spirit of the question is more: \"what are the reasons for making this choice and is there something that could be done to make this less painful for users?\"\r\n\r\n{quote}\r\nbq.  What if its a cron job? Does this inability at moving on past failure make it so backup cannot be cron'd?\r\n\r\nRunning backup repair automatically in case of a backup failure won't hurt and can be incorporated into cron job\r\n{quote}\r\n\r\nIf the standard-procedures would be to run a repair blindly, why can't this be encapsulated in BackupDriver? Making the user's life easier is certainly beneficial.",
                {
                    "property": {
                        "confidence": 0.13316653668880463,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0035892496816813946,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.8719606995582581,
                        "prediction": true
                    }
                }
            ],
            [
                2317053,
                "HBASE-17852",
                "I think the only outstanding code-review comment from [~stack] was consolidation of two log messages into one (other questions were \"why the bulk load backup table\" which I think we better understand now and the use of TableDescriptorBuilder which I had already dinged and Vlad has fixed).",
                {
                    "property": {
                        "confidence": 0.005976657848805189,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00792174693197012,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012183550745248795,
                        "prediction": false
                    }
                }
            ],
            [
                2317054,
                "HBASE-17852",
                "{quote}\r\nf the standard-procedures would be to run a repair blindly, why can't this be encapsulated in BackupDriver? Making the user's life easier is certainly beneficial.\r\n{quote}\r\n\r\nI can add auto-repair mode of execution for create/merge/delete.\r\n\r\nHere it is:\r\nhttps://issues.apache.org/jira/browse/HBASE-19380 (this is for 2.1 release)",
                {
                    "property": {
                        "confidence": 0.008233706466853619,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003279775148257613,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04043285548686981,
                        "prediction": false
                    }
                }
            ],
            [
                2317055,
                "HBASE-17852",
                "bq. Can you post your comments on RB, Stack?\r\n\r\nTraditionally it is the contributors' job keeping the feedback in order and making sure it all addressed whether in JIRA or RB. Not addressing reviewers feedback or dropping it w/o comment is a total no-no.\r\n\r\nbq. I have explained this many times already ... \r\n\r\nYou don't answer the question. You just make asserts that we have to rollback w/o justification other than backups 'become corrupt' or a backup is only 'safe' if it completes? Sounds like it needs to be 'transactional' but you don't describe the transaction (correct me if I'm wrong). I don't get why a completed backup can't just write a completion marker to the backup table. W/o it the backup is corrupt/incomplete and we just move on.\r\n\r\nbq. Running backup repair automatically in case of a backup failure won't hurt and can be incorporated into cron job\r\n\r\nDon't follow. An operator sets up a cron job. Works great for a few days. Then it stops. Operator needs to figure that he has to run a repair. Operator sets up two cron jobs? Or cron probes first for breakage...\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.0062414128333330154,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004054172430187464,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0599374994635582,
                        "prediction": false
                    }
                }
            ],
            [
                2317056,
                "HBASE-17852",
                "{quote}\r\nYou don't answer the question\r\n{quote}\r\n\r\nWhat question? What does \"corrupt\" mean? Why do I need to restore meta table? I am afraid, I can't add anything else to my answers above.\r\n\r\n{quote}\r\nDon't follow. An operator sets up a cron job. Works great for a few days. Then it stops. Operator needs to figure that he has to run a repair. Operator sets up two cron jobs? Or cron probes first for breakage...\r\n{quote}\r\n\r\nStops means fails. If cron job fails, operator will need to intervene, read logs, manuals and figure out that repair is required. Not a big deal, imo. We clearly log message, that repair tool has to be run. But for lazy operators I will add auto-repir mode of execution (see above ticket).\r\n\r\nI would like to add that repair will be required very rarely. *Any server-side backup failures are taken care of automatically* - no need to run repair tool. *Backup will be marked as failed in a backup meta table*. Only if client (cron in this case) exits abruptly, only then repair will be required. \r\n\r\nStack, can you be more technical and specific in your questions? The patch is no 8 already. Do you have any code - related questions and comments? If yes, then RB is the right place to put them on.",
                {
                    "property": {
                        "confidence": 0.010904409922659397,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003133215242996812,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.15553654730319977,
                        "prediction": false
                    }
                }
            ],
            [
                2317060,
                "HBASE-17852",
                "My attitude? Nice. Maybe yours? I tried several times to explain you obvious things, but you still not getting them. \r\n\r\n{quote}\r\nask questions and get rubbish back.\r\n{quote}\r\n\r\nYou are not Linus,btw\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.006862305104732513,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.020658738911151886,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012045599520206451,
                        "prediction": false
                    }
                }
            ],
            [
                2317061,
                "HBASE-17852",
                "[~vrodionov] - I think Josh clarified Stack's question to explain why he posits that you \"didn't answer the question\"\r\n\r\nbq. That's the technical explanation for why it is implemented as such, but I think the spirit of the question is more: \"what are the reasons for making this choice and is there something that could be done to make this less painful for users?\"",
                {
                    "property": {
                        "confidence": 0.00484722014516592,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005170941352844238,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03332662954926491,
                        "prediction": false
                    }
                }
            ],
            [
                2317062,
                "HBASE-17852",
                "The reason is the simplicity of the implementation. Is not this obvious? Should I have spent time trying to implement Tx management instead? I doubt. Did I answer original question? I thought that we are technical guys and we need technical answers. It seems that I was wrong. \r\n\r\nUser intervention is required only if user kills backup process or it dies on a client side, for some other reason. All cluster side failures get repaired automatically. I see nothing painful for users here, [~mdrob], especially when I will implement auto-repair feature. This is the question actually, should we do repair automatically or we need to inform user, that there was abnormal failure of a last backup/merge/delete command and user need to run repair.\r\n\r\nDo not we still have *hbck* for this reason? Repair all the s**t which happens periodically in HBase cluster.\r\n\r\nMoving feature out of beta-1 only because someone does not like *attitude of a contributor* means that something is not going well in HBase community.  ",
                {
                    "property": {
                        "confidence": 0.016907066106796265,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009716122411191463,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.11390118300914764,
                        "prediction": false
                    }
                }
            ],
            [
                2317063,
                "HBASE-17852",
                "bq. The reason is the simplicity of the implementation. Is not this obvious?\r\nIt's not obvious, hence the need for clarifying questions. We're all collaborators here, Vlad, not adversaries. I haven't reviewed the code, so in this instance I'm a messenger and attempted mediator.\r\n\r\nbq. Should I have spent time trying to implement Tx management instead?\r\nMaybe!\r\n\r\nbq. Did I answer original question? I thought that we are technical guys and we need technical answers. It seems that I was wrong.\r\nI'm reminded of advice I got early in my software engineer career - it's easy to write code, it's less easy to write correct code, and it is actively hard to know which code to write.\r\n\r\nThe technical answer may have been obvious like you assert, but it's not a complete answer. Understanding how the operators will need to use this feature and how they will interact with it is important in building something that is useful to them.\r\n\r\nbq. User intervention is required only if user kills backup process or it dies on a client side, for some other reason.\r\nThere's lots of reasons that a process might die on the client side. Seems we may disagree on the frequency here.\r\n\r\nbq. Do not we still have hbck for this reason?\r\nSure, we can extend hbck to take care of these failures as well. Does it currently do so? I have no idea. Probably not, given that I don't think hbck works with hbase-2.0 due to AMv2.\r\n\r\nbq. Moving feature out of beta-1 only because someone does not like attitude of a contributor\r\nIt seems like the feature is being moved out because it's incomplete...\r\n\r\nAnd some earlier comments:\r\nbq. But for lazy operators...\r\nLazy operators are the best kind. They are the ones that automate things, the ones that prepare and test for failure so that they don't get called in the middle of the night, the ones that actually make sure that the ship stays sailing.\r\n\r\nbq. The patch is no 8 already\r\nI'm not sure what this is intended to prove. Sometimes I get patches right on the first try, sometimes it takes twenty tries.",
                {
                    "property": {
                        "confidence": 0.0061011058278381824,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007761609274893999,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.06543884426355362,
                        "prediction": false
                    }
                }
            ],
            [
                2317064,
                "HBASE-17852",
                "bq. Operators who'd rather avoid reading logs and having to run repair tools are 'lazy'.\r\n\r\nbq. Do not we still have hbck for this reason? Repair \\[...\\] which happens periodically in HBase cluster.\r\n\r\nLet me also expand on this: I would consider \"lazy\" as a virtue for operators. The system should automatically handle as much as possible. There's a fundamental difference between what hbck is and what `hbase backup repair` is: HBCK is fixing things that inadvertently happen server-side (hopefully, only around bugs which has since been fixed) whereas hbase-backup are completely client-driven. For example, something as benign as a user ctrl-C'ing a backup because they mis-typed the backup name or table being backed up would cause the backup table to need a repair.\r\n\r\nbq. This is the question actually, should we do repair automatically or we need to inform user, that there was abnormal failure of a last backup/merge/delete command and user need to run repair.\r\n\r\nI was about to write that I thought it was a no-brainer to blindly run a repair as a part of the BackupDriver, but now I wonder about the following:\r\n\r\nTake two administrators running backups, unaware of each other. Admin1 starts a backup on Table1. Before Admin1's backup finishes, Admin2 tries to do a backup on Table2. Could Admin2 preempt/fail Admin1's backup by running a {{hbase backup repair}} while Admin1 is using the system?\r\n\r\nIn other words: does {{hbase backup repair}} have the ability to differentiate between \"user is currently executing a backup\" and \"stale state exists in the table from an aborted/unfinished operation\"?",
                {
                    "property": {
                        "confidence": 0.009360925294458866,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0049181049689650536,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.039106134325265884,
                        "prediction": false
                    }
                }
            ],
            [
                2317065,
                "HBASE-17852",
                "{quote}\r\nIt seems like the feature is being moved out because it's incomplete...\r\n{quote}\r\nReally, what is missing? Have you read the doc? Everything described in the B&R documentation have been implemented and tested.  I am running integration tests now on a scale, this is probably the last what developer is supposed to do before declaring feature fully complete? We are still at alpha stage, plenty time to harden the feature before beta-1 or 2.",
                {
                    "property": {
                        "confidence": 0.004391341935843229,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009102378971874714,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014221148565411568,
                        "prediction": false
                    }
                }
            ],
            [
                2317066,
                "HBASE-17852",
                "{quote}\r\nI'm not sure what this is intended to prove. Sometimes I get patches right on the first try, sometimes it takes twenty tries.\r\n{quote}\r\n\r\nNothing, actually except that when contributor submit a patch he expects comments/questions related to the code of a patch not a generic questions: Why have you chosen this design approach, especially when this approach has been discussed many times with other developers before. It is very hard and time consuming to explain everything from a  very beginning for  a person who wants to participate in a review, but is not familiar with the code. I have two committers on the feature [~tedyu@apache.org] and [~elserj] who have spent a lot of time working on the code. I trust them and although I appreciate help from other developers, I expect them to spend some time digging into the full feature code, before trying to review a particular patch (one of more than 100 already). This requires some commitment. \r\n\r\nAny question on the patch itself? ",
                {
                    "property": {
                        "confidence": 0.01369077805429697,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0028416661079972982,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.059884581714868546,
                        "prediction": false
                    }
                }
            ],
            [
                2317067,
                "HBASE-17852",
                "{quote}\r\nI was about to write that I thought it was a no-brainer to blindly run a repair as a part of the BackupDriver, but now I wonder about the following:\r\nTake two administrators running backups, unaware of each other. Admin1 starts a backup on Table1. Before Admin1's backup finishes, Admin2 tries to do a backup on Table2. Could Admin2 preempt/fail Admin1's backup by running a hbase backup repair while Admin1 is using the system?\r\nIn other words: does hbase backup repair have the ability to differentiate between \"user is currently executing a backup\" and \"stale state exists in the table from an aborted/unfinished operation\"?\r\n{quote}\r\n\r\nAll operations are serialized. Admin 2 will fail and will be waiting until first operation is complete (successfully or not). Multiple parallel backup sessions support is on roadmap for 2.1 release: https://issues.apache.org/jira/browse/HBASE-16391.",
                {
                    "property": {
                        "confidence": 0.005113671533763409,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005748062860220671,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0225498266518116,
                        "prediction": false
                    }
                }
            ],
            [
                2317068,
                "HBASE-17852",
                "bq. not a generic questions: Why have you chosen this design approach, especially when this approach has been discussed many times with other developers before\r\nCan you point me at a design document that covers this?",
                {
                    "property": {
                        "confidence": 0.015585058368742466,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004012981429696083,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.4175998568534851,
                        "prediction": false
                    }
                }
            ],
            [
                2317070,
                "HBASE-17852",
                "Thank you for pointing at the parent ticket, I missed that there was design doc in there.\r\n\r\nI'm worried about our current design choices for future concurrent backup design. Please correct my gaps in understanding here:\r\n\r\nCurrent approach, which is limited to single backup operation involves snapshot the backup state table (what you refer to as backup system table, but I think state is more appropriate term) and then if failure then we restore the state? In future are we going to have multiple tables in backup namespace for each table to be backed up so that we can have concurrent approaches? Otherwise the concurrent backup solution will be a complete rewrite I expect.\r\n\r\nDo backup operations have timeouts? I don't see them in the code, but could be looking at the wrong place.",
                {
                    "property": {
                        "confidence": 0.25826263427734375,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0023774506989866495,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.2831099331378937,
                        "prediction": false
                    }
                }
            ],
            [
                2317071,
                "HBASE-17852",
                "Yes, concurrent backup support will require some code rewrite. Rollback - via -snapshot won't work in this case probably, but this is internal implementation details and they won't affect users - backward compatibility is a must here.\r\n\r\nWe do not have any specific timeouts for backups - only those, low level HBase timeouts for RPC and distributed procedure ops. If they time out - backup fails.  ",
                {
                    "property": {
                        "confidence": 0.07867526262998581,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0026406869292259216,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0577029213309288,
                        "prediction": false
                    }
                }
            ],
            [
                2317072,
                "HBASE-17852",
                "Hmm... I don't think we can publish backup/restore without HBASE-16391 in a 2.0 release. I'd like to have confidence that the feature is rock solid before telling users that it's ok to use, parallel operations seems like a major shortcoming to me.\r\n\r\nMaybe this isn't the right JIRA to discuss this, apologies for stepping into the crossfire here. I left a few comments on the RB, will continue to look after reading more of the general design.",
                {
                    "property": {
                        "confidence": 0.009747345931828022,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.055550575256347656,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.005058859940618277,
                        "prediction": false
                    }
                }
            ],
            [
                2317073,
                "HBASE-17852",
                "Few questions:\r\nPardon me if my high level analysis of design is off. Is following correct description of current design?\r\nStart bulkload from client -> each RS gets its RPC for prepare and then do the actual bulkload --> Internally when bulk load is done,BackupObserver#postBulkLoadHFile writes paths to backup table.\r\nAnd to avoid full backup failures from affecting incremental backups (due to snapshot restore), you are putting bulk loaded paths data in a separate table, right?\r\n\r\n----\r\nThere were concerns above on cross RS rpc to write the paths, I was trying to think of easiest way of avoiding that. How about returning the [map as part of response here|https://github.com/apache/hbase/blob/master/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java#L2251] and then issue rpc to master from client side. It's easy and safer to retry from client side if remote resource isn't available.\r\nI'd suggest going extra step, an easy one though -  collect all paths on client side and do single put request. That'll give two benefits:\r\n- Will make it transactional incremental backup\r\n- If put fails repeatedly, you can either fail bulk load altogether, or throw error to user telling that these bulk loaded files failed to backup and that only full backup will include them. \r\n\r\n----\r\nWhat happens if during an ongoing backup, i create some backup sets, but then the backup fails? Snapshot restore will remove my backup sets?",
                {
                    "property": {
                        "confidence": 0.23700416088104248,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004886771086603403,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.6992783546447754,
                        "prediction": true
                    }
                }
            ],
            [
                2317074,
                "HBASE-17852",
                "{quote}\r\nAnd to avoid full backup failures from affecting incremental backups (due to snapshot restore), you are putting bulk loaded paths data in a separate table, right?\r\n{quote}\r\n\r\nYes, you are right.\r\n\r\n{quote}\r\nWhat happens if during an ongoing backup, i create some backup sets, but then the backup fails? Snapshot restore will remove my backup sets?\r\n{quote}\r\n\r\nYes. Any modifications to backup meta table *during* backup create/merge/delete session, which *fails* will be lost. It is the limitation currently. As a simple workaround, any updates (*backup sets operations only*) to backup meta table can be disabled during these sessions. ",
                {
                    "property": {
                        "confidence": 0.10037406533956528,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.001779108657501638,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.043336935341358185,
                        "prediction": false
                    }
                }
            ],
            [
                2317075,
                "HBASE-17852",
                "{quote}\r\nThere were concerns above on cross RS rpc to write the paths, I was trying to think of easiest way of avoiding that. How about returning the map as part of response here and then issue rpc to master from client side. It's easy and safer to retry from client side if remote resource isn't available.\r\nI'd suggest going extra step, an easy one though - collect all paths on client side and do single put request. That'll give two benefits:\r\nWill make it transactional incremental backup\r\nIf put fails repeatedly, you can either fail bulk load altogether, or throw error to user telling that these bulk loaded files failed to backup and that only full backup will include them.\r\n{quote}\r\n\r\nI will think about this and will get back to you, [~appy] shortly. Thanks, for suggestion.",
                {
                    "property": {
                        "confidence": 0.0746726244688034,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0018168309470638633,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.5113609433174133,
                        "prediction": true
                    }
                }
            ],
            [
                2317077,
                "HBASE-17852",
                "{quote}\r\nWhen we switch away from restore-via-snapshot and have proper transactions, does that mean this extra table will go away?\r\n{quote}\r\n\r\nYes, but you need to understand, that proper Tx management is a hard task in this case. It is even harder than classic Tx management. DB Tx got rollbacked automatically in case of a collision (updates to the same record), but we have to merge these updates correctly, because backup sessions always update shared records. Is it worth doing? Only Admin can run backups and what is the use case when Admin starts two sessions in parallel if he can run them serially?",
                {
                    "property": {
                        "confidence": 0.005833826027810574,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0090177608653903,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013323599472641945,
                        "prediction": false
                    }
                }
            ],
            [
                2317078,
                "HBASE-17852",
                "bq. Hmm... I don't think we can publish backup/restore without HBASE-16391 in a 2.0 release. I'd like to have confidence that the feature is rock solid before telling users that it's ok to use, parallel operations seems like a major shortcoming to me.\r\n\r\nLet's dig in on this some more, [~mdrob]. B&R is much more of an \"administrative function\" as opposed to a \"client feature\". My general expectation would be that, most aggressively, HBase admins (a couple of people) would run incremental backups on the order of \"hours\", e.g. incremental backup every 8 hours . I could see the extremely paranoid wanting to do incremental backups every hour over some collection of tables which _could_ cause issues if we can only execute one backup operation at a time (I'm thinking along the lines of 3 backup sets, incremental backups every hour, merging of those backups every few hours, full backup every day, etc).\r\n\r\nAs such, my opinion differs in that I don't see the lack of concurrent backup operations being a major impediment for \"most\" users. I completely agree with you that there will be some users in which this limitation would be problematic on what they want to use it, but, even for these edge cases, B&R without this would still have value to them. I think getting this feature into the hands of users (with the extremely clear caveats on current implementation) would actually better serve the feature than letting it fester more on JIRA. Thoughts?",
                {
                    "property": {
                        "confidence": 0.17102429270744324,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.046028152108192444,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.038807447999715805,
                        "prediction": false
                    }
                }
            ],
            [
                2317079,
                "HBASE-17852",
                "The problem is that backups and restores cannot occur simultaneously.\r\n\r\nLet's say that we have a hypothetical system set to backup nightly (via cron or some other non-interactive mechanism). While this full system backup is running, some problem is detected with a single table and it is determined that the correct course of action is to restore that table. Given that we base backup and restore operations on snapshots, this should be straightforward - the large backup can continue to run while a restore of the specific table (to the last known good state) is put in place without waiting for the backup to complete.\r\n\r\nThe current options appear to be wait until the backup finishes (maybe ok, depending on sizes/bandwidth/etc...) or cancel the nightly backup (very bad, especially  if we have to do manual cleanup of things). I think the position that I'm slowly arriving to is that we shouldn't be recommending nightly backups at all to folks - this is probably a use case better served by replication and having a wider variety of sinks available instead of only another HBase cluster (HBASE-18846 might help with this?). That said we would still need some kind of bulk restore wrappers. Let me think on this more...",
                {
                    "property": {
                        "confidence": 0.01636308990418911,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002366345841437578,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.16387857496738434,
                        "prediction": false
                    }
                }
            ],
            [
                2317080,
                "HBASE-17852",
                "bq. because backup sessions always update shared records.\r\nThis sounds like a design flaw.\r\n\r\nbq. what is the use case when Admin starts two sessions in parallel if he can run them serially\r\nCan an admin queue sessions? That would help the user experience quite a bit until we get parallel sessions. (Not that I'm suggesting that this is either necessary or sufficient; I would much rather see effort towards a proper solution rather than temporary workaround after workaround, but queued operations may be useful in other contexts.)",
                {
                    "property": {
                        "confidence": 0.20630905032157898,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0017187241464853287,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.582625687122345,
                        "prediction": true
                    }
                }
            ],
            [
                2317081,
                "HBASE-17852",
                "{quote}\r\nThe problem is that backups and restores cannot occur simultaneously.\r\n{quote}\r\nThis is much easier to fix, than concurrent backup sessions support, because restore does not access meta table.  \r\n{quote}\r\nCan an admin queue sessions? That would help the user experience quite a bit until we get parallel sessions. \r\n{quote}\r\nNo, this is client -side operation. Can someone queue *hbck*?\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.027183925732970238,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002201920608058572,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03735807538032532,
                        "prediction": false
                    }
                }
            ],
            [
                2317082,
                "HBASE-17852",
                "bq. The current options appear to be wait until the backup finishes (maybe ok, depending on sizes/bandwidth/etc...) or cancel the nightly backup (very bad, especially if we have to do manual cleanup of things).\r\n\r\n\"manual cleanup\" is only running the {{hbase backup repair}} command. I don't feel like that is too onerous and goes back to my original feelings (acceptable limitation to get this in the hands of users).\r\n\r\nbq. Can an admin queue sessions? That would help the user experience quite a bit until we get parallel sessions. (Not that I'm suggesting that this is either necessary or sufficient; I would much rather see effort towards a proper solution rather than temporary workaround after workaround, but queued operations may be useful in other contexts.)\r\n\r\nSpecifically, the client does a checkAndPut to specifics coordinates in the backup table and throws an exception when that fails. Remember that backups are client driven (per some design review from a long time ago), so queuing is tough to reason about (we have no \"centralized\" execution system to use). At a glance, it seems pretty straightforward to add some retry/backoff semantics to {{BackupSystemTable#startBackupExclusiveOperation()}}. Isn't exactly a \"queue\", but it would ease the pain you allude to.",
                {
                    "property": {
                        "confidence": 0.0885390043258667,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00238809990696609,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.5477723479270935,
                        "prediction": true
                    }
                }
            ],
            [
                2317083,
                "HBASE-17852",
                "bq. This is much easier to fix, than concurrent backup sessions support, because restore does not access meta table.\r\nRestore doesn't need to update the set of backup files (to remove references to no longer referenced files?) If we backup, add data, incremental backup, add data, restore to first backup, add data, incremental backup this will all work correctly without the Restore having needed to update any backup state? Where do I look for how this works?\r\n\r\nbq. No, this is client -side operation. Can someone queue hbck?\r\nIt's client-side... kind of. We're encouraging folks to automate these operations, comparing to hbck isn't the same.\r\n\r\nbq. \"manual cleanup\" is only running the hbase backup repair command. I don't feel like that is too onerous and goes back to my original feelings (acceptable limitation to get this in the hands of users).\r\nYea, this is probably ok. I thought we still had a pretty hairy situation here.\r\n\r\nbq. Specifically, the client does a checkAndPut to specifics coordinates in the backup table and throws an exception when that fails. Remember that backups are client driven (per some design review from a long time ago), so queuing is tough to reason about (we have no \"centralized\" execution system to use). At a glance, it seems pretty straightforward to add some retry/backoff semantics to BackupSystemTable#startBackupExclusiveOperation(). Isn't exactly a \"queue\", but it would ease the pain you allude to.\r\nYea, retry would be good. File a JIRA?",
                {
                    "property": {
                        "confidence": 0.07343743741512299,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00227738032117486,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.18314307928085327,
                        "prediction": false
                    }
                }
            ],
            [
                2317084,
                "HBASE-17852",
                "bq. To try to move the conversation forward, I tend to agree with Vlad that I don't seen an inherent problem with the rollback-via-snapshot implementation\r\n\r\nThe inherent problem with rollback-via-snapshot approach is - one operation is taking \"exclusive lock\" on the backup meta table, and that too in a very weird way.\r\nIt's weird because:\r\n1) It behaves like exclusive lock in certain cases. (We only restore on failure, i.e. exclusion kicks in only on failures. That leads to waterfall of issues mentioned below.)\r\n2) Some other operations on that table are following \"exclusion\" semantics (via locking a row), while others not.\r\n\r\nAs a result of which we see so many problems:\r\n1) Different table for incremental backup data: The problem is not that there's a different table, that's fine, but the reason which led to it.\r\n2) You can't run any other command in parallel! No restores (data loss, services are down, everything is on fire, oh but there's a cron job taking backup, so i can't do zilch!?), no merges, no deletes (prod cluster, running out of space, i have to wait for backup before i can free up space?). That's just absurd.\r\n3) Other successful commands are rolled back silently. If an operator add/remove/delete sets, they are gone if a totally different thing fails!\r\n4) During restore, backup table goes offline, cron job attempts backup and fails.\r\n\r\nOthers:\r\n- And then the issues around cross RS RPC from observer during bulk load. Was the alternative suggested yesterday considered in the design? Was there any alternative that was considered?\r\n- (Ref: Bulk loads) Backups are very important. But more important is user being able to load their data and use it. Preventing user to work with their data by putting backup in load path and failing everything if backup doesn't work is plain wrong. Find a different way to backup bulk load data without affecting core read/write paths.\r\n\r\nSo, I'd say, there are many things implicitly broken with current design.\r\n\r\nStrong -1 on shipping it unless they are fixed.",
                {
                    "property": {
                        "confidence": 0.09103750437498093,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0033425793517380953,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.866888701915741,
                        "prediction": true
                    }
                }
            ],
            [
                2317085,
                "HBASE-17852",
                "[~appy],\r\n\r\n# Only Admin user can run backups, therefore, there is no need to run multiple backups in parallel. Admin can run them in a single backup command.\r\n# Restore can be run in parallel with other commands. That is artificial limitation and can be removed easily. It means Admin can run backups session and multiple restore sessions in parallel. I personally, do not see or anticipate strong request to allow multiple backup sessions in parallel. I advise you to go through doc and you fill find and easy to work-around parallel sessions by combining them into single one, [~appy]\r\n# There is no issues with cross - RPC in backup case, because RPC call is a single hop and, hence, deadlock - free\r\n# Failure of BackupObserver to record bulk loaded file with result in bulk load failure - yes. *But I do not see an alternative here*, do you? We need to record *all bulk loaded file names and store them persistently before bulk load operation completes*. Do you have an idea, how can this be achieved, w/o failing bulk load itself and w/o touching hbase core code? \r\n\r\nThe only thing I agree here is support for parallel deletes, merges and if we will introduce this support we can easily add multiple backup session support for free.\r\n\r\nI personally, was very impressed by you, guys, you spent so much time looking for design and implementation flaws, when time was running out literally, during this week. Good job. Why haven't you done this couple months before? \r\n\r\nSome of the \"problems\" you described looks kind of artificial:\r\n{quote}\r\n4) During restore, backup table goes offline, cron job attempts backup and fails.\r\n{quote}\r\n\r\nAnd what? Table goes offline? Why would not you or somebody else to spend time and fix this offline regions/tables crap HBase is full of? \r\n\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.01758977398276329,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005633752793073654,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.37982138991355896,
                        "prediction": false
                    }
                }
            ],
            [
                2317086,
                "HBASE-17852",
                "bq. Yea, retry would be good. File a JIRA?\r\n\r\nHBASE-19441. Tagged in the \"Phase 4\" umbrella.\r\n\r\n{quote}\r\nSo, I'd say, there are many things implicitly broken with current design.\r\n\r\nStrong -1 on shipping it unless they are fixed.\r\n{quote}\r\n\r\n[~appy], while I appreciate the keen eye you're applying here, how can we move forward here? I know it's very frustrating for Vlad to have something that he's already built+tested be taken back to the drawing board abruptly. Do you truly feel like this feature is harmful as compared to what the current implementation is?\r\n\r\nI'd prefer to see this land in master, then we take the concept back to the drawing board and, with all of your help, we revisit this and come up with a design and implementation that works for concurrent backup sessions (as Vlad has this on the Phase4 roadmap already).",
                {
                    "property": {
                        "confidence": 0.013228865340352058,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0038103521801531315,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.2999580502510071,
                        "prediction": false
                    }
                }
            ],
            [
                2317087,
                "HBASE-17852",
                "bq. I'd prefer to see this land in master, then we take the concept back to the drawing board and, with all of your help, we revisit this and come up with a design and implementation that works for concurrent backup sessions (as Vlad has this on the Phase4 roadmap already).\r\n\r\nPing [~appy].",
                {
                    "property": {
                        "confidence": 0.06773392856121063,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005652321502566338,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.8879481554031372,
                        "prediction": true
                    }
                }
            ],
            [
                2317088,
                "HBASE-17852",
                "I'm fine with this landing in master.\r\nI'll try to take a thorough look at the code after 2.0 release (If i miss that, i'll consider myself ineligible for casting any +/- 1).\r\nOf the top of my head, I think the main areas to touch upon are:\r\n- Make backups concurrent\r\n- Use procedure framework: Long-standing request. The procv2 framework has features like locking, queuing operations, etc. Replication is already moving to it. I don't see a reason why backup can't too.\r\n- Can't use CP hooks for incremental backup. Backup should/will become first class feature - more important and critical than Coprocessor.\r\n- There should be some basic access control, if only, limiting everything to ADMIN (like RS group recently did in HBASE-19483)",
                {
                    "property": {
                        "confidence": 0.0666520968079567,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01117767859250307,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.8744003176689148,
                        "prediction": true
                    }
                }
            ],
            [
                2317089,
                "HBASE-17852",
                "So, we are returning back to procV2 and tight integration with hbase-server? [~appy], we used to have this before, but had to move everything from hbase-server more than a year ago by request from [~stack]. Therefore, I need [~stack] +1 on this plan before I start working on refactoring again.",
                {
                    "property": {
                        "confidence": 0.006787790916860104,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009653700515627861,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011576266027987003,
                        "prediction": false
                    }
                }
            ],
            [
                2317090,
                "HBASE-17852",
                "Replication is doing it, but it's already in hbase-server module so it's definitely not the ideal example. But I think its possible to do procv2 + backup without tight integration with hbase-server i.e. while keeping things in separate module. Won't be surprised if it requires some refactoring/small design improvements in proc2 code itself, but that'll be all for good. Maybe backup module become the poster face for \"Building features with procv2\" and we make replication do the same.",
                {
                    "property": {
                        "confidence": 0.657468318939209,
                        "prediction": true
                    },
                    "executive": {
                        "confidence": 0.25839316844940186,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.7600548267364502,
                        "prediction": true
                    }
                }
            ],
            [
                2317091,
                "HBASE-17852",
                "Adding more, so the likely dependencies will end up being:\r\nhbase-backup --> hbase-server\r\nhbase-backup --> hbase-procedure\r\n\r\nB&R's functionalities will be implementations of Procedure/StateMachineProcedure and use masterServices.getMasterProcedureExecutor().submitProcedure() to get stuff done. I do see some deps issues, but we can come with solutions. One thing we should definitely try to stay away from is, merging the code back in hbase-server module.\r\nFor now, what do you think are the biggest blockers for making procv2 + backup happen [~vrodionov]? You're right, we should definitely discuss concrete design/problems/solutions before staring with the refactoring. Can help with design review. ",
                {
                    "property": {
                        "confidence": 0.01898336596786976,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0044344328343868256,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.07688368856906891,
                        "prediction": false
                    }
                }
            ],
            [
                2317092,
                "HBASE-17852",
                "I said hbase-backup --> hbase-server above because backup needs snapshot. Our dependencies are in a state of orgy right now, otherwise following would have been perfect shape to be in.\r\n !screenshot-1.png|width=800! \r\n That said, we should still be able to do procv2+backup without having to refactor other modules out of hbase-server.",
                {
                    "property": {
                        "confidence": 0.0054014078341424465,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012115654535591602,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008511931635439396,
                        "prediction": false
                    }
                }
            ],
            [
                2317095,
                "HBASE-17852",
                "{quote}For now, what do you think are the biggest blockers for making procv2 + backup happen\u00a0[~vrodionov]?\r\n{quote}\r\nIf we could do procv2 implementation w/o getting into server <- backup dependency, then no blockers.\u00a0 But this won't be possible, for sure:\r\n\r\n{quote}\r\n - Can't use CP hooks for incremental backup. Backup should/will become first class feature - more important and critical than Coprocessor.\r\n\r\n{quote}\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.012483226135373116,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003159475512802601,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.30173996090888977,
                        "prediction": false
                    }
                }
            ],
            [
                2317098,
                "HBASE-17852",
                "{quote}I'm fine with this landing in master.\r\n I'll try to take a thorough look at the code after 2.0 release (If i miss that, i'll consider myself ineligible for casting any +/- 1).\r\n{quote}\r\nThanks Appy. Your input is appreciated. I think the direction you're proposing makes sense, but it might be premature to push this forward right now. I've been seeing some funkiness in branch-2 work around procv2. Letting it burn in on branch-2 first is probably a good idea. I'm glad we can help Vlad move forward now and revisit this later.\r\n\r\nI'm +1 on this one. Committing it now to master.",
                {
                    "property": {
                        "confidence": 0.0058614332228899,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008724917657673359,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016127029433846474,
                        "prediction": false
                    }
                }
            ],
            [
                2317100,
                "HBASE-17852",
                "[~appy] wrote:\r\n{quote}Of the top of my head, I think the main areas to touch upon are:\r\n - Make backups concurrent\r\n - Use procedure framework: Long-standing request. The procv2 framework has features like locking, queuing operations, etc. Replication is already moving to it. I don't see a reason why backup can't too.\r\n - Can't use CP hooks for incremental backup. Backup should/will become first class feature - more important and critical than Coprocessor.\r\n - There should be some basic access control, if only, limiting everything to ADMIN (like RS group recently did in\u00a0HBASE-19483){quote}\r\nOK,\u00a0\r\nh4. Concurrent backups\r\n\r\nIt is doable, but ...\r\n # Will require transaction management support - it complicates implementations a lot. We will need to provide full isolation of operations and complex conflict resolutions on commit. And rollback?\r\n # Complicates testing, as well - a lot. Imagine all different possible collisions between create, merge, delete sessions\r\n\r\nWhat I suggest is a slightly different approach:\r\n # Make restore operations concurrent\r\n # Implement fair queuing for *create-merge-delete* sessions\r\n # *create-merge-restore* executions will be serialized (one-by-one), but from user's point of view they will run, kind of, in parallel.\u00a0\r\n\r\nYES/NO\r\nh4. Use procedure framework\u00a0\r\n\r\nShort answer - no. I will wait until procv2 becomes more mature and robust. I do not want to build new feature on a foundation of a new feature. Too risky in my opinion. NO\r\nh4. Can't use CP hooks for incremental backup\r\n\r\nCurrently backup lives in a separate module and we would like to keep it there. There is no need for the tight integration of a HBase core and backup and therefore, CP is the only our option here. NO\r\nh4. Access control\r\n\r\nCurrently, only ADMIN can run backups/restore/delete/merge operations, but we do not enforce this explicitly, so we should probably, do the access right check *before* starting critical operation. YES.\r\n\r\n\u00a0\r\n\r\n[~appy], [~elserj] - comments?\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.0625033974647522,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.041952528059482574,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.9420158863067627,
                        "prediction": true
                    }
                }
            ],
            [
                2317101,
                "HBASE-17852",
                "Man....(lightly shaking head side-to-side)...such strong responses when we are trying to scope out needed work/design changes for a better B&R in 2.1. Please work with me here..smile.\r\n\r\nWhy do you believe procv2 is new feature? It's being used for core HBase functionality - create, delete tables, etc since 1.2 release.\r\nWhat would make it mature & robust enough for B&R in your opinion?\r\n",
                {
                    "property": {
                        "confidence": 0.009384434670209885,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.1716822236776352,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.060588110238313675,
                        "prediction": false
                    }
                }
            ],
            [
                2317102,
                "HBASE-17852",
                "[~appy] we have fully functional module already, but you suggest rewriting 20%-40% of code.\u00a0 That is why my response is so strong. As for procv2, I have heard a lot from other developers who worked on procv2-related\u00a0 bugs.\u00a0\r\n\r\nBackup is not like table create, truncate, split etc - it is in its own league.\u00a0\r\n\r\n{quote}\r\n\r\nWhat would make it mature & robust enough for B&R in your opinion?\r\n\r\n{quote}\r\n\r\n2-3 years of bug fixing :)\r\n\r\nFor concurrent sessions, as I said already it is doable, but will require a lot of efforts, especially in testing. Can you tell me, why do you think my approach (suggested) is not good enough? In a case when only ADMIN can run operations, what is the use case, where truly concurrent sessions are must?\u00a0\u00a0\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.07146522402763367,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004698412958532572,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02442469634115696,
                        "prediction": false
                    }
                }
            ],
            [
                2317103,
                "HBASE-17852",
                "I see only patch v10 in the attached files, and all it's doing is changing name of BackupSystemTable to BackupMetaTable. It's far from what the title says - \"Add Fault Tolerance....\". What am i missing?\r\n\r\n{color:red}Edit: {color} *Please never delete attachments which formed the basis of earlier discussions in a jira*",
                {
                    "property": {
                        "confidence": 0.0038001344073563814,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008334646932780743,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023040756583213806,
                        "prediction": false
                    }
                }
            ],
            [
                2317105,
                "HBASE-17852",
                "Forget all the design discussion, that's not important anymore.\r\n----\r\nHBASE-19568 had basically everything that was objected in the reviews here, why wasn't it brought to the attention of people who raised objections?  The title/reason of that jira reason doesn't matter.\r\nI see it as a really sly move - going behind community and committed changes which were heavily objected against, by using separate jira.\r\n\r\nPing reviewers of other jira: [~elserj] [~tedyu] \r\nPing [~stack] [~apurtell]",
                {
                    "property": {
                        "confidence": 0.006167536601424217,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007224164437502623,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.017868701368570328,
                        "prediction": false
                    }
                }
            ],
            [
                2317106,
                "HBASE-17852",
                "Nope, it turned out that this patch (HBASE-17852) also fixes the issue raised in HBASE-19568, that is why it was committed (with refactoring code stripped down). No conspiracy here.\u00a0 Besides this, I thought that we have agreed on pushing this to the master branch and continue working on a critical changes after that?\u00a0",
                {
                    "property": {
                        "confidence": 0.01368334237486124,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.6259756684303284,
                        "prediction": true
                    },
                    "existence": {
                        "confidence": 0.007355349604040384,
                        "prediction": false
                    }
                }
            ],
            [
                2317107,
                "HBASE-17852",
                "{quote}\r\nHBASE-19568 had basically everything that was objected in the reviews here, why wasn't it brought to the attention of people who raised objections? The title/reason of that jira reason doesn't matter.\r\nI see it as a really sly move - going behind community and committed changes which were heavily objected against, by using separate jira.\r\n{quote}\r\n\r\n[~appy], let's take a step back, please. I called this out to your attention -- I was under the impression that, based on your earlier comment ([here|https://issues.apache.org/jira/browse/HBASE-17852?focusedCommentId=16327774&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16327774]) that you were OK of this implementation landing in master as-is.\r\n\r\nHBASE-19568 was used to commit to master (with what I thought was your blessing) while we continue to use this JIRA issue to flesh out design because of all of the discussion that has happened. If I misunderstood you or poorly asked you the question, let's take that over to HBASE-19568 and get a revert in place. There was nothing malicious intending to happen here.",
                {
                    "property": {
                        "confidence": 0.005302488338202238,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.030459368601441383,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0397137850522995,
                        "prediction": false
                    }
                }
            ],
            [
                2317108,
                "HBASE-17852",
                "bq. Nope, it turned out that this patch (HBASE-17852) also fixes the issue raised in HBASE-19568, that is why it was committed (with refactoring code stripped down).\r\nNot a justification!\r\nDid you not use the patch in this jira to fix HBASE-19568?\r\nWasn't the said patch objected against committing by multiple members of the community?\r\nDid you brought to anyone's attention, who raised the objections (me/stack/andrew/[~mdrob]), the fact that you were committing these changes.\r\n\r\nbq. No conspiracy here.  Besides this, I thought that we have agreed on pushing this to the master branch and continue working on a critical changes after that? \r\nYou really think that'd work? People can match timestamps, you committed 4 days before i even replied back!\r\n",
                {
                    "property": {
                        "confidence": 0.006248900201171637,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.10955385118722916,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006595939863473177,
                        "prediction": false
                    }
                }
            ],
            [
                2317109,
                "HBASE-17852",
                "bq. ....There was nothing malicious intending to happen here\r\nI'll can't believe that because I can't believe that\r\n-  he started fixing the other jira from clean slate and somehow mysteriously ended up with exact same diff as was here, and which we all were against.\r\n- he had random urge to delete all previous 9 patches from this jira, but not from phase1 jira HBASE-14030 or phase2 jira HBASE-14123, which both have like 40 patches each\r\n",
                {
                    "property": {
                        "confidence": 0.003784752916544676,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.05257442221045494,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008030840195715427,
                        "prediction": false
                    }
                }
            ],
            [
                2317110,
                "HBASE-17852",
                "{quote}\r\n\r\nhe had random urge to delete all previous 9 patches from this jira\r\n\r\n{quote}\r\n\r\nNo conspiracy here as well. I was not able to submit patch v10 due to some Apache Jira issues and had to remove all previous patches to be able to submit v10.\u00a0",
                {
                    "property": {
                        "confidence": 0.0051928553730249405,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.3873872458934784,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009582320228219032,
                        "prediction": false
                    }
                }
            ],
            [
                2317111,
                "HBASE-17852",
                "{quote}The majority of this code (but not all) went into master in\u00a0HBASE-19568\u00a0btw.\r\n{quote}\r\nThe majority of 'HBASE-17852 Add Fault tolerance to HBASE-14417 (Support bulk loaded files in incremental backup)', a contentious issue, went into another\u00a0commit named 'HBASE-19568\u00a0Restore of HBase table using incremental backup doesn't restore rows from an earlier incremental backup' with no outline of what made it and what did not, and no changeset explaination. There is no release note. The two JIRAs are not even linked.\r\n{quote}Nope, it turned out that this patch (HBASE-17852) also fixes the issue raised in\u00a0HBASE-19568, that is why it was committed (with refactoring code stripped down). No conspiracy here.\u00a0 \u00a0\r\n{quote}\r\nBut hang on, now the patch here on 'fault tolerance' fixes issues over in the 'restore rows' issue,\u00a0-HBASE-19568?-\r\n\r\nI can see how\u00a0[~appy]\u00a0might arrive at his assessment.\r\n\r\nOn the 'declarations', the first offers options free of context or explanation.\r\n\r\nThis one I find interesting:\r\n\r\n\u00a0#\u00a0Use procedure framework:\u00a0 Short answer - no. I will wait until procv2 becomes more mature and robust. I do not want to build new feature on a foundation of a new feature. Too risky in my opinion. NO\r\n\r\n....when we are talking about a hbase3 (possibly) feature and when there is no alternative.\r\n\r\nAnyway, keeping it short.\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.018458453938364983,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011020615696907043,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018432578071951866,
                        "prediction": false
                    }
                }
            ],
            [
                2317112,
                "HBASE-17852",
                "{quote}\r\n\r\nWasn't the said patch objected against committing by multiple members of the community?\r\n\r\n{quote}\r\n\r\n\u00a0\r\n\r\nCalm down,\u00a0 [~appy]. We are not doing anything criminal here. The result of these two patches is what you have agreed on personally :\r\n\r\nhttps://issues.apache.org/jira/browse/HBASE-17852?focusedCommentId=16327774&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16327774",
                {
                    "property": {
                        "confidence": 0.00463896756991744,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.013780198991298676,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010806846432387829,
                        "prediction": false
                    }
                }
            ],
            [
                2317113,
                "HBASE-17852",
                "bq. I'll can't believe that because I can't believe that..\n\n [~appy], truly, boss, if you weren't giving your blessing on the fix going into master, say so and I'll revert it when next at a computer. I was operating under the assumption that we had time to address design and not look gift-contribtuion(horses) in the mouth.\n\nThe rest of this is a product of some heavy-handedness about the busted Yetus after the JIRA upgrade.\n\nNot trying to tell you something different than what you think happened, did. Trying to express that I thought you were ok with this plan against master (not branch-2).",
                {
                    "property": {
                        "confidence": 0.004822869785130024,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006626900285482407,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02339189499616623,
                        "prediction": false
                    }
                }
            ],
            [
                2317114,
                "HBASE-17852",
                "Okay, f**k it, I really don't want to waste anymore of my time fighting some fight. It's obvious from events what happened here, and that it shouldn't have - makes me very sad and angry.\r\nI leave its further handling to PMC.\r\nAt the very least, someone lost my basic trust and respect.\r\n\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.02783195860683918,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004279260989278555,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02266206592321396,
                        "prediction": false
                    }
                }
            ],
            [
                2317115,
                "HBASE-17852",
                "Commit date is 12th jan\r\n{noformat}\r\ncommit a5601c8eac6bfcac7d869574547f505d44e49065\r\nAuthor:     Vladimir Rodionov <vrodionov@hortonworks.com>\r\nAuthorDate: Wed Jan 10 16:26:09 2018 -0800\r\nCommit:     Josh Elser <elserj@apache.org>\r\nCommitDate: Fri Jan 12 13:13:17 2018 -0500\r\n\r\n    HBASE-19568: Restore of HBase table using incremental backup doesn't restore rows from an earlier incremental backup\r\n\r\n    Signed-off-by: Josh Elser <elserj@apache.org>\r\n{noformat}\r\n\r\nI did say it was okay to go in master, but that's like 4 days after the commit - 2018-01-16T12:46:19-0800\r\n\r\n{color:red}Edit{color}\r\nBtw, anyone wishing to cross check the diffs.\r\nDiff on this jira that wasn't approved (until 16th) : https://reviews.apache.org/r/63155/diff/5/\r\nDiff on HBASE-19568 which was committed on 12th: https://issues.apache.org/jira/secure/attachment/12905579/HBASE-19568-v4.patch",
                {
                    "property": {
                        "confidence": 0.005598858930170536,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005038876552134752,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.022506294772028923,
                        "prediction": false
                    }
                }
            ],
            [
                2317116,
                "HBASE-17852",
                "{quote}\r\n\r\nI did say it was okay to go in master, but that's like 4 days after the commit - 2018-01-16T12:46:19-0800\r\n\r\n{quote}\r\n\r\nOK, there was an issue found during QA testing -\u00a0HBASE-19568. It turned out that HBASE-17852 fixes the issue. Let us say I have had two options:\r\n # Find out which part of HBASE-17852 fixes the issue and create smaller HBASE-19568- specific patch\r\n # Apply HBASE-17852 patch directly (with some refactoring part stripped down)\u00a0 \u00a0 \u00a0\u00a0\r\n  \r\nSo I have chosen the latter one. Reasons: time, time, time. We can revert HBASE-19568 back if there are so many objections. \r\n",
                {
                    "property": {
                        "confidence": 0.0039052406791597605,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.015130111016333103,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014246814884245396,
                        "prediction": false
                    }
                }
            ],
            [
                2317118,
                "HBASE-17852",
                "bq. I did say it was okay to go in master, but that's like 4 days after the commit - 2018-01-16T12:46:19-0800\n\nI'm not messing with you, [~appy]. Check the push logs/comments on the other JIRA issue.. I swear to you that I did not push this until after I heard back from you. My guess is that this is due to me using git-am or cherry picking a commit from a local branch.",
                {
                    "property": {
                        "confidence": 0.005848568864166737,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00820165779441595,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011062916368246078,
                        "prediction": false
                    }
                }
            ],
            [
                2317121,
                "HBASE-17852",
                "bq. I'm not messing with you, Appy. Check the push logs/comments on the other JIRA issue.. I swear to you that I did not push this until after I heard back from you. My guess is that this is due to me using git-am or cherry picking a commit from a local branch.\r\n\r\nMy apologies, Appy. I am wrong. I apparently got impatient and pushed this because there was silence from the Dec 6th mention and the Jan 12th re-ping. My intent was not to squash your opinions, but to avoid being blocked if you were not interested/busy as seemed might be the case.\r\n\r\nIf you have since changed your mind about the reduced patch hitting master, my offer to revert stands. My apologies again for arguing with you while in the wrong.",
                {
                    "property": {
                        "confidence": 0.006495650392025709,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005582442041486502,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01827196218073368,
                        "prediction": false
                    }
                }
            ],
            [
                2317122,
                "HBASE-17852",
                "bq. My intent was not to squash your opinions, but to avoid being blocked if you were not interested/busy as seemed might be the case.\r\nThat's reasonable. Sorry for the delay on my part.\r\nLeaving a comment saying the same and that post-hoc reviews would be welcome would have avoided whole situation.\r\nThe only thing that put me off was, finding it out myself, followed by certain tone in certain comments.\r\n\r\n[~elserj] i believe you. Everyone makes mistakes from time-to-time, i'm certain i must have done too. Always happy with \"acknowledge, learn, and move past them\" way. All's good (between us two).\r\n",
                {
                    "property": {
                        "confidence": 0.0054319798946380615,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00468062050640583,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02337527833878994,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d376f4d395ee22183f6c",
        "key": "YETUS-810",
        "id": "13219344",
        "description": "{code}\r\nFailed conversion of ``'' using format ``%FT%T''\r\ndate: illegal time format\r\nusage: date [-jnRu] [-d dst] [-r seconds] [-t west] [-v[+|-]val[ymwdHMS]] ... \r\n            [-f fmt date | [[[mm]dd]HH]MM[[cc]yy][.ss]] [+format]\r\n{code}",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640753ae7e5ffe26e0b85e2e",
        "key": "CLOUDSTACK-7077",
        "id": "12725950",
        "description": "When trying to attach multiple data disks to a VM in quick succession, AttachVolumeCmds consistently fail with the below exception -.\n\n{noformat}\n2014-05-19 15:55:18,776 ERROR [storage.resource.VmwareStorageProcessor] (DirectAgent-xxx) AttachVolumeCommand failed due to Exception: java.lang.RuntimeException\nMessage: Invalid configuration for device '0'.\njava.lang.RuntimeException: Invalid configuration for device '0'.\nat com.cloud.hypervisor.vmware.util.VmwareClient.waitForTask(VmwareClient.java:412)\nat com.cloud.hypervisor.vmware.mo.VirtualMachineMO.attachDisk(VirtualMachineMO.java:1026)\nat com.cloud.storage.resource.VmwareStorageProcessor.attachVolume(VmwareStorageProcessor.java:1281)\nat com.cloud.storage.resource.VmwareStorageProcessor.attachVolume(VmwareStorageProcessor.java:1216)\nat com.cloud.storage.resource.StorageSubsystemCommandHandlerBase.execute(StorageSubsystemCommandHandlerBase.java:129)\nat com.cloud.storage.resource.StorageSubsystemCommandHandlerBase.handleStorageCommands(StorageSubsystemCommandHandlerBase.java:55)\nat com.cloud.hypervisor.vmware.resource.VmwareResource.executeRequest(VmwareResource.java:559)\nat com.cloud.agent.manager.DirectAgentAttache$Task.run(DirectAgentAttache.java:186)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\nat java.util.concurrent.FutureTask.run(FutureTask.java:166)\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:165)\nat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:266)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\nat java.lang.Thread.run(Thread.java:679)\n2014-05-19 15:55:18,778 DEBUG [agent.manager.DirectAgentAttache] (DirectAgent-151:null) Seq 51-1760168847: Response Received:\n2014-05-19 15:55:18,778 DEBUG [agent.transport.Request] (DirectAgent-151:null) Seq 51-1760168847: Processing: { Ans: , MgmtId: 345052289567, via: 51, Ver: v1, Flags: 10, [{\"org.apache.cloudstack.storage.command.AttachAnswer\":{\"result\":false,\"details\":\"AttachVolumeCommand failed due to Exception: java.lang.RuntimeException\\nMessage: Invalid configuration for device '0'.\\n\",\"wait\":0}}] }\n2014-05-19 15:55:18,778 DEBUG [agent.transport.Request] (Job-Executor-37:job-23717 = [ d261e185-5c78-407e-b3c4-f0d5fcf711df ]) Seq 51-1760168847: Received: { Ans: , MgmtId: 345052289567, via: 51, Ver: v1, Flags: 10,\n{ AttachAnswer }\n}\n2014-05-19 15:55:18,786 ERROR [cloud.async.AsyncJobManagerImpl] (Job-Executor-37:job-23717 = [ d261e185-5c78-407e-b3c4-f0d5fcf711df ]) Unexpected exception while executing org.apache.cloudstack.api.command.user.volume.AttachVolumeCmd\ncom.cloud.utils.exception.CloudRuntimeException: Failed to attach volume: psvgwin28c3pfeng [2] to VM: 37e328e4-c620-48a2-9e35-1fc5225d5a4b; AttachVolumeCommand failed due to Exception: java.lang.RuntimeException\nMessage: Invalid configuration for device '0'.\nat com.cloud.storage.VolumeManagerImpl.sendAttachVolumeCommand(VolumeManagerImpl.java:1712)\nat com.cloud.storage.VolumeManagerImpl.attachVolumeToVM(VolumeManagerImpl.java:1944)\nat com.cloud.utils.component.ComponentInstantiationPostProcessor$InterceptorDispatcher.intercept(ComponentInstantiationPostProcessor.java:125)\nat org.apache.cloudstack.api.command.user.volume.AttachVolumeCmd.execute(AttachVolumeCmd.java:122)\nat com.cloud.api.ApiDispatcher.dispatch(ApiDispatcher.java:158)\nat com.cloud.async.AsyncJobManagerImpl$1.run(AsyncJobManagerImpl.java:531)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\nat java.util.concurrent.FutureTask.run(FutureTask.java:166)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\nat java.lang.Thread.run(Thread.java:679)\n2014-05-19 15:55:18,789 DEBUG [cloud.async.AsyncJobManagerImpl] (Job-Executor-37:job-23717 = [ d261e185-5c78-407e-b3c4-f0d5fcf711df ]) Complete async job-23717 = [ d261e185-5c78-407e-b3c4-f0d5fcf711df ], jobStatus: 2, resultCode: 530, result: Error Code: 530 Error text: Failed to attach volume: psvgwin28c3pfeng [2] to VM: 37e328e4-c620-48a2-9e35-1fc5225d5a4b; AttachVolumeCommand failed due to Exception: java.lang.RuntimeException\nMessage: Invalid configuration for device '0'.\n{noformat}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009646417573094368
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0074765244498848915
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007119311951100826
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5dd3af4d395ee221ab2eb",
        "key": "SPARK-8587",
        "id": "12840039",
        "description": "Looking at PySpark the implementation of KMeansModel.predict https://github.com/apache/spark/blob/master/python/pyspark/mllib/clustering.py#L102 : \n\nCurrently:\nit calculates the cost of the closest cluster and returns the index only.\n\nMy expectation:\nEasy way to let the same function or a new function to return the cost with the index.",
        "predictions": {},
        "comments": [
            {
                "author_name": "apachespark",
                "id": "14599006",
                "body": "User 'samos123' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/6979"
            },
            {
                "author_name": "samos123",
                "id": "14599007",
                "body": "Implemented code example for PySpark: https://github.com/apache/spark/pull/6979 feel free to discard this pull request for a proper implementation in Scala and Java also."
            },
            {
                "author_name": "rakeshchalasani",
                "id": "14600079",
                "body": "+1 for this. \n\nBut we can't do what you did in the above PR for Java/ Scala. Its better to have a different function, \"computeDistance\". I will send a different PR for that."
            },
            {
                "author_name": "josephkb",
                "id": "14600237",
                "body": "I agree; we should not change the behavior of the existing function, and we will need to maintain matching APIs for Scala/Java and Python.  I think this will be easily supported within the Pipelines API, where KMeans is currently being added: [SPARK-7879].  The initial PR will add only a prediction column (predicted cluster), but a follow-up could add a column of costs or of soft/raw predictions (which could be 1/cost).\n\nWould you be able to help out with this extension of Pipelines, once the initial PR gets in?  If so, we could close this JIRA and PR for now.  Thanks!"
            },
            {
                "author_name": "rakeshchalasani",
                "id": "14600568",
                "body": "Sure, I can add this on the KMeans pipelines, whenever thats get added ( I will watch out for it).\n\nOn a slightly different topic that can help in our own development, since we are more inclined here to add these features to ML Pipelines over MLlib, eventually will MLlib won't be supported and future development going to happen more on Pipeline API alone? Thanks.\n\n"
            },
            {
                "author_name": "samos123",
                "id": "14600825",
                "body": "I also agree that this should have the same API accross the different languages. There is already a function computeCost but the problem is that it doesn't return the index, the problem with predict is that it only returns the index and not the cost."
            },
            {
                "author_name": "josephkb",
                "id": "14603592",
                "body": "Based on feedback we've gotten about the Pipelines API, we are trying to focus more on it.  We will continue to support the original API, but I do think that, eventually, new development will happen in Pipelines."
            },
            {
                "author_name": "rakeshchalasani",
                "id": "14605639",
                "body": "Hi Sam,\n\n\"computeCost\" now returns  the cumulative cost over a dataset, rather than cost per sample, which i think this JIRA is for. Internally, predict does compute the distance to nearest point but return only the predicted center. So, adding a method that returns distances is doing the job twice and that is what is pointed above for Bradley. In Pipelines, on the other hand, this can handled more gracefully and efficiently by adding a column to the returning DF. \n\nIf that is good for you, can you close this JIRA? I will create another one for adding distances to the KMeans pipeline, once that is merged. thanks."
            }
        ],
        "comments_predictions": [
            [
                685465,
                "SPARK-8587",
                "I agree; we should not change the behavior of the existing function, and we will need to maintain matching APIs for Scala/Java and Python.  I think this will be easily supported within the Pipelines API, where KMeans is currently being added: [SPARK-7879].  The initial PR will add only a prediction column (predicted cluster), but a follow-up could add a column of costs or of soft/raw predictions (which could be 1/cost).\n\nWould you be able to help out with this extension of Pipelines, once the initial PR gets in?  If so, we could close this JIRA and PR for now.  Thanks!",
                {
                    "property": {
                        "confidence": 0.011857756413519382,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0037181866355240345,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.2330721914768219,
                        "prediction": false
                    }
                }
            ],
            [
                685466,
                "SPARK-8587",
                "Sure, I can add this on the KMeans pipelines, whenever thats get added ( I will watch out for it).\n\nOn a slightly different topic that can help in our own development, since we are more inclined here to add these features to ML Pipelines over MLlib, eventually will MLlib won't be supported and future development going to happen more on Pipeline API alone? Thanks.\n\n",
                {
                    "property": {
                        "confidence": 0.002641135361045599,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0386950857937336,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01587037369608879,
                        "prediction": false
                    }
                }
            ],
            [
                685467,
                "SPARK-8587",
                "I also agree that this should have the same API accross the different languages. There is already a function computeCost but the problem is that it doesn't return the index, the problem with predict is that it only returns the index and not the cost.",
                {
                    "property": {
                        "confidence": 0.005359431263059378,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0048174867406487465,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.027193699032068253,
                        "prediction": false
                    }
                }
            ],
            [
                685468,
                "SPARK-8587",
                "Based on feedback we've gotten about the Pipelines API, we are trying to focus more on it.  We will continue to support the original API, but I do think that, eventually, new development will happen in Pipelines.",
                {
                    "property": {
                        "confidence": 0.009928813204169273,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003212569747120142,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.13105963170528412,
                        "prediction": false
                    }
                }
            ],
            [
                685469,
                "SPARK-8587",
                "Hi Sam,\n\n\"computeCost\" now returns  the cumulative cost over a dataset, rather than cost per sample, which i think this JIRA is for. Internally, predict does compute the distance to nearest point but return only the predicted center. So, adding a method that returns distances is doing the job twice and that is what is pointed above for Bradley. In Pipelines, on the other hand, this can handled more gracefully and efficiently by adding a column to the returning DF. \n\nIf that is good for you, can you close this JIRA? I will create another one for adding distances to the KMeans pipeline, once that is merged. thanks.",
                {
                    "property": {
                        "confidence": 0.007400729693472385,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0065805609337985516,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011015824042260647,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d60f9ff4d395ee2222abca",
        "key": "FLINK-8984",
        "id": "13145677",
        "description": "This is configuration issue. There are two options:\u00a0\r\n\r\ntaskmanager.network.credit-based-flow-control.enabled\r\n\r\nand\r\n\r\ntaskmanager.exactly-once.blocking.data.enabled\r\n\r\nIf we disable first one, but remain default value for the second one deadlocks will occur. I think we can safely drop the second config\u00a0value altogether and always use blocking\u00a0BarrierBuffer for credit based flow control and spilling\u00a0BarrierBuffer for non credit based flow control.\r\n\r\ncc [~zjwang]",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0033060042187571526
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.8359062075614929
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.06276047974824905
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16401817",
                "body": "GitHub user pnowojski opened a pull request:\n\n    https://github.com/apache/flink/pull/5708\n\n    [FLINK-8984][network] Drop taskmanager.exactly-once.blocking.data.enabled config option\n\n    Previously there were twe options:\r\n    \r\n    taskmanager.network.credit-based-flow-control.enabled\r\n    \r\n    and\r\n    \r\n    taskmanager.exactly-once.blocking.data.enabled\r\n    \r\n    If we disabled first one, but keept default value for the second one deadlocks will occur.\r\n    \r\n    By dropping taskmanager.exactly-once.blocking.data.enabled we can always use:\r\n     - blocking BarrierBuffer for credit based flow control\r\n     - spilling BarrierBuffer for non credit based flow control.\r\n    \r\n    ## Does this pull request potentially affect one of the following parts:\r\n    \r\n      - Dependencies (does it add or upgrade a dependency): (yes / **no**)\r\n      - The public API, i.e., is any changed class annotated with `@Public(Evolving)`: (yes / **no**)\r\n      - The serializers: (yes / **no** / don't know)\r\n      - The runtime per-record code paths (performance sensitive): (yes / **no** / don't know)\r\n      - Anything that affects deployment or recovery: JobManager (and its components), Checkpointing, Yarn/Mesos, ZooKeeper: (yes / **no** / don't know)\r\n      - The S3 file system connector: (yes / **no** / don't know)\r\n    \r\n    ## Documentation\r\n    \r\n      - Does this pull request introduce a new feature? (yes / **no**)\r\n      - If yes, how is the feature documented? (**not applicable** / docs / JavaDocs / not documented)\r\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/pnowojski/flink f8984\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/flink/pull/5708.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #5708\n    \n----\ncommit ed992c58502779d22e3e9b5c1a120329fc20c1a6\nAuthor: Piotr Nowojski <piotr.nowojski@...>\nDate:   2018-03-16T12:28:08Z\n\n    [FLINK-8984][network] Drop taskmanager.exactly-once.blocking.data.enabled config option\n    \n    Previously there were twe options:\n    \n    taskmanager.network.credit-based-flow-control.enabled\n    \n    and\n    \n    taskmanager.exactly-once.blocking.data.enabled\n    \n    If we disabled first one, but keept default value for the second one deadlocks will occur.\n    \n    By dropping taskmanager.exactly-once.blocking.data.enabled we can always use:\n     - blocking BarrierBuffer for credit based flow control\n     - spilling BarrierBuffer for non credit based flow control.\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "16401912",
                "body": "Github user zhijiangW commented on the issue:\n\n    https://github.com/apache/flink/pull/5708\n  \n    Thanks piotr, I agree with it. \n"
            },
            {
                "author_name": "githubbot",
                "id": "16404856",
                "body": "Github user zentol commented on the issue:\n\n    https://github.com/apache/flink/pull/5708\n  \n    What would happen if `taskmanager.network.credit-based-flow-control.enabled` is enabled, but `taskmanager.exactly-once.blocking.data.enabled` is disabled?\r\n    \r\n    Is this an invalid setting?\n"
            },
            {
                "author_name": "githubbot",
                "id": "16404966",
                "body": "Github user pnowojski commented on the issue:\n\n    https://github.com/apache/flink/pull/5708\n  \n    Yes, it's a valid setting, but has worse performance and whole credit based flow control looses it's sense. `taskmanager.exactly-once.blocking.data.enabled` setting was thought as a fallback option if there is a bug in new code path, but this is achieved by using `taskmanager.network.credit-based-flow-control.enabled` in two places (and both of those places are about using `credit-based-flow-control`).\r\n    \r\n    In other words, we do not think there is a much value in allowing `taskmanager.network.credit-based-flow-control.enabled` enabled, but `taskmanager.exactly-once.blocking.data.enabled` \r\n    disabled, and it would make the configuration more complex/confusing for the users.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16407856",
                "body": "Github user zentol commented on the issue:\n\n    https://github.com/apache/flink/pull/5708\n  \n    merging.\n"
            },
            {
                "author_name": "githubbot",
                "id": "16408011",
                "body": "Github user pnowojski commented on the issue:\n\n    https://github.com/apache/flink/pull/5708\n  \n    Thanks!\n"
            },
            {
                "author_name": "githubbot",
                "id": "16408707",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/flink/pull/5708\n"
            },
            {
                "author_name": "chesnay",
                "id": "16408710",
                "body": "master: 91707e35d39a1b9c11448f21eafc27f0fd949370\r\n1.5: 23005ee1f653a3fcddac0f710d56f3e0d6157a48"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d6055df4d395ee222148f9",
        "key": "HBASE-12717",
        "id": "12762577",
        "description": "\nWhen we set the start key and the end key in the function:\ncreateTable(HTableDescriptor desc, byte[] startKey, byte[] endKey, int numRegions)\nThe current pre-split algorithm could not find a split point between the keys like \"aaa\" and \"aab\", \"1111\" and \"1112\". \n\nExample Code for this bug:\nadmin.createTable(htd, Bytes.toBytes(\"aaa\"), Bytes.toBytes(\"aab\"), 4);\n\nwe will get the following ERROR:\nException in thread \"main\" java.lang.IllegalArgumentException: Unable to split key range into enough regions\n\tat org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:473)\n\tat test.JavaTest.main(JavaTest.java:28)\n\nWe hope this pre-split algorithm should be able to calculate the split point with an additional byte. for example:\n\"aaa\" and \"aab\", split point= \"aaaP\"\n\"1111\" and \"1112\", split point =\"1111P\" \n ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.01763131096959114
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0068683624267578125
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00523743499070406
                }
            }
        },
        "comments": [
            {
                "author_name": "ashish singhi",
                "id": "14259854",
                "body": "Duplicate of HBASE-12716 ?"
            },
            {
                "author_name": "yeweichen",
                "id": "14259891",
                "body": "[~ashish singhi] Yes. The bug is now fixed by the patch in HBASE12716."
            },
            {
                "author_name": "ndimiduk",
                "id": "14571041",
                "body": "Closing issues released in 1.1.0."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5da7af4d395ee221a5795",
        "key": "SPARK-32041",
        "id": "13312653",
        "description": "When an Exchange node is repeated at multiple places in the PhysicalPlan, and if that exchange has some some DPP Subquery filter, then ReuseExchange doesn't work for such Exchange and different stages are launched to compute same thing.\r\n\r\nExample:\r\n{noformat}\r\n// generate data\r\nval factData = (1 to 100).map(i => (i%5, i%20, i))\r\nfactData.toDF(\"store_id\", \"product_id\", \"units_sold\")\r\n  .write\r\n  .partitionBy(\"store_id\")\r\n  .format(\"parquet\")\r\n  .saveAsTable(\"fact_stats\")\r\n\r\nval dimData = Seq[(Int, String, String)](\r\n  (1, \"AU\", \"US\"),\r\n  (2, \"CA\", \"US\"),\r\n  (3, \"KA\", \"IN\"),\r\n  (4, \"DL\", \"IN\"),\r\n  (5, \"GA\", \"PA\"))\r\n\r\ndimData.toDF(\"store_id\", \"state_province\", \"country\")\r\n  .write\r\n  .format(\"parquet\")\r\n  .saveAsTable(\"dim_stats\")\r\n\r\nsql(\"ANALYZE TABLE fact_stats COMPUTE STATISTICS FOR COLUMNS store_id\")\r\nsql(\"ANALYZE TABLE dim_stats COMPUTE STATISTICS FOR COLUMNS store_id\")\r\n\r\n// Set Configs\r\nspark.sql(\"set spark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly=true\")\r\nspark.sql(\"set spark.sql.autoBroadcastJoinThreshold=1000\")\r\n\r\nval query = \"\"\"\r\n    With view1 as (\r\n      SELECT product_id, f.store_id\r\n      FROM fact_stats f JOIN dim_stats\r\n      ON f.store_id = dim_stats.store_id WHERE dim_stats.country = 'IN')\r\n    SELECT * FROM view1 v1 join view1 v2 WHERE v1.product_id = v2.product_id\r\n\"\"\"\r\nval df = spark.sql(query)\r\nprintln(df.queryExecution.executedPlan)\r\n\r\n{noformat}\r\n{noformat}\r\nPlan:\r\n *(7) SortMergeJoin [product_id#1968|#1968], [product_id#2060|#2060], Inner\r\n :- *(3) Sort [product_id#1968 ASC NULLS FIRST|#1968 ASC NULLS FIRST], false, 0\r\n : +- Exchange hashpartitioning(product_id#1968, 5), true, [id=#1140|#1140]\r\n : +- *(2) Project [product_id#1968, store_id#1970|#1968, store_id#1970]\r\n : +- *(2) BroadcastHashJoin [store_id#1970|#1970], [store_id#1971|#1971], Inner, BuildRight\r\n : :- *(2) Project [product_id#1968, store_id#1970|#1968, store_id#1970]\r\n : : +- *(2) Filter isnotnull(product_id#1968)\r\n : : +- *(2) ColumnarToRow\r\n : : +- FileScan parquet default.fact_stats[product_id#1968,store_id#1970|#1968,store_id#1970] Batched: true, DataFilters: [isnotnull(product_id#1968)|#1968)], Format: Parquet, Location: InMemoryFileIndex[file:/home/prakhar/src/os/1_spark/sql/core/spark-warehouse/org.apache.spark.sql..., PartitionFilters: [isnotnull(store_id#1970), dynamicpruningexpression(store_id#1970 IN dynamicpruning#2067)|#1970), dynamicpruningexpression(store_id#1970 IN dynamicpruning#2067)], PushedFilters: [IsNotNull(product_id)], ReadSchema: struct<product_id:int>\r\n : : +- SubqueryBroadcast dynamicpruning#2067, 0, [store_id#1971|#1971], [id=#1131|#1131]\r\n : : +- ReusedExchange [store_id#1971|#1971], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint))), [id=#1021|#1021]\r\n : +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint))), [id=#1021|#1021]\r\n : +- *(1) Project [store_id#1971|#1971]\r\n : +- *(1) Filter ((isnotnull(country#1973) AND (country#1973 = IN)) AND isnotnull(store_id#1971))\r\n : +- *(1) ColumnarToRow\r\n : +- FileScan parquet default.dim_stats[store_id#1971,country#1973|#1971,country#1973] Batched: true, DataFilters: [isnotnull(country#1973), (country#1973 = IN), isnotnull(store_id#1971)|#1973), (country#1973 = IN), isnotnull(store_id#1971)], Format: Parquet, Location: InMemoryFileIndex[file:/home/prakhar/src/os/1_spark/sql/core/spark-warehouse/org.apache.spark.sql..., PartitionFilters: [], PushedFilters: [IsNotNull(country), EqualTo(country,IN), IsNotNull(store_id)], ReadSchema: struct<store_id:int,country:string>\r\n +- *(6) Sort [product_id#2060 ASC NULLS FIRST|#2060 ASC NULLS FIRST], false, 0\r\n +- ReusedExchange [product_id#2060, store_id#2062|#2060, store_id#2062], Exchange hashpartitioning(product_id#1968, 5), true, [id=#1026|#1026]\r\n{noformat}\r\nIssue:\r\n Note the last line of plan. Its a ReusedExchange which is pointing to id=1026. But There is no Exchange node in plan with ID 1026. ReusedExchange node is pointing to incorrect Child node (1026 instead of 1140) and so in actual, exchange reuse won't happen in this query.\r\n\r\nAnother query where issue is because of ReuseSubquery:\r\n{noformat}\r\nspark.sql(\"set spark.sql.autoBroadcastJoinThreshold=-1\")\r\n\r\nval query1 = \"\"\"\r\n                  | With view1 as (\r\n                  |   SELECT product_id, units_sold\r\n                  |   FROM fact_stats\r\n                  |   WHERE store_id = (SELECT max(store_id) FROM dim_stats)\r\n                  |         and units_sold = 2\r\n                  | ), view2 as (\r\n                  |   SELECT product_id, units_sold\r\n                  |   FROM fact_stats\r\n                  |   WHERE store_id = (SELECT max(store_id) FROM dim_stats)\r\n                  |         and units_sold = 1\r\n                  | )\r\n                  |\r\n                  | SELECT *\r\n                  | FROM view1 v1 join view2 v2 join view2 v3\r\n                  | WHERE v1.product_id = v2.product_id and v2.product_id = v3.product_id\r\n\"\"\"\r\n// Here we are joining v2 with self. So it should use ReuseExchange. But final plan computes v2 twice.\r\nval df = spark.sql(query1);\r\nprintln(df.queryExecution.executedPlan){noformat}\r\nHere we are joining v2 with self. So it should use ReuseExchange. But final plan computes v2 twice.\r\n\r\n\u00a0",
        "predictions": {},
        "comments": [
            {
                "author_name": "apachespark",
                "id": "17141304",
                "body": "User 'prakharjain09' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/28881"
            },
            {
                "author_name": "apachespark",
                "id": "17141306",
                "body": "User 'prakharjain09' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/28881"
            },
            {
                "author_name": "apachespark",
                "id": "17141815",
                "body": "User 'peter-toth' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/28885"
            },
            {
                "author_name": "apachespark",
                "id": "17141816",
                "body": "User 'peter-toth' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/28885"
            },
            {
                "author_name": "petertoth",
                "id": "17272102",
                "body": "Let me reopen this ticket as this is not a duplicate of SPARK-29375 but more like a bug. The connection between this ticket, SPARK-29375 and SPARK-28940 is that my PR (https://github.com/apache/spark/pull/28885) fixes all of them. "
            },
            {
                "author_name": "cloud_fan",
                "id": "17366378",
                "body": "Issue resolved by pull request 28885\n[https://github.com/apache/spark/pull/28885]"
            }
        ],
        "comments_predictions": [
            [
                621226,
                "SPARK-32041",
                "Let me reopen this ticket as this is not a duplicate of SPARK-29375 but more like a bug. The connection between this ticket, SPARK-29375 and SPARK-28940 is that my PR (https://github.com/apache/spark/pull/28885) fixes all of them. ",
                {
                    "property": {
                        "confidence": 0.004945411346852779,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01301237940788269,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008515795692801476,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5ff9bf4d395ee22207cbc",
        "key": "HIVE-15212",
        "id": "13020951",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0035954248160123825
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.08192276209592819
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007518099155277014
                }
            }
        },
        "comments": [
            {
                "author_name": "sershe",
                "id": "15900630",
                "body": "The branch is not ready for merge due to ACID merge being in progress... to make some preliminary progress on the merge, attaching the current branch patch to see what non-MM (or MM) tests would need to be fixed after fixing all the MM issues discovered in HIVE-14990 \ncc [~wzheng] fyi"
            },
            {
                "author_name": "sershe",
                "id": "15903886",
                "body": "trying the same patch again"
            },
            {
                "author_name": "sershe",
                "id": "15922747",
                "body": "Ah, pressing \"submit patch\" might help"
            },
            {
                "author_name": "hiveqa",
                "id": "15922759",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12857093/HIVE-15212.01.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4103/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4103/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4103/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-03-13 19:08:45.334\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-4103/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-03-13 19:08:45.337\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at be47d9e HIVE-16132: DataSize stats don't seem correct in semijoin opt branch (Deepak Jaiswal via Gunther Hagleitner)\n+ git clean -f -d\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at be47d9e HIVE-16132: DataSize stats don't seem correct in semijoin opt branch (Deepak Jaiswal via Gunther Hagleitner)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-03-13 19:08:46.213\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java:205\nerror: ql/src/java/org/apache/hadoop/hive/ql/exec/FileSinkOperator.java: patch does not apply\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java:342\nerror: ql/src/java/org/apache/hadoop/hive/ql/io/HiveInputFormat.java: patch does not apply\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java:949\nerror: ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java: patch does not apply\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/parse/ProcessAnalyzeTable.java:30\nerror: ql/src/java/org/apache/hadoop/hive/ql/parse/ProcessAnalyzeTable.java: patch does not apply\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12857093 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "15922824",
                "body": "Merged master into branch... also reverts HIVE-15616 for now"
            },
            {
                "author_name": "hiveqa",
                "id": "15922906",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12858535/HIVE-15212.01.patch\n\n{color:green}SUCCESS:{color} +1 due to 18 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 142 failed/errored test(s), 9703 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_view] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_view_partitioned] (batchId=34)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cteViews] (batchId=71)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_all2] (batchId=81)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_all] (batchId=62)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_conversions] (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_current] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_insertonly_acid] (batchId=78)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_analyze] (batchId=21)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_map_emptynullvals] (batchId=31)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_null_element] (batchId=68)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_of_multi_field_struct] (batchId=48)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_of_optional_elements] (batchId=66)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_of_required_elements] (batchId=59)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_of_single_field_struct] (batchId=67)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_of_structs] (batchId=16)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_of_unannotated_groups] (batchId=51)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_array_of_unannotated_primitives] (batchId=77)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_avro_array_of_primitives] (batchId=46)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_avro_array_of_single_field_struct] (batchId=66)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_columnar] (batchId=6)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_create] (batchId=80)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_ctas] (batchId=62)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_decimal1] (batchId=48)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_decimal] (batchId=6)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_external_time] (batchId=12)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_int96_timestamp] (batchId=33)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_join] (batchId=18)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_map_null] (batchId=77)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_map_of_arrays_of_ints] (batchId=9)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_map_of_maps] (batchId=61)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_mixed_case] (batchId=35)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_partitioned] (batchId=65)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_ppd] (batchId=25)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_ppd_partition] (batchId=7)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_read_backward_compatible_files] (batchId=46)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_schema_evolution] (batchId=69)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_table_with_subschema] (batchId=9)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_thrift_array_of_primitives] (batchId=42)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_thrift_array_of_single_field_struct] (batchId=76)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_timestamp_conversion] (batchId=6)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_type_promotion] (batchId=77)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[parquet_write_correct_definition_levels] (batchId=37)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters1] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=137)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cbo_rp_unionDistinct_2] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_no_match] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[delete_where_non_partitioned] (batchId=147)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[parquet_predicate_pushdown] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[parquet_types] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_views] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[unionDistinct_2] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_all_types] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_tmp_table] (batchId=146)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_no_match] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[update_where_non_partitioned] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_parquet] (batchId=149)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vectorized_parquet_types] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver (batchId=161)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver (batchId=163)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=94)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[unionDistinct_2] (batchId=94)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[mm_truncate_cols] (batchId=87)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=100)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=101)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=102)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=103)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=104)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=105)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=106)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=107)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=108)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=109)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=110)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=111)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=112)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=113)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=114)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=115)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=116)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=117)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=118)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=119)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=120)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=121)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=122)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=123)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=124)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=125)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=126)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=127)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=128)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=129)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=130)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=131)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=132)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=133)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=134)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=96)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=97)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=98)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=99)\norg.apache.hadoop.hive.cli.TestSparkNegativeCliDriver.org.apache.hadoop.hive.cli.TestSparkNegativeCliDriver (batchId=232)\norg.apache.hadoop.hive.ql.io.TestAcidUtils.testAcidOperationalProperties (batchId=249)\norg.apache.hadoop.hive.ql.io.TestAcidUtils.testAcidOperationalPropertiesSettersAndGetters (batchId=249)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testAmbiguousSingleFieldGroupInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testAvroPrimitiveInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testAvroSingleFieldGroupInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testHiveRequiredGroupInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testMultiFieldGroupInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testNewOptionalGroupInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testNewRequiredGroupInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testThriftPrimitiveInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testThriftSingleFieldGroupInList (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testUnannotatedListOfGroups (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestArrayCompatibility.testUnannotatedListOfPrimitives (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestMapStructures.testDoubleMapWithStructValue (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestMapStructures.testMapWithComplexKey (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestMapStructures.testNestedMap (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestMapStructures.testStringMapOfOptionalArray (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestMapStructures.testStringMapOfOptionalIntArray (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestMapStructures.testStringMapOptionalPrimitive (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestMapStructures.testStringMapRequiredPrimitive (batchId=250)\norg.apache.hadoop.hive.ql.io.parquet.TestParquetRowGroupFilter.testRowGroupFilterTakeEffect (batchId=251)\norg.apache.hadoop.hive.ql.metadata.TestHive.testTable (batchId=257)\norg.apache.hadoop.hive.ql.metadata.TestHive.testThriftTable (batchId=257)\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testTable (batchId=258)\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testThriftTable (batchId=258)\norg.apache.hadoop.hive.ql.optimizer.TestGenMapRedUtilsCreateConditionalTask.testConditionalMoveOnHdfsIsNotOptimized (batchId=259)\norg.apache.hadoop.hive.ql.optimizer.TestGenMapRedUtilsCreateConditionalTask.testMergePathValidMoveWorkReturnsNewMoveWork (batchId=259)\norg.apache.hive.beeline.TestSchemaTool.testSchemaInit (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testSchemaUpgrade (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateLocations (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateNullValues (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateSchemaVersions (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateSequences (batchId=213)\norg.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.testSparkQuery (batchId=219)\norg.apache.hive.jdbc.TestJdbcWithLocalClusterSpark.testTempTable (batchId=219)\norg.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery (batchId=219)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4105/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4105/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4105/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 142 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12858535 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "15923389",
                "body": "TestHive#testTable, unionDistinct, view tests failed because of the MM id related diffs; will be gone after ACID integration.\nSchemaTool due to sql files mess, there's already JIRA for that - will be gone w/ACID integration or cleaned up before merge.\nFiled a bug for parquet tests (and unit tests).\nFixed a number of tests, also reverted the breakage of spark tests."
            },
            {
                "author_name": "sershe",
                "id": "15923393",
                "body": "mm_conversions test is also broken with incorrect results. Either start of ACID merge or something else did it, it looks like. I wonder if conversion from/to regular ACID is preventing MM conversion logic from running; will file a JIRA"
            },
            {
                "author_name": "hiveqa",
                "id": "15923596",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12858604/HIVE-15212.02.patch\n\n{color:green}SUCCESS:{color} +1 due to 18 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 26 failed/errored test(s), 10336 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_view] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_view_partitioned] (batchId=34)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cteViews] (batchId=71)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_buckets] (batchId=55)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_conversions] (batchId=69)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters1] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=137)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cbo_rp_unionDistinct_2] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_views] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[unionDistinct_2] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[unionDistinct_2] (batchId=94)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=96)\norg.apache.hadoop.hive.ql.io.TestAcidUtils.testAcidOperationalProperties (batchId=249)\norg.apache.hadoop.hive.ql.io.TestAcidUtils.testAcidOperationalPropertiesSettersAndGetters (batchId=249)\norg.apache.hadoop.hive.ql.metadata.TestHive.testTable (batchId=257)\norg.apache.hadoop.hive.ql.metadata.TestHive.testThriftTable (batchId=257)\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testTable (batchId=258)\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testThriftTable (batchId=258)\norg.apache.hive.beeline.TestSchemaTool.testSchemaInit (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testSchemaUpgrade (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateLocations (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateNullValues (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateSchemaVersions (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateSequences (batchId=213)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4117/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4117/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4117/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 26 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12858604 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "15923651",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12858604/HIVE-15212.02.patch\n\n{color:green}SUCCESS:{color} +1 due to 18 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 26 failed/errored test(s), 10336 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_view] (batchId=37)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_view_partitioned] (batchId=34)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cteViews] (batchId=71)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_buckets] (batchId=55)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_conversions] (batchId=69)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters1] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=137)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[cbo_rp_unionDistinct_2] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_views] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[unionDistinct_2] (batchId=142)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[unionDistinct_2] (batchId=94)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=97)\norg.apache.hadoop.hive.ql.io.TestAcidUtils.testAcidOperationalProperties (batchId=249)\norg.apache.hadoop.hive.ql.io.TestAcidUtils.testAcidOperationalPropertiesSettersAndGetters (batchId=249)\norg.apache.hadoop.hive.ql.metadata.TestHive.testTable (batchId=257)\norg.apache.hadoop.hive.ql.metadata.TestHive.testThriftTable (batchId=257)\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testTable (batchId=258)\norg.apache.hadoop.hive.ql.metadata.TestHiveRemote.testThriftTable (batchId=258)\norg.apache.hive.beeline.TestSchemaTool.testSchemaInit (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testSchemaUpgrade (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateLocations (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateNullValues (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateSchemaVersions (batchId=213)\norg.apache.hive.beeline.TestSchemaTool.testValidateSequences (batchId=213)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/4118/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/4118/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-4118/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 26 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12858604 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "15924743",
                "body": "The only relevant failures are \n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_buckets] (batchId=55)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_conversions] (batchId=69)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters1] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=137)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=97)\n{noformat}\nThe first one is an out file update, bug exists for conversions, diffs in MiniLlap is the # of HDFS ops - needs to be looked at, as does the failure to init for the Spark test."
            },
            {
                "author_name": "sershe",
                "id": "15924879",
                "body": "Spark test failed due to {noformat}\n2017-03-13T22:47:10,439 ERROR [c8c60e54-0f5e-4d72-8358-6c8bdd10ed96 main] SessionState: Job failed with java.io.IOException: Failed to create local dir in /tmp/blockmgr-33541d36-5096-47ce-8791-dff902c09eac/01.\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:70)\n\tat org.apache.spark.storage.DiskStore.contains(DiskStore.scala:124)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(BlockManager.scala:379)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:959)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:910)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:910)\n\tat org.apache.spark.storage.BlockManager.putIterator(BlockManager.scala:700)\n\tat org.apache.spark.storage.BlockManager.putSingle(BlockManager.scala:1213)\n\tat org.apache.spark.broadcast.TorrentBroadcast.writeBlocks(TorrentBroadcast.scala:103)\n\tat org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:86)\n\tat org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34)\n\tat org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:56)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1370)\n\tat org.apache.spark.rdd.HadoopRDD.<init>(HadoopRDD.scala:125)\n\tat org.apache.spark.SparkContext$$anonfun$hadoopRDD$1.apply(SparkContext.scala:965)\n\tat org.apache.spark.SparkContext$$anonfun$hadoopRDD$1.apply(SparkContext.scala:961)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.SparkContext.withScope(SparkContext.scala:682)\n\tat org.apache.spark.SparkContext.hadoopRDD(SparkContext.scala:961)\n\tat org.apache.spark.api.java.JavaSparkContext.hadoopRDD(JavaSparkContext.scala:412)\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.generateMapInput(SparkPlanGenerator.java:198)\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.generateParentTran(SparkPlanGenerator.java:138)\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.generate(SparkPlanGenerator.java:110)\n\tat org.apache.hadoop.hive.ql.exec.spark.RemoteHiveSparkClient$JobStatusJob.call(RemoteHiveSparkClient.java:346)\n\tat org.apache.hive.spark.client.RemoteDriver$JobWrapper.call(RemoteDriver.java:358)\n\tat org.apache.hive.spark.client.RemoteDriver$JobWrapper.call(RemoteDriver.java:323)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat} \nso probably bad luck... will see on future runs"
            },
            {
                "author_name": "sershe",
                "id": "15927209",
                "body": "Updating the patch after some fixes and another merge"
            },
            {
                "author_name": "sershe",
                "id": "15929201",
                "body": "The same patch again... [~wzheng] [~ekoifman] wrt the discussion in standup, the above is the current state of the tests. In the last run, all the non-q-file tests, as well as view and unionDistinct, are diffs due to mmId.\nI've fixed the 4 MiniLlap tests and all the mm_ tests that failed in the last run, hopefully HiveQA will pick it up someday.\n\nBasically the best way to test feature parity when converting is to run all mm_ tests, incl. negative.\nThen after major changes it might make sense to attach the patch with new branch state here, to see if tests pass overall."
            },
            {
                "author_name": "wzheng",
                "id": "16023916",
                "body": "ACID integration is done. Uploading patch 5 for testing."
            },
            {
                "author_name": "hiveqa",
                "id": "16024011",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12869749/HIVE-15212.05.patch\n\n{color:green}SUCCESS:{color} +1 due to 18 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 10767 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_conversions] (batchId=71)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mm_conversions] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=98)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdate.testNonAcidToAcidConversion3 (batchId=280)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=277)\norg.apache.hadoop.hive.ql.io.TestAcidUtils.testAcidOperationalProperties (batchId=258)\norg.apache.hadoop.hive.ql.io.TestAcidUtils.testAcidOperationalPropertiesSettersAndGetters (batchId=258)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5425/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5425/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5425/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 9 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12869749 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "wzheng",
                "id": "16025379",
                "body": "Upload patch 6 for testing"
            },
            {
                "author_name": "wzheng",
                "id": "16025458",
                "body": "I'm adding a dependency here: HIVE-14990"
            },
            {
                "author_name": "sershe",
                "id": "16025473",
                "body": "HIVE-14990 is a pain because most test failures there by design, from non-MM tables that are created as non-MM (ACID, or flat) mis-identified as MM in various places.\nWe should fix tests here and merge... I think feature parity based on existing MM tests is sufficient. If you look at the issues identified in HIVE-14990, most of them are bugs, and not fundamental limitations; further bugs in various obscure cases can be fixed later."
            },
            {
                "author_name": "wzheng",
                "id": "16025480",
                "body": "I agree with you :) Let me run precommit test for HIVE-14990 one more time and look thru the failures."
            },
            {
                "author_name": "hiveqa",
                "id": "16025601",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12869931/HIVE-15212.06.patch\n\n{color:green}SUCCESS:{color} +1 due to 19 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10799 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_conversions] (batchId=71)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mm_conversions] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[subquery_scalar] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5434/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5434/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5434/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 4 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12869931 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16039667",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12871662/HIVE-15212.07.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 10832 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_all] (batchId=64)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_conversions] (batchId=71)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[mm_conversions] (batchId=158)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainanalyze_2] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query78] (batchId=232)\norg.apache.hadoop.hive.llap.security.TestLlapSignerImpl.testSigning (batchId=289)\norg.apache.hive.jdbc.TestMultiSessionsHS2WithLocalClusterSpark.testSparkQuery (batchId=226)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5551/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5551/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5551/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 10 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12871662 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16042083",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12871943/HIVE-15212.08.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 10832 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=140)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=145)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=232)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query78] (batchId=232)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/5574/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/5574/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-5574/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 4 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12871943 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "wzheng",
                "id": "16158197",
                "body": "Upload patch 9 for testing"
            },
            {
                "author_name": "hiveqa",
                "id": "16158886",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12886001/HIVE-15212.09.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 46 failed/errored test(s), 11042 tests executed\n*Failed tests:*\n{noformat}\nTestAccumuloCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\nTestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[insert_values_orig_table_use_metadata] (batchId=61)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_all] (batchId=65)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[repl_2_exim_basic] (batchId=75)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[repl_3_exim_metadata] (batchId=55)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[skewjoin] (batchId=22)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[skewjoin] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=234)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query64] (batchId=234)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoin] (batchId=111)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion02 (batchId=270)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=270)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion02 (batchId=279)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=279)\norg.apache.hadoop.hive.ql.parse.TestExportImport.dataImportAfterMetadataOnlyImport (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenatePartitionedTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDropsWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDumpLimit (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testEventTypesForDynamicAddPartitionByInsert (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testExchangePartition (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalAdds (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertDropPartitionedTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertDropUnpartitionedTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertToPartition (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInserts (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoad (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoadFailAndRetry (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoadWithVariableLengthEventId (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnExistingObject (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnMissingObject (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnPartitionedTableWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnUnpartitionedTableWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertToMultiKeyPartition (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRemoveStats (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenamePartitionWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenameTableWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testStatus (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testViewsReplication (batchId=218)\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testBasicReplEximCommands (batchId=180)\norg.apache.hive.hcatalog.pig.TestTextFileHCatStorer.testWriteTinyint (batchId=183)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6732/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6732/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6732/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 46 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12886001 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "wzheng",
                "id": "16158955",
                "body": "[~sershe] [~ekoifman] Patch 9 is the latest diff'ed patch between master and hive-14535 branch. Looks like there are some relevant test failures as well as many related to replication. I will try to fix those non-replication related failures today.\n\nIt's strange that the test run didn't generate a test report although it sent the result here to the JIRA."
            },
            {
                "author_name": "wzheng",
                "id": "16159470",
                "body": "patch 10 for test"
            },
            {
                "author_name": "hiveqa",
                "id": "16159841",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12886185/HIVE-15212.10.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 44 failed/errored test(s), 11045 tests executed\n*Failed tests:*\n{noformat}\nTestAccumuloCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\nTestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=230)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[repl_2_exim_basic] (batchId=75)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[repl_3_exim_metadata] (batchId=55)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[skewjoin] (batchId=22)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=143)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[skewjoin] (batchId=150)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=99)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=234)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=234)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[skewjoin] (batchId=111)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion02 (batchId=270)\norg.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion3 (batchId=270)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion02 (batchId=279)\norg.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion3 (batchId=279)\norg.apache.hadoop.hive.ql.parse.TestExportImport.dataImportAfterMetadataOnlyImport (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenatePartitionedTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConstraints (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDropsWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testDumpLimit (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testEventTypesForDynamicAddPartitionByInsert (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testExchangePartition (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalAdds (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertDropPartitionedTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertDropUnpartitionedTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInsertToPartition (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalInserts (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoad (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoadFailAndRetry (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalLoadWithVariableLengthEventId (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnExistingObject (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testIncrementalRepeatEventOnMissingObject (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnPartitionedTableWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnUnpartitionedTableWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertToMultiKeyPartition (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRemoveStats (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenamePartitionWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testRenameTableWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testStatus (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateTable (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testTruncateWithCM (batchId=218)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testViewsReplication (batchId=218)\norg.apache.hive.hcatalog.api.repl.commands.TestCommands.testBasicReplEximCommands (batchId=180)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6745/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6745/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6745/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 44 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12886185 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "16161916",
                "body": "Looking into failures. One is that txn appears to be open where it wasn't before, e.g. in all the replication tests import fails because it's not supported in a transaction that as far as I can tell shouldn't have been opened. Looking... \ncc [~ekoifman]"
            },
            {
                "author_name": "sershe",
                "id": "16162107",
                "body": "skewjoin test is broken due to some incompatibility with HIVE-17113"
            },
            {
                "author_name": "sershe",
                "id": "16162218",
                "body": "Rebasing again; fixing various bugs, incorrect merges and test issues. "
            },
            {
                "author_name": "hiveqa",
                "id": "16164650",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12886530/HIVE-15212.11.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6797/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6797/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6797/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-09-13 13:28:34.116\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6797/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-09-13 13:28:34.118\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 309e891 HIVE-17410 : repl load task during subsequent DAG generation does not start from the last partition processed (Anishek Agarwal via Thejas Nair)\n+ git clean -f -d\nRemoving common/src/java/org/apache/hadoop/hive/conf/HiveConf.java.orig\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 309e891 HIVE-17410 : repl load task during subsequent DAG generation does not start from the last partition processed (Anishek Agarwal via Thejas Nair)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-09-13 13:28:35.977\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/exec/repl/bootstrap/load/table/LoadPartitions.java:44\nerror: ql/src/java/org/apache/hadoop/hive/ql/exec/repl/bootstrap/load/table/LoadPartitions.java: patch does not apply\nerror: patch failed: ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezUtils.java:315\nerror: ql/src/java/org/apache/hadoop/hive/ql/parse/GenTezUtils.java: patch does not apply\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12886530 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "16165149",
                "body": "Rebasing again. Doesn't look like it broke any tests (that I ran) despite the union prefix change. I thought I relied on that somewhere. Need to dbl check. For now, at least I'd get some results here."
            },
            {
                "author_name": "sershe",
                "id": "16165163",
                "body": "Nm, looks like the logic takes the directory name and doesn't actually rely on its exact format. We'll see"
            },
            {
                "author_name": "sershe",
                "id": "16166802",
                "body": "Looks like HiveQA run disappeared silently... the same patch"
            },
            {
                "author_name": "hiveqa",
                "id": "16167485",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12887162/HIVE-15212.12.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6821/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6821/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6821/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-09-15 07:52:07.409\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6821/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-09-15 07:52:07.412\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at 9329cd9 Revert \"HIVE-17261: Hive use deprecated ParquetInputSplit constructor which blocked parquet dictionary filter (Junjie Chen, reviewed by Ferdinand Xu)\"\n+ git clean -f -d\nRemoving standalone-metastore/src/gen/org/\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at 9329cd9 Revert \"HIVE-17261: Hive use deprecated ParquetInputSplit constructor which blocked parquet dictionary filter (Junjie Chen, reviewed by Ferdinand Xu)\"\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-09-15 07:52:11.302\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreThread.java: No such file or directory\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12887162 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "16168401",
                "body": "Rinse, repeat"
            },
            {
                "author_name": "sershe",
                "id": "16168432",
                "body": "A small update"
            },
            {
                "author_name": "sershe",
                "id": "16169482",
                "body": "HiveQA runs just keep disappearing... again"
            },
            {
                "author_name": "hiveqa",
                "id": "16169531",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12887575/HIVE-15212.14.patch\n\n{color:red}ERROR:{color} -1 due to build exiting with an error\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6857/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6857/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6857/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nTests exited with: NonZeroExitCodeException\nCommand 'bash /data/hiveptest/working/scratch/source-prep.sh' failed with exit status 1 and output '+ date '+%Y-%m-%d %T.%3N'\n2017-09-18 02:53:21.912\n+ [[ -n /usr/lib/jvm/java-8-openjdk-amd64 ]]\n+ export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n+ export PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ PATH=/usr/lib/jvm/java-8-openjdk-amd64/bin/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n+ export 'ANT_OPTS=-Xmx1g -XX:MaxPermSize=256m '\n+ ANT_OPTS='-Xmx1g -XX:MaxPermSize=256m '\n+ export 'MAVEN_OPTS=-Xmx1g '\n+ MAVEN_OPTS='-Xmx1g '\n+ cd /data/hiveptest/working/\n+ tee /data/hiveptest/logs/PreCommit-HIVE-Build-6857/source-prep.txt\n+ [[ false == \\t\\r\\u\\e ]]\n+ mkdir -p maven ivy\n+ [[ git = \\s\\v\\n ]]\n+ [[ git = \\g\\i\\t ]]\n+ [[ -z master ]]\n+ [[ -d apache-github-source-source ]]\n+ [[ ! -d apache-github-source-source/.git ]]\n+ [[ ! -d apache-github-source-source ]]\n+ date '+%Y-%m-%d %T.%3N'\n2017-09-18 02:53:21.915\n+ cd apache-github-source-source\n+ git fetch origin\n+ git reset --hard HEAD\nHEAD is now at a51ae9c HIVE-17203: Add InterfaceAudience and InterfaceStability annotations for HCat APIs (Sahil Takiar, reviewed by Aihua Xu)\n+ git clean -f -d\nRemoving standalone-metastore/src/gen/org/\n+ git checkout master\nAlready on 'master'\nYour branch is up-to-date with 'origin/master'.\n+ git reset --hard origin/master\nHEAD is now at a51ae9c HIVE-17203: Add InterfaceAudience and InterfaceStability annotations for HCat APIs (Sahil Takiar, reviewed by Aihua Xu)\n+ git merge --ff-only origin/master\nAlready up-to-date.\n+ date '+%Y-%m-%d %T.%3N'\n2017-09-18 02:53:27.049\n+ patchCommandPath=/data/hiveptest/working/scratch/smart-apply-patch.sh\n+ patchFilePath=/data/hiveptest/working/scratch/build.patch\n+ [[ -f /data/hiveptest/working/scratch/build.patch ]]\n+ chmod +x /data/hiveptest/working/scratch/smart-apply-patch.sh\n+ /data/hiveptest/working/scratch/smart-apply-patch.sh /data/hiveptest/working/scratch/build.patch\nerror: metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreThread.java: No such file or directory\nThe patch does not appear to apply with p0, p1, or p2\n+ exit 1\n'\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12887575 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16173263",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12887999/HIVE-15212.15.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 17 failed/errored test(s), 11056 tests executed\n*Failed tests:*\n{noformat}\nTestAccumuloCliDriver - did not produce a TEST-*.xml file (likely timed out) (batchId=231)\nTestDummy - did not produce a TEST-*.xml file (likely timed out) (batchId=231)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[create_view] (batchId=39)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_all] (batchId=65)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[udf_mask_hash] (batchId=28)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=171)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=100)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[drop_table_failure2] (batchId=90)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=235)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=235)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testCtasTezUnion (batchId=216)\norg.apache.hadoop.hive.ql.TestAcidOnTez.testNonStandardConversion01 (batchId=216)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenatePartitionedTable (batchId=219)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable (batchId=219)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnPartitionedTableWithCM (batchId=219)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnUnpartitionedTableWithCM (batchId=219)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/6903/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/6903/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-6903/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 17 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12887999 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "16174398",
                "body": "Looks like multi insert overwrite is another gap. I actually noticed that the tests on the branch were left in commented out state, and only one section that was valid, has failed. Looks like it's not a stable failure either and depends on sequence of processing. I restored all the old queries and left it with incorrect results for now. \nUnfortunately because noone else is doing breaking work in branches, it's impossible to maintain the branch for a long time against continuous changes from replication, metastore stuff, etc. \nSo, we are going to merge with this gap, and then fix it on master cc [~ekoifman] [~hagleitn]"
            },
            {
                "author_name": "sershe",
                "id": "16174403",
                "body": "I cannot repro TestReplicationScenarios. These are new tests that might be unstable.\nmm_all failed due to the above gap.\nThe rest of the failures are inherited from master\n\nUnfortunately there's another breaking change related to ACID... [~ekoifman] can you please forward port HIVE-15899 to the branch? I took a quick look but I'm out rest of the week and won't be able to do it today... you might be more familiar with its interplay with MM changes. \nAfter that we can probably do another run and merge..."
            },
            {
                "author_name": "ekoifman",
                "id": "16174977",
                "body": "[~wei.zheng] told me that IOW on MM branch wasn't complete since it uses base_N/ concept which MM doesn't yet understand."
            },
            {
                "author_name": "wzheng",
                "id": "16179929",
                "body": "[~ekoifman] You at'ed the wrong person ;)\n\nSorry for the late update. I left a todo comment in HiveInputFormat.java:processForWriteIds()\n{code}\n            // todo for IOW, we also need to count in base dir, if any\n            for (AcidUtils.ParsedDelta delta : dirInfo.getCurrentDirectories()) {\n              Utilities.LOG14535.info(\"Adding input \" + delta.getPath());\n              finalPaths.add(delta.getPath());\n            }\n{code}\nHere we just need to count in base dir if any."
            },
            {
                "author_name": "sershe",
                "id": "16179950",
                "body": "It looks like IOW works, but multi-IOW doesn't (see the mm_all test - where we I/IOW, IOW/IOW, etc. into the same or different tables).\n"
            },
            {
                "author_name": "sershe",
                "id": "16183114",
                "body": "[~hagleitn] [~ekoifman] [~wei.zheng]  given that this is pretty close to commit and the fundamentals won't change, do you want to start reviewing? Or give +1s given that most of this work has been collaborative so you are familiar with it :)\n+1 from my side.\n\nI think we are going to commit with some issues in MM tables (ensuring mainline Hive paths work), basically as if the work is done on master and not a feature branch, like with everyone else in Hive. Otherwise conflicts from people not using feature branches (there's another big one now) will prevent this from ever merging. Then fix it on master like everyone else :)"
            },
            {
                "author_name": "sershe",
                "id": "16183280",
                "body": "Updating the patch. Lots of merging, as well as final cleanup making this ready to commit conditional on the tests passing (I am going to disable MM-specific tests that fail and file bugs to fix them after merge)."
            },
            {
                "author_name": "hiveqa",
                "id": "16183853",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12889367/HIVE-15212.16.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 24 failed/errored test(s), 11100 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_predicate_pushdown] (batchId=232)\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_single_sourced_multi_insert] (batchId=232)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[cte_2] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[dynamic_partition_pruning_2] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[global_limit] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[intersect_merge] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_udf] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[parallel_colstats] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[rcfile_createas1] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schemeAuthority] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[tez_union_dynamic_partition] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[tez_union_dynamic_partition_2] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=171)\norg.apache.hadoop.hive.cli.TestMiniTezCliDriver.testCliDriver[explainuser_3] (batchId=100)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=236)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=203)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenatePartitionedTable (batchId=220)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable (batchId=220)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnPartitionedTableWithCM (batchId=220)\norg.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testInsertOverwriteOnUnpartitionedTableWithCM (batchId=220)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7018/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7018/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7018/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 24 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12889367 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "16185068",
                "body": "Many q files appear to be a combination of HIVE-17642, TEZ-3846 and HIVE-17643. Looking to confirm if there are any real failures... replication stuff seems real but I cannot repro it.\nWill take a look at the log from test server, maybe add better logging."
            },
            {
                "author_name": "sershe",
                "id": "16185199",
                "body": "I can actually repro it now... The error in one of the tests is {noformat}\n2017-09-28T17:22:42,587  WARN [main] exec.ReplCopyTask: Cannot find pfile:/Users/sergey/git/hivegit2/itests/hive-unit/target/warehouse/concatenatetable_org_apache_hadoop_hive_ql_parse_testreplicationscenarios_1506644534106.db/unptned/000000_0_copy_1 in source repo or cmroot\n2017-09-28T17:22:42,588 ERROR [main] exec.Task: Failed with exception java.io.FileNotFoundException: File file:/Users/sergey/git/hivegit2/itests/hive-unit/target/warehouse/org_apache_hadoop_hive_ql_parse_testreplicationscenarios_1506644534106/cmroot/000000_0_copy_1_552d7263007dc3582b713cd224d47925 does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:635)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:861)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:625)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:435)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:435)\n\tat org.apache.hadoop.fs.ProxyFileSystem.getFileStatus(ProxyFileSystem.java:268)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:435)\n\tat org.apache.hadoop.hive.metastore.ReplChangeManager.getFileStatus(ReplChangeManager.java:273)\n\tat org.apache.hadoop.hive.ql.exec.ReplCopyTask.filesInFileListing(ReplCopyTask.java:165)\n\tat org.apache.hadoop.hive.ql.exec.ReplCopyTask.execute(ReplCopyTask.java:98)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:204)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97)\n\tat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2194)\n\tat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1836)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1553)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1308)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1298)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.run(TestReplicationScenarios.java:3478)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.run(TestReplicationScenarios.java:3467)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.loadAndVerify(TestReplicationScenarios.java:237)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.incrementalLoadAndVerify(TestReplicationScenarios.java:209)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable(TestReplicationScenarios.java:2720)\n{noformat}\nLooking at the reason for this..."
            },
            {
                "author_name": "sershe",
                "id": "16185314",
                "body": "Fixing replication tests and some out files."
            },
            {
                "author_name": "hiveqa",
                "id": "16185940",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12889637/HIVE-15212.17.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 17 failed/errored test(s), 11101 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_predicate_pushdown] (batchId=232)\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_single_sourced_multi_insert] (batchId=232)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[cte_2] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[global_limit] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[llap_udf] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[rcfile_createas1] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[schemeAuthority] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[tez_union_dynamic_partition] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[tez_union_dynamic_partition_2] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=171)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.org.apache.hadoop.hive.cli.TestTezPerfCliDriver (batchId=240)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=203)\norg.apache.hive.jdbc.TestJdbcWithMiniHS2.testHttpRetryOnServerIdleTimeout (batchId=229)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7046/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7046/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7046/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 17 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12889637 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "16186416",
                "body": "The whole batch 144 failure is spurious, show go away with a recent fix on master.\nAll the other failures are from master.\nSo, this should be ready to commit for now :)\ncc [~ekoifman]"
            },
            {
                "author_name": "sershe",
                "id": "16186418",
                "body": "Another rebase"
            },
            {
                "author_name": "hiveqa",
                "id": "16186684",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12889768/HIVE-15212.18.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 11102 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_predicate_pushdown] (batchId=232)\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_single_sourced_multi_insert] (batchId=232)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[orc_merge8] (batchId=81)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[unionDistinct_1] (batchId=144)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=171)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.org.apache.hadoop.hive.cli.TestTezPerfCliDriver (batchId=240)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=203)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7055/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7055/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7055/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 9 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12889768 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16191288",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12890283/HIVE-15212.19.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 9 failed/errored test(s), 11210 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_predicate_pushdown] (batchId=232)\norg.apache.hadoop.hive.cli.TestAccumuloCliDriver.testCliDriver[accumulo_single_sourced_multi_insert] (batchId=232)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_all] (batchId=65)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[vector_varchar_simple] (batchId=74)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[union_fast_stats] (batchId=157)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=171)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query14] (batchId=240)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query23] (batchId=240)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7115/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7115/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7115/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 9 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12890283 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "16191928",
                "body": "One of the new failures is some jar access issue (unrelated). mm_all is a trivial change because I removed the noop MoveTask used for compat for HIVE-14990, so the explain changed a bit.\nStill ready for merge ;)"
            },
            {
                "author_name": "sershe",
                "id": "16197963",
                "body": "Another merge and one more jira"
            },
            {
                "author_name": "hiveqa",
                "id": "16198172",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12891175/HIVE-15212.20.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 7 failed/errored test(s), 11205 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_all] (batchId=65)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_exim] (batchId=87)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[spark_local_queries] (batchId=64)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=162)\norg.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] (batchId=171)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[mm_bucket_convert] (batchId=91)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query14] (batchId=239)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7204/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7204/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7204/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 7 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12891175 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sershe",
                "id": "16199474",
                "body": "Looks like import for mm is now completely broken. As per the above strategy, we'll fix it after the merge.\r\nUpdating other tests."
            },
            {
                "author_name": "hiveqa",
                "id": "16200124",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12891362/HIVE-15212.21.patch\n\n{color:green}SUCCESS:{color} +1 due to 20 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 4 failed/errored test(s), 11215 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[optimize_nullscan] (batchId=162)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query14] (batchId=239)\norg.apache.hadoop.hive.cli.TestTezPerfCliDriver.testCliDriver[query23] (batchId=239)\norg.apache.hadoop.hive.cli.control.TestDanglingQOuts.checkDanglingQOut (batchId=202)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/7230/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/7230/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-7230/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 4 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12891362 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "ekoifman",
                "id": "16201136",
                "body": "+1"
            },
            {
                "author_name": "hagleitn",
                "id": "16201170",
                "body": "+1"
            },
            {
                "author_name": "sershe",
                "id": "16201171",
                "body": "+1 also from my side. The branch contains a lot of patches from other people that I was reviewing over time."
            },
            {
                "author_name": "wzheng",
                "id": "16202268",
                "body": "+1 Thanks Sergey for putting it together!"
            },
            {
                "author_name": "sershe",
                "id": "16202901",
                "body": "Committed to master. The further feature development will happen there."
            },
            {
                "author_name": "sershe",
                "id": "16202902",
                "body": "Thanks [~ekoifman] for doing most of the reviews!"
            },
            {
                "author_name": "leftyl",
                "id": "16203069",
                "body": "How should the documentation for this new feature be handled?  (Does the TODOC3.0 label belong on this jira or on the umbrella HIVE-14535?)"
            },
            {
                "author_name": "kgyrtkirk",
                "id": "16205598",
                "body": "[~sershe] the test failure of TestDanglingQOuts is related...is there any specific reason {{mm_exim.q}} is added to the disabled list?\r\n\r\n{code}\r\ndangling qouts: [/home/hiveptest/104.154.154.66-hiveptest-0/apache-github-source-source/ql/src/test/results/clientpositive/mm_exim.q.out]\r\n{code}\r\n"
            },
            {
                "author_name": "sershe",
                "id": "16206411",
                "body": "Import/export for MM has been broken in a recent merge. We are going to be bringing MM tables to the parity they once enjoyed over the coming weeks/months :)"
            },
            {
                "author_name": "sershe",
                "id": "16206417",
                "body": "[~leftylev] we should have some documentation... It could be part of ACID documentation actually. TODO label probably belongs to the umbrella.\r\nI think we will update the wiki in due course."
            },
            {
                "author_name": "leftyl",
                "id": "16248816",
                "body": "Okay, thanks Sergey.\r\n\r\nSo far I've only found one configuration parameter added to master by this merge (*hive.mm.avoid.s3.globstatus* in HIVE-14953) but there may be a few more.\r\n\r\nUpdate 13/Nov/17:  The merge also added *hive.exim.test.mode* (HIVE-15019) and changed the description of *hive.txn.operational.properties* (HIVE-14878) but the latter is internal and so doesn't need to be documented.  Most test configs aren't documented but perhaps *hive.exim.test.mode* should be because it wouldn't show up in a search for \"hive.test.*\" configs."
            },
            {
                "author_name": "vgarg",
                "id": "16486082",
                "body": "Hive 3.0.0 has been released so closing this jira."
            }
        ],
        "comments_predictions": [
            [
                1934588,
                "HIVE-15212",
                "The branch is not ready for merge due to ACID merge being in progress... to make some preliminary progress on the merge, attaching the current branch patch to see what non-MM (or MM) tests would need to be fixed after fixing all the MM issues discovered in HIVE-14990 \ncc [~wzheng] fyi",
                {
                    "property": {
                        "confidence": 0.004370188806205988,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008509882725775242,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018946640193462372,
                        "prediction": false
                    }
                }
            ],
            [
                1934594,
                "HIVE-15212",
                "TestHive#testTable, unionDistinct, view tests failed because of the MM id related diffs; will be gone after ACID integration.\nSchemaTool due to sql files mess, there's already JIRA for that - will be gone w/ACID integration or cleaned up before merge.\nFiled a bug for parquet tests (and unit tests).\nFixed a number of tests, also reverted the breakage of spark tests.",
                {
                    "property": {
                        "confidence": 0.004350260365754366,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012415959499776363,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009353158995509148,
                        "prediction": false
                    }
                }
            ],
            [
                1934595,
                "HIVE-15212",
                "mm_conversions test is also broken with incorrect results. Either start of ACID merge or something else did it, it looks like. I wonder if conversion from/to regular ACID is preventing MM conversion logic from running; will file a JIRA",
                {
                    "property": {
                        "confidence": 0.0056693595834076405,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007601501885801554,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010429627262055874,
                        "prediction": false
                    }
                }
            ],
            [
                1934598,
                "HIVE-15212",
                "The only relevant failures are \n{noformat}\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_buckets] (batchId=55)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[mm_conversions] (batchId=69)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters1] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_llap_counters] (batchId=139)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_basic] (batchId=136)\norg.apache.hadoop.hive.cli.TestMiniLlapCliDriver.testCliDriver[orc_ppd_schema_evol_3a] (batchId=137)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.org.apache.hadoop.hive.cli.TestSparkCliDriver (batchId=97)\n{noformat}\nThe first one is an out file update, bug exists for conversions, diffs in MiniLlap is the # of HDFS ops - needs to be looked at, as does the failure to init for the Spark test.",
                {
                    "property": {
                        "confidence": 0.006893162615597248,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007577467244118452,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.00846504420042038,
                        "prediction": false
                    }
                }
            ],
            [
                1934599,
                "HIVE-15212",
                "Spark test failed due to {noformat}\n2017-03-13T22:47:10,439 ERROR [c8c60e54-0f5e-4d72-8358-6c8bdd10ed96 main] SessionState: Job failed with java.io.IOException: Failed to create local dir in /tmp/blockmgr-33541d36-5096-47ce-8791-dff902c09eac/01.\n\tat org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:70)\n\tat org.apache.spark.storage.DiskStore.contains(DiskStore.scala:124)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$getCurrentBlockStatus(BlockManager.scala:379)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:959)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:910)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:910)\n\tat org.apache.spark.storage.BlockManager.putIterator(BlockManager.scala:700)\n\tat org.apache.spark.storage.BlockManager.putSingle(BlockManager.scala:1213)\n\tat org.apache.spark.broadcast.TorrentBroadcast.writeBlocks(TorrentBroadcast.scala:103)\n\tat org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:86)\n\tat org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34)\n\tat org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:56)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1370)\n\tat org.apache.spark.rdd.HadoopRDD.<init>(HadoopRDD.scala:125)\n\tat org.apache.spark.SparkContext$$anonfun$hadoopRDD$1.apply(SparkContext.scala:965)\n\tat org.apache.spark.SparkContext$$anonfun$hadoopRDD$1.apply(SparkContext.scala:961)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.SparkContext.withScope(SparkContext.scala:682)\n\tat org.apache.spark.SparkContext.hadoopRDD(SparkContext.scala:961)\n\tat org.apache.spark.api.java.JavaSparkContext.hadoopRDD(JavaSparkContext.scala:412)\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.generateMapInput(SparkPlanGenerator.java:198)\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.generateParentTran(SparkPlanGenerator.java:138)\n\tat org.apache.hadoop.hive.ql.exec.spark.SparkPlanGenerator.generate(SparkPlanGenerator.java:110)\n\tat org.apache.hadoop.hive.ql.exec.spark.RemoteHiveSparkClient$JobStatusJob.call(RemoteHiveSparkClient.java:346)\n\tat org.apache.hive.spark.client.RemoteDriver$JobWrapper.call(RemoteDriver.java:358)\n\tat org.apache.hive.spark.client.RemoteDriver$JobWrapper.call(RemoteDriver.java:323)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n{noformat} \nso probably bad luck... will see on future runs",
                {
                    "property": {
                        "confidence": 0.005748417694121599,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010995069518685341,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0078930938616395,
                        "prediction": false
                    }
                }
            ],
            [
                1934601,
                "HIVE-15212",
                "The same patch again... [~wzheng] [~ekoifman] wrt the discussion in standup, the above is the current state of the tests. In the last run, all the non-q-file tests, as well as view and unionDistinct, are diffs due to mmId.\nI've fixed the 4 MiniLlap tests and all the mm_ tests that failed in the last run, hopefully HiveQA will pick it up someday.\n\nBasically the best way to test feature parity when converting is to run all mm_ tests, incl. negative.\nThen after major changes it might make sense to attach the patch with new branch state here, to see if tests pass overall.",
                {
                    "property": {
                        "confidence": 0.004329565446823835,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008707132190465927,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014472132548689842,
                        "prediction": false
                    }
                }
            ],
            [
                1934606,
                "HIVE-15212",
                "HIVE-14990 is a pain because most test failures there by design, from non-MM tables that are created as non-MM (ACID, or flat) mis-identified as MM in various places.\nWe should fix tests here and merge... I think feature parity based on existing MM tests is sufficient. If you look at the issues identified in HIVE-14990, most of them are bugs, and not fundamental limitations; further bugs in various obscure cases can be fixed later.",
                {
                    "property": {
                        "confidence": 0.0038279006257653236,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01793825626373291,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01458858884871006,
                        "prediction": false
                    }
                }
            ],
            [
                1934613,
                "HIVE-15212",
                "[~sershe] [~ekoifman] Patch 9 is the latest diff'ed patch between master and hive-14535 branch. Looks like there are some relevant test failures as well as many related to replication. I will try to fix those non-replication related failures today.\n\nIt's strange that the test run didn't generate a test report although it sent the result here to the JIRA.",
                {
                    "property": {
                        "confidence": 0.0051400307565927505,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005969282239675522,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01661885902285576,
                        "prediction": false
                    }
                }
            ],
            [
                1934616,
                "HIVE-15212",
                "Looking into failures. One is that txn appears to be open where it wasn't before, e.g. in all the replication tests import fails because it's not supported in a transaction that as far as I can tell shouldn't have been opened. Looking... \ncc [~ekoifman]",
                {
                    "property": {
                        "confidence": 0.007046021055430174,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007421576417982578,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010024330578744411,
                        "prediction": false
                    }
                }
            ],
            [
                1934629,
                "HIVE-15212",
                "Looks like multi insert overwrite is another gap. I actually noticed that the tests on the branch were left in commented out state, and only one section that was valid, has failed. Looks like it's not a stable failure either and depends on sequence of processing. I restored all the old queries and left it with incorrect results for now. \nUnfortunately because noone else is doing breaking work in branches, it's impossible to maintain the branch for a long time against continuous changes from replication, metastore stuff, etc. \nSo, we are going to merge with this gap, and then fix it on master cc [~ekoifman] [~hagleitn]",
                {
                    "property": {
                        "confidence": 0.010823461227118969,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0028803071472793818,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.025210313498973846,
                        "prediction": false
                    }
                }
            ],
            [
                1934630,
                "HIVE-15212",
                "I cannot repro TestReplicationScenarios. These are new tests that might be unstable.\nmm_all failed due to the above gap.\nThe rest of the failures are inherited from master\n\nUnfortunately there's another breaking change related to ACID... [~ekoifman] can you please forward port HIVE-15899 to the branch? I took a quick look but I'm out rest of the week and won't be able to do it today... you might be more familiar with its interplay with MM changes. \nAfter that we can probably do another run and merge...",
                {
                    "property": {
                        "confidence": 0.005770285148173571,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00709084328263998,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011413473635911942,
                        "prediction": false
                    }
                }
            ],
            [
                1934632,
                "HIVE-15212",
                "[~ekoifman] You at'ed the wrong person ;)\n\nSorry for the late update. I left a todo comment in HiveInputFormat.java:processForWriteIds()\n{code}\n            // todo for IOW, we also need to count in base dir, if any\n            for (AcidUtils.ParsedDelta delta : dirInfo.getCurrentDirectories()) {\n              Utilities.LOG14535.info(\"Adding input \" + delta.getPath());\n              finalPaths.add(delta.getPath());\n            }\n{code}\nHere we just need to count in base dir if any.",
                {
                    "property": {
                        "confidence": 0.005675553344190121,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009272169321775436,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008976690471172333,
                        "prediction": false
                    }
                }
            ],
            [
                1934634,
                "HIVE-15212",
                "[~hagleitn] [~ekoifman] [~wei.zheng]  given that this is pretty close to commit and the fundamentals won't change, do you want to start reviewing? Or give +1s given that most of this work has been collaborative so you are familiar with it :)\n+1 from my side.\n\nI think we are going to commit with some issues in MM tables (ensuring mainline Hive paths work), basically as if the work is done on master and not a feature branch, like with everyone else in Hive. Otherwise conflicts from people not using feature branches (there's another big one now) will prevent this from ever merging. Then fix it on master like everyone else :)",
                {
                    "property": {
                        "confidence": 0.0052872891537845135,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004705678205937147,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.06311256438493729,
                        "prediction": false
                    }
                }
            ],
            [
                1934635,
                "HIVE-15212",
                "Updating the patch. Lots of merging, as well as final cleanup making this ready to commit conditional on the tests passing (I am going to disable MM-specific tests that fail and file bugs to fix them after merge).",
                {
                    "property": {
                        "confidence": 0.005673947278410196,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.037887491285800934,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.005927609279751778,
                        "prediction": false
                    }
                }
            ],
            [
                1934637,
                "HIVE-15212",
                "Many q files appear to be a combination of HIVE-17642, TEZ-3846 and HIVE-17643. Looking to confirm if there are any real failures... replication stuff seems real but I cannot repro it.\nWill take a look at the log from test server, maybe add better logging.",
                {
                    "property": {
                        "confidence": 0.005087518598884344,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00860743410885334,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013514542020857334,
                        "prediction": false
                    }
                }
            ],
            [
                1934638,
                "HIVE-15212",
                "I can actually repro it now... The error in one of the tests is {noformat}\n2017-09-28T17:22:42,587  WARN [main] exec.ReplCopyTask: Cannot find pfile:/Users/sergey/git/hivegit2/itests/hive-unit/target/warehouse/concatenatetable_org_apache_hadoop_hive_ql_parse_testreplicationscenarios_1506644534106.db/unptned/000000_0_copy_1 in source repo or cmroot\n2017-09-28T17:22:42,588 ERROR [main] exec.Task: Failed with exception java.io.FileNotFoundException: File file:/Users/sergey/git/hivegit2/itests/hive-unit/target/warehouse/org_apache_hadoop_hive_ql_parse_testreplicationscenarios_1506644534106/cmroot/000000_0_copy_1_552d7263007dc3582b713cd224d47925 does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:635)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:861)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:625)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:435)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:435)\n\tat org.apache.hadoop.fs.ProxyFileSystem.getFileStatus(ProxyFileSystem.java:268)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:435)\n\tat org.apache.hadoop.hive.metastore.ReplChangeManager.getFileStatus(ReplChangeManager.java:273)\n\tat org.apache.hadoop.hive.ql.exec.ReplCopyTask.filesInFileListing(ReplCopyTask.java:165)\n\tat org.apache.hadoop.hive.ql.exec.ReplCopyTask.execute(ReplCopyTask.java:98)\n\tat org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:204)\n\tat org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97)\n\tat org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2194)\n\tat org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1836)\n\tat org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1553)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1308)\n\tat org.apache.hadoop.hive.ql.Driver.run(Driver.java:1298)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.run(TestReplicationScenarios.java:3478)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.run(TestReplicationScenarios.java:3467)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.loadAndVerify(TestReplicationScenarios.java:237)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.incrementalLoadAndVerify(TestReplicationScenarios.java:209)\n\tat org.apache.hadoop.hive.ql.parse.TestReplicationScenarios.testConcatenateTable(TestReplicationScenarios.java:2720)\n{noformat}\nLooking at the reason for this...",
                {
                    "property": {
                        "confidence": 0.006133401766419411,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01003996655344963,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007065568119287491,
                        "prediction": false
                    }
                }
            ],
            [
                1934645,
                "HIVE-15212",
                "One of the new failures is some jar access issue (unrelated). mm_all is a trivial change because I removed the noop MoveTask used for compat for HIVE-14990, so the explain changed a bit.\nStill ready for merge ;)",
                {
                    "property": {
                        "confidence": 0.00611148402094841,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006610007956624031,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010647471062839031,
                        "prediction": false
                    }
                }
            ],
            [
                1934657,
                "HIVE-15212",
                "[~sershe] the test failure of TestDanglingQOuts is related...is there any specific reason {{mm_exim.q}} is added to the disabled list?\r\n\r\n{code}\r\ndangling qouts: [/home/hiveptest/104.154.154.66-hiveptest-0/apache-github-source-source/ql/src/test/results/clientpositive/mm_exim.q.out]\r\n{code}\r\n",
                {
                    "property": {
                        "confidence": 0.006626909598708153,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00840394850820303,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0077897412702441216,
                        "prediction": false
                    }
                }
            ],
            [
                1934660,
                "HIVE-15212",
                "Okay, thanks Sergey.\r\n\r\nSo far I've only found one configuration parameter added to master by this merge (*hive.mm.avoid.s3.globstatus* in HIVE-14953) but there may be a few more.\r\n\r\nUpdate 13/Nov/17:  The merge also added *hive.exim.test.mode* (HIVE-15019) and changed the description of *hive.txn.operational.properties* (HIVE-14878) but the latter is internal and so doesn't need to be documented.  Most test configs aren't documented but perhaps *hive.exim.test.mode* should be because it wouldn't show up in a search for \"hive.test.*\" configs.",
                {
                    "property": {
                        "confidence": 0.004321948159486055,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007530600763857365,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.015542474575340748,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d60e54f4d395ee22228c4c",
        "key": "FLINK-17066",
        "id": "13297305",
        "description": "We need to\u00a0update pyarrow version bounds less than 0.14.0 in PyFlink 1.10. The bug[1] comes from the dependency of beam 2.15 which has been resolved in beam 2.17.\r\n\r\n\u00a0[1]\u00a0https://issues.apache.org/jira/browse/BEAM-8368",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.9286742806434631
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.012164204381406307
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.015813486650586128
                }
            }
        },
        "comments": [
            {
                "author_name": "hequn8128",
                "id": "17079412",
                "body": "The problem does not exist in 1.11.0 since pyflink depends on beam-2.19.0 in 1.11.0. "
            },
            {
                "author_name": "hequn8128",
                "id": "17079413",
                "body": "Fixed in 1.10.1 via 2833504f830ddb7b1172ae57428865fcb5cc9a83 "
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d623eff4d395ee222597ae",
        "key": "BIGTOP-526",
        "id": "12550722",
        "description": "We've been using a pretty free-for-all configs. Perhaps it would be useful to turn permission checks on to better match what users would encounter on a real HDFS deployment.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.022265860810875893
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006375439465045929
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.04079238325357437
                }
            }
        },
        "comments": [
            {
                "author_name": "plinnell",
                "id": "13252745",
                "body": "+1 Completely sensible."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5fc52f4d395ee22202018",
        "key": "IGNITE-2580",
        "id": "12937445",
        "description": "*Problem*\nGridDhtTxPrepareFuture is initialized with empty HashSet by default. When single lock is ready HashSet.add() is called causing immediate expansion of underlying HashMap table.\n\n*Solution*\nDo we really need fully-fledged hash set immediately? Probably we can optimize for single-lock case so that HashSet is not needed at all.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.002688422566279769
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.045698072761297226
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.12110712379217148
                }
            }
        },
        "comments": [
            {
                "author_name": "vozerov",
                "id": "16178718",
                "body": "No longer relevant."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d609c4f4d395ee2221eb46",
        "key": "GROOVY-8507",
        "id": "13144666",
        "description": "This\u00a0problem was discovered in a Jenkins pipeline, but then nailed down and found it failed with *groovyc* compiler too.\r\n\r\nCreating a script with\u00a0two nested enums, like:\r\n{code:java}\r\nclass TestClass {\r\n    enum OuterEnum {\r\n        VALUE,\r\n        enum InnerEnum {\r\n            A\r\n        }\r\n    }\r\n}\r\n{code}\r\nAnd compiling with groovyc script.groovy makes the compiler freeze with 100% CPU usage.\r\n\r\nIn Jenkins, this results in the Job and executor being freezed and zombie (need to kill the\u00a0job and executor thread), but I am reporting this to Jenkins as an independent issue.\r\n\r\nAs the problem seems to happen in a stripped down groovy script, I\u00a0am reporting it here too.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.015603621490299702
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009527384303510189
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00385316857136786
                }
            }
        },
        "comments": [
            {
                "author_name": "daniel_sun",
                "id": "16396826",
                "body": "The issue is fixed in the Parrot parser. Please try 2.6.0+ and 3.0.0+. If you try 2.6.0, {{-Dgroovy.antlr4=true}} is required to enable the Parrot parser."
            },
            {
                "author_name": "abayer",
                "id": "16397955",
                "body": "We\u2019re on 2.4.x in Jenkins and can\u2019t move to those."
            },
            {
                "author_name": "emilles",
                "id": "16965683",
                "body": "The antlr2 grammar was fixed for nested enums in GROOVY-4438.  The addition of the trailing comma after {{VALUE}} above is still causes a loop in the antlr2 parser."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d60433f4d395ee222123a6",
        "key": "HBASE-22289",
        "id": "13229439",
        "description": "Not sure if this is handled better in procedure based WAL splitting; in any case it affects versions before that.\r\nThe problem is not in ZK as such but in internal state tracking in master, it seems.\r\n\r\nMaster:\r\n{noformat}\r\n2019-04-21 01:49:49,584 INFO  [master/<master>:17000.splitLogManager..Chore.1] coordination.SplitLogManagerCoordination: Resubmitting task <path>.1555831286638\r\n{noformat}\r\n\r\nworker-rs, split fails \r\n{noformat}\r\n....\r\n2019-04-21 02:05:31,774 INFO  [RS_LOG_REPLAY_OPS-regionserver/<worker-rs>:17020-1] wal.WALSplitter: Processed 24 edits across 2 regions; edits skipped=457; log file=<path>.1555831286638, length=2156363702, corrupted=false, progress failed=true\r\n{noformat}\r\n\r\n\r\nMaster (not sure about the delay of the acquired-message; at any rate it seems to detect the failure fine from this server)\r\n{noformat}\r\n2019-04-21 02:11:14,928 INFO  [main-EventThread] coordination.SplitLogManagerCoordination: Task <path>.1555831286638 acquired by <worker-rs>,17020,1555539815097\r\n2019-04-21 02:19:41,264 INFO  [master/<master>:17000.splitLogManager..Chore.1] coordination.SplitLogManagerCoordination: Skipping resubmissions of task <path>.1555831286638 because threshold 3 reached\r\n{noformat}\r\n\r\nAfter that this task is stuck in the limbo forever with the old worker, and never resubmitted. \r\nRS never logs anything else for this task.\r\nKilling the RS on the worker unblocked the task and some other server did the split very quickly, so seems like master doesn't clear the worker name in its internal state when hitting the threshold... master never restarted so restarting the master might have also cleared it.\r\nThis is extracted from splitlogmanager log messages, note the times.\r\n{noformat}\r\n2019-04-21 02:2   1555831286638=last_update = 1555837874928 last_version = 11 cur_worker_name = <worker-rs>,17020,1555539815097 status = in_progress incarnation = 3 resubmits = 3 batch = installed = 24 done = 3 error = 20, \r\n....\r\n2019-04-22 11:1   1555831286638=last_update = 1555837874928 last_version = 11 cur_worker_name = <worker-rs>,17020,1555539815097 status = in_progress incarnation = 3 resubmits = 3 batch = installed = 24 done = 3 error = 20}\r\n{noformat}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006551673635840416
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0158022902905941
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008122894912958145
                }
            }
        },
        "comments": [
            {
                "author_name": "sershe",
                "id": "16823487",
                "body": "I see that for other tasks that reached threshold, eventually an error is detected:\r\n2019-04-21 02:36:52,951 INFO  [main-EventThread] coordination.SplitLogManagerCoordination: Skipping resubmissions of task <path>.1555832335124 because threshold 3 reached\r\n2019-04-21 02:36:52,951 WARN  [main-EventThread] coordination.SplitLogManagerCoordination: Error splitting <path>.1555832335124\r\n\r\nHowever, no error is logged for the above task. It stays in the tasks map, but after the threshold flag is set, it's never picked up by the timer again."
            },
            {
                "author_name": "sershe",
                "id": "16823503",
                "body": "So the root cause is that for this task in particular, RS'es ZK operation to report error failed permanently against ZK, this RS was having a bad time but then recovered. \r\nBasically ZK task update from RS is a critical message and if it is lost but RS doesn't die, master will forever think the task is in progress.\r\nAnd if the resubmit threshold happens to be hit, it will never resubmit the \"in progress\" task. Hence it will be stuck until either worker RS or master die.\r\n\r\n[~tianjingyun] Not sure if procedures-based implementation in HBASE-21588 is affected by a similar issue if the message from RS to master is lost. Worth checking, because OpenRegion proc has special handling for this, where RS reports to master and kills itself if the report fails (otherwise if the message is lost that too will be stuck forever)\r\n\r\nThat might be what needs to be done for ZK implementation too pre-2.2. The proper fix would be to get rid of imperative updates and report/handle current state, but it's too much of a change for older branches given that ZK impl is abandoned."
            },
            {
                "author_name": "sershe",
                "id": "16823507",
                "body": "Actually nm, ZK error was a red herring (although it could still happen if other ZK update fails; in this case it was actually a take-ownership that failed, and it succeeded on retry).\r\nI see that RS logged handler.WALSplitterHandler: task execution preempted for this task.\r\nThat led me to this helpful TODO:\r\n{noformat}\r\n    // TODO have to correctly figure out when log splitting has been\r\n    // interrupted or has encountered a transient error and when it has\r\n    // encountered a bad non-retry-able persistent error.\r\n      if (!WALSplitter.splitLogFile(walDir, fs.getFileStatus(new Path(walDir, name)), fs, conf, p,\r\n        sequenceIdChecker, splitLogWorkerCoordination, factory)) {\r\n        return Status.PREEMPTED;\r\n      }\r\n{noformat}\r\nWhen task is preempted RS in fact never updates task for the master. I'm not sure what the logic is behind that, what is master supposed to gain from not having the updated information."
            },
            {
                "author_name": "HBaseQA",
                "id": "16823629",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 14s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 12s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 11s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 14s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m  1s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  1m 15s{color} | {color:red} hbase-server: The patch generated 6 new + 17 unchanged - 7 fixed = 23 total (was 24) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m  8s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green}  8m 33s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 34s{color} | {color:red} hbase-server generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 33s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}131m 26s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}167m 44s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hbase-server |\r\n|  |  Switch statement found in org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.process() where one case falls through to the next case  At WALSplitterHandler.java:where one case falls through to the next case  At WALSplitterHandler.java:[lines 80-83] |\r\n| Failed junit tests | hadoop.hbase.regionserver.TestSplitLogWorker |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/149/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12966657/HBASE-22289.01-branch-2.1.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 3c810e771730 4.4.0-143-generic #169~14.04.2-Ubuntu SMP Wed Feb 13 15:00:41 UTC 2019 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / aaa2f50ae1 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/149/artifact/patchprocess/diff-checkstyle-hbase-server.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HBASE-Build/149/artifact/patchprocess/new-findbugs-hbase-server.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/149/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/149/testReport/ |\r\n| Max. process+thread count | 4814 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/149/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "stack",
                "id": "16823661",
                "body": "We don't do increment anymore?\r\n\r\n        SplitLogCounters.tot_wkr_preempt_task.increment();\t\r\n\r\nAdd note on how this fixes the issue? Into code?\r\n\r\nTest too hard?\r\n\r\nThanks [~sershe]\r\n\r\n"
            },
            {
                "author_name": "sershe",
                "id": "16824718",
                "body": "The counter is passed to the report method that increments the passed-in counters. Looks like it broke some test, let me see how to fix it :)\r\nWill add comments"
            },
            {
                "author_name": "sershe",
                "id": "16824736",
                "body": "Updated... looks like this path is already covered, I changed the counter to keep the old semantics (other paths update counter only if ZK update succeeds)"
            },
            {
                "author_name": "HBaseQA",
                "id": "16824831",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 42s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 34s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 15s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 16s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  9s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 32s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 10s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  1m 14s{color} | {color:red} hbase-server: The patch generated 7 new + 23 unchanged - 6 fixed = 30 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 11s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green}  8m 58s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 27s{color} | {color:red} hbase-server generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}173m 15s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}210m 55s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hbase-server |\r\n|  |  Switch statement found in org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.process() where one case falls through to the next case  At WALSplitterHandler.java:where one case falls through to the next case  At WALSplitterHandler.java:[lines 85-88] |\r\n| Failed junit tests | hadoop.hbase.coprocessor.TestMetaTableMetrics |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/168/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12966830/HBASE-22289.02-branch-2.1.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 6bd107ce264b 4.4.0-141-generic #167~14.04.1-Ubuntu SMP Mon Dec 10 13:20:24 UTC 2018 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / 899610e657 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/168/artifact/patchprocess/diff-checkstyle-hbase-server.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HBASE-Build/168/artifact/patchprocess/new-findbugs-hbase-server.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/168/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/168/testReport/ |\r\n| Max. process+thread count | 4845 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/168/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "sershe",
                "id": "16826490",
                "body": "Fixed checkstyle; findbugs issue is the same as the previous fall-thru pattern in this case. "
            },
            {
                "author_name": "HBaseQA",
                "id": "16826579",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 52s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 39s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 23s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 52s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 31s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  1m 18s{color} | {color:red} hbase-server: The patch generated 1 new + 15 unchanged - 14 fixed = 16 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 52s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 10m  8s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 42s{color} | {color:red} hbase-server generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}179m 18s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 28s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}222m 56s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hbase-server |\r\n|  |  Switch statement found in org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.process() where one case falls through to the next case  At WALSplitterHandler.java:where one case falls through to the next case  At WALSplitterHandler.java:[lines 84-87] |\r\n| Failed junit tests | hadoop.hbase.quotas.TestSpaceQuotas |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/190/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967068/HBASE-22289.03-branch-2.1.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 7507ee5a95f4 4.4.0-143-generic #169~14.04.2-Ubuntu SMP Wed Feb 13 15:00:41 UTC 2019 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / c7a70dfaba |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/190/artifact/patchprocess/diff-checkstyle-hbase-server.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HBASE-Build/190/artifact/patchprocess/new-findbugs-hbase-server.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/190/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/190/testReport/ |\r\n| Max. process+thread count | 5263 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/190/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "sershe",
                "id": "16827377",
                "body": "[~stack] the last patch should be good... :) checkstyle is a long line I can fix on commit, and findbugs is the same issue already existing in this code "
            },
            {
                "author_name": "stack",
                "id": "16842808",
                "body": "Patch looks good [~sershe] Let me try and fix the FB.."
            },
            {
                "author_name": "HBaseQA",
                "id": "16843110",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 42s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 19s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 16s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 17s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 32s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 33s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 14s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 19s{color} | {color:green} hbase-server: The patch generated 0 new + 15 unchanged - 14 fixed = 15 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 12s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green}  8m 17s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}226m  2s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 46s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}263m 55s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/349/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12969061/HBASE-22289.branch-2.1.001.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 7fd171e1cb9a 4.4.0-143-generic #169~14.04.2-Ubuntu SMP Wed Feb 13 15:00:41 UTC 2019 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / c5d5cd3ff2 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/349/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/349/testReport/ |\r\n| Max. process+thread count | 5148 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/349/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "HBaseQA",
                "id": "16843242",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 43s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 27s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 15s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m  3s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 11s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 31s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 15s{color} | {color:green} hbase-server: The patch generated 0 new + 15 unchanged - 14 fixed = 15 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m  3s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green}  8m 25s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}177m 49s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}214m 19s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/354/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12969080/HBASE-22289.branch-2.1.001.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 843e384d8666 4.4.0-143-generic #169~14.04.2-Ubuntu SMP Wed Feb 13 15:00:41 UTC 2019 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / c5d5cd3ff2 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/354/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/354/testReport/ |\r\n| Max. process+thread count | 5073 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/354/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "stack",
                "id": "16843245",
                "body": "Fails here:\r\n\r\n{code}\r\n[ERROR] org.apache.maven.surefire.booter.SurefireBooterForkException: ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\r\n[ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-server && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2019-05-18T18:07:33Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true -jar /testptch/hbase/hbase-server/target/surefire/surefirebooter969393008550780328.jar /testptch/hbase/hbase-server/target/surefire 2019-05-18T18-08-18_047-jvmRun2 surefire8098665633275435126tmp surefire_10648533127163597806951tmp\r\n[ERROR] Error occurred in starting fork, check output in log\r\n[ERROR] Process Exit Code: 1\r\n[ERROR] Crashed tests:\r\n[ERROR] org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.awaitResultsDone(ForkStarter.java:494)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.runSuitesForkPerTestSet(ForkStarter.java:441)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:293)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:245)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1194)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1022)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:868)\r\n[ERROR] \tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:154)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:146)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)\r\n[ERROR] \tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)\r\n[ERROR] \tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)\r\n[ERROR] \tat org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)\r\n[ERROR] \tat org.apache.maven.cli.MavenCli.execute(MavenCli.java:954)\r\n[ERROR] \tat org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)\r\n[ERROR] \tat org.apache.maven.cli.MavenCli.main(MavenCli.java:192)\r\n[ERROR] \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n[ERROR] \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n[ERROR] \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n[ERROR] \tat java.lang.reflect.Method.invoke(Method.java:498)\r\n[ERROR] \tat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)\r\n[ERROR] \tat org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)\r\n[ERROR] \tat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)\r\n[ERROR] \tat org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)\r\n[ERROR] Caused by: org.apache.maven.surefire.booter.SurefireBooterForkException: The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\r\n[ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-server && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2019-05-18T18:07:33Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true -jar /testptch/hbase/hbase-server/target/surefire/surefirebooter969393008550780328.jar /testptch/hbase/hbase-server/target/surefire 2019-05-18T18-08-18_047-jvmRun2 surefire8098665633275435126tmp surefire_10648533127163597806951tmp\r\n[ERROR] Error occurred in starting fork, check output in log\r\n[ERROR] Process Exit Code: 1\r\n[ERROR] Crashed tests:\r\n[ERROR] org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:671)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:533)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.access$600(ForkStarter.java:115)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter$2.call(ForkStarter.java:429)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter$2.call(ForkStarter.java:406)\r\n[ERROR] \tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n[ERROR] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[ERROR] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[ERROR] \tat java.lang.Thread.run(Thread.java:748)\r\n[ERROR] -> [Help 1]\r\n{code}\r\n\r\nBefore this, it was in [ERROR] Tests run: 21, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 449.006 s <<< FAILURE! - in org.apache.hadoop.hbase.util.TestFromClientSide3WoUnsafe\r\n[ERROR] testMultiRowMutations(org.apache.hadoop.hbase.util.TestFromClientSide3WoUnsafe)  Time elapsed: 27.04 s  <<< ERROR!\r\norg.apache.hadoop.hbase.client.RetriesExhaustedException: \r\n... and [ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-server && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2019-05-18T03:38:39Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true -jar /testptch/hbase/hbase-server/target/surefire/surefirebooter477464835149665861.jar /testptch/hbase/hbase-server/target/surefire 2019-05-18T03-39-27_504-jvmRun5 surefire1809558336861907377tmp surefire_9163845162714239793346tmp\r\n[ERROR] Error occurred in starting fork, check output in log\r\n[ERROR] Process Exit Code: 1\r\n[ERROR] Crashed tests:\r\n[ERROR] org.apache.hadoop.hbase.replication.multiwal.TestReplicationKillMasterRSCompressedWithMultipleWAL\r\n[ERROR] org.apache.maven.surefire.booter.SurefireBooterForkException: ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\r\n[ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-server && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2019-05-18T03:38:39Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true -jar /testptch/hbase/hbase-server/target/surefire/surefirebooter477464835149665861.jar /testptch/hbase/hbase-server/target/surefire 2019-05-18T03-39-27_504-jvmRun5 surefire1809558336861907377tmp surefire_9163845162714239793346tmp\r\n[ERROR] Error occurred in starting fork, check output in log\r\n[ERROR] Process Exit Code: 1\r\n[ERROR] Crashed tests:\r\n[ERROR] org.apache.hadoop.hbase.replication.multiwal.TestReplicationKillMasterRSCompressedWithMultipleWAL\r\n\r\n... Let me try again."
            },
            {
                "author_name": "HBaseQA",
                "id": "16843275",
                "body": "| (/) *{color:green}+1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 29s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m  1s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  9s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m  1s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 16s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 30s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 48s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  8s{color} | {color:green} hbase-server: The patch generated 0 new + 15 unchanged - 14 fixed = 15 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  3m 53s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 32s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}137m 14s{color} | {color:green} hbase-server in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}163m 55s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/356/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12969083/HBASE-22289.branch-2.1.001.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  checkstyle  compile  |\r\n| uname | Linux 28f8508a8dae 4.4.0-138-generic #164-Ubuntu SMP Tue Oct 2 17:16:02 UTC 2018 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / fe7a73c9e9 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/356/testReport/ |\r\n| Max. process+thread count | 4919 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/356/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "stack",
                "id": "16844092",
                "body": "All green. I pushed this to branch-2.1 and branch-2.0. Fails against branch-2.2. Lets open a subtask if you think it needs to go to branch-2.2 [~sershe] Thanks."
            },
            {
                "author_name": "sershe",
                "id": "16844157",
                "body": "Thanks for taking it over the finish line! \r\nIt shouldn't affect 2.2 and later versions, at least in this form, because this code has been replaced by procedures. They might have a similar bug but it would require a different fix."
            },
            {
                "author_name": "hudson",
                "id": "16844356",
                "body": "Results for branch branch-2.1\n\t[build #1164 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/branch-2.1/1164/]: (x) *{color:red}-1 overall{color}*\n----\ndetails (if available):\n\n(x) {color:red}-1 general checks{color}\n-- Something went wrong running this stage, please [check relevant console output|https://builds.apache.org/job/HBase%20Nightly/job/branch-2.1/1164//console].\n\n\n\n\n(/) {color:green}+1 jdk8 hadoop2 checks{color}\n-- For more information [see jdk8 (hadoop2) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2.1/1164//JDK8_Nightly_Build_Report_(Hadoop2)/]\n\n\n(/) {color:green}+1 jdk8 hadoop3 checks{color}\n-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2.1/1164//JDK8_Nightly_Build_Report_(Hadoop3)/]\n\n\n(/) {color:green}+1 source release artifact{color}\n-- See build output for details.\n\n\n(/) {color:green}+1 client integration test{color}\n"
            },
            {
                "author_name": "hudson",
                "id": "16844493",
                "body": "Results for branch branch-2.0\n\t[build #1605 on builds.a.o|https://builds.apache.org/job/HBase%20Nightly/job/branch-2.0/1605/]: (x) *{color:red}-1 overall{color}*\n----\ndetails (if available):\n\n(x) {color:red}-1 general checks{color}\n-- Something went wrong running this stage, please [check relevant console output|https://builds.apache.org/job/HBase%20Nightly/job/branch-2.0/1605//console].\n\n\n\n\n(x) {color:red}-1 jdk8 hadoop2 checks{color}\n-- Something went wrong running this stage, please [check relevant console output|https://builds.apache.org/job/HBase%20Nightly/job/branch-2.0/1605//console].\n\n\n(/) {color:green}+1 jdk8 hadoop3 checks{color}\n-- For more information [see jdk8 (hadoop3) report|https://builds.apache.org/job/HBase%20Nightly/job/branch-2.0/1605//JDK8_Nightly_Build_Report_(Hadoop3)/]\n\n\n(/) {color:green}+1 source release artifact{color}\n-- See build output for details.\n"
            }
        ],
        "comments_predictions": [
            [
                2268473,
                "HBASE-22289",
                "I see that for other tasks that reached threshold, eventually an error is detected:\r\n2019-04-21 02:36:52,951 INFO  [main-EventThread] coordination.SplitLogManagerCoordination: Skipping resubmissions of task <path>.1555832335124 because threshold 3 reached\r\n2019-04-21 02:36:52,951 WARN  [main-EventThread] coordination.SplitLogManagerCoordination: Error splitting <path>.1555832335124\r\n\r\nHowever, no error is logged for the above task. It stays in the tasks map, but after the threshold flag is set, it's never picked up by the timer again.",
                {
                    "property": {
                        "confidence": 0.007394074462354183,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006688087712973356,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009037639945745468,
                        "prediction": false
                    }
                }
            ],
            [
                2268474,
                "HBASE-22289",
                "So the root cause is that for this task in particular, RS'es ZK operation to report error failed permanently against ZK, this RS was having a bad time but then recovered. \r\nBasically ZK task update from RS is a critical message and if it is lost but RS doesn't die, master will forever think the task is in progress.\r\nAnd if the resubmit threshold happens to be hit, it will never resubmit the \"in progress\" task. Hence it will be stuck until either worker RS or master die.\r\n\r\n[~tianjingyun] Not sure if procedures-based implementation in HBASE-21588 is affected by a similar issue if the message from RS to master is lost. Worth checking, because OpenRegion proc has special handling for this, where RS reports to master and kills itself if the report fails (otherwise if the message is lost that too will be stuck forever)\r\n\r\nThat might be what needs to be done for ZK implementation too pre-2.2. The proper fix would be to get rid of imperative updates and report/handle current state, but it's too much of a change for older branches given that ZK impl is abandoned.",
                {
                    "property": {
                        "confidence": 0.006702885497361422,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0050834971480071545,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.13380926847457886,
                        "prediction": false
                    }
                }
            ],
            [
                2268475,
                "HBASE-22289",
                "Actually nm, ZK error was a red herring (although it could still happen if other ZK update fails; in this case it was actually a take-ownership that failed, and it succeeded on retry).\r\nI see that RS logged handler.WALSplitterHandler: task execution preempted for this task.\r\nThat led me to this helpful TODO:\r\n{noformat}\r\n    // TODO have to correctly figure out when log splitting has been\r\n    // interrupted or has encountered a transient error and when it has\r\n    // encountered a bad non-retry-able persistent error.\r\n      if (!WALSplitter.splitLogFile(walDir, fs.getFileStatus(new Path(walDir, name)), fs, conf, p,\r\n        sequenceIdChecker, splitLogWorkerCoordination, factory)) {\r\n        return Status.PREEMPTED;\r\n      }\r\n{noformat}\r\nWhen task is preempted RS in fact never updates task for the master. I'm not sure what the logic is behind that, what is master supposed to gain from not having the updated information.",
                {
                    "property": {
                        "confidence": 0.007632492575794458,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004719305317848921,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01324704010039568,
                        "prediction": false
                    }
                }
            ],
            [
                2268476,
                "HBASE-22289",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 14s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 12s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 11s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 14s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m  1s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  1m 15s{color} | {color:red} hbase-server: The patch generated 6 new + 17 unchanged - 7 fixed = 23 total (was 24) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m  8s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green}  8m 33s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 34s{color} | {color:red} hbase-server generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 33s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}131m 26s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}167m 44s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hbase-server |\r\n|  |  Switch statement found in org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.process() where one case falls through to the next case  At WALSplitterHandler.java:where one case falls through to the next case  At WALSplitterHandler.java:[lines 80-83] |\r\n| Failed junit tests | hadoop.hbase.regionserver.TestSplitLogWorker |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/149/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12966657/HBASE-22289.01-branch-2.1.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 3c810e771730 4.4.0-143-generic #169~14.04.2-Ubuntu SMP Wed Feb 13 15:00:41 UTC 2019 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / aaa2f50ae1 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/149/artifact/patchprocess/diff-checkstyle-hbase-server.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HBASE-Build/149/artifact/patchprocess/new-findbugs-hbase-server.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/149/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/149/testReport/ |\r\n| Max. process+thread count | 4814 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/149/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004075228236615658,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008291480131447315,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.022650612518191338,
                        "prediction": false
                    }
                }
            ],
            [
                2268480,
                "HBASE-22289",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 42s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 34s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 15s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 16s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  9s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 32s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 10s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  1m 14s{color} | {color:red} hbase-server: The patch generated 7 new + 23 unchanged - 6 fixed = 30 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 11s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green}  8m 58s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 27s{color} | {color:red} hbase-server generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}173m 15s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}210m 55s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hbase-server |\r\n|  |  Switch statement found in org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.process() where one case falls through to the next case  At WALSplitterHandler.java:where one case falls through to the next case  At WALSplitterHandler.java:[lines 85-88] |\r\n| Failed junit tests | hadoop.hbase.coprocessor.TestMetaTableMetrics |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/168/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12966830/HBASE-22289.02-branch-2.1.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 6bd107ce264b 4.4.0-141-generic #167~14.04.1-Ubuntu SMP Mon Dec 10 13:20:24 UTC 2018 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / 899610e657 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/168/artifact/patchprocess/diff-checkstyle-hbase-server.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HBASE-Build/168/artifact/patchprocess/new-findbugs-hbase-server.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/168/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/168/testReport/ |\r\n| Max. process+thread count | 4845 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/168/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.0040803952142596245,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008262109942734241,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02272336371243,
                        "prediction": false
                    }
                }
            ],
            [
                2268482,
                "HBASE-22289",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 52s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  5m 39s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 23s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 52s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 31s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  1m 18s{color} | {color:red} hbase-server: The patch generated 1 new + 15 unchanged - 14 fixed = 16 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 52s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green} 10m  8s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 42s{color} | {color:red} hbase-server generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}179m 18s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 28s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}222m 56s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| FindBugs | module:hbase-server |\r\n|  |  Switch statement found in org.apache.hadoop.hbase.regionserver.handler.WALSplitterHandler.process() where one case falls through to the next case  At WALSplitterHandler.java:where one case falls through to the next case  At WALSplitterHandler.java:[lines 84-87] |\r\n| Failed junit tests | hadoop.hbase.quotas.TestSpaceQuotas |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/190/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12967068/HBASE-22289.03-branch-2.1.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 7507ee5a95f4 4.4.0-143-generic #169~14.04.2-Ubuntu SMP Wed Feb 13 15:00:41 UTC 2019 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / c7a70dfaba |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-HBASE-Build/190/artifact/patchprocess/diff-checkstyle-hbase-server.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-HBASE-Build/190/artifact/patchprocess/new-findbugs-hbase-server.html |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/190/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/190/testReport/ |\r\n| Max. process+thread count | 5263 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/190/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004139904864132404,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008078687824308872,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.022910458967089653,
                        "prediction": false
                    }
                }
            ],
            [
                2268485,
                "HBASE-22289",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 42s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 19s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 57s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 16s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 17s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 32s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 33s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 14s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 19s{color} | {color:green} hbase-server: The patch generated 0 new + 15 unchanged - 14 fixed = 15 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m 12s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green}  8m 17s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 23s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}226m  2s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 46s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}263m 55s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/349/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12969061/HBASE-22289.branch-2.1.001.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 7fd171e1cb9a 4.4.0-143-generic #169~14.04.2-Ubuntu SMP Wed Feb 13 15:00:41 UTC 2019 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / c5d5cd3ff2 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/349/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/349/testReport/ |\r\n| Max. process+thread count | 5148 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/349/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.00417883787304163,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008186369203031063,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.019607188180088997,
                        "prediction": false
                    }
                }
            ],
            [
                2268486,
                "HBASE-22289",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 43s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} hbaseanti {color} | {color:green}  0m  0s{color} | {color:green} Patch does not have any anti-patterns. {color} |\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 27s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 51s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 15s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m  3s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 11s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 31s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 15s{color} | {color:green} hbase-server: The patch generated 0 new + 15 unchanged - 14 fixed = 15 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m  3s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} hadoopcheck {color} | {color:green}  8m 25s{color} | {color:green} Patch does not cause any errors with Hadoop 2.7.4 or 3.0.0. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}177m 49s{color} | {color:red} hbase-server in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}214m 19s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/354/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12969080/HBASE-22289.branch-2.1.001.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  hbaseanti  checkstyle  compile  |\r\n| uname | Linux 843e384d8666 4.4.0-143-generic #169~14.04.2-Ubuntu SMP Wed Feb 13 15:00:41 UTC 2019 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / c5d5cd3ff2 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n| unit | https://builds.apache.org/job/PreCommit-HBASE-Build/354/artifact/patchprocess/patch-unit-hbase-server.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/354/testReport/ |\r\n| Max. process+thread count | 5073 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/354/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.0041403332725167274,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008292983286082745,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.019581474363803864,
                        "prediction": false
                    }
                }
            ],
            [
                2268487,
                "HBASE-22289",
                "Fails here:\r\n\r\n{code}\r\n[ERROR] org.apache.maven.surefire.booter.SurefireBooterForkException: ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\r\n[ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-server && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2019-05-18T18:07:33Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true -jar /testptch/hbase/hbase-server/target/surefire/surefirebooter969393008550780328.jar /testptch/hbase/hbase-server/target/surefire 2019-05-18T18-08-18_047-jvmRun2 surefire8098665633275435126tmp surefire_10648533127163597806951tmp\r\n[ERROR] Error occurred in starting fork, check output in log\r\n[ERROR] Process Exit Code: 1\r\n[ERROR] Crashed tests:\r\n[ERROR] org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.awaitResultsDone(ForkStarter.java:494)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.runSuitesForkPerTestSet(ForkStarter.java:441)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:293)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.run(ForkStarter.java:245)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeProvider(AbstractSurefireMojo.java:1194)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.AbstractSurefireMojo.executeAfterPreconditionsChecked(AbstractSurefireMojo.java:1022)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.AbstractSurefireMojo.execute(AbstractSurefireMojo.java:868)\r\n[ERROR] \tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:208)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:154)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:146)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56)\r\n[ERROR] \tat org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)\r\n[ERROR] \tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:305)\r\n[ERROR] \tat org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192)\r\n[ERROR] \tat org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105)\r\n[ERROR] \tat org.apache.maven.cli.MavenCli.execute(MavenCli.java:954)\r\n[ERROR] \tat org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)\r\n[ERROR] \tat org.apache.maven.cli.MavenCli.main(MavenCli.java:192)\r\n[ERROR] \tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n[ERROR] \tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n[ERROR] \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n[ERROR] \tat java.lang.reflect.Method.invoke(Method.java:498)\r\n[ERROR] \tat org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)\r\n[ERROR] \tat org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)\r\n[ERROR] \tat org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)\r\n[ERROR] \tat org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)\r\n[ERROR] Caused by: org.apache.maven.surefire.booter.SurefireBooterForkException: The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\r\n[ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-server && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2019-05-18T18:07:33Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true -jar /testptch/hbase/hbase-server/target/surefire/surefirebooter969393008550780328.jar /testptch/hbase/hbase-server/target/surefire 2019-05-18T18-08-18_047-jvmRun2 surefire8098665633275435126tmp surefire_10648533127163597806951tmp\r\n[ERROR] Error occurred in starting fork, check output in log\r\n[ERROR] Process Exit Code: 1\r\n[ERROR] Crashed tests:\r\n[ERROR] org.apache.hadoop.hbase.regionserver.TestHRegionWithInMemoryFlush\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:671)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.fork(ForkStarter.java:533)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter.access$600(ForkStarter.java:115)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter$2.call(ForkStarter.java:429)\r\n[ERROR] \tat org.apache.maven.plugin.surefire.booterclient.ForkStarter$2.call(ForkStarter.java:406)\r\n[ERROR] \tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n[ERROR] \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[ERROR] \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[ERROR] \tat java.lang.Thread.run(Thread.java:748)\r\n[ERROR] -> [Help 1]\r\n{code}\r\n\r\nBefore this, it was in [ERROR] Tests run: 21, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 449.006 s <<< FAILURE! - in org.apache.hadoop.hbase.util.TestFromClientSide3WoUnsafe\r\n[ERROR] testMultiRowMutations(org.apache.hadoop.hbase.util.TestFromClientSide3WoUnsafe)  Time elapsed: 27.04 s  <<< ERROR!\r\norg.apache.hadoop.hbase.client.RetriesExhaustedException: \r\n... and [ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-server && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2019-05-18T03:38:39Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true -jar /testptch/hbase/hbase-server/target/surefire/surefirebooter477464835149665861.jar /testptch/hbase/hbase-server/target/surefire 2019-05-18T03-39-27_504-jvmRun5 surefire1809558336861907377tmp surefire_9163845162714239793346tmp\r\n[ERROR] Error occurred in starting fork, check output in log\r\n[ERROR] Process Exit Code: 1\r\n[ERROR] Crashed tests:\r\n[ERROR] org.apache.hadoop.hbase.replication.multiwal.TestReplicationKillMasterRSCompressedWithMultipleWAL\r\n[ERROR] org.apache.maven.surefire.booter.SurefireBooterForkException: ExecutionException The forked VM terminated without properly saying goodbye. VM crash or System.exit called?\r\n[ERROR] Command was /bin/sh -c cd /testptch/hbase/hbase-server && /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java -enableassertions -Dhbase.build.id=2019-05-18T03:38:39Z -Xmx2800m -Djava.security.egd=file:/dev/./urandom -Djava.net.preferIPv4Stack=true -Djava.awt.headless=true -Djdk.net.URLClassPath.disableClassPathURLCheck=true -jar /testptch/hbase/hbase-server/target/surefire/surefirebooter477464835149665861.jar /testptch/hbase/hbase-server/target/surefire 2019-05-18T03-39-27_504-jvmRun5 surefire1809558336861907377tmp surefire_9163845162714239793346tmp\r\n[ERROR] Error occurred in starting fork, check output in log\r\n[ERROR] Process Exit Code: 1\r\n[ERROR] Crashed tests:\r\n[ERROR] org.apache.hadoop.hbase.replication.multiwal.TestReplicationKillMasterRSCompressedWithMultipleWAL\r\n\r\n... Let me try again.",
                {
                    "property": {
                        "confidence": 0.008392870426177979,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007963188923895359,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007702867966145277,
                        "prediction": false
                    }
                }
            ],
            [
                2268488,
                "HBASE-22289",
                "| (/) *{color:green}+1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 29s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:orange}-0{color} | {color:orange} test4tests {color} | {color:orange}  0m  0s{color} | {color:orange} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |\r\n|| || || || {color:brown} branch-2.1 Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m  1s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 50s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  9s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  4m  1s{color} | {color:green} branch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 16s{color} | {color:green} branch-2.1 passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 30s{color} | {color:green} branch-2.1 passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 48s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m  8s{color} | {color:green} hbase-server: The patch generated 0 new + 15 unchanged - 14 fixed = 15 total (was 29) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} shadedjars {color} | {color:green}  3m 53s{color} | {color:green} patch has no errors when building our shaded downstream artifacts. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 32s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}137m 14s{color} | {color:green} hbase-server in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}163m 55s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce base: https://builds.apache.org/job/PreCommit-HBASE-Build/356/artifact/patchprocess/Dockerfile |\r\n| JIRA Issue | HBASE-22289 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12969083/HBASE-22289.branch-2.1.001.patch |\r\n| Optional Tests |  dupname  asflicense  javac  javadoc  unit  findbugs  shadedjars  hadoopcheck  checkstyle  compile  |\r\n| uname | Linux 28f8508a8dae 4.4.0-138-generic #164-Ubuntu SMP Tue Oct 2 17:16:02 UTC 2018 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | dev-support/hbase-personality.sh |\r\n| git revision | branch-2.1 / fe7a73c9e9 |\r\n| maven | version: Apache Maven 3.5.4 (1edded0938998edf8bf061f1ceb3cfdeccf443fe; 2018-06-17T18:33:14Z) |\r\n| Default Java | 1.8.0_181 |\r\n| findbugs | v3.1.11 |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-HBASE-Build/356/testReport/ |\r\n| Max. process+thread count | 4919 (vs. ulimit of 10000) |\r\n| modules | C: hbase-server U: hbase-server |\r\n| Console output | https://builds.apache.org/job/PreCommit-HBASE-Build/356/console |\r\n| Powered by | Apache Yetus 0.9.0 http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004158239811658859,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007047153078019619,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.024091199040412903,
                        "prediction": false
                    }
                }
            ],
            [
                2268490,
                "HBASE-22289",
                "Thanks for taking it over the finish line! \r\nIt shouldn't affect 2.2 and later versions, at least in this form, because this code has been replaced by procedures. They might have a similar bug but it would require a different fix.",
                {
                    "property": {
                        "confidence": 0.006031955126672983,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.020398365333676338,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.005929227918386459,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d62d47f4d395ee2226cd96",
        "key": "AMBARI-24384",
        "id": "13175604",
        "description": "Add logic and declaration used to determine if Kerberos is enabled for a service.\r\n\r\nTo support a robust method to determine whether Kerberos is enabled or not, a new attribute should be added - {{kerberosEnabledTest}}.  \r\n\r\nThe {{kerberosEnabledTest}} attribute is to contain a JSON document that can be _compiled_ into a {{org.apache.commons.collections.Predicate}} (ideally using {{org.apache.ambari.server.collections.PredicateUtils#fromJSON}}).  For example\r\n\r\n{code}\r\n<sso>\r\n  <supported>true</supported>\r\n  <kerberosRequired>true</kerberosRequired>\r\n  ...\r\n</sso>\r\n<kerberosEnabledTest>\r\n    {\r\n      \"equals\": [\r\n        \"service-properties/kerberos.enabled\",\r\n        \"true\"\r\n      ]\r\n    }\r\n</kerberosEnabledTest>\r\n\r\n{code}\r\n\r\n{code}\r\n<sso>\r\n  <supported>true</supported>\r\n  <kerberosRequired>true</kerberosRequired>\r\n  ...\r\n</sso>\r\n<kerberosEnabledTest>\r\n    {\r\n      \"or\": [\r\n        {\r\n          \"equals\": [\r\n            \"oozie-site/oozie.authentication.type\",\r\n            \"kerberos\"\r\n          ]\r\n        },\r\n        {\r\n          \"equals\": [\r\n            \"oozie-site/oozie.authentication.type\",\r\n            \"org.apache.hadoop.security.authentication.server.JWTRedirectAuthenticationHandler\"\r\n          ]\r\n        }\r\n      ]\r\n    }\r\n  </kerberosEnabledTest>\r\n{code}\r\nThe result of the test, is to be available via the services REST API:\r\n\r\n{code:title=GET /api/v1/clusters/CLUSTERNAME/services/OOZIE}\r\n{\r\n  \"href\" : \"http://ambari_host:8080/api/v1/clusters/CLUSTERNAME/services/OOZIE\",\r\n  \"ServiceInfo\" : {\r\n    ...\r\n    \"kerberos_enabled\" : true,\r\n    ...\r\n   },\r\n   ...\r\n}\r\n{code}\r\n\r\n\r\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009337681345641613
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.29602620005607605
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00604115379974246
                }
            }
        },
        "comments": [
            {
                "author_name": "hudson",
                "id": "16562648",
                "body": "SUCCESS: Integrated in Jenkins build Ambari-branch-2.7 #91 (See [https://builds.apache.org/job/Ambari-branch-2.7/91/])\n[AMBARI-24384] Logic and declaration used to determine if Kerberos is (rlevas: [https://gitbox.apache.org/repos/asf?p=ambari.git&a=commit&h=1372f03a0b19457467002c8eea5f900b9fbb1e86])\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/state/ServiceInfo.java\n* (edit) ambari-server/src/test/java/org/apache/ambari/server/state/ServiceTest.java\n* (edit) ambari-server/src/test/resources/stacks/HDP/0.1/services/HDFS/metainfo.xml\n* (edit) ambari-server/src/test/java/org/apache/ambari/server/state/ServiceInfoTest.java\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ServiceResourceProvider.java\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/controller/ServiceResponse.java\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/state/Service.java\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/state/ServiceImpl.java\n"
            },
            {
                "author_name": "hudson",
                "id": "16562661",
                "body": "FAILURE: Integrated in Jenkins build Ambari-trunk-Commit #9699 (See [https://builds.apache.org/job/Ambari-trunk-Commit/9699/])\n[AMBARI-24384] Logic and declaration used to determine if Kerberos is (rlevas: [https://gitbox.apache.org/repos/asf?p=ambari.git&a=commit&h=c03d33d9f7e5791e02186564b4c3e00182218387])\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/controller/ServiceResponse.java\n* (edit) ambari-server/src/test/java/org/apache/ambari/server/state/ServiceInfoTest.java\n* (edit) ambari-server/src/test/java/org/apache/ambari/server/state/ServiceTest.java\n* (edit) ambari-server/src/test/resources/stacks/HDP/0.1/services/HDFS/metainfo.xml\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/state/ServiceImpl.java\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ServiceResourceProvider.java\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/state/ServiceInfo.java\n* (edit) ambari-server/src/main/java/org/apache/ambari/server/state/Service.java\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d61e22f4d395ee2224dab6",
        "key": "CASSANDRA-15277",
        "id": "13250641",
        "description": "To better mitigate cluster overload the executor services for various stages should be configurable at runtime (probably as a JMX hot property). \r\n\r\nRelated to CASSANDRA-5044, this would add the capability to resize to multiThreadedLowSignalStage pools based on SEPExecutor.\r\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.1063847616314888
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.05210401862859726
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.3646962642669678
                }
            }
        },
        "comments": [
            {
                "author_name": "jmeredithco",
                "id": "16906591",
                "body": "Branch: https://github.com/jonmeredith/cassandra/tree/CASSANDRA-15277\r\nPull request: https://github.com/apache/cassandra/pull/340 Add support for resizing the SEPExecutor thread pools used by some of the work stages.\r\n\r\nThis version has the smallest change to the SEPExecutor itself and introduces a new flag to make the workers release and re-acquire work permits while the thread setting the size adds/discards work permits to get the desired maximum concurrency.\r\n\r\nThere are two other design choices I could explore.\r\n\r\n1) Convert the work permit representation to signed and have worker threads return permits while it is non-positive. This allows the resizing thread to immediately exit.\r\n\r\n2) Save introducing the resizing volatile boolean, by dedicating a bit in `permits` to mark when resizing is taking place - it gets checked anyway, but would be a slightly larger change and would reduce the maximum number of taskwork permits representable."
            },
            {
                "author_name": "jmeredithco",
                "id": "16916085",
                "body": "I went ahead and changed SEPExecutor to understand negative permits as resizing and give up their work permits, added support for nodetool to get/set concurrency, tried to clear up confusion with the JMXEnabledThreadPoolExecutor pool size getters/setters and cleaned up the unnecessary JMXConfigurableThreadPoolExecutor as it doesn't add anything to JMXEnabledPoolExecutor any more.\r\n\r\nAlso, switched the code to be based on CASSANDRA-15227 as there are changes to Stage/StageManager that impact this work and it seemed easier to make the changes after."
            },
            {
                "author_name": "jmeredithco",
                "id": "16958229",
                "body": "[~ifesdjeen]\u00a0I've rebased and cleaned things up and pushed to a new branch. \u00a0There's not longer a dependency on merging CASSANDRA-15227.\r\n\r\nBranch: [https://github.com/jonmeredith/cassandra/tree/CASSANDRA-15277-v3]\r\n\r\nGitHub PR: [https://github.com/apache/cassandra/pull/369]\r\n\r\nCircleCI run:\u00a0https://circleci.com/workflow-run/1102a711-b347-4370-8bcc-fc9f7e326b32"
            },
            {
                "author_name": "jmeredithco",
                "id": "16961249",
                "body": "And CASSANDRA-15227 landed, so reverted to the original version with review feedback applied and rebased against the current trunk.\r\n\r\n[Branch|https://github.com/jonmeredith/cassandra/tree/CASSANDRA-15277-v4]\r\n\r\n[GitHub PR|https://github.com/apache/cassandra/pull/371]\r\n\r\n[CircleCI run|https://circleci.com/workflow-run/37c049c2-0a7b-4780-9d35-20493bf7a4e5]"
            },
            {
                "author_name": "jmeredithco",
                "id": "16970372",
                "body": "Here's a quick summary of activity.  Thanks [~benedict] for the review and feedback.\r\n\r\nTesting showed up that the CASSANDRA-15227 change to move the stage executors from StageManager to Stage caused issues with the in-JVM dtests.  Referencing message Verbs in the messaging filters initialized the Verb enum which initialized Stage and created the stage thread pools on the parent in-JVM test instance.  The stage executor has been switched over to lazy initialization, and to make the refactor a little nicer added submit/execute helper functions that submit work to the stage executor. \r\n\r\nSquashed all the review feedback, rebased on trunk and force-pushed to get a clean CircleCI run.\r\n\r\n[CircleCI Run|https://circleci.com/workflow-run/1bb5f0c0-bdba-4ee8-91c7-007d99ce93b6]"
            }
        ],
        "comments_predictions": [
            [
                3427263,
                "CASSANDRA-15277",
                "Branch: https://github.com/jonmeredith/cassandra/tree/CASSANDRA-15277\r\nPull request: https://github.com/apache/cassandra/pull/340 Add support for resizing the SEPExecutor thread pools used by some of the work stages.\r\n\r\nThis version has the smallest change to the SEPExecutor itself and introduces a new flag to make the workers release and re-acquire work permits while the thread setting the size adds/discards work permits to get the desired maximum concurrency.\r\n\r\nThere are two other design choices I could explore.\r\n\r\n1) Convert the work permit representation to signed and have worker threads return permits while it is non-positive. This allows the resizing thread to immediately exit.\r\n\r\n2) Save introducing the resizing volatile boolean, by dedicating a bit in `permits` to mark when resizing is taking place - it gets checked anyway, but would be a slightly larger change and would reduce the maximum number of taskwork permits representable.",
                {
                    "property": {
                        "confidence": 0.006712791044265032,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011950165033340454,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.38070613145828247,
                        "prediction": false
                    }
                }
            ],
            [
                3427264,
                "CASSANDRA-15277",
                "I went ahead and changed SEPExecutor to understand negative permits as resizing and give up their work permits, added support for nodetool to get/set concurrency, tried to clear up confusion with the JMXEnabledThreadPoolExecutor pool size getters/setters and cleaned up the unnecessary JMXConfigurableThreadPoolExecutor as it doesn't add anything to JMXEnabledPoolExecutor any more.\r\n\r\nAlso, switched the code to be based on CASSANDRA-15227 as there are changes to Stage/StageManager that impact this work and it seemed easier to make the changes after.",
                {
                    "property": {
                        "confidence": 0.005949413403868675,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004136650823056698,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.034230053424835205,
                        "prediction": false
                    }
                }
            ],
            [
                3427265,
                "CASSANDRA-15277",
                "[~ifesdjeen]\u00a0I've rebased and cleaned things up and pushed to a new branch. \u00a0There's not longer a dependency on merging CASSANDRA-15227.\r\n\r\nBranch: [https://github.com/jonmeredith/cassandra/tree/CASSANDRA-15277-v3]\r\n\r\nGitHub PR: [https://github.com/apache/cassandra/pull/369]\r\n\r\nCircleCI run:\u00a0https://circleci.com/workflow-run/1102a711-b347-4370-8bcc-fc9f7e326b32",
                {
                    "property": {
                        "confidence": 0.005506142042577267,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007496508304029703,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011301741935312748,
                        "prediction": false
                    }
                }
            ],
            [
                3427266,
                "CASSANDRA-15277",
                "And CASSANDRA-15227 landed, so reverted to the original version with review feedback applied and rebased against the current trunk.\r\n\r\n[Branch|https://github.com/jonmeredith/cassandra/tree/CASSANDRA-15277-v4]\r\n\r\n[GitHub PR|https://github.com/apache/cassandra/pull/371]\r\n\r\n[CircleCI run|https://circleci.com/workflow-run/37c049c2-0a7b-4780-9d35-20493bf7a4e5]",
                {
                    "property": {
                        "confidence": 0.003725572256371379,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012816212140023708,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01671850122511387,
                        "prediction": false
                    }
                }
            ],
            [
                3427267,
                "CASSANDRA-15277",
                "Here's a quick summary of activity.  Thanks [~benedict] for the review and feedback.\r\n\r\nTesting showed up that the CASSANDRA-15227 change to move the stage executors from StageManager to Stage caused issues with the in-JVM dtests.  Referencing message Verbs in the messaging filters initialized the Verb enum which initialized Stage and created the stage thread pools on the parent in-JVM test instance.  The stage executor has been switched over to lazy initialization, and to make the refactor a little nicer added submit/execute helper functions that submit work to the stage executor. \r\n\r\nSquashed all the review feedback, rebased on trunk and force-pushed to get a clean CircleCI run.\r\n\r\n[CircleCI Run|https://circleci.com/workflow-run/1bb5f0c0-bdba-4ee8-91c7-007d99ce93b6]",
                {
                    "property": {
                        "confidence": 0.006784962490200996,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0038945397827774286,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03833432123064995,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640755b9bd8b7a4429ca9abc",
        "key": "CASSANDRA-13833",
        "id": "13098935",
        "description": "Follow up for CASSANDRA-13785, when the compaction failed, it fails silently. No error message is logged and exceptions metric is not updated. Basically, it's unable to get the exception: [CompactionManager.java:1491|https://github.com/apache/cassandra/blob/cassandra-2.2/src/java/org/apache/cassandra/db/compaction/CompactionManager.java#L1491]\n\nHere is the call stack:\n{noformat}\n    at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:195)\n    at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)\n    at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:89)\n    at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61)\n    at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:264)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)\n    at java.lang.Thread.run(Thread.java:745)\n{noformat}\nThere're 2 {{FutureTask}} in the call stack, for example {{FutureTask1(FutureTask2))}}, If the call thrown an exception, {{FutureTask2}} sets the status, save the exception and return. But FutureTask1 doesn't get any exception, then set the status to normal. So we're unable to get the exception in:\n[CompactionManager.java:1491|https://github.com/apache/cassandra/blob/cassandra-2.2/src/java/org/apache/cassandra/db/compaction/CompactionManager.java#L1491]\n\n2.1.x is working fine, here is the call stack:\n{noformat}\n    at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:177) ~[main/:na]\n    at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]\n    at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:73) ~[main/:na]\n    at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:59) ~[main/:na]\n    at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:264) ~[main/:na]\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_141]\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_141]\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_141]\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_141]\n    at java.lang.Thread.run(Thread.java:748) [na:1.8.0_141]\n{noformat}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014360282570123672
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008242662996053696
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0045721582137048244
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f655f4d395ee221f2bbf",
        "key": "JENA-286",
        "id": "12600236",
        "description": "In tracking down the error reported by a user on the mailing list with running the scripts on Windows I discovered they don't appropriately handle spaces.\n\nWhile someone clearly wrote them with this in mind as written it doesn't work.  For example consider sparql.bat which is written like so currently:\n\nset JVM_ARGS=-Xmx1024M\nset JENA_CP=\"%JENAROOT%\\lib\\*;\"\nset LOGGING=-Dlog4j.configuration=file:%JENAROOT%/jena-log4j.properties\n\njava %JVM_ARGS% %LOGGING% -cp %JENA_CP% arq.sparql %*\nexit /B\n\n\nIn order to work correctly it must actually be written like this:\n\nset JVM_ARGS=-Xmx1024M\nset JENA_CP=%JENAROOT%\\lib\\*;\n\njava %JVM_ARGS% -Dlog4j.configuration=\"file:%JENAROOT%/jena-log4j.properties\" -cp \"%JENA_CP%\" arq.sparql %*\nexit /B\n\nThe cause of the error is that quotes used when setting a variable do not actually carry through when that variable is accessed\n\nIssue will be closed when all batch scripts are appropriately updated",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009322951547801495
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.011742093600332737
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004141233861446381
                }
            }
        },
        "comments": [
            {
                "author_name": "rvesse",
                "id": "13422748",
                "body": "Should now be fixed in Trunk, will leave open to allow others to test and for a snapshot to be produced with the change so the affected user can be asked to check the change resolves their issue.\n\nIn my local testing this change does resolve the issue when paths contain spaces\n\nAlso added a note to the README about checking that JENAROOT is set correctly by doing a simple cd $JENAROOT"
            },
            {
                "author_name": "andy",
                "id": "13424506",
                "body": "The bat scripts are generated by the script \"cmd-maker\" and template \"template.bat\".  I've ported the fixed to the template, set the line-endings to DOS style and regenerated the scripts.\n\nTested with a directory with a space in a directory component name.\n"
            },
            {
                "author_name": "andy",
                "id": "13424507",
                "body": "Please check."
            },
            {
                "author_name": "rvesse",
                "id": "13424904",
                "body": "I didn't realise the scripts were generated from a template, I will check the changes"
            }
        ],
        "comments_predictions": [
            [
                1711445,
                "JENA-286",
                "Should now be fixed in Trunk, will leave open to allow others to test and for a snapshot to be produced with the change so the affected user can be asked to check the change resolves their issue.\n\nIn my local testing this change does resolve the issue when paths contain spaces\n\nAlso added a note to the README about checking that JENAROOT is set correctly by doing a simple cd $JENAROOT",
                {
                    "property": {
                        "confidence": 0.005195528268814087,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004984868224710226,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02719149738550186,
                        "prediction": false
                    }
                }
            ],
            [
                1711446,
                "JENA-286",
                "The bat scripts are generated by the script \"cmd-maker\" and template \"template.bat\".  I've ported the fixed to the template, set the line-endings to DOS style and regenerated the scripts.\n\nTested with a directory with a space in a directory component name.\n",
                {
                    "property": {
                        "confidence": 0.00435766251757741,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006209950428456068,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03663584962487221,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5debaf4d395ee221b121f",
        "key": "SMXCOMP-772",
        "id": "12490652",
        "description": "when run features with felix framework 3.0.1, I get the exception like\nException in thread \"SpringOsgiExtenderThread-52\" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.apache.cxf.resource.ResourceManager' defined in OSGi resource[classpath:META-INF/cxf/cxf.xml|bnd.id=156|bnd.sym=servicemix-cxf-se]: Initialization of bean failed; nested exception is org.springframework.beans.factory.CannotLoadBeanClassException: Cannot find class [org.apache.cxf.binding.jbi.JBIBindingFactory] for bean with name 'org.apache.cxf.binding.jbi.JBIBindingFactory' defined in OSGi resource[classpath:META-INF/cxf/binding/jbi/cxf-binding-jbi.xml|bnd.id=156|bnd.sym=servicemix-cxf-se]; nested exception is java.lang.ClassNotFoundException: org.apache.cxf.binding.jbi.JBIBindingFactory not found from bundle [servicemix-cxf-se]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:480)\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory$1.run(AbstractAutowireCapableBeanFactory.java:409)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:380)\n\tat org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:264)\n\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:261)\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:185)\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:164)\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:429)\n\tat org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:728)\n\tat org.springframework.osgi.context.support.AbstractDelegatedExecutionApplicationContext.access$1600(AbstractDelegatedExecutionApplicationContext.java:69)\n\tat org.springframework.osgi.context.support.AbstractDelegatedExecutionApplicationContext$4.run(AbstractDelegatedExecutionApplicationContext.java:355)\n\tat org.springframework.osgi.util.internal.PrivilegedUtils.executeWithCustomTCCL(PrivilegedUtils.java:85)\n\tat org.springframework.osgi.context.support.AbstractDelegatedExecutionApplicationContext.completeRefresh(AbstractDelegatedExecutionApplicationContext.java:320)\n\tat org.springframework.osgi.extender.internal.dependencies.startup.DependencyWaiterApplicationContextExecutor$CompleteRefreshTask.run(DependencyWaiterApplicationContextExecutor.java:136)\n\tat java.lang.Thread.run(Thread.java:637)\nCaused by: org.springframework.beans.factory.CannotLoadBeanClassException: Cannot find class [org.apache.cxf.binding.jbi.JBIBindingFactory] for bean with name 'org.apache.cxf.binding.jbi.JBIBindingFactory' defined in OSGi resource[classpath:META-INF/cxf/binding/jbi/cxf-binding-jbi.xml|bnd.id=156|bnd.sym=servicemix-cxf-se]; nested exception is java.lang.ClassNotFoundException: org.apache.cxf.binding.jbi.JBIBindingFactory not found from bundle [servicemix-cxf-se]\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1141)\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.predictBeanType(AbstractAutowireCapableBeanFactory.java:524)\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.isFactoryBean(AbstractBeanFactory.java:1177)\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:222)\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:303)\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeansOfType(DefaultListableBeanFactory.java:297)\n\tat org.springframework.context.support.AbstractApplicationContext.getBeansOfType(AbstractApplicationContext.java:941)\n\tat org.apache.cxf.bus.spring.Jsr250BeanPostProcessor.postProcessAfterInitialization(Jsr250BeanPostProcessor.java:76)\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:361)\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1344)\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:473)\n\t... 16 more\nCaused by: java.lang.ClassNotFoundException: org.apache.cxf.binding.jbi.JBIBindingFactory not found from bundle [servicemix-cxf-se]\n\tat org.springframework.osgi.util.BundleDelegatingClassLoader.findClass(BundleDelegatingClassLoader.java:103)\n\tat org.springframework.osgi.util.BundleDelegatingClassLoader.loadClass(BundleDelegatingClassLoader.java:156)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:254)\n\tat org.springframework.util.ClassUtils.forName(ClassUtils.java:211)\n\tat org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:385)\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1138)\n\t... 26 more\nCaused by: java.lang.ClassNotFoundException: org.apache.cxf.binding.jbi.JBIBindingFactory\n\tat org.apache.felix.framework.ModuleImpl.findClassOrResourceByDelegation(ModuleImpl.java:772)\n\tat org.apache.felix.framework.ModuleImpl.access$200(ModuleImpl.java:73)\n\tat org.apache.felix.framework.ModuleImpl$ModuleClassLoader.loadClass(ModuleImpl.java:1685)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:254)\n\tat org.apache.felix.framework.ModuleImpl.getClassByDelegation(ModuleImpl.java:634)\n\tat org.apache.felix.framework.Felix.loadBundleClass(Felix.java:1639)\n\tat org.apache.felix.framework.BundleImpl.loadClass(BundleImpl.java:887)\n\tat org.springframework.osgi.util.BundleDelegatingClassLoader.findClass(BundleDelegatingClassLoader.java:99)\n\t... 31 more\nThis is never a problem with felix 2.x, explicitly adding missing package can resolve it",
        "predictions": {},
        "comments": [
            {
                "author_name": "ffang",
                "id": "12963186",
                "body": "commit fix\nhttp://svn.apache.org/viewvc?rev=960493&view=rev"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d5c5f4d395ee22191171",
        "key": "TUSCANY-582",
        "id": "12346718",
        "description": "While I find it mildly surprising that you can convert from a Day to a Date, I would expect that in doing so the Day (Date.getDate()) value within Date would be accurate (even if all other fields are meaningless). \n\n// The output of each println (from a single run) is placed in comments beside it\n   public void testShowErrorsInSimpleFashion() throws Exception\n   {\n      Date temp = new Date(System.currentTimeMillis());\n\n      // In following sequence - would expect the Day value (here, 21) to be maintained.\n      System.out.println(\"temp = \" + temp); // temp = Fri Jul 21 03:51:01 EDT 2006\n      String day = data_helper.toDay(temp);\n      System.out.println(\"day = \" + day); // day = ---21 EDT\n      Date date2 = data_helper.toDate(day);\n      System.out.println(\"date2 = \" + date2); // date2 = Thu Feb 29 23:00:00 EST 1968\n      String day2 = data_helper.toDay(date2);\n      System.out.println(\"day2 = \" + day2); // day2 = ---29 EST\n   }\n\n   When I look in DataHelperImpl.java, I see a series of Date Patterns. It seems that Day is being matched to an earlier pattern than the expected one (the expected one is \"---dd zz\"). When I move that pattern to first in the list, the outcome is affected.  Were it not matching an earlier pattern, I would think that moving the correct one to the front of the  list would not have an effect.\n\n   Leaving DataHelperImpl.java unaltered, Day = 21 EDT, and Day2 = 29 EST (in the case above). However, if I put the appropriate pattern first in the list, Day2 is instead = 20 EST. Interestingly, it is still not the correct day (21). \n\nFrank pointed out that there have been recent updates to DataHelper, however I've retested with build level 425652 and see the same behavior.\n\nSide note:\n   The following is not a JIRA issue, but it is related.  In the second table on page 146 the Date conversions for most types are essentially to the same  type, to Date, and to String. It seems that several more are possible. The following seem capable of being added:\n      DateTime-> Month, MonthDay, YearMonth, YearMonthDay, Time, Year, Duration, Day\n      Duration->Month, MonthDay, YearMonth, YearMonthDay, Time, Year, DateTime, Day\n      MonthDay->Month, Day\n      YearMonth->Month, Year\n      YearMonthDay->Month, Year, Day, YearMonth, MonthDay",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.007792904041707516
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.012128319591283798
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004706040024757385
                }
            }
        },
        "comments": [
            {
                "author_name": "frankb",
                "id": "12424117",
                "body": "Fuhwei Lwo is looking at this for me."
            },
            {
                "author_name": "okstatendn",
                "id": "12427470",
                "body": "The attached patch addresses the problem mentioned in this issue (Tuscany-582).  The change for this original problem is a one line fix (setting isLenient to false).  Previously, an earlier SimpleDateFormat in the list of possibilties was matching for a String that should have matched the Day format.\n\nIt also includes changes to the toDate method to allow permitted variations (e.g. incusion or exclusion of time zone) to be converted to a Date using DataHelper.toDate().  Previously, many Strings that should give a valid result from DateHelper.toDate() would have resulted in null.\n\nI have created a test case that addresses both the original issue, as well as the secondary issue also addressed.   I will attach it shortly.\n\nWould a committer please review the patch and test case and let me know of any issues?"
            },
            {
                "author_name": "okstatendn",
                "id": "12427488",
                "body": "Attached is the test case that uncovered the original issue and has been used to verify both the fix for that defect as well as the other defect mentioned above.  Please let me know of any concerns.\n\n"
            },
            {
                "author_name": "kgoodson",
                "id": "12428089",
                "body": "I have checked this patch and there is an issue\n\n...  without the patch applied the testcase gives\n\njunit.framework.ComparisonFailure: The expected value did not result when calling toDay after initializing with toDay. expected:<...15 GM...> but was:<...01 BS...>\n\tat junit.framework.Assert.assertEquals(Assert.java:81)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase$Test.executeConversion(DateConversionTestCase.java:180)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase$Test.attemptConversion(DateConversionTestCase.java:156)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase.testConversionsFromDay(DateConversionTestCase.java:192)\n\t\nand \n\njunit.framework.AssertionFailedError: DataHelper.toData() should not return null for '---04'.\n\tat junit.framework.Assert.fail(Assert.java:47)\n\tat junit.framework.Assert.assertTrue(Assert.java:20)\n\tat junit.framework.Assert.assertNotNull(Assert.java:220)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase.testToDateFormats(DateConversionTestCase.java:345)\n\n\nbut with the patch applied a different test fails ...\n\njunit.framework.ComparisonFailure: The expected value did not result when calling toTime after initializing with toTime. expected:<...0...> but was:<...1...>\n\tat junit.framework.Assert.assertEquals(Assert.java:81)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase$Test.executeConversion(DateConversionTestCase.java:180)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase$Test.attemptConversion(DateConversionTestCase.java:156)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase.testConversionsFromTime(DateConversionTestCase.java:272)\n\n"
            },
            {
                "author_name": "okstatendn",
                "id": "12428195",
                "body": "Kelvin,\n\nThank you for looking at this patch and test case.\n\nI tested it on my machine and it ran correctly (both earlier and just now).  What time zone are you in and about what time did you run the test case?  I think it's likely that one of these two variables is causing it to run correctly for me and fail for you.  What I'm unsure of is whether the test case or the patch has been revealed to be faulty by your unsuccessful run.\n\nThank you,\n\nBrian Murray"
            },
            {
                "author_name": "kgoodson",
                "id": "12428367",
                "body": "Hi,  I ran this mid morning yesterday with time zone GMT and dayl;ight savings accounted for on a Windows box.  I just ran it again at11:39 my clock time, and the assertion failure said it was expecting 11:39 and got 12:39 which is kind of odd, because 11:39 is GMT+DST=10:39+1:00  and its getting a result of 10:39+2, i.e. DST seems to be being accounted for twice (perhaps)."
            },
            {
                "author_name": "okstatendn",
                "id": "12428718",
                "body": "I have attached an updated version of DateConversionTestCase.java that does show the problem caused by daylight savings time which existed in the original test case.  (If somebody has the authority to do so, could you please remove the initial version?)  \n\nIn the newer version the verification is done by comparing individual fields from a Calendar object.  "
            },
            {
                "author_name": "okstatendn",
                "id": "12428982",
                "body": "Updates to both Tuscany582.patch and DataHelperImpl.java.  The most recent versions are the correct versions.\n\nThe updates reflect the need to parse negative Date, DateTime, Duration, Year, YearMonth, and YearMonthDay.  For Duration it is treated as a negative value.  For the others, -1 indicates a BCE (formerly BC) value.\n\n"
            },
            {
                "author_name": "okstatendn",
                "id": "12428983",
                "body": "Some updates to insure that negative values are parsed.  Also, remove parsing for and test cases for Duration with timezone included."
            },
            {
                "author_name": "okstatendn",
                "id": "12430314",
                "body": "Some minor revisions resulting from a code review with a peer."
            },
            {
                "author_name": "frankb",
                "id": "12430323",
                "body": "Fixed in revision 434519."
            },
            {
                "author_name": "kgoodson",
                "id": "12477002",
                "body": "retrospectively setting fix version in preparation for SDO M3"
            },
            {
                "author_name": "kgoodson",
                "id": "12477016",
                "body": "Closing issues fixed in SDO Java M2 in preparation for M3 release"
            }
        ],
        "comments_predictions": [
            [
                319563,
                "TUSCANY-582",
                "The attached patch addresses the problem mentioned in this issue (Tuscany-582).  The change for this original problem is a one line fix (setting isLenient to false).  Previously, an earlier SimpleDateFormat in the list of possibilties was matching for a String that should have matched the Day format.\n\nIt also includes changes to the toDate method to allow permitted variations (e.g. incusion or exclusion of time zone) to be converted to a Date using DataHelper.toDate().  Previously, many Strings that should give a valid result from DateHelper.toDate() would have resulted in null.\n\nI have created a test case that addresses both the original issue, as well as the secondary issue also addressed.   I will attach it shortly.\n\nWould a committer please review the patch and test case and let me know of any issues?",
                {
                    "property": {
                        "confidence": 0.004967489279806614,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004731018096208572,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04298017919063568,
                        "prediction": false
                    }
                }
            ],
            [
                319565,
                "TUSCANY-582",
                "I have checked this patch and there is an issue\n\n...  without the patch applied the testcase gives\n\njunit.framework.ComparisonFailure: The expected value did not result when calling toDay after initializing with toDay. expected:<...15 GM...> but was:<...01 BS...>\n\tat junit.framework.Assert.assertEquals(Assert.java:81)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase$Test.executeConversion(DateConversionTestCase.java:180)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase$Test.attemptConversion(DateConversionTestCase.java:156)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase.testConversionsFromDay(DateConversionTestCase.java:192)\n\t\nand \n\njunit.framework.AssertionFailedError: DataHelper.toData() should not return null for '---04'.\n\tat junit.framework.Assert.fail(Assert.java:47)\n\tat junit.framework.Assert.assertTrue(Assert.java:20)\n\tat junit.framework.Assert.assertNotNull(Assert.java:220)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase.testToDateFormats(DateConversionTestCase.java:345)\n\n\nbut with the patch applied a different test fails ...\n\njunit.framework.ComparisonFailure: The expected value did not result when calling toTime after initializing with toTime. expected:<...0...> but was:<...1...>\n\tat junit.framework.Assert.assertEquals(Assert.java:81)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase$Test.executeConversion(DateConversionTestCase.java:180)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase$Test.attemptConversion(DateConversionTestCase.java:156)\n\tat org.apache.tuscany.sdo.test.DateConversionTestCase.testConversionsFromTime(DateConversionTestCase.java:272)\n\n",
                {
                    "property": {
                        "confidence": 0.005064417142421007,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006082493346184492,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01580001413822174,
                        "prediction": false
                    }
                }
            ],
            [
                319566,
                "TUSCANY-582",
                "Kelvin,\n\nThank you for looking at this patch and test case.\n\nI tested it on my machine and it ran correctly (both earlier and just now).  What time zone are you in and about what time did you run the test case?  I think it's likely that one of these two variables is causing it to run correctly for me and fail for you.  What I'm unsure of is whether the test case or the patch has been revealed to be faulty by your unsuccessful run.\n\nThank you,\n\nBrian Murray",
                {
                    "property": {
                        "confidence": 0.005065606907010078,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012660801410675049,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011678081005811691,
                        "prediction": false
                    }
                }
            ],
            [
                319567,
                "TUSCANY-582",
                "Hi,  I ran this mid morning yesterday with time zone GMT and dayl;ight savings accounted for on a Windows box.  I just ran it again at11:39 my clock time, and the assertion failure said it was expecting 11:39 and got 12:39 which is kind of odd, because 11:39 is GMT+DST=10:39+1:00  and its getting a result of 10:39+2, i.e. DST seems to be being accounted for twice (perhaps).",
                {
                    "property": {
                        "confidence": 0.007656775414943695,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007222243119031191,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008999099023640156,
                        "prediction": false
                    }
                }
            ],
            [
                319568,
                "TUSCANY-582",
                "I have attached an updated version of DateConversionTestCase.java that does show the problem caused by daylight savings time which existed in the original test case.  (If somebody has the authority to do so, could you please remove the initial version?)  \n\nIn the newer version the verification is done by comparing individual fields from a Calendar object.  ",
                {
                    "property": {
                        "confidence": 0.004513647872954607,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.08763724565505981,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007187197916209698,
                        "prediction": false
                    }
                }
            ],
            [
                319569,
                "TUSCANY-582",
                "Updates to both Tuscany582.patch and DataHelperImpl.java.  The most recent versions are the correct versions.\n\nThe updates reflect the need to parse negative Date, DateTime, Duration, Year, YearMonth, and YearMonthDay.  For Duration it is treated as a negative value.  For the others, -1 indicates a BCE (formerly BC) value.\n\n",
                {
                    "property": {
                        "confidence": 0.004914422053843737,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.019935935735702515,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008450512774288654,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d3edf4d395ee22187055",
        "key": "XW-176",
        "id": "12594041",
        "description": "Interceptors are currently instantiated, with parameters, for every ActionConfig.\n\nThis is inefficient as the same interceptor could be instantiated hundreds of times. \n\nTo solve this, we need to create an InterceptorManager which caches instantiated interceptors by name & parameters.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0049802325665950775
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.03143208846449852
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008093925192952156
                }
            }
        },
        "comments": [
            {
                "author_name": "andersengstrom",
                "id": "13393752",
                "body": "I suppose naming conventions are kinda personal :) But IMO [InterceptorFactory -> InterceptorCache] or even [InterceptorFactory -> ObjectCache] is better."
            },
            {
                "author_name": "plightbo",
                "id": "13393861",
                "body": "This sounds post-2.0. And also XWork... BAD MIKE"
            },
            {
                "author_name": "plightbo",
                "id": "13394130",
                "body": "Mike -- IM me if you think this is important enough to put back to 1.1"
            },
            {
                "author_name": "alexandrupopescu",
                "id": "13394472",
                "body": "Implementing such a mechanism is way to complex: the interceptor parameters are evaluated against the current invocation stack, and so a cache mechanism a la EHCache query cache would be needed.\n\n./alex\n--\n.w( the_mindstorm )p."
            }
        ],
        "comments_predictions": [
            [
                204061,
                "XW-176",
                "Implementing such a mechanism is way to complex: the interceptor parameters are evaluated against the current invocation stack, and so a cache mechanism a la EHCache query cache would be needed.\n\n./alex\n--\n.w( the_mindstorm )p.",
                {
                    "property": {
                        "confidence": 0.018467752262949944,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004076140001416206,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.6102480292320251,
                        "prediction": true
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d910f4d395ee2219fefd",
        "key": "STREAMS-527",
        "id": "13100839",
        "description": "A problem is introduced when merging configuration objects when the default values are initialized on object creation.  Specifically, it becomes much harder to create partial configurations to merge, as every instance of the configuration class contains the default values across most fields.\n\nTypesafe config provides a recommended method for managing default values by putting a reference.conf in each module containing defaults.\n\nGoing this route, creating a streams configuration bean with StreamsConfigurator or a component configuration bean with ComponentConfigurator will work exactly as before, and create a bean with a constructor will contain only the fields that are explicitly set by user code, ensuring that merging an ordered list of beans with juneau PojoMerge or similar methods will do exactly what is asked instead of messing up on fields with defined defaults.",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d874f4d395ee2219d996",
        "key": "SYNCOPE-628",
        "id": "12764908",
        "description": "[Jel.Camel|https://github.com/giacomolm/jel.camel] is a tool for Camel route graphical management, also reported in Camel's [user stories|http://camel.apache.org/user-stories.htm].\n\nSimilarly to [this guide for enabling the Activiti Modeler in the admin console|https://cwiki.apache.org/confluence/display/SYNCOPE/Enable+Activiti+Modeler], provide a guide for enabling Jel.Camel.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.38317227363586426
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.07396610081195831
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0068555171601474285
                }
            }
        },
        "comments": [
            {
                "author_name": "giacomolm",
                "id": "14322513",
                "body": "Jel is not ready for a stable integration in Syncope."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e4cdf4d395ee221c4eac",
        "key": "PDFBOX-591",
        "id": "12444852",
        "description": "The load time for loading documents into PDFBox (PDDocument) is too slow.\n\nOne culprit is the method:  org.apach.pdfbox.pdfparser.BaseParser.readUntilEndStream(OutputStream out)\n\nThe current implementation of this method uses a very slow test for end of stream conditions.   A profile of the readUntilEndStream() method shows that a huge chunk of the method's processing time is being consumed in the cmpCircularBuffer() call - which is purely part of the test for for the end of stream marker.  In other words, the readUntilEndOfStream() is spending twice as much time testing for the end of stream marker as it is reading bytes from the stream.\n\nA better solution is to use a simpler, direct fail-fast test conditional structure that uses byte primitives.   I strongly recommend that the current method be removed and replaced with the following code below.  This results in a relative speed up of readUntilEndStream() method of a little over a factor of 3 (a ratio of 113/37 = 3.05 if you want to be more precise).  This in turn helps the overall performance of PDDocument.parse() by about a factor of 2.7.\n\nNote the addition of some byte constants used to make the code readable.\n\n-----------------------------------------------------------------\n    private static final int E = 101;\n    private static final int N = 110;\n    private static final int D = 100;\n    \n    private static final int S = 115;\n    private static final int T = 116;\n    private static final int R = 114;\n    private static final int A = 97;\n    private static final int M = 109;\n    \n    private static final int O = 111;\n    private static final int B = 98;\n    private static final int J = 106;\n    \n    \n    /**\n     * This method will read through the current stream object until\n     * we find the keyword \"endstream\" meaning we're at the end of this\n     * object. Some pdf files, however, forget to write some endstream tags\n     * and just close off objects with an \"endobj\" tag so we have to handle\n     * this case as well.\n     * @param out The stream we write out to. \n     * @throws IOException\n     */\n    private void readUntilEndStream( OutputStream out ) throws IOException{\n    \tint byteRead;\n    \tdo{ //use a fail fast test for end of stream markers\n    \t\tbyteRead = pdfSource.read();\n    \t\tif(byteRead==E){//only branch if \"e\"\n    \t\t\tbyteRead = pdfSource.read();\n    \t\t\tif(byteRead==N){ //only continue branch if \"en\"\n    \t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\tif(byteRead==D){//up to \"end\" now\n    \t\t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\t\tif(byteRead==S){\n    \t\t\t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\t\t\tif(byteRead==T){\n    \t\t\t\t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\t\t\t\tif(byteRead==R){\n    \t\t\t\t\t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\t\t\t\t\tif(byteRead==E){\n    \t\t\t\t\t\t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\t\t\t\t\t\tif(byteRead==A){\n    \t\t\t\t\t\t\t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\t\t\t\t\t\t\tif(byteRead==M){\n    \t\t\t\t\t\t\t\t\t\t\t//found the whole marker\n    \t\t\t\t\t\t\t\t\t\t\tpdfSource.unread( ENDSTREAM );\n    \t\t\t\t\t\t\t                return;\n    \t\t\t\t\t\t\t\t\t\t}\n    \t\t\t\t\t\t\t\t\t}else{\n    \t\t\t\t\t\t\t\t\t\tout.write(ENDSTREAM, 0, 7);\n    \t\t\t\t\t\t\t\t\t}\n    \t\t\t\t\t\t\t\t}else{\n    \t\t\t\t\t\t\t\t\tout.write(ENDSTREAM, 0, 6);\n    \t\t\t\t\t\t\t\t}\n    \t\t\t\t\t\t\t}else{\n    \t\t\t\t\t\t\t\tout.write(ENDSTREAM, 0, 5);\n    \t\t\t\t\t\t\t}\n    \t\t\t\t\t\t}else{\n        \t\t\t\t\t\tout.write(ENDSTREAM, 0, 4);\n    \t\t\t\t\t\t}\n    \t\t\t\t\t}else if(byteRead==O){\n    \t\t\t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\t\t\tif(byteRead==B){\n    \t\t\t\t\t\t\tbyteRead = pdfSource.read();\n    \t\t\t\t\t\t\tif(byteRead==J){\n    \t\t\t\t\t\t\t\t//found whole marker\n    \t\t\t\t\t\t\t\tpdfSource.unread( ENDOBJ );\n    \t\t\t\t                return;\n    \t\t\t\t\t\t\t}\n    \t\t\t\t\t\t}else{\n        \t\t\t\t\t\tout.write(ENDOBJ, 0, 4);\n    \t\t\t\t\t\t}\n    \t\t\t\t\t}else{\n    \t\t\t\t\t\tout.write(E);\n    \t\t\t\t\t\tout.write(N);\n    \t\t\t\t\t\tout.write(D);\n    \t\t\t\t\t}\n    \t\t\t\t}else{\n    \t\t\t\t\tout.write(E);\n    \t\t\t\t\tout.write(N);\n    \t\t\t\t}\n    \t\t\t}else{\n    \t\t\t\tout.write(E);\n    \t\t\t}\n    \t\t}\n    \t\tif(byteRead!=-1)out.write(byteRead);\n\n    \t}while(byteRead!=-1);\n    }\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.024302378296852112
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.024381285533308983
                },
                "property": {
                    "prediction": true,
                    "confidence": 0.7479748725891113
                }
            }
        },
        "comments": [
            {
                "author_name": "m.martinez",
                "id": "12797393",
                "body": "tweaked version of BaseParser  to improve performance of readUntilEndStream() method."
            },
            {
                "author_name": "m.martinez",
                "id": "12800333",
                "body": "Changed from 'bug' to improvement.\n\nA much needed improvement, though!"
            },
            {
                "author_name": "jukkaz",
                "id": "12800440",
                "body": "Good stuff! Committed in revision 899479.\n\nThe deeply nested conditional looks a bit funny, but it's obviously better than the previous code. I made a minor improvement to the code by using characters instead of numbers for the E, N, D, S, T, R, A, M, O, B, J constants."
            },
            {
                "author_name": "lehmi",
                "id": "12836803",
                "body": "closed after releasing version 1.0.0"
            }
        ],
        "comments_predictions": [
            [
                1018100,
                "PDFBOX-591",
                "Good stuff! Committed in revision 899479.\n\nThe deeply nested conditional looks a bit funny, but it's obviously better than the previous code. I made a minor improvement to the code by using characters instead of numbers for the E, N, D, S, T, R, A, M, O, B, J constants.",
                {
                    "property": {
                        "confidence": 0.005671071819961071,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00923384539783001,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008007223717868328,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d63154f4d395ee22275f13",
        "key": "ACCUMULO-3033",
        "id": "12731088",
        "description": "I noticed yesterday that {{SiteConfiguration#getProperties(Map, PropertyFilter)}} is invoked very frequently (at least 30 times a second on my single machine) to extract the Iterator configurations before a table scan happens. Printing a stack trace shows that this is the dominating caller of {{getProperties}} is {{IteratorUtil#parseIterConf()}}.\n\nWhat this translates to is repeatedly reading, filtering and adding the same elements to a map to satisfy the {{AccumuloConfiguration#getPropertiesWithPrefix}} from an immutable source (accumulo-site.xml). While this is probably not a huge time waste in terms of actual time spent, it's repeatedly happening and will slow things down (especially when the underlying Hadoop Configuration is creating a new HashMap with the contents of the accumulo-site.xml for every call).\n\nNeed to think about some options for making the \"extract keys with this prefix\" case faster from SiteConfiguration.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014046440832316875
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.00679152412340045
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007687963545322418
                }
            }
        },
        "comments": [
            {
                "author_name": "elserj",
                "id": "14081018",
                "body": "* We could push down the logic of efficient filtering to the PropertyFilter implementation, but that would be difficult to implement in a single location as it would have to know how to handle the variety of sources in which we get our Property's from (ZooKeeper, accumulo-site.xml, Property defaults).\n* Add some sort of LRU cache to the immutable AccumuloConfigurations (SiteConfiguration and DefaultConfiguration) that would be able to cache results for a given PropertyFilter implementation\n\nI think the latter is the better, but would be open to other ideas people have."
            },
            {
                "author_name": "ctubbsii",
                "id": "14980724",
                "body": "This seemed familiar, so I looked up and found ACCUMULO-2838. I don't know if it's similar enough to model a fix here after that."
            },
            {
                "author_name": "elserj",
                "id": "14980743",
                "body": "Oh cool. Thanks for the extra info!"
            },
            {
                "author_name": "ctubbsii",
                "id": "16824546",
                "body": "Not sure if this was fully addressed or not, but this is probably OBE by code in 2.0. If not, we can re-open at https://github.com/apache/accumulo/issues"
            }
        ],
        "comments_predictions": [
            [
                3947384,
                "ACCUMULO-3033",
                "* We could push down the logic of efficient filtering to the PropertyFilter implementation, but that would be difficult to implement in a single location as it would have to know how to handle the variety of sources in which we get our Property's from (ZooKeeper, accumulo-site.xml, Property defaults).\n* Add some sort of LRU cache to the immutable AccumuloConfigurations (SiteConfiguration and DefaultConfiguration) that would be able to cache results for a given PropertyFilter implementation\n\nI think the latter is the better, but would be open to other ideas people have.",
                {
                    "property": {
                        "confidence": 0.12350461632013321,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0015544877387583256,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.10099383443593979,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d62d47f4d395ee2226d8fe",
        "key": "AMBARI-21460",
        "id": "13086692",
        "description": "As part of this [commit|https://github.com/apache/incubator-atlas/commit/0e7f8ea4603c858cc295259bbd1a22314b732f62], below new kafka client properties are introduced, need to add this to the ambari managed atlas config.\natlas.kafka.enable.auto.commit=false\natlas.kafka.session.timeout.ms=30000\natlas.kafka.auto.commit.enable is deleted",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02117566391825676
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.05801146477460861
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.002762431278824806
                }
            }
        },
        "comments": [
            {
                "author_name": "ayubpathan",
                "id": "16084651",
                "body": "Attaching patch for review."
            },
            {
                "author_name": "hadoopqa",
                "id": "16084931",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12876944/AMBARI-21460.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in ambari-server.\n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/11781//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "16086953",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12877098/AMBARI-21460_branch-2.5.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/11787//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "sumitmohanty",
                "id": "16088232",
                "body": "Committed to trunk and branch-2.5"
            },
            {
                "author_name": "hudson",
                "id": "16088274",
                "body": "SUCCESS: Integrated in Jenkins build Ambari-branch-2.5 #1692 (See [https://builds.apache.org/job/Ambari-branch-2.5/1692/])\nAMBARI-21460. Add new kafka client properties to the ambari managed (smohanty: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=4ddbd6246b5718f30912dec0f30939ac33b052dc])\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.6/upgrades/upgrade-2.6.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.6/upgrades/nonrolling-upgrade-2.6.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.5/upgrades/upgrade-2.6.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.6/upgrades/config-upgrade.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.5/upgrades/nonrolling-upgrade-2.6.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.5/upgrades/config-upgrade.xml\n* (edit) ambari-server/src/main/resources/stacks/BigInsights/4.0/stack-advisor/stack_advisor_25.py\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.6/services/ATLAS/configuration/application-properties.xml\n"
            },
            {
                "author_name": "hudson",
                "id": "16088282",
                "body": "SUCCESS: Integrated in Jenkins build Ambari-trunk-Commit #7768 (See [https://builds.apache.org/job/Ambari-trunk-Commit/7768/])\nAMBARI-21460. Add new kafka client properties to the ambari managed (smohanty: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=c7f42285a2bd36a215b6c8988cfd7fd025461285])\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.6/upgrades/config-upgrade.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.6/services/ATLAS/configuration/application-properties.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.5/upgrades/nonrolling-upgrade-2.6.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.5/upgrades/upgrade-2.6.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.6/upgrades/upgrade-2.6.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.6/upgrades/nonrolling-upgrade-2.6.xml\n* (edit) ambari-server/src/main/resources/stacks/HDP/2.5/upgrades/config-upgrade.xml\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d618eff4d395ee22241fac",
        "key": "CXF-7514",
        "id": "13104337",
        "description": "https://issues.apache.org/jira/browse/CXF-6891\n\nwas about supporting the non-empty streams which return isAvailable=0 and support no marks.\n\nThe problem is, if the stream is really empty in such cases (ex DELETE) then the JAX-RS filter code, 'hasEntity' has no way to return 'false' unless Content-Length=0 is also set (which is not available with DELETE).\n\nI suspect that for 3.2.1, we actually need to return IOUtils.isEmpty() = true if the stream isAvailable == 0 and stream.markSupported == false. And add a property to assume the stream is non-empty under these conditions to support a CXF-6891 case... \n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.007415316067636013
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008894288912415504
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0062896073795855045
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640744b0a3a0f968fd33b9ad",
        "key": "RANGER-3590",
        "id": "13423313",
        "description": "h3. Reproduction\r\nh3. Precondition\r\n # User hrt_2, and hrt_3 have roles User in Ranger.\r\n # Create a security zone with name \"test_security_zone\" and with:\r\nAdmin users: hrt_2\r\nAuditor Users: hrt_3\r\nResource Services: cm_hive, and for database test_db\r\n # Login as hrt_2, and create a hive policy named \"test_security_zone_policy\" with arbitrary content.\r\n\r\nh4. Test steps\r\n # Login as hrt_3 and try to create a new hive policy \"new_test_security_zone_policy\" with arbitrary content.\r\n # As hrt_3, try to change the name or description of \"test_security_zone_policy\".\r\n # As hrt_3, try to change the resource, or permissions of \"test_security_zone_policy\" (e.g. add another database, or add a new user to Allow Conditions)\r\n\r\nh4. Expected behavior\r\n # Creation of new policy should be denied for hrt_3.\r\n # Update of already existing policy's name or description should be denied for hrt_3.\r\n # Update of resources, permissions should be denied for hrt_3.\r\n\r\nh4. Actual behavior\r\n # Creation of new policy is denied as expected.\r\n # Update succeeds.\r\n # Trying to update resources or permission results in access denied, as expected.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006471088621765375
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.10390357673168182
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004033935256302357
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e327f4d395ee221be68c",
        "key": "QPID-3403",
        "id": "12518362",
        "description": "Each queue that is created is automatically bound to the default (direct)\nexchange with a routing key that matches the queue name.  When the queue is\ndeleted, the queue is correctly removed from the binding map, but the mapping\nfrom routing key to queues is not removed even when there are no queues bound\nto the routing key.  \n\nIn a case where thousands of uniquely named queues are created and deleted as\ntransient storage, the memory usage of the broker will continue to grow as the\ndefault exchange's routing key map continues to grow. ",
        "predictions": {},
        "comments": [
            {
                "author_name": "dillaman",
                "id": "13081907",
                "body": "Potential patch for issue"
            },
            {
                "author_name": "gsim",
                "id": "13082246",
                "body": "I think you have attached the wrong patch here?\n\nSuggested patch attached. Good catch btw!"
            },
            {
                "author_name": "dillaman",
                "id": "13082768",
                "body": "Sorry ... definitely the wrong patch.  My suggested patch was basically the same as your patch.  The only difference is that I had CopyOnWriteArray::empty() return true if the shared pointer wasn't initialized."
            },
            {
                "author_name": "gsim",
                "id": "13083044",
                "body": "That's a good suggestion; I've added that test in."
            },
            {
                "author_name": "jross",
                "id": "13745379",
                "body": "http://svn.apache.org/viewvc?view=revision&revision=1156560"
            }
        ],
        "comments_predictions": [
            [
                871695,
                "QPID-3403",
                "Sorry ... definitely the wrong patch.  My suggested patch was basically the same as your patch.  The only difference is that I had CopyOnWriteArray::empty() return true if the shared pointer wasn't initialized.",
                {
                    "property": {
                        "confidence": 0.005729746539145708,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00640910305082798,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012865141034126282,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5fa29f4d395ee221fcd98",
        "key": "IMPALA-6857",
        "id": "13152789",
        "description": "In IMPALA-3114, we added a pause monitor for Impala. In addition to that, we should port/borrow Hadoop's JvmPauseMonitor [https://github.com/apache/hadoop/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/JvmPauseMonitor.java.]\u00a0I believe that when the JVM is aggressively GCing, the C++ threads will continue to get scheduled (and won't log), but the Java ones will log. (I've definitely seen JvmPauseMonitor be accurate many times.)\r\n\r\n[~bharathv], when you were testing this, were you able to reproduce it triggering when the JVM half was in \"GC hell\"?",
        "predictions": {},
        "comments": [
            {
                "author_name": "bharathv",
                "id": "16439842",
                "body": "No, I haven't tried the JVM part of it. Personally, I haven't seen many GC problems in Impala, but I could be wrong. This would be a nice addition, especially to the Catalog server, where there is a lot of memory churn."
            },
            {
                "author_name": "tarmstrong",
                "id": "16459239",
                "body": "Are there any JVM metrics about GC we could also expose? E.g. number of GCs, time of last GC, GC duration?"
            },
            {
                "author_name": "philip",
                "id": "16459251",
                "body": "[~tarmstrong], yes. You also want to copy [https://github.com/apache/hadoop-common/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/jmx/JMXJsonServlet.java]\u00a0while you're at it. With that, you get things like the following, which can be interpreted.\r\n\r\nThe annoying bit about interpreting these, btw, is that they vary based on the Garbage Collector you choose.\r\n\r\n\u00a0\r\n{code:java}\r\n\r\n    \"ObjectName\" : \"java.lang:type=MemoryPool,name=Par Eden Space\"\r\n  }, {\r\n    \"name\" : \"java.lang:type=GarbageCollector,name=ParNew\",\r\n    \"modelerType\" : \"sun.management.GarbageCollectorImpl\",\r\n    \"LastGcInfo\" : {\r\n      \"GcThreadCount\" : 11,\r\n      \"duration\" : 18,\r\n      \"endTime\" : 213402847,\r\n      \"id\" : 893,\r\n      \"memoryUsageAfterGc\" : [ {\r\n        \"key\" : \"Par Survivor Space\",\r\n        \"value\" : {\r\n          \"committed\" : 26345472,\r\n          \"init\" : 26345472,\r\n          \"max\" : 26345472,\r\n          \"used\" : 5140592\r\n        }\r\n      }, {\r\n        \"key\" : \"Compressed Class Space\",\r\n        \"value\" : {\r\n          \"committed\" : 8368128,\r\n          \"init\" : 0,\r\n          \"max\" : 1073741824,\r\n          \"used\" : 7938576\r\n        }\r\n      }, {\r\n        \"key\" : \"Metaspace\",\r\n        \"value\" : {\r\n          \"committed\" : 79052800,\r\n          \"init\" : 0,\r\n          \"max\" : -1,\r\n          \"used\" : 77537496\r\n        }\r\n      }, {\r\n        \"key\" : \"Code Cache\",\r\n        \"value\" : {\r\n          \"committed\" : 54591488,\r\n          \"init\" : 2555904,\r\n          \"max\" : 251658240,\r\n          \"used\" : 53044352\r\n        }\r\n      }, {\r\n        \"key\" : \"Par Eden Space\",\r\n        \"value\" : {\r\n          \"committed\" : 210829312,\r\n          \"init\" : 210829312,\r\n          \"max\" : 210829312,\r\n          \"used\" : 0\r\n        }\r\n      }, {\r\n        \"key\" : \"CMS Old Gen\",\r\n        \"value\" : {\r\n          \"committed\" : 527106048,\r\n          \"init\" : 527106048,\r\n          \"max\" : 527106048,\r\n          \"used\" : 45992680\r\n        }\r\n      } ],\r\n      \"memoryUsageBeforeGc\" : [ {\r\n        \"key\" : \"Par Survivor Space\",\r\n        \"value\" : {\r\n          \"committed\" : 26345472,\r\n          \"init\" : 26345472,\r\n          \"max\" : 26345472,\r\n          \"used\" : 5056128\r\n        }\r\n      }, {\r\n        \"key\" : \"Compressed Class Space\",\r\n        \"value\" : {\r\n          \"committed\" : 8368128,\r\n          \"init\" : 0,\r\n          \"max\" : 1073741824,\r\n          \"used\" : 7938576\r\n        }\r\n      }, {\r\n        \"key\" : \"Metaspace\",\r\n        \"value\" : {\r\n          \"committed\" : 79052800,\r\n          \"init\" : 0,\r\n          \"max\" : -1,\r\n          \"used\" : 77537496\r\n        }\r\n      }, {\r\n        \"key\" : \"Code Cache\",\r\n        \"value\" : {\r\n          \"committed\" : 54591488,\r\n          \"init\" : 2555904,\r\n          \"max\" : 251658240,\r\n          \"used\" : 53044352\r\n        }\r\n      }, {\r\n        \"key\" : \"Par Eden Space\",\r\n        \"value\" : {\r\n          \"committed\" : 210829312,\r\n          \"init\" : 210829312,\r\n          \"max\" : 210829312,\r\n          \"used\" : 210829312\r\n        }\r\n      }, {\r\n        \"key\" : \"CMS Old Gen\",\r\n        \"value\" : {\r\n          \"committed\" : 527106048,\r\n          \"init\" : 527106048,\r\n          \"max\" : 527106048,\r\n          \"used\" : 45982688\r\n        }\r\n      } ],\r\n      \"startTime\" : 213402829\r\n    },\r\n    \"CollectionCount\" : 893,\r\n    \"CollectionTime\" : 16618,\r\n    \"MemoryPoolNames\" : [ \"Par Eden Space\", \"Par Survivor Space\" ],\r\n    \"Valid\" : true,\r\n    \"Name\" : \"ParNew\",\r\n    \"ObjectName\" : \"java.lang:type=GarbageCollector,name=ParNew\"\r\n  }, {\r\n    \"name\" : \"Hadoop:service=NameNode,name=NNTopUserOpCounts\",\r\n    \"modelerType\" : \"NNTopUserOpCounts\",\r\n    \"tag.Context\" : \"dfs\",\r\n    \"tag.Hostname\" : \"...\",\r\n    \"tag.Context.1\" : \"dfs\",\r\n    \"tag.Hostname.1\" : \"...\",\r\n    \"tag.Context.2\" : \"dfs\",\r\n    \"tag.Hostname.2\" : \"...\"\r\n  }, {\r\n    \"name\" : \"java.lang:type=GarbageCollector,name=ConcurrentMarkSweep\",\r\n    \"modelerType\" : \"sun.management.GarbageCollectorImpl\",\r\n    \"LastGcInfo\" : {\r\n      \"GcThreadCount\" : 11,\r\n      \"duration\" : 5147,\r\n      \"endTime\" : 31665,\r\n      \"id\" : 2,\r\n      \"memoryUsageAfterGc\" : [ {\r\n        \"key\" : \"Par Survivor Space\",\r\n        \"value\" : {\r\n          \"committed\" : 26345472,\r\n          \"init\" : 26345472,\r\n          \"max\" : 26345472,\r\n          \"used\" : 20233232\r\n        }\r\n      }, {\r\n        \"key\" : \"Compressed Class Space\",\r\n        \"value\" : {\r\n          \"committed\" : 7057408,\r\n          \"init\" : 0,\r\n          \"max\" : 1073741824,\r\n          \"used\" : 6842328\r\n        }\r\n      }, {\r\n        \"key\" : \"Metaspace\",\r\n        \"value\" : {\r\n          \"committed\" : 61751296,\r\n          \"init\" : 0,\r\n          \"max\" : -1,\r\n          \"used\" : 60704360\r\n        }\r\n      }, {\r\n        \"key\" : \"Code Cache\",\r\n        \"value\" : {\r\n          \"committed\" : 11730944,\r\n          \"init\" : 2555904,\r\n          \"max\" : 251658240,\r\n          \"used\" : 11637952\r\n        }\r\n      }, {\r\n        \"key\" : \"Par Eden Space\",\r\n        \"value\" : {\r\n          \"committed\" : 210829312,\r\n          \"init\" : 210829312,\r\n          \"max\" : 210829312,\r\n          \"used\" : 30868728\r\n        }\r\n      }, {\r\n        \"key\" : \"CMS Old Gen\",\r\n        \"value\" : {\r\n          \"committed\" : 527106048,\r\n          \"init\" : 527106048,\r\n          \"max\" : 527106048,\r\n          \"used\" : 23349304\r\n        }\r\n      } ],\r\n      \"memoryUsageBeforeGc\" : [ {\r\n        \"key\" : \"Par Survivor Space\",\r\n        \"value\" : {\r\n          \"committed\" : 26345472,\r\n          \"init\" : 26345472,\r\n          \"max\" : 26345472,\r\n          \"used\" : 13266608\r\n        }\r\n      }, {\r\n        \"key\" : \"Compressed Class Space\",\r\n        \"value\" : {\r\n          \"committed\" : 6275072,\r\n          \"init\" : 0,\r\n          \"max\" : 1073741824,\r\n          \"used\" : 6106680\r\n        }\r\n      }, {\r\n        \"key\" : \"Metaspace\",\r\n        \"value\" : {\r\n          \"committed\" : 54689792,\r\n          \"init\" : 0,\r\n          \"max\" : -1,\r\n          \"used\" : 53807072\r\n        }\r\n      }, {\r\n        \"key\" : \"Code Cache\",\r\n        \"value\" : {\r\n          \"committed\" : 11141120,\r\n          \"init\" : 2555904,\r\n          \"max\" : 251658240,\r\n          \"used\" : 10582208\r\n        }\r\n      }, {\r\n        \"key\" : \"Par Eden Space\",\r\n        \"value\" : {\r\n          \"committed\" : 210829312,\r\n          \"init\" : 210829312,\r\n          \"max\" : 210829312,\r\n          \"used\" : 115745272\r\n        }\r\n      }, {\r\n        \"key\" : \"CMS Old Gen\",\r\n        \"value\" : {\r\n          \"committed\" : 527106048,\r\n          \"init\" : 527106048,\r\n          \"max\" : 527106048,\r\n          \"used\" : 30169768\r\n        }\r\n      } ],\r\n      \"startTime\" : 26518\r\n    },\r\n    \"CollectionCount\" : 2,\r\n    \"CollectionTime\" : 68,\r\n    \"MemoryPoolNames\" : [ \"Par Eden Space\", \"Par Survivor Space\", \"CMS Old Gen\" ],\r\n    \"Valid\" : true,\r\n    \"Name\" : \"ConcurrentMarkSweep\",\r\n    \"ObjectName\" : \"java.lang:type=GarbageCollector,name=ConcurrentMarkSweep\"\r\n  }, {{code}"
            },
            {
                "author_name": "bharathv",
                "id": "16556915",
                "body": "Patch is up for review [https://gerrit.cloudera.org/#/c/10998/.]\u00a0It uses the GarbageCollectorMXBean data but they are exposed using the traditional Impala metrics framework. For some reason, we didn't take the JMX route for JVM memory metrics, so my patch just builds on top of that."
            },
            {
                "author_name": "bharathv",
                "id": "16574350",
                "body": "Ended up doing the /jmx\u00a0endpoint that is compatible with the hadoop stack.\u00a0https://gerrit.cloudera.org/#/c/10998/\u00a0"
            },
            {
                "author_name": "jira-bot",
                "id": "16575434",
                "body": "Commit 4976ff3c07f465915ac31312ca67519a600212e6 in impala's branch refs/heads/master from Bharath Vissapragada\n[ https://git-wip-us.apache.org/repos/asf?p=impala.git;h=4976ff3 ]\n\nIMPALA-6857: Add Jvm pause/GC Monitor utility and expose JMX metrics\n\nPause monitor:\n=============\n\nThis commit adds a stripped down version of Hadoop's JvmPauseMonitor\nclass (https://bit.ly/2O6qSwm) . The core implementaion is borrowed\nfrom hadoop-common project and the hadoop dependencies are removed.\n\n- Removed dependency on AbstractService.\n- Not relying on Hadoop's Configuration object for reading confs.\n- Switched to Guava's implementation of Stopwatch.\n\nThis utility class can detect both GC/non-GC pauses. In case of GC\npauses, the GC metrics during the pause period are logged.\n\nSample Output:\n=============\nDetected pause in JVM or host machine (eg GC): pause of approximately\n2356ms\nGC pool 'PS MarkSweep' had collection(s): count=1 time=2241ms\nGC pool 'PS Scavenge' had collection(s): count=3 time=352ms\nDetected pause in JVM or host machine (eg GC): pause of approximately\n1964ms\nGC pool 'PS MarkSweep' had collection(s): count=1 time=2082ms\nGC pool 'PS Scavenge' had collection(s): count=1 time=251ms\nDetected pause in JVM or host machine (eg GC): pause of approximately\n2120ms\nGC pool 'PS MarkSweep' had collection(s): count=1 time=2454ms\nDetected pause in JVM or host machine (eg GC): pause of approximately\n2238ms\nGC pool 'PS MarkSweep' had collection(s): count=5 time=13464ms\nDetected pause in JVM or host machine (eg GC): pause of approximately\n2233ms\nGC pool 'PS MarkSweep' had collection(s): count=1 time=2733ms\n\nJMX Metrics:\n============\n\nJMX metrics are now emmitted for Impala and Catalog JVMs at the web end\npoint /jmx.\n\n- Impalad: http(s)://<impalad-host>:25000/jmx\n- Catalogd: http(s)://<catalogd-host>:25020/jmx\n\nMisc:\n====\n\nRenamed JvmMetric -> JvmMemoryMetric to make the intent more clear. It\ndoesn't relate to the functionality of the patch in anyway.\n\nTesting:\n=======\n- Tested it manually with kill -SIGSTOP/-SIGCONT <pid>. Made sure that\n  the non-GC JVM pauses are logged.\n- This class' functionality is tested manually by invoking it's main()\n- Injected a memory leak into the Catalog server code and made sure the\n  GC is detected.\n\nChange-Id: I30d897b7e063846ad6d8f88243e2c04264da0341\nReviewed-on: http://gerrit.cloudera.org:8080/10998\nReviewed-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>\nTested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16631014",
                "body": "Commit abd230647fa92db29ac3719096eb4ebc7c151069 in impala's branch refs/heads/master from [~philip]\n[ https://git-wip-us.apache.org/repos/asf?p=impala.git;h=abd2306 ]\n\nIMPALA-7596. Adding JvmPauseMonitor (and other GC) metrics to Impala metrics.\n\nFollowing up to IMPALA-6857, it's useful for monitoring tools to see if\nthe pause monitor is getting triggered, and to see other GC metrics.\n\nThe Java side here, and the Thrift side, were easy enough.\n\nHowever, the Impala metric implementation here caused us to call into\nthe frontend to read through the JMX memory beans 72 times, because each\ncall to GetValue() was getting all the data for the pool. This structure\nmade it hard to add additional, non-pool, metrics, and it felt wasteful.\nTo combat this, I added a cache of 10 seconds for getting the metrics\nfrom the Frontend. The counters will typically re-use the same data.\n\nThere are five metrics here, and to avoid yet another enum class, I used\nC++ lambdas to capture which field of the Thrift object I care about. If\nfolks like the approach, I think it can simplify way the enums for the\npool metrics as well.\n\nI measured the cost of calling into the metrics code by\nlooping the metrics-gathering 100 times and looking at CPU\ntime for the process using this script:\n\n  START_CPU=$(cat /proc/$(fuser 25000/tcp 2> /dev/null | tr -d ' ')/stat | awk '{ print $14 + $15 }')\n  for i in $(seq 100); do\n    curl http://localhost:25000/jsonmetrics?json > /dev/null 2> /dev/null\n  done\n  END_CPU=$(  cat /proc/$(fuser 25000/tcp 2> /dev/null | tr -d ' ')/stat | awk '{ print $14 + $15 }')\n  echo $START_CPU $END_CPU $(($END_CPU - $START_CPU))\n\nOn a release build on my development machine, gathering metrics 100\ntimes took 0.16 cpu seconds without this change and 0.07 cpu seconds\nwith this change. The measurement accuracy here is 0.01 (I spot-checked\nthis with using the cpuacct cgroup infrastructure which gives you nanos,\nbut it was more painful to script), but this convinces me that this is a\nnet improvement.\n\nChange-Id: Ia707393962ad94ef715ec015b3fe3bb1769104a2\nReviewed-on: http://gerrit.cloudera.org:8080/11468\nReviewed-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>\nTested-by: Impala Public Jenkins <impala-public-jenkins@cloudera.com>\n"
            }
        ],
        "comments_predictions": [
            [
                1790049,
                "IMPALA-6857",
                "No, I haven't tried the JVM part of it. Personally, I haven't seen many GC problems in Impala, but I could be wrong. This would be a nice addition, especially to the Catalog server, where there is a lot of memory churn.",
                {
                    "property": {
                        "confidence": 0.006729749497026205,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03456689417362213,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01854819245636463,
                        "prediction": false
                    }
                }
            ],
            [
                1790051,
                "IMPALA-6857",
                "[~tarmstrong], yes. You also want to copy [https://github.com/apache/hadoop-common/blob/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/jmx/JMXJsonServlet.java]\u00a0while you're at it. With that, you get things like the following, which can be interpreted.\r\n\r\nThe annoying bit about interpreting these, btw, is that they vary based on the Garbage Collector you choose.\r\n\r\n\u00a0\r\n{code:java}\r\n\r\n    \"ObjectName\" : \"java.lang:type=MemoryPool,name=Par Eden Space\"\r\n  }, {\r\n    \"name\" : \"java.lang:type=GarbageCollector,name=ParNew\",\r\n    \"modelerType\" : \"sun.management.GarbageCollectorImpl\",\r\n    \"LastGcInfo\" : {\r\n      \"GcThreadCount\" : 11,\r\n      \"duration\" : 18,\r\n      \"endTime\" : 213402847,\r\n      \"id\" : 893,\r\n      \"memoryUsageAfterGc\" : [ {\r\n        \"key\" : \"Par Survivor Space\",\r\n        \"value\" : {\r\n          \"committed\" : 26345472,\r\n          \"init\" : 26345472,\r\n          \"max\" : 26345472,\r\n          \"used\" : 5140592\r\n        }\r\n      }, {\r\n        \"key\" : \"Compressed Class Space\",\r\n        \"value\" : {\r\n          \"committed\" : 8368128,\r\n          \"init\" : 0,\r\n          \"max\" : 1073741824,\r\n          \"used\" : 7938576\r\n        }\r\n      }, {\r\n        \"key\" : \"Metaspace\",\r\n        \"value\" : {\r\n          \"committed\" : 79052800,\r\n          \"init\" : 0,\r\n          \"max\" : -1,\r\n          \"used\" : 77537496\r\n        }\r\n      }, {\r\n        \"key\" : \"Code Cache\",\r\n        \"value\" : {\r\n          \"committed\" : 54591488,\r\n          \"init\" : 2555904,\r\n          \"max\" : 251658240,\r\n          \"used\" : 53044352\r\n        }\r\n      }, {\r\n        \"key\" : \"Par Eden Space\",\r\n        \"value\" : {\r\n          \"committed\" : 210829312,\r\n          \"init\" : 210829312,\r\n          \"max\" : 210829312,\r\n          \"used\" : 0\r\n        }\r\n      }, {\r\n        \"key\" : \"CMS Old Gen\",\r\n        \"value\" : {\r\n          \"committed\" : 527106048,\r\n          \"init\" : 527106048,\r\n          \"max\" : 527106048,\r\n          \"used\" : 45992680\r\n        }\r\n      } ],\r\n      \"memoryUsageBeforeGc\" : [ {\r\n        \"key\" : \"Par Survivor Space\",\r\n        \"value\" : {\r\n          \"committed\" : 26345472,\r\n          \"init\" : 26345472,\r\n          \"max\" : 26345472,\r\n          \"used\" : 5056128\r\n        }\r\n      }, {\r\n        \"key\" : \"Compressed Class Space\",\r\n        \"value\" : {\r\n          \"committed\" : 8368128,\r\n          \"init\" : 0,\r\n          \"max\" : 1073741824,\r\n          \"used\" : 7938576\r\n        }\r\n      }, {\r\n        \"key\" : \"Metaspace\",\r\n        \"value\" : {\r\n          \"committed\" : 79052800,\r\n          \"init\" : 0,\r\n          \"max\" : -1,\r\n          \"used\" : 77537496\r\n        }\r\n      }, {\r\n        \"key\" : \"Code Cache\",\r\n        \"value\" : {\r\n          \"committed\" : 54591488,\r\n          \"init\" : 2555904,\r\n          \"max\" : 251658240,\r\n          \"used\" : 53044352\r\n        }\r\n      }, {\r\n        \"key\" : \"Par Eden Space\",\r\n        \"value\" : {\r\n          \"committed\" : 210829312,\r\n          \"init\" : 210829312,\r\n          \"max\" : 210829312,\r\n          \"used\" : 210829312\r\n        }\r\n      }, {\r\n        \"key\" : \"CMS Old Gen\",\r\n        \"value\" : {\r\n          \"committed\" : 527106048,\r\n          \"init\" : 527106048,\r\n          \"max\" : 527106048,\r\n          \"used\" : 45982688\r\n        }\r\n      } ],\r\n      \"startTime\" : 213402829\r\n    },\r\n    \"CollectionCount\" : 893,\r\n    \"CollectionTime\" : 16618,\r\n    \"MemoryPoolNames\" : [ \"Par Eden Space\", \"Par Survivor Space\" ],\r\n    \"Valid\" : true,\r\n    \"Name\" : \"ParNew\",\r\n    \"ObjectName\" : \"java.lang:type=GarbageCollector,name=ParNew\"\r\n  }, {\r\n    \"name\" : \"Hadoop:service=NameNode,name=NNTopUserOpCounts\",\r\n    \"modelerType\" : \"NNTopUserOpCounts\",\r\n    \"tag.Context\" : \"dfs\",\r\n    \"tag.Hostname\" : \"...\",\r\n    \"tag.Context.1\" : \"dfs\",\r\n    \"tag.Hostname.1\" : \"...\",\r\n    \"tag.Context.2\" : \"dfs\",\r\n    \"tag.Hostname.2\" : \"...\"\r\n  }, {\r\n    \"name\" : \"java.lang:type=GarbageCollector,name=ConcurrentMarkSweep\",\r\n    \"modelerType\" : \"sun.management.GarbageCollectorImpl\",\r\n    \"LastGcInfo\" : {\r\n      \"GcThreadCount\" : 11,\r\n      \"duration\" : 5147,\r\n      \"endTime\" : 31665,\r\n      \"id\" : 2,\r\n      \"memoryUsageAfterGc\" : [ {\r\n        \"key\" : \"Par Survivor Space\",\r\n        \"value\" : {\r\n          \"committed\" : 26345472,\r\n          \"init\" : 26345472,\r\n          \"max\" : 26345472,\r\n          \"used\" : 20233232\r\n        }\r\n      }, {\r\n        \"key\" : \"Compressed Class Space\",\r\n        \"value\" : {\r\n          \"committed\" : 7057408,\r\n          \"init\" : 0,\r\n          \"max\" : 1073741824,\r\n          \"used\" : 6842328\r\n        }\r\n      }, {\r\n        \"key\" : \"Metaspace\",\r\n        \"value\" : {\r\n          \"committed\" : 61751296,\r\n          \"init\" : 0,\r\n          \"max\" : -1,\r\n          \"used\" : 60704360\r\n        }\r\n      }, {\r\n        \"key\" : \"Code Cache\",\r\n        \"value\" : {\r\n          \"committed\" : 11730944,\r\n          \"init\" : 2555904,\r\n          \"max\" : 251658240,\r\n          \"used\" : 11637952\r\n        }\r\n      }, {\r\n        \"key\" : \"Par Eden Space\",\r\n        \"value\" : {\r\n          \"committed\" : 210829312,\r\n          \"init\" : 210829312,\r\n          \"max\" : 210829312,\r\n          \"used\" : 30868728\r\n        }\r\n      }, {\r\n        \"key\" : \"CMS Old Gen\",\r\n        \"value\" : {\r\n          \"committed\" : 527106048,\r\n          \"init\" : 527106048,\r\n          \"max\" : 527106048,\r\n          \"used\" : 23349304\r\n        }\r\n      } ],\r\n      \"memoryUsageBeforeGc\" : [ {\r\n        \"key\" : \"Par Survivor Space\",\r\n        \"value\" : {\r\n          \"committed\" : 26345472,\r\n          \"init\" : 26345472,\r\n          \"max\" : 26345472,\r\n          \"used\" : 13266608\r\n        }\r\n      }, {\r\n        \"key\" : \"Compressed Class Space\",\r\n        \"value\" : {\r\n          \"committed\" : 6275072,\r\n          \"init\" : 0,\r\n          \"max\" : 1073741824,\r\n          \"used\" : 6106680\r\n        }\r\n      }, {\r\n        \"key\" : \"Metaspace\",\r\n        \"value\" : {\r\n          \"committed\" : 54689792,\r\n          \"init\" : 0,\r\n          \"max\" : -1,\r\n          \"used\" : 53807072\r\n        }\r\n      }, {\r\n        \"key\" : \"Code Cache\",\r\n        \"value\" : {\r\n          \"committed\" : 11141120,\r\n          \"init\" : 2555904,\r\n          \"max\" : 251658240,\r\n          \"used\" : 10582208\r\n        }\r\n      }, {\r\n        \"key\" : \"Par Eden Space\",\r\n        \"value\" : {\r\n          \"committed\" : 210829312,\r\n          \"init\" : 210829312,\r\n          \"max\" : 210829312,\r\n          \"used\" : 115745272\r\n        }\r\n      }, {\r\n        \"key\" : \"CMS Old Gen\",\r\n        \"value\" : {\r\n          \"committed\" : 527106048,\r\n          \"init\" : 527106048,\r\n          \"max\" : 527106048,\r\n          \"used\" : 30169768\r\n        }\r\n      } ],\r\n      \"startTime\" : 26518\r\n    },\r\n    \"CollectionCount\" : 2,\r\n    \"CollectionTime\" : 68,\r\n    \"MemoryPoolNames\" : [ \"Par Eden Space\", \"Par Survivor Space\", \"CMS Old Gen\" ],\r\n    \"Valid\" : true,\r\n    \"Name\" : \"ConcurrentMarkSweep\",\r\n    \"ObjectName\" : \"java.lang:type=GarbageCollector,name=ConcurrentMarkSweep\"\r\n  }, {{code}",
                {
                    "property": {
                        "confidence": 0.004380953032523394,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01419506873935461,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008846434764564037,
                        "prediction": false
                    }
                }
            ],
            [
                1790052,
                "IMPALA-6857",
                "Patch is up for review [https://gerrit.cloudera.org/#/c/10998/.]\u00a0It uses the GarbageCollectorMXBean data but they are exposed using the traditional Impala metrics framework. For some reason, we didn't take the JMX route for JVM memory metrics, so my patch just builds on top of that.",
                {
                    "property": {
                        "confidence": 0.0028652548789978027,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.06501499563455582,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.025804640725255013,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5da7af4d395ee221a5c66",
        "key": "SPARK-30806",
        "id": "13285010",
        "description": null,
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d62d47f4d395ee2226bcbd",
        "key": "AMQ-3131",
        "id": "12495322",
        "description": "\nThe following error just started showing up in our ActiveMQ log file for unknown reasons (repeated 11 times, all within a second):\n\n{noformat}\n\n2011-01-11 03:42:00,997 | ERROR | Failed to reset batching | org.apache.activemq.store.kahadb.KahaDBStore | Thread-2002\njava.lang.IllegalStateException: PageFile is not loaded\n        at org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721)\n        at org.apache.kahadb.page.PageFile.tx(PageFile.java:239)\n        at org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.resetBatching(KahaDBStore.java:512)\n        at org.apache.activemq.store.ProxyMessageStore.resetBatching(ProxyMessageStore.java:93)\n        at org.apache.activemq.broker.region.cursors.QueueStorePrefetch.resetBatch(QueueStorePrefetch.java:85)\n        at org.apache.activemq.broker.region.cursors.AbstractStoreCursor.stop(AbstractStoreCursor.java:69)\n        at org.apache.activemq.broker.region.cursors.StoreQueueCursor.stop(StoreQueueCursor.java:84)\n        at org.apache.activemq.broker.region.Queue.stop(Queue.java:853)\n        at org.apache.activemq.broker.region.AbstractRegion.stop(AbstractRegion.java:110)\n        at org.apache.activemq.util.ServiceStopper.stop(ServiceStopper.java:41)\n        at org.apache.activemq.broker.region.RegionBroker.doStop(RegionBroker.java:713)\n        at org.apache.activemq.broker.jmx.ManagedRegionBroker.doStop(ManagedRegionBroker.java:113)\n        at org.apache.activemq.broker.region.RegionBroker.stop(RegionBroker.java:213)\n        at org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n        at org.apache.activemq.broker.scheduler.SchedulerBroker.stop(SchedulerBroker.java:104)\n        at org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n        at org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n        at org.apache.activemq.broker.TransactionBroker.stop(TransactionBroker.java:114)\n        at org.apache.activemq.broker.BrokerService$3.stop(BrokerService.java:1773)\n        at org.apache.activemq.util.ServiceStopper.stop(ServiceStopper.java:41)\n        at org.apache.activemq.broker.BrokerService.stop(BrokerService.java:575)\n        at org.apache.activemq.console.command.StartCommand$1.run(StartCommand.java:135)\n{noformat}\n\nSimilarly we now have an issue on shutdown, with the following error (also repeating 11 times):\n\n{noformat}\n2011-01-11 10:34:39,652 | ERROR | Failed to reset batching | org.apache.activemq.store.kahadb.KahaDBStore | ActiveMQ ShutdownHook\njava.lang.IllegalStateException: PageFile is not loaded\n        at org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721)\n        at org.apache.kahadb.page.PageFile.tx(PageFile.java:239)\n        at org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.resetBatching(KahaDBStore.java:512)\n        at org.apache.activemq.store.ProxyMessageStore.resetBatching(ProxyMessageStore.java:93)\n        at org.apache.activemq.broker.region.cursors.QueueStorePrefetch.resetBatch(QueueStorePrefetch.java:85)\n        at org.apache.activemq.broker.region.cursors.AbstractStoreCursor.stop(AbstractStoreCursor.java:69)\n        at org.apache.activemq.broker.region.cursors.StoreQueueCursor.stop(StoreQueueCursor.java:84)\n        at org.apache.activemq.broker.region.Queue.stop(Queue.java:853)\n        at org.apache.activemq.broker.region.AbstractRegion.stop(AbstractRegion.java:110)\n        at org.apache.activemq.util.ServiceStopper.stop(ServiceStopper.java:41)\n        at org.apache.activemq.broker.region.RegionBroker.doStop(RegionBroker.java:713)\n        at org.apache.activemq.broker.jmx.ManagedRegionBroker.doStop(ManagedRegionBroker.java:113)\n        at org.apache.activemq.broker.region.RegionBroker.stop(RegionBroker.java:213)\n        at org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n        at org.apache.activemq.broker.scheduler.SchedulerBroker.stop(SchedulerBroker.java:104)\n        at org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n        at org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n        at org.apache.activemq.broker.TransactionBroker.stop(TransactionBroker.java:114)\n        at org.apache.activemq.broker.BrokerService$3.stop(BrokerService.java:1773)\n        at org.apache.activemq.util.ServiceStopper.stop(ServiceStopper.java:41)\n        at org.apache.activemq.broker.BrokerService.stop(BrokerService.java:575)\n        at org.apache.activemq.broker.BrokerService.containerShutdown(BrokerService.java:1971)\n        at org.apache.activemq.broker.BrokerService$4.run(BrokerService.java:1938)\n{noformat}\n\nSubsequent start / stops result in the same shutdown errors above.\n\nIs there a workaround for this besides deleting the datastore DB files?\n\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009994227439165115
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007849707268178463
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005682149901986122
                }
            }
        },
        "comments": [
            {
                "author_name": "gtully",
                "id": "12981699",
                "body": "please attach the full log of the broker if this occurs again. the additional context may help diagnose."
            },
            {
                "author_name": "fgynnild",
                "id": "12990094",
                "body": "I ran into the same issue today, but I got if after changing some parameters in the activemq.xml file and then did a restart of AMQ."
            },
            {
                "author_name": "ives.stoddard",
                "id": "12990122",
                "body": "@Frank: couple questions...\n\n1) do you recall what the changes were to activemq.xml?\n2) are you using the scheduler functionality?\n3) are you using anything other than the default prefectch or batching settings?\n\nThanks."
            },
            {
                "author_name": "iocanel",
                "id": "12999312",
                "body": "I am having similar issues. In my case they are clearly related to the scheduler.\n\n\njavax.jms.JMSException: PageFile is not loaded\n        at org.apache.activemq.util.JMSExceptionSupport.create(JMSExceptionSupport.java:49)\n        at org.apache.activemq.ActiveMQConnection.onAsyncException(ActiveMQConnection.java:1833)\n        at org.apache.activemq.ActiveMQConnection$2$1.run(ActiveMQConnection.java:1754)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:619)\nCaused by: java.lang.IllegalStateException: PageFile is not loaded\n        at org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721)\n        at org.apache.kahadb.page.PageFile.tx(PageFile.java:239)\n        at org.apache.activemq.broker.scheduler.JobSchedulerImpl.schedule(JobSchedulerImpl.java:110)\n        at org.apache.activemq.broker.scheduler.SchedulerBroker.send(SchedulerBroker.java:185)\n        at org.apache.activemq.broker.BrokerFilter.send(BrokerFilter.java:129)\n        at org.apache.activemq.broker.CompositeDestinationBroker.send(CompositeDestinationBroker.java:96)\n        at org.apache.activemq.broker.TransactionBroker.send(TransactionBroker.java:227)\n        at org.apache.activemq.broker.MutableBrokerFilter.send(MutableBrokerFilter.java:135)\n        at org.apache.activemq.broker.TransportConnection.processMessage(TransportConnection.java:462)\n        at org.apache.activemq.command.ActiveMQMessage.visit(ActiveMQMessage.java:677)\n        at org.apache.activemq.broker.TransportConnection.service(TransportConnection.java:311)\n        at org.apache.activemq.broker.TransportConnection$1.onCommand(TransportConnection.java:185)\n        at org.apache.activemq.transport.TransportFilter.onCommand(TransportFilter.java:69)\n        at org.apache.activemq.transport.WireFormatNegotiator.onCommand(WireFormatNegotiator.java:113)\n        at org.apache.activemq.transport.InactivityMonitor.onCommand(InactivityMonitor.java:228)\n        at org.apache.activemq.transport.TransportSupport.doConsume(TransportSupport.java:83)\n        at org.apache.activemq.transport.nio.NIOTransport.serviceRead(NIOTransport.java:129)\n        at org.apache.activemq.transport.nio.NIOTransport.access$000(NIOTransport.java:44)\n        at org.apache.activemq.transport.nio.NIOTransport$1.onSelect(NIOTransport.java:68)\n        at org.apache.activemq.transport.nio.SelectorSelection.onSelect(SelectorSelection.java:94)\n        at org.apache.activemq.transport.nio.SelectorWorker$1.run(SelectorWorker.java:119)\n        ... 3 more\n"
            },
            {
                "author_name": "sbucci",
                "id": "13001363",
                "body": "I have the same problem after an activemq.xml change.\nEnvironment : \n - Windows xp/2008 r2\n - I'm using scheduler\n\n{code:java}\n2011-02-10 05:00:46,992 | ERROR | Failed to reset batching | org.apache.activemq.store.kahadb.KahaDBStore | ActiveMQ ShutdownHook\njava.lang.IllegalStateException: PageFile is not loaded\n\tat org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721)\n\tat org.apache.kahadb.page.PageFile.tx(PageFile.java:239)\n\tat org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.resetBatching(KahaDBStore.java:512)\n\tat org.apache.activemq.store.ProxyMessageStore.resetBatching(ProxyMessageStore.java:93)\n\tat org.apache.activemq.broker.region.cursors.QueueStorePrefetch.resetBatch(QueueStorePrefetch.java:85)\n\tat org.apache.activemq.broker.region.cursors.AbstractStoreCursor.stop(AbstractStoreCursor.java:69)\n\tat org.apache.activemq.broker.region.cursors.StoreQueueCursor.stop(StoreQueueCursor.java:84)\n\tat org.apache.activemq.broker.region.Queue.stop(Queue.java:853)\n\tat org.apache.activemq.broker.region.AbstractRegion.stop(AbstractRegion.java:110)\n\tat org.apache.activemq.util.ServiceStopper.stop(ServiceStopper.java:41)\n\tat org.apache.activemq.broker.region.RegionBroker.doStop(RegionBroker.java:713)\n\tat org.apache.activemq.broker.jmx.ManagedRegionBroker.doStop(ManagedRegionBroker.java:113)\n\tat org.apache.activemq.broker.region.RegionBroker.stop(RegionBroker.java:213)\n\tat org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n\tat org.apache.activemq.broker.scheduler.SchedulerBroker.stop(SchedulerBroker.java:104)\n\tat org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n\tat org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n\tat org.apache.activemq.broker.TransactionBroker.stop(TransactionBroker.java:114)\n\tat org.apache.activemq.broker.BrokerService$3.stop(BrokerService.java:1773)\n\tat org.apache.activemq.util.ServiceStopper.stop(ServiceStopper.java:41)\n\tat org.apache.activemq.broker.BrokerService.stop(BrokerService.java:575)\n\tat org.apache.activemq.broker.BrokerService.containerShutdown(BrokerService.java:1971)\n\tat org.apache.activemq.broker.BrokerService$4.run(BrokerService.java:1938)\n{code}"
            },
            {
                "author_name": "matt_good@yahoo.com",
                "id": "13017697",
                "body": "I have the same problem.  In my case, I deleted several queues from admin console.  These queues were used for testing scheduled messages.  When I stopped ActiveMQ, I got 5 of these errors.  When I restarted it 5 of the queues I deleted reappeared.  Coincidence or part of the problem - I can't say."
            },
            {
                "author_name": "jplmelanson",
                "id": "13153051",
                "body": "Similar stack trace here:\n{code}\nCaused by: java.lang.IllegalStateException: PageFile is not loaded \n  at org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721) \n  at org.apache.kahadb.page.PageFile.tx(PageFile.java:239) \n  at org.apache.activemq.broker.scheduler.JobSchedulerImpl.schedule(JobSchedulerImpl.java:110) \n  at org.apache.activemq.broker.scheduler.SchedulerBroker.send(SchedulerBroker.java:185) \n  at org.apache.activemq.broker.BrokerFilter.send(BrokerFilter.java:129) \n  at org.apache.activemq.broker.CompositeDestinationBroker.send(CompositeDestinationBroker.java:96)\n{code} \n\nI haven't reproduced it yet, but I opened up the trunk code and seems like {{JobSchedulerImpl.schedule()}} methods are using the {{tx()}} method, which in turn asserts that the {{PageFile}} is loaded, which doesn't seems to be the case. \n\nI don't know the code at all, but I wonder if the job scheduler should check if the page file is loaded first, load it if needed and process with the transaction? What do you think?"
            },
            {
                "author_name": "gtully",
                "id": "13155545",
                "body": "For the shutdown case, there is a fix on trunk, the org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.resetBatching(KahaDBStore.java:512) checks if the page file has been unloaded as it will be due to being shutdown before the destinations.\nhttp://svn.apache.org/viewvc?rev=1170201&view=rev"
            },
            {
                "author_name": "gtully",
                "id": "13155551",
                "body": "The schedular store is not started when it is created so the use before initialisation error should not occur on trunk. Reopen if this is reproducible with trunk of 5.6 "
            },
            {
                "author_name": "artnaseef",
                "id": "13185731",
                "body": "Hey Gary, we need to back-port a patch as we are not comfortable to run the 5.6-SNAPSHOT to fix this problem and the 5.5.1 version is still problematic.\n\nAfter back-porting all of the changes to the Scheduler code, this still happens.\n\nDo you have any idea where else I should look?  I've been going through all of the Jira entries resolved in 5.6 and not finding any promising leads.\n"
            },
            {
                "author_name": "artnaseef",
                "id": "13187945",
                "body": "SCRATCH THAT.\n\nI had build problems that prevented the updates from taking effect.  Using the latest version of the scheduler sources resolves the problem for us."
            },
            {
                "author_name": "gtully",
                "id": "13187960",
                "body": "Glad you got sorted :-)\nOn Jan 17, 2012 7:51 p.m., \"Arthur Naseef (Commented) (JIRA)\" <\n\n"
            },
            {
                "author_name": "ishitori",
                "id": "13188334",
                "body": "Arthur, right now I experience the same error. Moreover, I can see a lot of .log files in KahaDb. I believe that they are not got cleaned up because of this exception.\n\nI also don't want to move to 5.6.0 and I would love to have this fix in 5.5.1 version. Can you commit your changes into 5.5.1 version so the latest snapshot of 5.5.1 would have your changes?"
            },
            {
                "author_name": "devantor",
                "id": "13188495",
                "body": "I don't know the steps to reproduce this one. But this bug affect also expired messages. org.apache.activemq.broker.region.Queue.expireMessages(Queue.java:772)\n\nFailed to reset batching\njava.lang.IllegalStateException: PageFile is not loaded\nat org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721)\nat org.apache.kahadb.page.PageFile.tx(PageFile.java:239)\nat org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.resetBatching(KahaDBStore.java:469)\nat org.apache.activemq.store.ProxyMessageStore.resetBatching(ProxyMessageStore.java:93)\nat org.apache.activemq.broker.region.cursors.QueueStorePrefetch.resetBatch(QueueStorePrefetch.java:85)\nat org.apache.activemq.broker.region.cursors.AbstractStoreCursor.fillBatch(AbstractStoreCursor.java:256)\nat org.apache.activemq.broker.region.cursors.AbstractStoreCursor.reset(AbstractStoreCursor.java:110)\nat org.apache.activemq.broker.region.cursors.StoreQueueCursor.reset(StoreQueueCursor.java:157)\nat org.apache.activemq.broker.region.Queue.doBrowse(Queue.java:1009)\nat org.apache.activemq.broker.region.Queue.expireMessages(Queue.java:772)\nat org.apache.activemq.broker.region.Queue.access$100(Queue.java:83)\nat org.apache.activemq.broker.region.Queue$2.run(Queue.java:123)\nat org.apache.activemq.thread.SchedulerTimerTask.run(SchedulerTimerTask.java:33)\nat java.util.TimerThread.mainLoop(Timer.java:512)\nat java.util.TimerThread.run(Timer.java:462)"
            },
            {
                "author_name": "gtully",
                "id": "13188504",
                "body": "@devantor: for the periodic expiry case, that can be disabled via policy entry, expireMessagesPeriod=0\nExpiry will still occur on send/dispatch, the only problem will be when there are no consumers, there will be no check for expiry, so expired messages can build up till dispatch is attempted again. "
            },
            {
                "author_name": "artnaseef",
                "id": "13188543",
                "body": "Sergei - my issue was with the scheduler for which the fixes are in 5.5.1, I believe.  If your having trouble due to the scheduler, the latest head version of the sources for the following directory fixed my problem:\n\nactivemq-core/src/main/java/org/apache/activemq/broker/scheduler\n\nNote that we still see \"failed to reset batching\" errors with this update when shutting down the brokers if there are messages still pending delivery in the scheduler, but that's not a problem for us.\n"
            }
        ],
        "comments_predictions": [
            [
                3812083,
                "AMQ-3131",
                "@Frank: couple questions...\n\n1) do you recall what the changes were to activemq.xml?\n2) are you using the scheduler functionality?\n3) are you using anything other than the default prefectch or batching settings?\n\nThanks.",
                {
                    "property": {
                        "confidence": 0.0036810983438044786,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008858497254550457,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023392679169774055,
                        "prediction": false
                    }
                }
            ],
            [
                3812084,
                "AMQ-3131",
                "I am having similar issues. In my case they are clearly related to the scheduler.\n\n\njavax.jms.JMSException: PageFile is not loaded\n        at org.apache.activemq.util.JMSExceptionSupport.create(JMSExceptionSupport.java:49)\n        at org.apache.activemq.ActiveMQConnection.onAsyncException(ActiveMQConnection.java:1833)\n        at org.apache.activemq.ActiveMQConnection$2$1.run(ActiveMQConnection.java:1754)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:619)\nCaused by: java.lang.IllegalStateException: PageFile is not loaded\n        at org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721)\n        at org.apache.kahadb.page.PageFile.tx(PageFile.java:239)\n        at org.apache.activemq.broker.scheduler.JobSchedulerImpl.schedule(JobSchedulerImpl.java:110)\n        at org.apache.activemq.broker.scheduler.SchedulerBroker.send(SchedulerBroker.java:185)\n        at org.apache.activemq.broker.BrokerFilter.send(BrokerFilter.java:129)\n        at org.apache.activemq.broker.CompositeDestinationBroker.send(CompositeDestinationBroker.java:96)\n        at org.apache.activemq.broker.TransactionBroker.send(TransactionBroker.java:227)\n        at org.apache.activemq.broker.MutableBrokerFilter.send(MutableBrokerFilter.java:135)\n        at org.apache.activemq.broker.TransportConnection.processMessage(TransportConnection.java:462)\n        at org.apache.activemq.command.ActiveMQMessage.visit(ActiveMQMessage.java:677)\n        at org.apache.activemq.broker.TransportConnection.service(TransportConnection.java:311)\n        at org.apache.activemq.broker.TransportConnection$1.onCommand(TransportConnection.java:185)\n        at org.apache.activemq.transport.TransportFilter.onCommand(TransportFilter.java:69)\n        at org.apache.activemq.transport.WireFormatNegotiator.onCommand(WireFormatNegotiator.java:113)\n        at org.apache.activemq.transport.InactivityMonitor.onCommand(InactivityMonitor.java:228)\n        at org.apache.activemq.transport.TransportSupport.doConsume(TransportSupport.java:83)\n        at org.apache.activemq.transport.nio.NIOTransport.serviceRead(NIOTransport.java:129)\n        at org.apache.activemq.transport.nio.NIOTransport.access$000(NIOTransport.java:44)\n        at org.apache.activemq.transport.nio.NIOTransport$1.onSelect(NIOTransport.java:68)\n        at org.apache.activemq.transport.nio.SelectorSelection.onSelect(SelectorSelection.java:94)\n        at org.apache.activemq.transport.nio.SelectorWorker$1.run(SelectorWorker.java:119)\n        ... 3 more\n",
                {
                    "property": {
                        "confidence": 0.007502869237214327,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005573251284658909,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010599392466247082,
                        "prediction": false
                    }
                }
            ],
            [
                3812085,
                "AMQ-3131",
                "I have the same problem after an activemq.xml change.\nEnvironment : \n - Windows xp/2008 r2\n - I'm using scheduler\n\n{code:java}\n2011-02-10 05:00:46,992 | ERROR | Failed to reset batching | org.apache.activemq.store.kahadb.KahaDBStore | ActiveMQ ShutdownHook\njava.lang.IllegalStateException: PageFile is not loaded\n\tat org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721)\n\tat org.apache.kahadb.page.PageFile.tx(PageFile.java:239)\n\tat org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.resetBatching(KahaDBStore.java:512)\n\tat org.apache.activemq.store.ProxyMessageStore.resetBatching(ProxyMessageStore.java:93)\n\tat org.apache.activemq.broker.region.cursors.QueueStorePrefetch.resetBatch(QueueStorePrefetch.java:85)\n\tat org.apache.activemq.broker.region.cursors.AbstractStoreCursor.stop(AbstractStoreCursor.java:69)\n\tat org.apache.activemq.broker.region.cursors.StoreQueueCursor.stop(StoreQueueCursor.java:84)\n\tat org.apache.activemq.broker.region.Queue.stop(Queue.java:853)\n\tat org.apache.activemq.broker.region.AbstractRegion.stop(AbstractRegion.java:110)\n\tat org.apache.activemq.util.ServiceStopper.stop(ServiceStopper.java:41)\n\tat org.apache.activemq.broker.region.RegionBroker.doStop(RegionBroker.java:713)\n\tat org.apache.activemq.broker.jmx.ManagedRegionBroker.doStop(ManagedRegionBroker.java:113)\n\tat org.apache.activemq.broker.region.RegionBroker.stop(RegionBroker.java:213)\n\tat org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n\tat org.apache.activemq.broker.scheduler.SchedulerBroker.stop(SchedulerBroker.java:104)\n\tat org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n\tat org.apache.activemq.broker.BrokerFilter.stop(BrokerFilter.java:161)\n\tat org.apache.activemq.broker.TransactionBroker.stop(TransactionBroker.java:114)\n\tat org.apache.activemq.broker.BrokerService$3.stop(BrokerService.java:1773)\n\tat org.apache.activemq.util.ServiceStopper.stop(ServiceStopper.java:41)\n\tat org.apache.activemq.broker.BrokerService.stop(BrokerService.java:575)\n\tat org.apache.activemq.broker.BrokerService.containerShutdown(BrokerService.java:1971)\n\tat org.apache.activemq.broker.BrokerService$4.run(BrokerService.java:1938)\n{code}",
                {
                    "property": {
                        "confidence": 0.004554531071335077,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009652071632444859,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010446920059621334,
                        "prediction": false
                    }
                }
            ],
            [
                3812086,
                "AMQ-3131",
                "I have the same problem.  In my case, I deleted several queues from admin console.  These queues were used for testing scheduled messages.  When I stopped ActiveMQ, I got 5 of these errors.  When I restarted it 5 of the queues I deleted reappeared.  Coincidence or part of the problem - I can't say.",
                {
                    "property": {
                        "confidence": 0.005468118004500866,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006002010777592659,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014211861416697502,
                        "prediction": false
                    }
                }
            ],
            [
                3812087,
                "AMQ-3131",
                "Similar stack trace here:\n{code}\nCaused by: java.lang.IllegalStateException: PageFile is not loaded \n  at org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721) \n  at org.apache.kahadb.page.PageFile.tx(PageFile.java:239) \n  at org.apache.activemq.broker.scheduler.JobSchedulerImpl.schedule(JobSchedulerImpl.java:110) \n  at org.apache.activemq.broker.scheduler.SchedulerBroker.send(SchedulerBroker.java:185) \n  at org.apache.activemq.broker.BrokerFilter.send(BrokerFilter.java:129) \n  at org.apache.activemq.broker.CompositeDestinationBroker.send(CompositeDestinationBroker.java:96)\n{code} \n\nI haven't reproduced it yet, but I opened up the trunk code and seems like {{JobSchedulerImpl.schedule()}} methods are using the {{tx()}} method, which in turn asserts that the {{PageFile}} is loaded, which doesn't seems to be the case. \n\nI don't know the code at all, but I wonder if the job scheduler should check if the page file is loaded first, load it if needed and process with the transaction? What do you think?",
                {
                    "property": {
                        "confidence": 0.005726248491555452,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005043236538767815,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018527118489146233,
                        "prediction": false
                    }
                }
            ],
            [
                3812088,
                "AMQ-3131",
                "For the shutdown case, there is a fix on trunk, the org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.resetBatching(KahaDBStore.java:512) checks if the page file has been unloaded as it will be due to being shutdown before the destinations.\nhttp://svn.apache.org/viewvc?rev=1170201&view=rev",
                {
                    "property": {
                        "confidence": 0.006186619400978088,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005278461612761021,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014113123528659344,
                        "prediction": false
                    }
                }
            ],
            [
                3812090,
                "AMQ-3131",
                "Hey Gary, we need to back-port a patch as we are not comfortable to run the 5.6-SNAPSHOT to fix this problem and the 5.5.1 version is still problematic.\n\nAfter back-porting all of the changes to the Scheduler code, this still happens.\n\nDo you have any idea where else I should look?  I've been going through all of the Jira entries resolved in 5.6 and not finding any promising leads.\n",
                {
                    "property": {
                        "confidence": 0.006939959712326527,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007655554451048374,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008842661045491695,
                        "prediction": false
                    }
                }
            ],
            [
                3812093,
                "AMQ-3131",
                "Arthur, right now I experience the same error. Moreover, I can see a lot of .log files in KahaDb. I believe that they are not got cleaned up because of this exception.\n\nI also don't want to move to 5.6.0 and I would love to have this fix in 5.5.1 version. Can you commit your changes into 5.5.1 version so the latest snapshot of 5.5.1 would have your changes?",
                {
                    "property": {
                        "confidence": 0.005776402540504932,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006975854281336069,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01139021199196577,
                        "prediction": false
                    }
                }
            ],
            [
                3812094,
                "AMQ-3131",
                "I don't know the steps to reproduce this one. But this bug affect also expired messages. org.apache.activemq.broker.region.Queue.expireMessages(Queue.java:772)\n\nFailed to reset batching\njava.lang.IllegalStateException: PageFile is not loaded\nat org.apache.kahadb.page.PageFile.assertLoaded(PageFile.java:721)\nat org.apache.kahadb.page.PageFile.tx(PageFile.java:239)\nat org.apache.activemq.store.kahadb.KahaDBStore$KahaDBMessageStore.resetBatching(KahaDBStore.java:469)\nat org.apache.activemq.store.ProxyMessageStore.resetBatching(ProxyMessageStore.java:93)\nat org.apache.activemq.broker.region.cursors.QueueStorePrefetch.resetBatch(QueueStorePrefetch.java:85)\nat org.apache.activemq.broker.region.cursors.AbstractStoreCursor.fillBatch(AbstractStoreCursor.java:256)\nat org.apache.activemq.broker.region.cursors.AbstractStoreCursor.reset(AbstractStoreCursor.java:110)\nat org.apache.activemq.broker.region.cursors.StoreQueueCursor.reset(StoreQueueCursor.java:157)\nat org.apache.activemq.broker.region.Queue.doBrowse(Queue.java:1009)\nat org.apache.activemq.broker.region.Queue.expireMessages(Queue.java:772)\nat org.apache.activemq.broker.region.Queue.access$100(Queue.java:83)\nat org.apache.activemq.broker.region.Queue$2.run(Queue.java:123)\nat org.apache.activemq.thread.SchedulerTimerTask.run(SchedulerTimerTask.java:33)\nat java.util.TimerThread.mainLoop(Timer.java:512)\nat java.util.TimerThread.run(Timer.java:462)",
                {
                    "property": {
                        "confidence": 0.006198374554514885,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009210662916302681,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007816946133971214,
                        "prediction": false
                    }
                }
            ],
            [
                3812095,
                "AMQ-3131",
                "@devantor: for the periodic expiry case, that can be disabled via policy entry, expireMessagesPeriod=0\nExpiry will still occur on send/dispatch, the only problem will be when there are no consumers, there will be no check for expiry, so expired messages can build up till dispatch is attempted again. ",
                {
                    "property": {
                        "confidence": 0.006007466930896044,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005393574479967356,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.019104044884443283,
                        "prediction": false
                    }
                }
            ],
            [
                3812096,
                "AMQ-3131",
                "Sergei - my issue was with the scheduler for which the fixes are in 5.5.1, I believe.  If your having trouble due to the scheduler, the latest head version of the sources for the following directory fixed my problem:\n\nactivemq-core/src/main/java/org/apache/activemq/broker/scheduler\n\nNote that we still see \"failed to reset batching\" errors with this update when shutting down the brokers if there are messages still pending delivery in the scheduler, but that's not a problem for us.\n",
                {
                    "property": {
                        "confidence": 0.005724215880036354,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004895511548966169,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.020833130925893784,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "6407469d477a70e2ad81dba5",
        "key": "SPARK-40974",
        "id": "13493690",
        "description": "Im trying to determine if indirectly selecting an outer column is a bug or an intended feature of the EXPLODE function.\u00a0\r\n\r\n\u00a0\r\n\r\nIf I run the following SQL statement:\r\n\r\n```\r\n\r\nSELECT\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0(SELECT FIRST(name_element_)\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0FROM LATERAL VIEW EXPLODE(name) AS name_element_\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0*)*\r\n\r\nFROM patient\r\n\r\n```\r\n\r\n\u00a0\r\n\r\nit fails with:\r\n\r\n```\r\n\r\nAccessing outer query column is not allowed in:\r\n\r\nGenerate explode(outer(name#9628))\r\n\r\n```\r\n\r\n\u00a0\r\n\r\nHowever, if I do a \"cheeky select\" (bolded below), the SQL query is valid and runs:\r\n\r\n```\r\n\r\nSELECT(\r\n\r\n\u00a0\u00a0\u00a0\u00a0SELECT FIRST(name_element_)\r\n\r\n\u00a0\u00a0\u00a0\u00a0FROM (SELECT EXPLODE(name_element_) AS name_element_\u00a0\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\\{*}FROM ({*}{*}SELECT{*} *name AS name_element_)*\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 **\u00a0 \u00a0 \u00a0 \u00a0 )\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0)\r\n\r\nFROM patient\r\n\r\n```\r\n\r\nFrom the viewpoint of the EXPLODE function, it seems like the column name_element_ does not come from an outer column. Is this an intended feature or a bug?",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d615b4f4d395ee22239f3f",
        "key": "DRILL-6645",
        "id": "13175273",
        "description": "TopN operator is not supported in Lateral Unnest pipeline. Hence transform the TopN to use Sort and Limit.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.003993622958660126
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.1360803097486496
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006174247246235609
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16567106",
                "body": "HanumathRao opened a new pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417\n \n \n   \r\n   In Lateral/Unnest pipeline, for the sake of getting correct results it is required to introduce a ParitionLimit instead of Limit. ParitionLimit is introduced by PR for DRILL-6652. Similarly a TopN should have another version like PartitionTopN. Since ParitionTopN operator is not yet implemented we can use Limit and sort to replace a TopN. This PR includes changes to transform the TopN -> Sort and Limit.\r\n   \r\n   @gparai  @sohami  Can you please review these changes.\r\n   \r\n   This PR needs to be committed after the DRILL-6652 committed.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16567618",
                "body": "gparai commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207410445\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java\n ##########\n @@ -115,6 +118,16 @@ public Prel addImplicitRowIDCol(List<RelNode> children) {\n                                     .replace(this.getTraitSet().getTrait(DrillDistributionTraitDef.INSTANCE))\n                                     .replace(collationTrait)\n                                     .replace(DRILL_PHYSICAL);\n-    return (Prel) this.copy(traits, children);\n+    return transformTopNToSortAndLimit(children, traits, collationTrait);\n+  }\n+\n+  private Prel transformTopNToSortAndLimit(List<RelNode> children, RelTraitSet traits, RelCollation collationTrait) {\n+    SortPrel sortprel = new SortPrel(this.getCluster(), traits, children.get(0), collationTrait);\n+    RexNode offset = this.getCluster().getRexBuilder().makeExactLiteral(BigDecimal.valueOf(0),\n+            this.getCluster().getTypeFactory().createSqlType(SqlTypeName.INTEGER));\n+    RexNode limit = this.getCluster().getRexBuilder().makeExactLiteral(BigDecimal.valueOf(this.limit),\n \n Review comment:\n   Just a minor comment - you can add a comment describing why we don't need SMEX.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "priteshm",
                "id": "16567768",
                "body": "Added ready-to-commit for the batch committer to review as well."
            },
            {
                "author_name": "githubbot",
                "id": "16568399",
                "body": "sohami commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207583353\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/Prel.java\n ##########\n @@ -56,7 +56,13 @@ public boolean useAbstractConvertersForConversion(RelTraitSet fromTraits,\n   SelectionVectorMode getEncoding();\n   boolean needsFinalColumnReordering();\n \n-  default Prel addImplicitRowIDCol(List<RelNode> children) {\n+  /**\n+   * If the operator is in Lateral/Unnest pipeline, then it generates a new operator which knows how to process\n+   * the rows accordingly during execution.\n+   * eg: TopNPrel -> SortPrel and LimitPrel\n+   * Other operators like FilterPrel, ProjectPrel etc will add an implicit row id to the output.\n+   */\n+  default Prel getRelForLateralUnnestPipeline(List<RelNode> children) {\n     throw new UnsupportedOperationException(\"Adding Implicit RowID column is not supported for \" +\n \n Review comment:\n   This function name is changed from `addImplicitRowIdCol` to `getRelForLateralUnnestPipeline` but from comments it looks like it does both the functionality. Based on my understanding for all operators except `TopNPrel` it's actually adding the `implicitRowIdCol` information, but since topN will not be supported inside subquery and needs to be replaced by PartitionLimit + Sort we are transforming it inside this function. And the new limit and Sort will have the information about the implicitRowIdCol. If this is true, then we should keep the name same as before and in TopN as you have done calling separate private function `transformTopNToSortAndLimit` is fine.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568400",
                "body": "sohami commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207584274\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/visitor/LateralUnnestRowIDVisitor.java\n ##########\n @@ -43,7 +43,7 @@ public static Prel insertRowID(Prel prel){\n   public Prel visitPrel(Prel prel, Boolean isRightOfLateral) throws RuntimeException {\n     List<RelNode> children = getChildren(prel, isRightOfLateral);\n     if (isRightOfLateral) {\n-      return prel.addImplicitRowIDCol(children);\n+      return prel.getRelForLateralUnnestPipeline(children);\n     } else {\n       return (Prel) prel.copy(prel.getTraitSet(), children);\n \n Review comment:\n   given that Unnest can also be on left side of Lateral shouldn't we add implicit column for operators on left subtree of Lateral as well iff Unnest is present ?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568401",
                "body": "sohami commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207586797\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java\n ##########\n @@ -115,6 +118,16 @@ public Prel addImplicitRowIDCol(List<RelNode> children) {\n                                     .replace(this.getTraitSet().getTrait(DrillDistributionTraitDef.INSTANCE))\n                                     .replace(collationTrait)\n                                     .replace(DRILL_PHYSICAL);\n-    return (Prel) this.copy(traits, children);\n+    return transformTopNToSortAndLimit(children, traits, collationTrait);\n+  }\n+\n+  private Prel transformTopNToSortAndLimit(List<RelNode> children, RelTraitSet traits, RelCollation collationTrait) {\n+    SortPrel sortprel = new SortPrel(this.getCluster(), traits, children.get(0), collationTrait);\n+    RexNode offset = this.getCluster().getRexBuilder().makeExactLiteral(BigDecimal.valueOf(0),\n+            this.getCluster().getTypeFactory().createSqlType(SqlTypeName.INTEGER));\n+    RexNode limit = this.getCluster().getRexBuilder().makeExactLiteral(BigDecimal.valueOf(this.limit),\n+            this.getCluster().getTypeFactory().createSqlType(SqlTypeName.INTEGER));\n+    LimitPrel limitPrel = new LimitPrel(this.getCluster(), traits, sortprel, offset, limit, false);\n \n Review comment:\n   `LimitPrel` created here should be for `PartitionLimit` or will it be taken care of in `LimitPrel::addImplicitRowIDCol` ?\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568402",
                "body": "sohami commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207585625\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java\n ##########\n @@ -115,6 +118,16 @@ public Prel addImplicitRowIDCol(List<RelNode> children) {\n                                     .replace(this.getTraitSet().getTrait(DrillDistributionTraitDef.INSTANCE))\n                                     .replace(collationTrait)\n                                     .replace(DRILL_PHYSICAL);\n-    return (Prel) this.copy(traits, children);\n+    return transformTopNToSortAndLimit(children, traits, collationTrait);\n+  }\n+\n+  private Prel transformTopNToSortAndLimit(List<RelNode> children, RelTraitSet traits, RelCollation collationTrait) {\n \n Review comment:\n   the transform is just replacing `TopNPrel` with new `SortPrel` and `PartitionLimitPrel`. My understanding is at this stage all the `SelectionVectorRemoverPrel` is also created wherever needed. In this case also between `SortPrel` and `LimitPrel` we have to insert a `SelectionVectorRemoverPrel` since `Limit` can only accept `SV2/SV None` whereas `Sort` can produce `SV None and SV4`\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568573",
                "body": "HanumathRao commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207628346\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/Prel.java\n ##########\n @@ -56,7 +56,13 @@ public boolean useAbstractConvertersForConversion(RelTraitSet fromTraits,\n   SelectionVectorMode getEncoding();\n   boolean needsFinalColumnReordering();\n \n-  default Prel addImplicitRowIDCol(List<RelNode> children) {\n+  /**\n+   * If the operator is in Lateral/Unnest pipeline, then it generates a new operator which knows how to process\n+   * the rows accordingly during execution.\n+   * eg: TopNPrel -> SortPrel and LimitPrel\n+   * Other operators like FilterPrel, ProjectPrel etc will add an implicit row id to the output.\n+   */\n+  default Prel getRelForLateralUnnestPipeline(List<RelNode> children) {\n     throw new UnsupportedOperationException(\"Adding Implicit RowID column is not supported for \" +\n \n Review comment:\n   changed the name of the function to prepareForLateralUnnestPipeline.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568576",
                "body": "HanumathRao commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207628559\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/visitor/LateralUnnestRowIDVisitor.java\n ##########\n @@ -43,7 +43,7 @@ public static Prel insertRowID(Prel prel){\n   public Prel visitPrel(Prel prel, Boolean isRightOfLateral) throws RuntimeException {\n     List<RelNode> children = getChildren(prel, isRightOfLateral);\n     if (isRightOfLateral) {\n-      return prel.addImplicitRowIDCol(children);\n+      return prel.getRelForLateralUnnestPipeline(children);\n     } else {\n       return (Prel) prel.copy(prel.getTraitSet(), children);\n \n Review comment:\n   As discussed this is not an issue as if an unnest is on the leftside of the lateral it should be on right side to some lateral.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568577",
                "body": "HanumathRao commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207628609\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/visitor/LateralUnnestRowIDVisitor.java\n ##########\n @@ -43,7 +43,7 @@ public static Prel insertRowID(Prel prel){\n   public Prel visitPrel(Prel prel, Boolean isRightOfLateral) throws RuntimeException {\n     List<RelNode> children = getChildren(prel, isRightOfLateral);\n     if (isRightOfLateral) {\n-      return prel.addImplicitRowIDCol(children);\n+      return prel.getRelForLateralUnnestPipeline(children);\n     } else {\n       return (Prel) prel.copy(prel.getTraitSet(), children);\n \n Review comment:\n   Here is the plan for the query.\r\n   \r\n   00-00    Screen : rowType = RecordType(ANY c_name, ANY c_address, ANY order_id, ANY order_amt, ANY itemName, ANY itemNum): rowcount = 4.0, cumulative cost = {17.4 rows, 160.4 cpu, 0.0 io, 0.0 network, 1.0 memory}, id = 747\r\n   00-01      Project(c_name=[$0], c_address=[$1], order_id=[$2], order_amt=[$3], itemName=[$4], itemNum=[$5]) : rowType = RecordType(ANY c_name, ANY c_address, ANY order_id, ANY order_amt, ANY itemName, ANY itemNum): rowcount = 4.0, cumulative cost = {17.0 rows, 160.0 cpu, 0.0 io, 0.0 network, 1.0 memory}, id = 746\r\n   00-02        LateralJoin(correlation=[$cor2], joinType=[inner], requiredColumns=[{0}], column excluded from output: =[`orders`]) : rowType = RecordType(ANY c_name, ANY c_address, ANY order_id, ANY order_amt, ANY itemName, ANY itemNum): rowcount = 4.0, cumulative cost = {13.0 rows, 136.0 cpu, 0.0 io, 0.0 network, 1.0 memory}, id = 745\r\n   00-04          Scan(groupscan=[ParquetGroupScan [entries=[ReadEntryWithPath [path=classpath:/lateraljoin/nested-customer.parquet]], selectionRoot=classpath:/lateraljoin/nested-customer.parquet, numFiles=1, numRowGroups=1, usedMetadataFile=false, columns=[`orders`, `c_name`, `c_address`]]]) : rowType = RecordType(ANY orders, ANY c_name, ANY c_address): rowcount = 4.0, cumulative cost = {4.0 rows, 12.0 cpu, 0.0 io, 0.0 network, 0.0 memory}, id = 741\r\n   00-03          Project($drill_implicit_field$=[$0], order_id=[ITEM($1, 'o_id')], order_amt=[ITEM($1, 'o_amount')], itemName=[$2], itemNum=[$3]) : rowType = RecordType(INTEGER $drill_implicit_field$, ANY order_id, ANY order_amt, ANY itemName, ANY itemNum): rowcount = 1.0, cumulative cost = {5.0 rows, 28.0 cpu, 0.0 io, 0.0 network, 1.0 memory}, id = 744\r\n   00-05            LateralJoin(correlation=[$cor1], joinType=[inner], requiredColumns=[{0}]) : rowType = RecordType(INTEGER $drill_implicit_field$, ANY orders, ANY item_name, ANY item_num): rowcount = 1.0, cumulative cost = {4.0 rows, 23.0 cpu, 0.0 io, 0.0 network, 1.0 memory}, id = 743\r\n   00-07              Unnest [srcOp=00-02]  : rowType = RecordType(INTEGER $drill_implicit_field$, ANY orders): rowcount = 1.0, cumulative cost = {1.0 rows, 2.0 cpu, 0.0 io, 0.0 network, 0.0 memory}, id = 726\r\n   00-06              Project($drill_implicit_field$=[$0], item_name=[ITEM($1, 'i_name')], item_num=[ITEM($1, 'i_number')]) : rowType = RecordType(INTEGER $drill_implicit_field$, ANY item_name, ANY item_num): rowcount = 1.0, cumulative cost = {2.0 rows, 5.0 cpu, 0.0 io, 0.0 network, 0.0 memory}, id = 742\r\n   00-08                Unnest [srcOp=00-05]  : rowType = RecordType(INTEGER $drill_implicit_field$, ANY orders): rowcount = 1.0, cumulative cost = {1.0 rows, 2.0 cpu, 0.0 io, 0.0 network, 0.0 memory}, id = 727\r\n   \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568579",
                "body": "HanumathRao commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207628873\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java\n ##########\n @@ -115,6 +118,16 @@ public Prel addImplicitRowIDCol(List<RelNode> children) {\n                                     .replace(this.getTraitSet().getTrait(DrillDistributionTraitDef.INSTANCE))\n                                     .replace(collationTrait)\n                                     .replace(DRILL_PHYSICAL);\n-    return (Prel) this.copy(traits, children);\n+    return transformTopNToSortAndLimit(children, traits, collationTrait);\n+  }\n+\n+  private Prel transformTopNToSortAndLimit(List<RelNode> children, RelTraitSet traits, RelCollation collationTrait) {\n \n Review comment:\n   SelectionVector are created at the later stage. This is called before inserting the selectionvector.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568580",
                "body": "HanumathRao commented on a change in pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#discussion_r207629168\n \n \n\n ##########\n File path: exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java\n ##########\n @@ -115,6 +118,16 @@ public Prel addImplicitRowIDCol(List<RelNode> children) {\n                                     .replace(this.getTraitSet().getTrait(DrillDistributionTraitDef.INSTANCE))\n                                     .replace(collationTrait)\n                                     .replace(DRILL_PHYSICAL);\n-    return (Prel) this.copy(traits, children);\n+    return transformTopNToSortAndLimit(children, traits, collationTrait);\n+  }\n+\n+  private Prel transformTopNToSortAndLimit(List<RelNode> children, RelTraitSet traits, RelCollation collationTrait) {\n+    SortPrel sortprel = new SortPrel(this.getCluster(), traits, children.get(0), collationTrait);\n+    RexNode offset = this.getCluster().getRexBuilder().makeExactLiteral(BigDecimal.valueOf(0),\n+            this.getCluster().getTypeFactory().createSqlType(SqlTypeName.INTEGER));\n+    RexNode limit = this.getCluster().getRexBuilder().makeExactLiteral(BigDecimal.valueOf(this.limit),\n+            this.getCluster().getTypeFactory().createSqlType(SqlTypeName.INTEGER));\n+    LimitPrel limitPrel = new LimitPrel(this.getCluster(), traits, sortprel, offset, limit, false);\n \n Review comment:\n   Yes Limit created should be partition limit but it is not created here because that API is not yet available in the master. Once it is available it will be rebased upon it.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568587",
                "body": "HanumathRao commented on issue #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417#issuecomment-410338434\n \n \n   Thank you @gparai and @sohami  for the review. I have made the changes.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16568972",
                "body": "ilooner closed pull request #1417: DRILL-6645: Transform TopN in Lateral Unnest pipeline to Sort and Limit.\nURL: https://github.com/apache/drill/pull/1417\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/AggPrelBase.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/AggPrelBase.java\nindex a4f51f315eb..ca68a7d1a44 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/AggPrelBase.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/AggPrelBase.java\n@@ -189,7 +189,7 @@ public boolean needsFinalColumnReordering() {\n   }\n \n   @Override\n-  public Prel addImplicitRowIDCol(List<RelNode> children) {\n+  public Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     List<Integer> groupingCols = Lists.newArrayList();\n     groupingCols.add(0);\n     for (int groupingCol : groupSet.asList()) {\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/FilterPrel.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/FilterPrel.java\nindex 1c9112c5673..33c29448432 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/FilterPrel.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/FilterPrel.java\n@@ -85,7 +85,7 @@ public boolean needsFinalColumnReordering() {\n   }\n \n   @Override\n-  public Prel addImplicitRowIDCol(List<RelNode> children) {\n+  public Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     RexBuilder builder = this.getCluster().getRexBuilder();\n     // right shift the previous field indices.\n     return (Prel) this.copy(this.traitSet, children.get(0), DrillRelOptUtil.transformExpr(builder,\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/LimitPrel.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/LimitPrel.java\nindex 057cfaed2c4..ccbff17f86a 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/LimitPrel.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/LimitPrel.java\n@@ -111,7 +111,7 @@ public boolean needsFinalColumnReordering() {\n   }\n \n   @Override\n-  public Prel addImplicitRowIDCol(List<RelNode> children) {\n+  public Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     return new LimitPrel(this.getCluster(), this.traitSet, children.get(0), getOffset(), getFetch(), isPushDown(), true);\n   }\n }\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/Prel.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/Prel.java\nindex b72aff70b9c..01d8e9c33be 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/Prel.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/Prel.java\n@@ -56,7 +56,13 @@ public boolean useAbstractConvertersForConversion(RelTraitSet fromTraits,\n   SelectionVectorMode getEncoding();\n   boolean needsFinalColumnReordering();\n \n-  default Prel addImplicitRowIDCol(List<RelNode> children) {\n+  /**\n+   * If the operator is in Lateral/Unnest pipeline, then it generates a new operator which knows how to process\n+   * the rows accordingly during execution.\n+   * eg: TopNPrel -> SortPrel and LimitPrel\n+   * Other operators like FilterPrel, ProjectPrel etc will add an implicit row id to the output.\n+   */\n+  default Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     throw new UnsupportedOperationException(\"Adding Implicit RowID column is not supported for \" +\n             this.getClass().getSimpleName() + \" operator \");\n   }\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/ProjectPrel.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/ProjectPrel.java\nindex 0a9e8bf1aeb..4d5de20d583 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/ProjectPrel.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/ProjectPrel.java\n@@ -136,7 +136,7 @@ public boolean needsFinalColumnReordering() {\n   }\n \n   @Override\n-  public Prel addImplicitRowIDCol(List<RelNode> children) {\n+  public Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     RelDataTypeFactory typeFactory = this.getCluster().getTypeFactory();\n     RexBuilder builder = this.getCluster().getRexBuilder();\n     List<RexNode> projects = Lists.newArrayList();\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/SelectionVectorRemoverPrel.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/SelectionVectorRemoverPrel.java\nindex a4cd9211d0c..3fad0172842 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/SelectionVectorRemoverPrel.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/SelectionVectorRemoverPrel.java\n@@ -55,7 +55,7 @@ public SelectionVectorMode getEncoding() {\n   }\n \n   @Override\n-  public Prel addImplicitRowIDCol(List<RelNode> children) {\n+  public Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     return (Prel) this.copy(this.traitSet, children);\n   }\n }\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/SortPrel.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/SortPrel.java\nindex 686e04a4031..aa7158a683d 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/SortPrel.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/SortPrel.java\n@@ -124,7 +124,7 @@ public boolean needsFinalColumnReordering() {\n   }\n \n   @Override\n-  public Prel addImplicitRowIDCol(List<RelNode> children) {\n+  public Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     List<RelFieldCollation> relFieldCollations = Lists.newArrayList();\n     relFieldCollations.add(new RelFieldCollation(0,\n                             RelFieldCollation.Direction.ASCENDING, RelFieldCollation.NullDirection.FIRST));\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java\nindex 9bdcad06b9d..3e407f74678 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/TopNPrel.java\n@@ -18,11 +18,14 @@\n package org.apache.drill.exec.planner.physical;\n \n import java.io.IOException;\n+import java.math.BigDecimal;\n import java.util.List;\n \n import com.google.common.collect.Lists;\n import org.apache.calcite.rel.RelCollationImpl;\n import org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.calcite.rex.RexNode;\n+import org.apache.calcite.sql.type.SqlTypeName;\n import org.apache.drill.exec.physical.base.PhysicalOperator;\n import org.apache.drill.exec.physical.config.TopN;\n import org.apache.drill.exec.planner.cost.DrillCostBase;\n@@ -101,7 +104,7 @@ public SelectionVectorMode getEncoding() {\n   }\n \n   @Override\n-  public Prel addImplicitRowIDCol(List<RelNode> children) {\n+  public Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     List<RelFieldCollation> relFieldCollations = Lists.newArrayList();\n     relFieldCollations.add(new RelFieldCollation(0,\n                           RelFieldCollation.Direction.ASCENDING, RelFieldCollation.NullDirection.FIRST));\n@@ -115,6 +118,17 @@ public Prel addImplicitRowIDCol(List<RelNode> children) {\n                                     .replace(this.getTraitSet().getTrait(DrillDistributionTraitDef.INSTANCE))\n                                     .replace(collationTrait)\n                                     .replace(DRILL_PHYSICAL);\n-    return (Prel) this.copy(traits, children);\n+    return transformTopNToSortAndLimit(children, traits, collationTrait);\n+  }\n+\n+  private Prel transformTopNToSortAndLimit(List<RelNode> children, RelTraitSet traits, RelCollation collationTrait) {\n+    SortPrel sortprel = new SortPrel(this.getCluster(), traits, children.get(0), collationTrait);\n+    RexNode offset = this.getCluster().getRexBuilder().makeExactLiteral(BigDecimal.valueOf(0),\n+            this.getCluster().getTypeFactory().createSqlType(SqlTypeName.INTEGER));\n+    RexNode limit = this.getCluster().getRexBuilder().makeExactLiteral(BigDecimal.valueOf(this.limit),\n+            this.getCluster().getTypeFactory().createSqlType(SqlTypeName.INTEGER));\n+    //SMEX is not needed here because Lateral/Unnest pipeline doesn't support exchanges.\n+    LimitPrel limitPrel = new LimitPrel(this.getCluster(), traits, sortprel, offset, limit, false, true);\n+    return limitPrel;\n   }\n }\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/UnnestPrel.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/UnnestPrel.java\nindex 23311383242..274f27a2e0b 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/UnnestPrel.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/UnnestPrel.java\n@@ -86,7 +86,7 @@ public boolean needsFinalColumnReordering() {\n   }\n \n   @Override\n-  public Prel addImplicitRowIDCol(List<RelNode> children) {\n+  public Prel prepareForLateralUnnestPipeline(List<RelNode> children) {\n     RelDataTypeFactory typeFactory = this.getCluster().getTypeFactory();\n     List<String> fieldNames = new ArrayList<>();\n     List<RelDataType> fieldTypes = new ArrayList<>();\ndiff --git a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/visitor/LateralUnnestRowIDVisitor.java b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/visitor/LateralUnnestRowIDVisitor.java\nindex 469220252eb..dc4af5b08ff 100644\n--- a/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/visitor/LateralUnnestRowIDVisitor.java\n+++ b/exec/java-exec/src/main/java/org/apache/drill/exec/planner/physical/visitor/LateralUnnestRowIDVisitor.java\n@@ -43,7 +43,7 @@ public static Prel insertRowID(Prel prel){\n   public Prel visitPrel(Prel prel, Boolean isRightOfLateral) throws RuntimeException {\n     List<RelNode> children = getChildren(prel, isRightOfLateral);\n     if (isRightOfLateral) {\n-      return prel.addImplicitRowIDCol(children);\n+      return prel.prepareForLateralUnnestPipeline(children);\n     } else {\n       return (Prel) prel.copy(prel.getTraitSet(), children);\n     }\n@@ -61,7 +61,7 @@ public Prel visitPrel(Prel prel, Boolean isRightOfLateral) throws RuntimeExcepti\n   @Override\n   public Prel visitLateral(LateralJoinPrel prel, Boolean value) throws RuntimeException {\n     List<RelNode> children = Lists.newArrayList();\n-    children.add(((Prel)prel.getInput(0)).accept(this, false));\n+    children.add(((Prel)prel.getInput(0)).accept(this, value));\n     children.add(((Prel) prel.getInput(1)).accept(this, true));\n \n     return (Prel) prel.copy(prel.getTraitSet(), children);\n@@ -69,6 +69,6 @@ public Prel visitLateral(LateralJoinPrel prel, Boolean value) throws RuntimeExce\n \n   @Override\n   public Prel visitUnnest(UnnestPrel prel, Boolean value) throws RuntimeException {\n-    return prel.addImplicitRowIDCol(null);\n+    return prel.prepareForLateralUnnestPipeline(null);\n   }\n }\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5fc52f4d395ee2220227f",
        "key": "IGNITE-1965",
        "id": "12914786",
        "description": "*Problem*\nUser tries to get a field from an object. If field is an object, we return IBinaryObject which is correct. If field is enum we always try to deserialize it which is wrong because there could be no matching type in runtime.\n\n*Proposed solution*\n1) Introduce \"BinaryEnum\" class with the following methods:\n- int TypeId() - get type ID\n- int Ordinal() - get ordinal\n- T deserialize() - deserialize using type ID -> class lookup.\n- T deserialize(Type) - deserialize using provided Type. If (typeId != -1 && typeid(Type) != typeId), throw an exception.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.007969490252435207
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.256435751914978
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004746249411255121
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "15022033",
                "body": "GitHub user ptupitsyn opened a pull request:\n\n    https://github.com/apache/ignite/pull/254\n\n    IGNITE-1965 .NET: Introduce wrapper for enums, similar to \"IBinaryObject\".\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/ptupitsyn/ignite ignite-1965\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/ignite/pull/254.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #254\n    \n----\ncommit 55a6bf25d0a5f48e0b9b571f3e16a8d7cac8cb69\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T12:44:11Z\n\n    IGNITE-1964 .NET: Write enum type ID if possible.\n\ncommit 18353b540dabad20fea88dbef60f13f0281334e5\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T13:18:50Z\n\n    wip tests\n\ncommit 12dd21846034c29a01037c4aa1ef3d927443bcfb\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T13:23:18Z\n\n    wip tests\n\ncommit a962331c210511454f8c6e739e9a6e4cdbf52963\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T13:30:25Z\n\n    Test created\n\ncommit 43839176408021519616929af81c323e094953b0\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T13:41:20Z\n\n    Merge remote-tracking branch 'remotes/upstream/ignite-1282' into ignite-1964\n\ncommit bae0304659dda4fe98ec141394ba1affd45ab95e\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T13:54:12Z\n\n    Fix test\n\ncommit 04fa262089e825fbb1831088b30e85fc6692ced8\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T14:02:47Z\n\n    Cleanup\n\ncommit 6cba694b13326cc4ad84a42bf7c68425cd49c261\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T14:56:06Z\n\n    IGNITE-1965 .NET: Introduce wrapper for enums, similar to \"IBinaryObject\".\n\ncommit 20be963f4efdd9e6b9c840fc2a9b41d13634164f\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T15:13:40Z\n\n    refactor system type logic\n\ncommit 6f2184daf666bedb0a56d8347ebf5858f432bd7c\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T15:53:22Z\n\n    IGNITE-1965 .NET: Introduce wrapper for enums, similar to \"IBinaryObject\".\n\ncommit 49d134d40a91839d95cd3fcb9c5b8e76cf60483d\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T15:59:21Z\n\n    Fix tests\n\ncommit ec00ba4ed6fa57ed54007bf1b3614978c6bef241\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T16:07:30Z\n\n    wip\n\ncommit 3ec8c668116203959777e2d95fc556a84bda7ad1\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T16:15:41Z\n\n    wip\n\ncommit 3363fbb0fe5f93789fe51a0d1db560f7329627bc\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T16:27:23Z\n\n    wip\n\ncommit 005a7a2d11eea1e62f49d0b90b4b127f2142ca46\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T17:04:19Z\n\n    wip broken test\n\ncommit 1446c994e3a3dc29bde12bd560d4631243d605d5\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T17:06:52Z\n\n    wip\n\ncommit ddaa253b099616c6f321db94c59ce5f18efd1cd2\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T17:27:58Z\n\n    Fix enum arrays\n\ncommit e6adb9cab99290019648776807874642fab3140c\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T17:37:00Z\n\n    Fix tests\n\ncommit 4fce68ade828aad107ddab330e7efc7620762f05\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-20T17:38:07Z\n\n    Merge branch 'ignite-1964' into ignite-1965\n\ncommit f559a331d646680a662c33966dda62aedcda7380\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T07:11:12Z\n\n    Merge remote-tracking branch 'remotes/upstream/ignite-1282' into ignite-1965\n\ncommit 71d7a36856e1af13f9053c60a2bf824e6777015b\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T08:49:26Z\n\n    wip IBinaryEnum\n\ncommit 1116501ddebf8ba5c1142b6c18b10112267f3834\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T09:07:03Z\n\n    Merge remote-tracking branch 'remotes/upstream/ignite-1.5' into ignite-1965\n\ncommit b6d502cc93fff89f8ac480ac374cf1a469113a22\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T09:39:47Z\n\n    Impl done\n\ncommit 8302b2ca1da9a80974669c6efeaa7ff4d5728a59\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T09:41:48Z\n\n    Fixing tests\n\ncommit e560fd20c154ad57a68e613dfd5c7f3069ae9592\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T09:57:14Z\n\n    wip tests\n\ncommit bd2393d78cf932a5d4907bd5b30d6fbe698f4c35\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T10:07:17Z\n\n    Wip tests\n\ncommit a98be04c8ea2c167c6d4b6975e2971962fd848a5\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T10:10:14Z\n\n    wip\n\ncommit 00f8df99339d4df1d1bd04b4c197e5af8879b6a9\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T11:30:10Z\n\n    wip\n\ncommit b7f012b72ae2abce69bc1c4e20015f54226da9f3\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T11:33:03Z\n\n    wip tests\n\ncommit 7349071d3e059b9009cf30713f203abba5e133c8\nAuthor: Pavel Tupitsyn <ptupitsyn@gridgain.com>\nDate:   2015-11-23T11:42:42Z\n\n    Broken composite array test\n\n----\n"
            },
            {
                "author_name": "vozerov",
                "id": "15028348",
                "body": "In general looks goods, but some changes to public API is needed:\n1) Remove IBinaryObject.isEnum - no need to have it in two places\n2) Let's move IBinaryObject.typeId() to IBinaryType (this will be done in Java as well)."
            },
            {
                "author_name": "ptupitsyn",
                "id": "15028487",
                "body": "Done, + IIgniteBinary renamed to IBinary"
            },
            {
                "author_name": "vozerov",
                "id": "15028521",
                "body": "Pavel,\n\nOne more problem - exception thrown from GetField() method. When we use reflection and try to get missing field, we have identical behavior for both classes, structs and enums. We must have identical behavior in binaries as well.\n\nFor now binaries return null in case field is missing. And to check whether field is really null, or not present in binary at all, user has method \"BinaryObject.hasFIeld()\" in Java. For some reason there is no such method in .NET. Let's do the following:\n1) Add \"IBinaryObject.HasField()\" method (must be trivial to implement)\n2) In enums \"GetField\" always return \"default(T)\" and \"HasField\" always return \"false\". \n\n"
            },
            {
                "author_name": "ptupitsyn",
                "id": "15028655",
                "body": "Done, tests updated"
            },
            {
                "author_name": "vozerov",
                "id": "15028814",
                "body": "Merged to IGNITE-1956."
            },
            {
                "author_name": "githubbot",
                "id": "15409105",
                "body": "Github user ptupitsyn closed the pull request at:\n\n    https://github.com/apache/ignite/pull/254\n"
            }
        ],
        "comments_predictions": [
            [
                1860496,
                "IGNITE-1965",
                "In general looks goods, but some changes to public API is needed:\n1) Remove IBinaryObject.isEnum - no need to have it in two places\n2) Let's move IBinaryObject.typeId() to IBinaryType (this will be done in Java as well).",
                {
                    "property": {
                        "confidence": 0.0058096833527088165,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006024201400578022,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01359388418495655,
                        "prediction": false
                    }
                }
            ],
            [
                1860498,
                "IGNITE-1965",
                "Pavel,\n\nOne more problem - exception thrown from GetField() method. When we use reflection and try to get missing field, we have identical behavior for both classes, structs and enums. We must have identical behavior in binaries as well.\n\nFor now binaries return null in case field is missing. And to check whether field is really null, or not present in binary at all, user has method \"BinaryObject.hasFIeld()\" in Java. For some reason there is no such method in .NET. Let's do the following:\n1) Add \"IBinaryObject.HasField()\" method (must be trivial to implement)\n2) In enums \"GetField\" always return \"default(T)\" and \"HasField\" always return \"false\". \n\n",
                {
                    "property": {
                        "confidence": 0.005803809035569429,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005325613543391228,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.022045576944947243,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "64074492016d21d91d33b601",
        "key": "SPARK-37484",
        "id": "13414277",
        "description": "There are some combined calls of get and getOrElse that can be directly replaced by getOrElse\r\n\r\n\u00a0",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d626a4f4d395ee2225daa7",
        "key": "BATIK-492",
        "id": "12619849",
        "description": "There seems to be a bug in the UpdateManager suspend() and resume()\nmethods in Batik 1.5.1.\n\nThe bug is that a thread can invoke and return from both suspend()\nand resume() before the suspension has even taken effect, and then\nthe resume() seems to get lost.\n\nE.g., my code looks like this:\n\n        System.out.println(\"SUSPENDING\");\n        um.suspend();\n\n        .. do some stuff ..\n\n        System.out.println(\"RESUMING\");\n        um.resume();\n\nI also have an UpdateManagerListener which prints the events.\nThe output when it works correctly is:\n\n        SUSPENDING\n        listener: update manager was suspended\n        RESUMING\n        listener: update manager was resumed\n\nThe output when it fails is:\n\n        SUSPENDING\n        RESUMING\n        listener: update manager was suspended\n\n..and then no updates until further notice!",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008230798877775669
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0156478863209486
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005132508929818869
                }
            }
        },
        "comments": [
            {
                "author_name": "deweese@apache.org",
                "id": "13512845",
                "body": "Without a standalone reproducable test case there isn't\nmuch I can do with this bug report.\n"
            },
            {
                "author_name": "archie",
                "id": "13512846",
                "body": "The problem is clear by looking at the code...\n\n    /**\n     * Suspends the update manager.\n     */\n    public synchronized void suspend() {\n        if (running) {\n            suspendCalled = true;\n            updateRunnableQueue.suspendExecution(false);\n        }\n    }\n\nNote the \"false\", which means \"don't wait for the suspension\nto actually take effect\".\n\nWhat would be helpful is if there was a version of suspend()\nthat took a boolean parameter, which was passed on to the\nsuspendExecution() invocation.\n\nAlso, the existing no-arg version should be documented to\nnote that it doesn't wait by default.\n\nSo this is not really a code bug I guess, just a lack of clarity\nin the API doc which tripped me up.\n\nAs a workaround I'll try listening for the notification that\nthe update manager has been suspended before proceeding.\n\n"
            },
            {
                "author_name": "deweese@apache.org",
                "id": "13512847",
                "body": "Actually, I still consider this a bug.\nThe interface should ensure that if you call suspend then resume\nthings will eventually resume.\n\nSo can you still provide a test case?"
            },
            {
                "author_name": "archie",
                "id": "13512848",
                "body": "I don't have a test case handy and unfortunately it will take me a while to\ncreate one because of work overload at the moment.\n\nHowever, if you look at the code for UpdateManager.suspend() and\nRunnableQueue.suspendExecution() (~35 lines total) it's obvious\nwhat's going on:\n\n1. RunnableQueue.suspendExecution() returns immediately\n   because UpdateManager.suspend() invokes it with waitTillSuspended=false.\n\n2. UpdateManager.resume(), does nothing unless UpdateManager.running\n   is false. But it won't immediately be false because\n   UpdateManager.UpdateManagerRunHander.executionSuspended(), which\n   is the listener notification method that sets running to false,\n   hasn't had time to be invoked yet (because the suspension hasn't\n   actually happened yet).\n\nPerhaps the fix is for UpdateManager.resume() to check for the\npredicate \"suspendCalled && running\", and if so, invoke\nupdateRunnableQueue.resumeExecution().. ?\n\n"
            },
            {
                "author_name": "deweese@apache.org",
                "id": "13512849",
                "body": "I believe this bug is fixed in CVS on Feb 20.\nPlease reopen if you dissagree."
            }
        ],
        "comments_predictions": [
            [
                3674417,
                "BATIK-492",
                "The problem is clear by looking at the code...\n\n    /**\n     * Suspends the update manager.\n     */\n    public synchronized void suspend() {\n        if (running) {\n            suspendCalled = true;\n            updateRunnableQueue.suspendExecution(false);\n        }\n    }\n\nNote the \"false\", which means \"don't wait for the suspension\nto actually take effect\".\n\nWhat would be helpful is if there was a version of suspend()\nthat took a boolean parameter, which was passed on to the\nsuspendExecution() invocation.\n\nAlso, the existing no-arg version should be documented to\nnote that it doesn't wait by default.\n\nSo this is not really a code bug I guess, just a lack of clarity\nin the API doc which tripped me up.\n\nAs a workaround I'll try listening for the notification that\nthe update manager has been suspended before proceeding.\n\n",
                {
                    "property": {
                        "confidence": 0.00529691344127059,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005759187508374453,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.015723761171102524,
                        "prediction": false
                    }
                }
            ],
            [
                3674419,
                "BATIK-492",
                "I don't have a test case handy and unfortunately it will take me a while to\ncreate one because of work overload at the moment.\n\nHowever, if you look at the code for UpdateManager.suspend() and\nRunnableQueue.suspendExecution() (~35 lines total) it's obvious\nwhat's going on:\n\n1. RunnableQueue.suspendExecution() returns immediately\n   because UpdateManager.suspend() invokes it with waitTillSuspended=false.\n\n2. UpdateManager.resume(), does nothing unless UpdateManager.running\n   is false. But it won't immediately be false because\n   UpdateManager.UpdateManagerRunHander.executionSuspended(), which\n   is the listener notification method that sets running to false,\n   hasn't had time to be invoked yet (because the suspension hasn't\n   actually happened yet).\n\nPerhaps the fix is for UpdateManager.resume() to check for the\npredicate \"suspendCalled && running\", and if so, invoke\nupdateRunnableQueue.resumeExecution().. ?\n\n",
                {
                    "property": {
                        "confidence": 0.005613239947706461,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004998215474188328,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.020759141072630882,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "6407542f7b28a75d8967f660",
        "key": "INFRA-5144",
        "id": "12603549",
        "description": "As discussed on the ooo-dev mailing list at http://s.apache.org/EEb please redirect the following entire subdomains (currently unused; the first and second are actually the same subdomain, with two different protocols):\n\nhttps://registration2.services.openoffice.org/\nhttp://registration2.services.openoffice.org/\nhttp://survey.services.openoffice.org/\n\nto\n\nhttp://www.openoffice.org/legacy/thankyou.html",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d621b4f4d395ee22254636",
        "key": "CAMEL-9385",
        "id": "12917538",
        "description": "As a part of the the IoT project I'm working on, I have created a Spark component (1) to make it easier to handle analytics requests from devices. I would like to donate this code to the ASF Camel and extend it here, as I guess that there would be many people interested in using Spark from Camel.\n\nThe URI looks like {{spark:rdd/rddName/rddCallback}} or {{spark:dataframe/frameName/frameCallback}} depending if you would like to work with RDDs or DataFrames.\n\nThe idea here is that Camel route acts as a driver application. You specify RDD/DataFrames definitions (and callbacks to act against those) in a registry (for example as Spring beans or OSGi services). Then you send a parameters for the computations as a body of a message.\n\nFor example in Spring Boot you specify RDD+callback as:\n\n{code}\n@Bean\nJavaRDD myRdd(SparkContext sparkContext) {\n  return sparkContext.textFile(\"foo.txt\");\n}\n\n@Bean\nclass MyAnalytics {\n\n  @RddCallback\n  long countLines(JavaRDD<String> textFile, long argument) {\n     return rdd.count() * argument;\n  }\n\n}\n{code}\n\nThen you ask for the results of computations:\n\n{code}\nlong results = producerTemplate.requestBody(\"spark:rdd/myRdd/MyAnalytics\", 10, long.class);\n{code}\n\nSuch setup is extremely useful for bridging Spark computations via different transports.\n\n(1) https://github.com/rhiot/rhiot/tree/master/components/camel-spark",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.8729262948036194
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.4317377209663391
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.03368205204606056
                }
            }
        },
        "comments": [
            {
                "author_name": "hekonsek",
                "id": "15041422",
                "body": "Initial version committed in b46392c25bd517cbb7d04e6dd7611d1634378a13."
            },
            {
                "author_name": "davsclaus",
                "id": "15042774",
                "body": "You should add component doc to this, so we have all of them documented. Currently its all empty."
            },
            {
                "author_name": "hekonsek",
                "id": "15044565",
                "body": "Will do. I'm working now on documentation page for component, so I will add annotations docs as well."
            },
            {
                "author_name": "hekonsek",
                "id": "15060877",
                "body": "Done."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d616c0f4d395ee2223b9b1",
        "key": "DOXIASITETOOLS-149",
        "id": "12937341",
        "description": "currently, a skin is a jar containing at least {{META-INF/maven/site.vm}}, which is the Velocity template file\n\nadding a skin descriptor (as XML with Modello, to be consistent with Maven style) would permit meta-data definition.\nThe first case I see is Doxia Site Tools prerequisites, to have a skin make clear that it requires a newer version of Doxia Site Tools (which is a dependency of maven-site-plugin = what end-users see): this would permit newer Doxia Site Tools versions to provide new features for skins (like DOXIASITETOOLS-150) and skins using these features without fearing failing because being used in older maven-site-plugin versions\n\nthis would also create a new \"skin-model\" module that would give us a natural place to document practices around skins",
        "predictions": {},
        "comments": [
            {
                "author_name": "hboutemy",
                "id": "15136186",
                "body": "notice that in future versions, a skin could contain java code made accessible to the template, to ease extensions without writing everything as Velocity VTL language\nnot for the next release, since this will require serious work (with classloading, dependencies loading...), but this descriptor prepares the future improvements"
            },
            {
                "author_name": "hudson",
                "id": "15136535",
                "body": "SUCCESS: Integrated in doxia-all #242 (See [https://builds.apache.org/job/doxia-all/242/])\n[DOXIASITETOOLS-149] created a skin descriptor to contain meta-data about the skin (hboutemy: [http://svn.apache.org/viewvc/?view=rev&rev=1729055])\n* ./doxia-sitetools/doxia-site-renderer/pom.xml\n* ./doxia-sitetools/doxia-site-renderer/src/main/java/org/apache/maven/doxia/siterenderer/DefaultSiteRenderer.java\n* ./doxia-sitetools/doxia-site-renderer/src/main/java/org/apache/maven/doxia/siterenderer/Renderer.java\n* ./doxia-sitetools/doxia-site-renderer/src/main/java/org/apache/maven/doxia/siterenderer/SiteRenderingContext.java\n* ./doxia-sitetools/doxia-site-renderer/src/site/apt/index.apt.vm\n* ./doxia-sitetools/doxia-site-renderer/src/test/java/org/apache/maven/doxia/siterenderer/DefaultSiteRendererTest.java\n* ./doxia-sitetools/doxia-skin-model\n* ./doxia-sitetools/doxia-skin-model/pom.xml\n* ./doxia-sitetools/doxia-skin-model/src\n* ./doxia-sitetools/doxia-skin-model/src/main\n* ./doxia-sitetools/doxia-skin-model/src/main/mdo\n* ./doxia-sitetools/doxia-skin-model/src/main/mdo/skin.mdo\n* ./doxia-sitetools/doxia-skin-model/src/site\n* ./doxia-sitetools/doxia-skin-model/src/site/apt\n* ./doxia-sitetools/doxia-skin-model/src/site/apt/index.apt\n* ./doxia-sitetools/doxia-skin-model/src/site/site.xml\n* ./doxia-sitetools/pom.xml\n* ./doxia-sitetools/src/site/resources/images/doxia-sitetools-deps.png\n* ./doxia-sitetools/src/site/xdoc/doxia-sitetools-deps.odg\n* ./doxia-sitetools/src/site/xdoc/index.xml\n"
            },
            {
                "author_name": "hudson",
                "id": "15136537",
                "body": "SUCCESS: Integrated in maven-plugins #5068 (See [https://builds.apache.org/job/maven-plugins/5068/])\n[DOXIASITETOOLS-149] updated code for new exception thrown (hboutemy: [http://svn.apache.org/viewvc/?view=rev&rev=1729058])\n* maven-site-plugin/src/main/java/org/apache/maven/plugins/site/render/AbstractSiteRenderingMojo.java\n"
            },
            {
                "author_name": "michael-o",
                "id": "15136763",
                "body": "Not bad at all. {{<field xml.tagName=\"doxia-site-tools\">}}: note that the official name is Doxia Sitetools, so I would rather see {{<field xml.tagName=\"doxia-sitetools\">}}. Do you mind if I would change all resources accordingly?"
            },
            {
                "author_name": "hboutemy",
                "id": "15137453",
                "body": "happy you like it :)\nI'll probably add more data later, like source encoding, for example\n\n+1 to rename {{doxia-site-tools}} to {{doxia-sitetools}} (and review docs, please)"
            },
            {
                "author_name": "michael-o",
                "id": "15137475",
                "body": "Source encoding can automatically derived from the input property. Wouldn't that be enough?"
            },
            {
                "author_name": "hboutemy",
                "id": "15137515",
                "body": "input property of the skin project, yes, but not from the project using the skin\nand if we auto-detect while building the skin artifact, that will mean generating skin.xml: too complex IMHO"
            },
            {
                "author_name": "michael-o",
                "id": "15137541",
                "body": "Yes, I was referring to the skin project of course. So you want to rely on the input of the user in that case? Would you create an IT for this? Would make it easier to test.\nAlternatively, we could add a manifest entry with the source encoding of resources."
            },
            {
                "author_name": "michael-o",
                "id": "15137658",
                "body": "Updated with [r1729249|http://svn.apache.org/r1729249]."
            },
            {
                "author_name": "michael-o",
                "id": "15137661",
                "body": "Is there any reason why you have supplied {{<firstVersion>1.0.0</firstVersion>}} to Modello altough there was none? I am inclined to remove such false information."
            },
            {
                "author_name": "hudson",
                "id": "15137694",
                "body": "SUCCESS: Integrated in doxia-all #243 (See [https://builds.apache.org/job/doxia-all/243/])\n[DOXIASITETOOLS-149] Create a skin descriptor to contain metadata about the skin\n\nCorrect spelling of Doxia Sitetools throughout. (michaelo: [http://svn.apache.org/viewvc/?view=rev&rev=1729249])\n* ./doxia-sitetools/doxia-site-renderer/src/main/java/org/apache/maven/doxia/siterenderer/DefaultSiteRenderer.java\n* ./doxia-sitetools/doxia-skin-model/pom.xml\n* ./doxia-sitetools/doxia-skin-model/src/main/mdo/skin.mdo\n* ./doxia-sitetools/doxia-skin-model/src/site/apt/index.apt\n"
            },
            {
                "author_name": "michael-o",
                "id": "15137763",
                "body": "Just added the descriptor to the Default Skin."
            },
            {
                "author_name": "hboutemy",
                "id": "15137820",
                "body": "no, just copy/paste :)"
            },
            {
                "author_name": "hboutemy",
                "id": "15137824",
                "body": "in fact, the Default Skin is not a default skin, IMHO: nobody uses it, the default skin is the default template in doxia-site-renderer"
            },
            {
                "author_name": "michael-o",
                "id": "15137872",
                "body": "OK, I will remove it."
            },
            {
                "author_name": "michael-o",
                "id": "15137873",
                "body": "Reopening, need to remove {{<firstVersion>1.0.0</firstVersion>}}, etc."
            },
            {
                "author_name": "michael-o",
                "id": "15137888",
                "body": "And that is probably something we need to improve. I haven't found a compelling reason why it shouldn't be in the skin directly. I just added it to comply with the rest."
            },
            {
                "author_name": "hudson",
                "id": "15139909",
                "body": "SUCCESS: Integrated in doxia-all #249 (See [https://builds.apache.org/job/doxia-all/249/])\n[DOXIASITETOOLS-149] first version is 1.7.0 (hboutemy: [http://svn.apache.org/viewvc/?view=rev&rev=1729489])\n* ./doxia-sitetools/doxia-skin-model/pom.xml\n"
            },
            {
                "author_name": "michael-o",
                "id": "15139911",
                "body": "Version upated in [r1729489|http://svn.apache.org/r1729489]."
            }
        ],
        "comments_predictions": [
            [
                3154181,
                "DOXIASITETOOLS-149",
                "notice that in future versions, a skin could contain java code made accessible to the template, to ease extensions without writing everything as Velocity VTL language\nnot for the next release, since this will require serious work (with classloading, dependencies loading...), but this descriptor prepares the future improvements",
                {
                    "property": {
                        "confidence": 0.009303065948188305,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.4885019063949585,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011241829954087734,
                        "prediction": false
                    }
                }
            ],
            [
                3154184,
                "DOXIASITETOOLS-149",
                "Not bad at all. {{<field xml.tagName=\"doxia-site-tools\">}}: note that the official name is Doxia Sitetools, so I would rather see {{<field xml.tagName=\"doxia-sitetools\">}}. Do you mind if I would change all resources accordingly?",
                {
                    "property": {
                        "confidence": 0.003880526404827833,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.019659588113427162,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008441786281764507,
                        "prediction": false
                    }
                }
            ],
            [
                3154188,
                "DOXIASITETOOLS-149",
                "Yes, I was referring to the skin project of course. So you want to rely on the input of the user in that case? Would you create an IT for this? Would make it easier to test.\nAlternatively, we could add a manifest entry with the source encoding of resources.",
                {
                    "property": {
                        "confidence": 0.004224168136715889,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006099790800362825,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02829919569194317,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640743eec8b42db502d2b51c",
        "key": "ATLAS-3700",
        "id": "13294566",
        "description": "*Details:*\r\n\r\n1) The model definition is in \"https://github.com/apache/atlas/blob/master/addons/models/4000-MachineLearning/4010-ml_model.json#L90\"\r\n\r\n2) I created a request of type EntityCreateRequestV2. It contains an entity of type ml_model_build with an attribute \"metadata\", which is a map, and contains key-value entries for \"engineImageTag\" and \"engineImageName\".\r\n\r\n3) Then I created a request of type EntityPartialUpdateRequestV2. It contains an entity of type ml_model_build with an attribute \"metadata\", which is a map, and contains key-value entry for \"updated_at\".\r\n\r\n4) In the properties of the entity ml_model_build, the * attribute \"*metadata\" only contains key-value entry for \"updated_at\".\r\n\r\n*Desired behavior:*\r\n\r\nThe attribute \"metadata\" should contains key-value entries for \"engineImageTag\", \"engineImageName\" and \"updated_at\".\r\n\r\nCurrent behavior:\r\n\r\nthe attribute \"metadata\" only contains key-value entry for \"updated_at\".\r\n\r\n\u00a0\r\n Added 'isAppendOnPartialUpdate' option in attribute-def, to enable appending of values to array/map type attributes during partial-update operation.\r\n\r\nExample:\r\n{code:java}\r\n{\r\n    \"name\":        \"metadata\",\r\n    \"typeName\":    \"map<string,string>\",\r\n    \"isIndexable\": false,\r\n    \"isOptional\":  true,\r\n    \"isUnique\":    false,\r\n    \"options\": {\r\n      \"isAppendOnPartialUpdate\": \"true\"\r\n    }\r\n  }{code}\r\n\u00a0\r\n\r\nThe value specified for this attribute in partial-update API calls will be appended to existing value - if present. Full-update API calls will overwrite the value of the attribute, as it does currently; there is no change in full-update behavior.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.007965544238686562
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.1005738377571106
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0034591867588460445
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d910f4d395ee2219f229",
        "key": "SUREFIRE-1948",
        "id": "13404422",
        "description": "I am getting \"Error in Forked Process\" with cause saying that one of the @test is depending on a method and the Method is not annotated with @test.\r\n\r\nMy testng.xml does not have the mentioned @test class at all and I am not sure why this @test is being picked up in first place.\r\n\r\nMy POM.XML\r\n\u00a0{{    <plugin>\r\n            <groupId>org.apache.maven.plugins</groupId>\r\n            <artifactId>maven-surefire-plugin</artifactId>\r\n            <version>3.0.0-M5</version>\r\n                \r\n            <executions>\r\n                <execution>\r\n                    <configuration>\r\n                        \r\n                        <skip>false</skip>\r\n                        <forkCount>2</forkCount>\r\n                        <argLine>-Xmx1024m -XX:MaxPermSize=256m</argLine>\r\n                        <maven.test.failure.ignore>false</maven.test.failure.ignore>\r\n                        <rerunFailingTestsCount>2</rerunFailingTestsCount>\r\n                        <suiteXmlFiles>\r\n                            <suiteXmlFile>testng.xml</suiteXmlFile>\r\n                        </suiteXmlFiles>\r\n                    </configuration>\r\n                </execution>\r\n            </executions>\r\n        </plugin>}}\r\nJunit & testNG versions :\r\n\u00a0{{<dependency>\r\n            <groupId>junit</groupId>\r\n            <artifactId>junit</artifactId>\r\n            <version>4.13.2</version>\r\n            <scope>test</scope>\r\n        </dependency>\r\n\r\n<dependency>\r\n            <groupId>org.testng</groupId>\r\n            <artifactId>testng</artifactId>\r\n            <version>6.9.8</version>\r\n        </dependency>}}\r\nTestnG :\r\n\u00a0{{<suite name=\"StoresCentral_TestSuite_Param\" configfailurepolicy=\"continue\" verbose=\"10\" \r\nthreadcount=\"1\" parallel=\"none\"><test name=\"POC_tests_0\"><classes><class \r\nname=\"au.wow.ngbomain.tests.PracticeArtLookupTest\"></class></classes></test></suite>}}\r\nError :\r\n\r\n[ERROR] Please refer to C:\\Automation\\ForkErrorCheck\\s\\Test\\target\\surefire-reports for the individual test results. [ERROR] Please refer to dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream. [ERROR] There was an error in the forked process [ERROR] [ERROR] au.wow.ngbomain.tests.AdjustmentLogReportTests.pageValidation() is depending on method public void au.wow.ngbomain.tests.Sample.check() throws java.lang.Exception, which is not annotated with @Test or not included. [ERROR] org.testng.TestNGException:",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014481969177722931
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008528106845915318
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004194365348666906
                }
            }
        },
        "comments": [
            {
                "author_name": "sjaranowski",
                "id": "17461569",
                "body": "Can you prepare example project which show this issue, as attachment in zip or on github?"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d616c0f4d395ee2223b850",
        "key": "DRILL-210",
        "id": "12666988",
        "description": "0: jdbc:drill:schema=parquet-local> select count(1) from \"/tmp/tpc-h/supplier\";\n+---------+\n| EXPR$0  |\n+---------+\n| 15783   |\n+---------+\n1 row selected (0.577 seconds)\n\nThere should be 100,000 rows in this table",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012896073050796986
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008785330690443516
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005015640519559383
                }
            }
        },
        "comments": [
            {
                "author_name": "sphillips",
                "id": "13758724",
                "body": "From the logs, I can see that ParquetRecordReader is only reading 15783 records. So this appears to be a problem with the ParquetRecordReader."
            },
            {
                "author_name": "jnadeau",
                "id": "13759968",
                "body": "Fixed in fef2204"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d63154f4d395ee22276565",
        "key": "ACCUMULO-1415",
        "id": "12647396",
        "description": "We created a special SystemToken for the internal authentication mechanisms used by Accumulo. However, this token should be under the server project to prevent confusion of the end user.\n\nI think this should be done for 1.5, but I don't know how that fares with the release schedule going.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02830670401453972
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.09178917855024338
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.023919638246297836
                }
            }
        },
        "comments": [
            {
                "author_name": "ctubbsii",
                "id": "13656609",
                "body": "I agree, it should be done for 1.5.0, if the impact is small. If the impact is too large, keeping it out of the \"client\" packages should be sufficient for 1.5.0."
            },
            {
                "author_name": "vines",
                "id": "13657494",
                "body": "Nothing in the client should be using it. I tested it, worked fine, minimal code changes (i.e. just moving the source and creating the package in server)"
            },
            {
                "author_name": "hudson",
                "id": "13657531",
                "body": "Integrated in Accumulo-Trunk #869 (See [https://builds.apache.org/job/Accumulo-Trunk/869/])\n    ACCUMULO-1415 - SystemToken moving to server (Revision 1482580)\n\n     Result = UNSTABLE\nvines : \nFiles : \n* /accumulo/trunk\n* /accumulo/trunk/core\n* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/SystemToken.java\n* /accumulo/trunk/server\n* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/security\n"
            },
            {
                "author_name": "hudson",
                "id": "13657535",
                "body": "Integrated in Accumulo-Trunk-Hadoop-2.0 #227 (See [https://builds.apache.org/job/Accumulo-Trunk-Hadoop-2.0/227/])\n    ACCUMULO-1415 - SystemToken moving to server (Revision 1482580)\n\n     Result = SUCCESS\nvines : \nFiles : \n* /accumulo/trunk\n* /accumulo/trunk/core\n* /accumulo/trunk/core/src/main/java/org/apache/accumulo/core/client/security/tokens/SystemToken.java\n* /accumulo/trunk/server\n* /accumulo/trunk/server/src/main/java/org/apache/accumulo/server/client/security\n"
            },
            {
                "author_name": "hudson",
                "id": "13657653",
                "body": "Integrated in Accumulo-1.5-Hadoop-2.0 #117 (See [https://builds.apache.org/job/Accumulo-1.5-Hadoop-2.0/117/])\n    ACCUMULO-1415 - SystemToken moving to server (Revision 1482579)\n\n     Result = SUCCESS\nvines : \nFiles : \n* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/SystemToken.java\n* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security\n* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security/token\n* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security/token/SystemToken.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13657664",
                "body": "Integrated in Accumulo-1.5 #115 (See [https://builds.apache.org/job/Accumulo-1.5/115/])\n    ACCUMULO-1415 - SystemToken moving to server (Revision 1482579)\n\n     Result = SUCCESS\nvines : \nFiles : \n* /accumulo/branches/1.5/core/src/main/java/org/apache/accumulo/core/client/security/tokens/SystemToken.java\n* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security\n* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security/token\n* /accumulo/branches/1.5/server/src/main/java/org/apache/accumulo/server/client/security/token/SystemToken.java\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d615b4f4d395ee2223a2dc",
        "key": "DRILL-5718",
        "id": "13094261",
        "description": "Configurations\n{noformat}\nplanner.memory.max_query_memory_per_node: 17179869184 (16 GB)\nplanner.width.max_per_node: 48\nstore.parquet.block-size: 134217728 (128 MB, this is the block size used to create the parquet files)\n{noformat}\n\n{noformat}\nFragment 0:0\n\n[Error Id: 05c39a1e-c8a8-4147-870f-e0cdbb454e53 on iWebStitchFixDev:31010]\n[BitServer-4] INFO org.apache.drill.exec.work.fragment.FragmentExecutor - 267104f2-e48d-1d66-63f4-387848c1ccf2:1:10: State change requested RUNNING --> CANCELLATION_REQUESTED\norg.apache.drill.common.exceptions.UserException: SYSTEM ERROR: ChannelClosedException: Channel closed /127.0.0.1:31010 <--> /127.0.0.1:40404.\n\nFragment 0:0\n\n[Error Id: 05c39a1e-c8a8-4147-870f-e0cdbb454e53 on iWebStitchFixDev:31010]\n        at org.apache.drill.common.exceptions.UserException$Builder.build(UserException.java:550)\n        at org.apache.drill.exec.work.fragment.FragmentExecutor.sendFinalState(FragmentExecutor.java:295)\n        at org.apache.drill.exec.work.fragment.FragmentExecutor.cleanup(FragmentExecutor.java:160)\n        at org.apache.drill.exec.work.fragment.FragmentExecutor.run(FragmentExecutor.java:264)\n        at org.apache.drill.common.SelfCleaningRunnable.run(SelfCleaningRunnable.java:38)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.drill.exec.rpc.ChannelClosedException: Channel closed /127.0.0.1:31010 <--> /127.0.0.1:40404.\n        at org.apache.drill.exec.rpc.RpcBus$ChannelClosedHandler.operationComplete(RpcBus.java:164)\n        at org.apache.drill.exec.rpc.RpcBus$ChannelClosedHandler.operationComplete(RpcBus.java:144)\n        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680)\n        at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603)\n        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563)\n        at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:406)\n        at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:82)\n        at io.netty.channel.AbstractChannel$CloseFuture.setClosed(AbstractChannel.java:943)\n        at io.netty.channel.AbstractChannel$AbstractUnsafe.doClose0(AbstractChannel.java:592)\n        at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:584)\n        at io.netty.channel.DefaultChannelPipeline$HeadContext.close(DefaultChannelPipeline.java:1099)\n        at io.netty.channel.AbstractChannelHandlerContext.invokeClose(AbstractChannelHandlerContext.java:615)\n        at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:600)\n        at io.netty.channel.ChannelOutboundHandlerAdapter.close(ChannelOutboundHandlerAdapter.java:71)\n        at io.netty.channel.AbstractChannelHandlerContext.invokeClose(AbstractChannelHandlerContext.java:615)\n        at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:600)\n        at io.netty.channel.AbstractChannelHandlerContext.close(AbstractChannelHandlerContext.java:466)\n        at io.netty.handler.timeout.ReadTimeoutHandler.readTimedOut(ReadTimeoutHandler.java:187)\n        at org.apache.drill.exec.rpc.BasicServer$LoggingReadTimeoutHandler.readTimedOut(BasicServer.java:122)\n        at io.netty.handler.timeout.ReadTimeoutHandler$ReadTimeoutTask.run(ReadTimeoutHandler.java:212)\n        at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)\n        at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)\n        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:357)\n        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:357)\n        at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)\n        ... 1 more\nSuppressed: org.apache.drill.exec.rpc.RpcException: Failure sending message.\n                at org.apache.drill.exec.rpc.RpcBus.send(RpcBus.java:124)\n                at org.apache.drill.exec.rpc.user.UserServer$BitToUserConnection.sendData(UserServer.java:173)\n                at org.apache.drill.exec.ops.AccountingUserConnection.sendData(AccountingUserConnection.java:42)\n                at org.apache.drill.exec.physical.impl.ScreenCreator$ScreenRoot.innerNext(ScreenCreator.java:118)\n                at org.apache.drill.exec.physical.impl.BaseRootExec.next(BaseRootExec.java:95)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor$1.run(FragmentExecutor.java:234)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor$1.run(FragmentExecutor.java:227)\n                at java.security.AccessController.doPrivileged(Native Method)\n                at javax.security.auth.Subject.doAs(Subject.java:422)\n                at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor.run(FragmentExecutor.java:227)\n                at org.apache.drill.common.SelfCleaningRunnable.run(SelfCleaningRunnable.java:38)\n                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n                ... 1 more\n        Caused by: java.lang.IllegalArgumentException: Attempted to send a message when connection is no longer valid.\n                at com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)\n                at org.apache.drill.exec.rpc.RequestIdMap.createNewRpcListener(RequestIdMap.java:88)\n                at org.apache.drill.exec.rpc.AbstractRemoteConnection.createNewRpcListener(AbstractRemoteConnection.java:162)\n                at org.apache.drill.exec.rpc.RpcBus.send(RpcBus.java:117)\n                ... 14 more\n        Suppressed: java.lang.IllegalStateException: Memory was leaked by query. Memory leaked: (5259264)\nAllocator(op:0:0:0:Screen) 1000000/5259264/11538432/10000000000 (res/actual/peak/limit)\n\n                at org.apache.drill.exec.memory.BaseAllocator.close(BaseAllocator.java:521)\n                at org.apache.drill.exec.ops.AbstractOperatorExecContext.close(AbstractOperatorExecContext.java:86)\n                at org.apache.drill.exec.ops.OperatorContextImpl.close(OperatorContextImpl.java:108)\n                at org.apache.drill.exec.ops.FragmentContext.suppressingClose(FragmentContext.java:436)\n                at org.apache.drill.exec.ops.FragmentContext.close(FragmentContext.java:425)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor.closeOutResources(FragmentExecutor.java:320)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor.cleanup(FragmentExecutor.java:155)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor.run(FragmentExecutor.java:264)\n                at org.apache.drill.common.SelfCleaningRunnable.run(SelfCleaningRunnable.java:38)\n                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n                ... 1 more\n        Suppressed: org.apache.drill.exec.rpc.ChannelClosedException: java.nio.channels.ClosedChannelException\n                at org.apache.drill.exec.rpc.RequestIdMap$RpcListener.operationComplete(RequestIdMap.java:122)\n                at org.apache.drill.exec.rpc.RequestIdMap$RpcListener.operationComplete(RequestIdMap.java:98)\n                at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:680)\n                at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:603)\n                at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:563)\n                at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:424)\n                at io.netty.channel.ChannelOutboundBuffer.safeFail(ChannelOutboundBuffer.java:645)\n                at io.netty.channel.ChannelOutboundBuffer.remove(ChannelOutboundBuffer.java:290)\n                at io.netty.channel.ChannelOutboundBuffer.failFlushed(ChannelOutboundBuffer.java:589)\n                at io.netty.channel.AbstractChannel$AbstractUnsafe.closeAndDeregister(AbstractChannel.java:603)\n                at io.netty.channel.AbstractChannel$AbstractUnsafe.close(AbstractChannel.java:585)\n                ... 16 more\n        Caused by: java.nio.channels.ClosedChannelException\n        Suppressed: java.lang.IllegalStateException: Memory was leaked by query. Memory leaked: (1000000)\nAllocator(frag:0:0) 5000000/1000000/1146165504/50000000000 (res/actual/peak/limit)\n\n                at org.apache.drill.exec.memory.BaseAllocator.close(BaseAllocator.java:521)\n                at org.apache.drill.exec.ops.FragmentContext.suppressingClose(FragmentContext.java:436)\n                at org.apache.drill.exec.ops.FragmentContext.close(FragmentContext.java:430)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor.closeOutResources(FragmentExecutor.java:320)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor.cleanup(FragmentExecutor.java:155)\n                at org.apache.drill.exec.work.fragment.FragmentExecutor.run(FragmentExecutor.java:264)\n                at org.apache.drill.common.SelfCleaningRunnable.run(SelfCleaningRunnable.java:38)\n                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n                ... 1 more\n{noformat}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.016282616183161736
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007255678065121174
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004983066115528345
                }
            }
        },
        "comments": [
            {
                "author_name": "kkhatua",
                "id": "16505743",
                "body": "[~mgelbana] does this still occur with the latest Drill release (1.13.0)?"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e9f5f4d395ee221d3eae",
        "key": "NETBEANS-4862",
        "id": "13329906",
        "description": "I'm using Bell Soft 14, which comes bundled with JavaFX 14 I've added javafx javadoc URL in Java Platforms. But recently I noticed that it isn't caching some downloaded javadoc locally, instead it's only keeping the javadoc stored temporary while it's focused on frame (from the auto-completion menu)... And always I go to next item or close the frame it looses the javadoc and download it over again! The process is very repetitive.\r\n\r\nAnd to clarify, that doesn't happens to all Java classes - it somehow chooses...\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.4822768568992615
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.011051508598029613
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007026120088994503
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e1aef4d395ee221ba180",
        "key": "ROL-1366",
        "id": "12421026",
        "description": "Details from Allen's emailed proposal to the Roller community:\n\n2 of the things that pretty much all weblog owners tend to put in their templates are 1) a picture, typically of themselves and 2) a short bio paragraph.  Right now, Roller doesn't provide any easy way for these items to be controlled via the editing UI and so for people to add them to their blogs they must hack at templates.\n\nI am currently working with some folks at Sun who are designing some new blog themes and these 2 items have come up in every one of the designs so I'd like to propose that they be added as built-in attributes of a weblog.  This way theme writers and template hackers can have a simple and consistent way of getting these pieces of information for a weblog and allowing users to control them without having to edit templates.\n\nThe technical side of this would be very simple, just adding 2 new columns to the website table ...\n\nimage varchar(255) null\nbio text null (or can varchar work?)\n\nthen of course adding them to the pojos and a couple of simple UI controls on the Weblog Settings page to edit them.  The UI controls would be simple right now, just a textfield for the image and a textarea for the bio.  In the future we can improve the image field to use some kind of image selector from the users uploads, etc. ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.033383745700120926
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.7443034052848816
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.2001827359199524
                }
            }
        },
        "comments": [
            {
                "author_name": "agilliland",
                "id": "12690607",
                "body": "support for this has been added in roller trunk revision 539635."
            },
            {
                "author_name": "gmazza",
                "id": "13545068",
                "body": "Closing all resolved/fixed issues of already released versions of Roller."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640746691daae3a58081d545",
        "key": "BEAM-14554",
        "id": "13448220",
        "description": "Create a setting inside of BigtableConfig to report external system throttle time to Dataflow. This setting will inform Dataflow that the client is throttling and Dataflow will either maintain or decrease workers.\u00a0\r\n\r\nThis should help with overloading issues on the Bigtable side.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014700829051434994
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.06259143352508545
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0026709947269409895
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d60bfaf4d395ee2222445a",
        "key": "GEODE-1146",
        "id": "12954685",
        "description": "https://brazil.gemstone.com:8080/job/Geode_develop_DistributedTests/2082/testReport/com.gemstone.gemfire.cache.query.dunit/QueryUsingPoolDUnitTest/testBindParamsWithMulitipleClients/\n\njava.lang.AssertionError: Suspicious strings were written to the log during this run.\nFix the strings or use IgnoredException.addIgnoredException to ignore.\n-----------------------------------------------------------------------\nFound suspect string in log4j at line 1143688\n\n[fatal 2016/03/29 22:31:26.669 PDT <unicast receiver,latvia-7176> tid=0xc63] Membership service failure: Member isn't responding to heartbeat requests\ncom.gemstone.gemfire.ForcedDisconnectException: Member isn't responding to heartbeat requests\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.mgr.GMSMembershipManager.forceDisconnect(GMSMembershipManager.java:2586)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.forceDisconnect(GMSJoinLeave.java:885)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processRemoveRequest(GMSJoinLeave.java:578)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processMessage(GMSJoinLeave.java:1542)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.JGroupsMessenger$JGroupsReceiver.receive(JGroupsMessenger.java:1089)\n\tat org.jgroups.JChannel.invokeCallback(JChannel.java:817)\n\tat org.jgroups.JChannel.up(JChannel.java:741)\n\tat org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:1030)\n\tat org.jgroups.protocols.FRAG2.up(FRAG2.java:165)\n\tat org.jgroups.protocols.FlowControl.up(FlowControl.java:392)\n\tat org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1064)\n\tat org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:779)\n\tat org.jgroups.protocols.UNICAST3.up(UNICAST3.java:426)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.StatRecorder.up(StatRecorder.java:71)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.AddressManager.up(AddressManager.java:75)\n\tat org.jgroups.protocols.TP.passMessageUp(TP.java:1590)\n\tat org.jgroups.protocols.TP$SingleMessageHandler.run(TP.java:1802)\n\tat org.jgroups.util.DirectExecutor.execute(DirectExecutor.java:10)\n\tat org.jgroups.protocols.TP.handleSingleMessage(TP.java:1718)\n\tat org.jgroups.protocols.TP.receive(TP.java:1643)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.Transport.receive(Transport.java:160)\n\tat org.jgroups.protocols.UDP$PacketReceiver.run(UDP.java:701)\n\tat java.lang.Thread.run(Thread.java:745)",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012540278024971485
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.00713282311335206
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007432824466377497
                }
            }
        },
        "comments": [
            {
                "author_name": "upthewaterspout",
                "id": "15231439",
                "body": "Looks like there is a force disconnect happening in the middle of this test."
            },
            {
                "author_name": "bschuchardt",
                "id": "15232748",
                "body": "The server (vm_1)  that was kicked out failed the final health check\n\n[locator][info 2016/03/29 22:30:52.630 PDT <Geode Failure Detection thread 1> tid=0x45] Performing final check for suspect member latvia(17424)<ec><v149>:1026 reason=Member isn't responding to heartbeat requests\n\n[locator][info 2016/03/29 22:30:57.637 PDT <Geode Failure Detection thread 1> tid=0x45] Final check failed - requesting removal of suspect member latvia(17424)<ec><v149>:1026\n\nThis was one of two cache servers in the test.  The other server initiated suspect processing when it did not receive responses to heartbeat requests."
            },
            {
                "author_name": "klund",
                "id": "15243792",
                "body": "If bugs like this don't reproduce, maybe the standard course should be to: 1) convert test to junit4 syntax, 2) replace thread sleeps with await calls, 3) make sure there are no AsyncInvocation orphans (this test does leave some possible AsyncInvocations orphaned without completing), 4) eliminate any uses of random AvailablePort with zero port wildcard (#4 needs some changes to product code at the time of this comment)."
            },
            {
                "author_name": "klund",
                "id": "15246919",
                "body": "Flaky: time senstiive, thread sleeps, uses zero port for servers (good!), async actions, AsyncInvocation orphans"
            },
            {
                "author_name": "jira-bot",
                "id": "15252447",
                "body": "Commit 7e1656b0847ddc1f1f5f7fdba60513ba7e814d43 in incubator-geode's branch refs/heads/develop from [~ukohlmeyer]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=7e1656b ]\n\nGEODE-1146: Test cleanup, converting many VM invoke statements to lambda expressions\n"
            },
            {
                "author_name": "ukohlmeyer",
                "id": "15252459",
                "body": "this issue can be reproduced by running the test often. GC then kicks in and causes the issue.\nThis flaky behaviour should be fixed once the VMs are bounced. \n\nIn a test I ran the test 80 times which caused a GC and then test failure. When I introduced the capability to bounce the VM every 30 tests, the GC problem disappeared and this test ran over 3hrs (over 3500 iterations) without failure until I stopped it. "
            },
            {
                "author_name": "ukohlmeyer",
                "id": "15256845",
                "body": "This failure is most likely caused by a GC that happens to be running at that time. I was able to replicate this GC issue. The bouncing of the VM's need to be revisited. As most likely the bouncing/cleaning up of the VMs would be the best way to solve this issue."
            },
            {
                "author_name": "ukohlmeyer",
                "id": "15256873",
                "body": "The fixing of this test is dependent on GEODE-1305 being completed."
            },
            {
                "author_name": "eshu",
                "id": "15258718",
                "body": "{noformat}\nbuild# 2318\n\nError Message\n\njava.lang.AssertionError: Suspicious strings were written to the log during this run.\nFix the strings or use IgnoredException.addIgnoredException to ignore.\n-----------------------------------------------------------------------\nFound suspect string in log4j at line 988118\n\n[fatal 2016/04/19 03:46:39.131 PDT <unicast receiver,cc3-rh6-54933> tid=0x430] Membership service failure: Member isn't responding to heartbeat requests\ncom.gemstone.gemfire.ForcedDisconnectException: Member isn't responding to heartbeat requests\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.mgr.GMSMembershipManager.forceDisconnect(GMSMembershipManager.java:2586)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.forceDisconnect(GMSJoinLeave.java:885)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processRemoveRequest(GMSJoinLeave.java:578)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processMessage(GMSJoinLeave.java:1540)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.JGroupsMessenger$JGroupsReceiver.receive(JGroupsMessenger.java:1095)\n\tat org.jgroups.JChannel.invokeCallback(JChannel.java:816)\n\tat org.jgroups.JChannel.up(JChannel.java:741)\n\tat org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:1030)\n\tat org.jgroups.protocols.FRAG2.up(FRAG2.java:165)\n\tat org.jgroups.protocols.FlowControl.up(FlowControl.java:392)\n\tat org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1064)\n\tat org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:779)\n\tat org.jgroups.protocols.UNICAST3.up(UNICAST3.java:426)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.StatRecorder.up(StatRecorder.java:75)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.AddressManager.up(AddressManager.java:75)\n\tat org.jgroups.protocols.TP.passMessageUp(TP.java:1567)\n\tat org.jgroups.protocols.TP$SingleMessageHandler.run(TP.java:1783)\n\tat org.jgroups.util.DirectExecutor.execute(DirectExecutor.java:10)\n\tat org.jgroups.protocols.TP.handleSingleMessage(TP.java:1695)\n\tat org.jgroups.protocols.TP.receive(TP.java:1620)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.Transport.receive(Transport.java:160)\n\tat org.jgroups.protocols.UDP$PacketReceiver.run(UDP.java:701)\n\tat java.lang.Thread.run(Thread.java:745)\n\nStacktrace\n\njava.lang.AssertionError: Suspicious strings were written to the log during this run.\nFix the strings or use IgnoredException.addIgnoredException to ignore.\n-----------------------------------------------------------------------\nFound suspect string in log4j at line 988118\n\n[fatal 2016/04/19 03:46:39.131 PDT <unicast receiver,cc3-rh6-54933> tid=0x430] Membership service failure: Member isn't responding to heartbeat requests\ncom.gemstone.gemfire.ForcedDisconnectException: Member isn't responding to heartbeat requests\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.mgr.GMSMembershipManager.forceDisconnect(GMSMembershipManager.java:2586)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.forceDisconnect(GMSJoinLeave.java:885)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processRemoveRequest(GMSJoinLeave.java:578)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processMessage(GMSJoinLeave.java:1540)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.JGroupsMessenger$JGroupsReceiver.receive(JGroupsMessenger.java:1095)\n\tat org.jgroups.JChannel.invokeCallback(JChannel.java:816)\n\tat org.jgroups.JChannel.up(JChannel.java:741)\n\tat org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:1030)\n\tat org.jgroups.protocols.FRAG2.up(FRAG2.java:165)\n\tat org.jgroups.protocols.FlowControl.up(FlowControl.java:392)\n\tat org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1064)\n\tat org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:779)\n\tat org.jgroups.protocols.UNICAST3.up(UNICAST3.java:426)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.StatRecorder.up(StatRecorder.java:75)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.AddressManager.up(AddressManager.java:75)\n\tat org.jgroups.protocols.TP.passMessageUp(TP.java:1567)\n\tat org.jgroups.protocols.TP$SingleMessageHandler.run(TP.java:1783)\n\tat org.jgroups.util.DirectExecutor.execute(DirectExecutor.java:10)\n\tat org.jgroups.protocols.TP.handleSingleMessage(TP.java:1695)\n\tat org.jgroups.protocols.TP.receive(TP.java:1620)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.Transport.receive(Transport.java:160)\n\tat org.jgroups.protocols.UDP$PacketReceiver.run(UDP.java:701)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat com.gemstone.gemfire.test.dunit.standalone.DUnitLauncher.closeAndCheckForSuspects(DUnitLauncher.java:352)\n\tat com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase.cleanupAllVms(JUnit4DistributedTestCase.java:542)\n\tat com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase.tearDownDistributedTestCase(JUnit4DistributedTestCase.java:491)\n\tat com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase.tearDown(JUnit4DistributedTestCase.java:480)\n\tat com.gemstone.gemfire.test.dunit.internal.JUnit3DistributedTestCase.tearDown(JUnit3DistributedTestCase.java:206)\n\tat junit.framework.TestCase.runBare(TestCase.java:146)\n\tat junit.framework.TestResult$1.protect(TestResult.java:122)\n\tat junit.framework.TestResult.runProtected(TestResult.java:142)\n\tat junit.framework.TestResult.run(TestResult.java:125)\n\tat junit.framework.TestCase.run(TestCase.java:129)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:252)\n\tat junit.framework.TestSuite.run(TestSuite.java:247)\n\tat org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:86)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:105)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:56)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)\n\tat sun.reflect.GeneratedMethodAccessor369.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n\tat org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n\tat com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)\n\tat sun.reflect.GeneratedMethodAccessor368.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)\n\tat org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n{noformat}"
            },
            {
                "author_name": "jira-bot",
                "id": "15281898",
                "body": "Commit 2c2caae9db8d687107d5d15af44a5f0d14465b35 in incubator-geode's branch refs/heads/develop from [~ukohlmeyer]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=2c2caae ]\n\nGEODE-1146: Amending Testcase to use proper client caches rather than peer servers. Also amending JUnit4CacheTestCase.java to set \"locators\" and \"mcast-port\" to correct settings for clients.\n"
            },
            {
                "author_name": "ukohlmeyer",
                "id": "15281903",
                "body": "Refactored test code. Removed time sensitive waits and used Awaitility. Also converted client VMs to start ClientCaches, not normal Peer caches. Hopefully code a little less flaky now."
            },
            {
                "author_name": "jira-bot",
                "id": "15282884",
                "body": "Commit 7051c7ad61ef1c41db192c62277ff2dc0f332842 in incubator-geode's branch refs/heads/develop from [~bschuchardt]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=7051c7a ]\n\nRevert \"GEODE-1146: Amending Testcase to use proper client caches rather than peer servers. Also amending JUnit4CacheTestCase.java to set \"locators\" and \"mcast-port\" to correct settings for clients.\"\n\nThis reverts commit 2c2caae9db8d687107d5d15af44a5f0d14465b35, which caused\na number of tests to fail.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15282978",
                "body": "Commit 7051c7ad61ef1c41db192c62277ff2dc0f332842 in incubator-geode's branch refs/heads/feature/GEODE-1376 from [~bschuchardt]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=7051c7a ]\n\nRevert \"GEODE-1146: Amending Testcase to use proper client caches rather than peer servers. Also amending JUnit4CacheTestCase.java to set \"locators\" and \"mcast-port\" to correct settings for clients.\"\n\nThis reverts commit 2c2caae9db8d687107d5d15af44a5f0d14465b35, which caused\na number of tests to fail.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15291990",
                "body": "Commit 2c2caae9db8d687107d5d15af44a5f0d14465b35 in incubator-geode's branch refs/heads/feature/GEODE-1372 from [~ukohlmeyer]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=2c2caae ]\n\nGEODE-1146: Amending Testcase to use proper client caches rather than peer servers. Also amending JUnit4CacheTestCase.java to set \"locators\" and \"mcast-port\" to correct settings for clients.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15295771",
                "body": "Commit 617c9fd47e798c4cf0fdcae45697855760d39036 in incubator-geode's branch refs/heads/develop from [~ukohlmeyer]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=617c9fd ]\n\nGEODE-1146: Cleaned up QueryUsingPoolDUnitTest.java to use proper client caches.\nAdded client specific properties for JUnit4CacheTestCase.java\n"
            }
        ],
        "comments_predictions": [
            [
                2769649,
                "GEODE-1146",
                "The server (vm_1)  that was kicked out failed the final health check\n\n[locator][info 2016/03/29 22:30:52.630 PDT <Geode Failure Detection thread 1> tid=0x45] Performing final check for suspect member latvia(17424)<ec><v149>:1026 reason=Member isn't responding to heartbeat requests\n\n[locator][info 2016/03/29 22:30:57.637 PDT <Geode Failure Detection thread 1> tid=0x45] Final check failed - requesting removal of suspect member latvia(17424)<ec><v149>:1026\n\nThis was one of two cache servers in the test.  The other server initiated suspect processing when it did not receive responses to heartbeat requests.",
                {
                    "property": {
                        "confidence": 0.007230264600366354,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0044969599694013596,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02448536641895771,
                        "prediction": false
                    }
                }
            ],
            [
                2769650,
                "GEODE-1146",
                "If bugs like this don't reproduce, maybe the standard course should be to: 1) convert test to junit4 syntax, 2) replace thread sleeps with await calls, 3) make sure there are no AsyncInvocation orphans (this test does leave some possible AsyncInvocations orphaned without completing), 4) eliminate any uses of random AvailablePort with zero port wildcard (#4 needs some changes to product code at the time of this comment).",
                {
                    "property": {
                        "confidence": 0.0041567194275557995,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011575906537473202,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010804043151438236,
                        "prediction": false
                    }
                }
            ],
            [
                2769653,
                "GEODE-1146",
                "this issue can be reproduced by running the test often. GC then kicks in and causes the issue.\nThis flaky behaviour should be fixed once the VMs are bounced. \n\nIn a test I ran the test 80 times which caused a GC and then test failure. When I introduced the capability to bounce the VM every 30 tests, the GC problem disappeared and this test ran over 3hrs (over 3500 iterations) without failure until I stopped it. ",
                {
                    "property": {
                        "confidence": 0.005887473467737436,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005166350863873959,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018442759290337563,
                        "prediction": false
                    }
                }
            ],
            [
                2769654,
                "GEODE-1146",
                "This failure is most likely caused by a GC that happens to be running at that time. I was able to replicate this GC issue. The bouncing of the VM's need to be revisited. As most likely the bouncing/cleaning up of the VMs would be the best way to solve this issue.",
                {
                    "property": {
                        "confidence": 0.014039157889783382,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0037460720632225275,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013175031170248985,
                        "prediction": false
                    }
                }
            ],
            [
                2769656,
                "GEODE-1146",
                "{noformat}\nbuild# 2318\n\nError Message\n\njava.lang.AssertionError: Suspicious strings were written to the log during this run.\nFix the strings or use IgnoredException.addIgnoredException to ignore.\n-----------------------------------------------------------------------\nFound suspect string in log4j at line 988118\n\n[fatal 2016/04/19 03:46:39.131 PDT <unicast receiver,cc3-rh6-54933> tid=0x430] Membership service failure: Member isn't responding to heartbeat requests\ncom.gemstone.gemfire.ForcedDisconnectException: Member isn't responding to heartbeat requests\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.mgr.GMSMembershipManager.forceDisconnect(GMSMembershipManager.java:2586)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.forceDisconnect(GMSJoinLeave.java:885)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processRemoveRequest(GMSJoinLeave.java:578)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processMessage(GMSJoinLeave.java:1540)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.JGroupsMessenger$JGroupsReceiver.receive(JGroupsMessenger.java:1095)\n\tat org.jgroups.JChannel.invokeCallback(JChannel.java:816)\n\tat org.jgroups.JChannel.up(JChannel.java:741)\n\tat org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:1030)\n\tat org.jgroups.protocols.FRAG2.up(FRAG2.java:165)\n\tat org.jgroups.protocols.FlowControl.up(FlowControl.java:392)\n\tat org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1064)\n\tat org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:779)\n\tat org.jgroups.protocols.UNICAST3.up(UNICAST3.java:426)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.StatRecorder.up(StatRecorder.java:75)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.AddressManager.up(AddressManager.java:75)\n\tat org.jgroups.protocols.TP.passMessageUp(TP.java:1567)\n\tat org.jgroups.protocols.TP$SingleMessageHandler.run(TP.java:1783)\n\tat org.jgroups.util.DirectExecutor.execute(DirectExecutor.java:10)\n\tat org.jgroups.protocols.TP.handleSingleMessage(TP.java:1695)\n\tat org.jgroups.protocols.TP.receive(TP.java:1620)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.Transport.receive(Transport.java:160)\n\tat org.jgroups.protocols.UDP$PacketReceiver.run(UDP.java:701)\n\tat java.lang.Thread.run(Thread.java:745)\n\nStacktrace\n\njava.lang.AssertionError: Suspicious strings were written to the log during this run.\nFix the strings or use IgnoredException.addIgnoredException to ignore.\n-----------------------------------------------------------------------\nFound suspect string in log4j at line 988118\n\n[fatal 2016/04/19 03:46:39.131 PDT <unicast receiver,cc3-rh6-54933> tid=0x430] Membership service failure: Member isn't responding to heartbeat requests\ncom.gemstone.gemfire.ForcedDisconnectException: Member isn't responding to heartbeat requests\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.mgr.GMSMembershipManager.forceDisconnect(GMSMembershipManager.java:2586)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.forceDisconnect(GMSJoinLeave.java:885)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processRemoveRequest(GMSJoinLeave.java:578)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.membership.GMSJoinLeave.processMessage(GMSJoinLeave.java:1540)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.JGroupsMessenger$JGroupsReceiver.receive(JGroupsMessenger.java:1095)\n\tat org.jgroups.JChannel.invokeCallback(JChannel.java:816)\n\tat org.jgroups.JChannel.up(JChannel.java:741)\n\tat org.jgroups.stack.ProtocolStack.up(ProtocolStack.java:1030)\n\tat org.jgroups.protocols.FRAG2.up(FRAG2.java:165)\n\tat org.jgroups.protocols.FlowControl.up(FlowControl.java:392)\n\tat org.jgroups.protocols.UNICAST3.deliverMessage(UNICAST3.java:1064)\n\tat org.jgroups.protocols.UNICAST3.handleDataReceived(UNICAST3.java:779)\n\tat org.jgroups.protocols.UNICAST3.up(UNICAST3.java:426)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.StatRecorder.up(StatRecorder.java:75)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.AddressManager.up(AddressManager.java:75)\n\tat org.jgroups.protocols.TP.passMessageUp(TP.java:1567)\n\tat org.jgroups.protocols.TP$SingleMessageHandler.run(TP.java:1783)\n\tat org.jgroups.util.DirectExecutor.execute(DirectExecutor.java:10)\n\tat org.jgroups.protocols.TP.handleSingleMessage(TP.java:1695)\n\tat org.jgroups.protocols.TP.receive(TP.java:1620)\n\tat com.gemstone.gemfire.distributed.internal.membership.gms.messenger.Transport.receive(Transport.java:160)\n\tat org.jgroups.protocols.UDP$PacketReceiver.run(UDP.java:701)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n\tat org.junit.Assert.fail(Assert.java:88)\n\tat com.gemstone.gemfire.test.dunit.standalone.DUnitLauncher.closeAndCheckForSuspects(DUnitLauncher.java:352)\n\tat com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase.cleanupAllVms(JUnit4DistributedTestCase.java:542)\n\tat com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase.tearDownDistributedTestCase(JUnit4DistributedTestCase.java:491)\n\tat com.gemstone.gemfire.test.dunit.internal.JUnit4DistributedTestCase.tearDown(JUnit4DistributedTestCase.java:480)\n\tat com.gemstone.gemfire.test.dunit.internal.JUnit3DistributedTestCase.tearDown(JUnit3DistributedTestCase.java:206)\n\tat junit.framework.TestCase.runBare(TestCase.java:146)\n\tat junit.framework.TestResult$1.protect(TestResult.java:122)\n\tat junit.framework.TestResult.runProtected(TestResult.java:142)\n\tat junit.framework.TestResult.run(TestResult.java:125)\n\tat junit.framework.TestCase.run(TestCase.java:129)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:252)\n\tat junit.framework.TestSuite.run(TestSuite.java:247)\n\tat org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:86)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:105)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:56)\n\tat org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:64)\n\tat org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:50)\n\tat sun.reflect.GeneratedMethodAccessor369.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n\tat org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n\tat com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n\tat org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:106)\n\tat sun.reflect.GeneratedMethodAccessor368.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n\tat org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n\tat org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:360)\n\tat org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)\n\tat org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n\n{noformat}",
                {
                    "property": {
                        "confidence": 0.005851591005921364,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.018669668585062027,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008928089402616024,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640746652112148e1181d847",
        "key": "CAMEL-18443",
        "id": "13479326",
        "description": "When upgrading to 3.18.1 I see a problem with some of my project's existing tests that break. I've isolated the problem to tests that use AdviceWith on routes that make use of try-catch-finally.\r\n\r\nHere is a test that succeeds in 3.18.0 but fails in 3.18.1:\r\n{code:java}\r\nimport static org.apache.camel.builder.AdviceWith.adviceWith;\r\n\r\nimport org.apache.camel.RoutesBuilder;\r\nimport org.apache.camel.builder.RouteBuilder;\r\nimport org.apache.camel.test.junit5.CamelTestSupport;\r\nimport org.junit.jupiter.api.Test;\r\n\r\npublic class TryCatchFinallyTest extends CamelTestSupport {\r\n\r\n  @Test\r\n  public void tryCatchFinallyUsingAdviceWith() throws Exception {\r\n    adviceWith(context, \"my-route\", a ->\r\n        a.weaveById(\"replace-me\")\r\n            .replace()\r\n            .to(\"mock:replaced\")\r\n    );\r\n\r\n    context.start();\r\n  }\r\n  \r\n  @Override\r\n  public boolean isUseAdviceWith() {\r\n    return true;\r\n  }\r\n  \r\n  @Override\r\n  protected RoutesBuilder createRouteBuilder() {\r\n    return new RouteBuilder() {\r\n      @Override\r\n      public void configure() {\r\n        from(\"direct:start\")\r\n            .routeId(\"my-route\")\r\n            .doTry()\r\n              .log(\"try\")\r\n              .to(\"mock:replace-me\").id(\"replace-me\")\r\n            .doCatch(Exception.class)\r\n              .log(\"catch\")\r\n            .doFinally()\r\n              .log(\"finally\")\r\n            .end();\r\n      }\r\n    };\r\n  }\r\n  \r\n} {code}\r\nThe stack trace:\r\n{noformat}\r\nFailed to create route my-route at: >>> DoTry[[Log[try], To[mock:replaced], DoCatch[ [class java.lang.Exception] -> [Log[catch]]], DoFinally[[Log[finally]]]]] <<< in route: Route(my-route)[From[direct:start] -> [DoTry[[Log[try], To[m... because of Multiple finally clauses added: DoFinally[[Log[finally]]] and DoFinally[[Log[finally]]]\r\norg.apache.camel.FailedToCreateRouteException: Failed to create route my-route at: >>> DoTry[[Log[try], To[mock:replaced], DoCatch[ [class java.lang.Exception] -> [Log[catch]]], DoFinally[[Log[finally]]]]] <<< in route: Route(my-route)[From[direct:start] -> [DoTry[[Log[try], To[m... because of Multiple finally clauses added: DoFinally[[Log[finally]]] and DoFinally[[Log[finally]]]\r\n\u00a0 \u00a0 at app//org.apache.camel.reifier.RouteReifier.doCreateRoute(RouteReifier.java:240)\r\n\u00a0 \u00a0 at app//org.apache.camel.reifier.RouteReifier.createRoute(RouteReifier.java:74)\r\n\u00a0 \u00a0 at app//org.apache.camel.impl.DefaultModelReifierFactory.createRoute(DefaultModelReifierFactory.java:49)\r\n\u00a0 \u00a0 at app//org.apache.camel.impl.DefaultCamelContext.startRouteDefinitions(DefaultCamelContext.java:862)\r\n\u00a0 \u00a0 at app//org.apache.camel.impl.DefaultCamelContext.startRouteDefinitions(DefaultCamelContext.java:750)\r\n\u00a0 \u00a0 at app//org.apache.camel.impl.engine.AbstractCamelContext.doInit(AbstractCamelContext.java:2947)\r\n\u00a0 \u00a0 at app//org.apache.camel.support.service.BaseService.init(BaseService.java:83)\r\n\u00a0 \u00a0 at app//org.apache.camel.impl.engine.AbstractCamelContext.init(AbstractCamelContext.java:2630)\r\n\u00a0 \u00a0 at app//org.apache.camel.support.service.BaseService.start(BaseService.java:111)\r\n\u00a0 \u00a0 at app//org.apache.camel.impl.engine.AbstractCamelContext.start(AbstractCamelContext.java:2649)\r\n\u00a0 \u00a0 at app//org.apache.camel.impl.DefaultCamelContext.start(DefaultCamelContext.java:262)\r\n\u00a0 \u00a0 at app//TryCatchFinallyTest.tryCatchFinallyUsingAdviceWith(TryCatchFinallyTest.java:18)\r\n\u00a0 \u00a0 at java.base@11.0.16/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\u00a0 \u00a0 at java.base@11.0.16/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\u00a0 \u00a0 at java.base@11.0.16/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\u00a0 \u00a0 at java.base@11.0.16/java.lang.reflect.Method.invoke(Method.java:566)\r\n\u00a0 \u00a0 at app//org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)\r\n\u00a0 \u00a0 at app//org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\r\n\u00a0 \u00a0 at java.base@11.0.16/java.util.ArrayList.forEach(ArrayList.java:1541)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\r\n\u00a0 \u00a0 at java.base@11.0.16/java.util.ArrayList.forEach(ArrayList.java:1541)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)\r\n\u00a0 \u00a0 at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)\r\n\u00a0 \u00a0 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:108)\r\n\u00a0 \u00a0 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)\r\n\u00a0 \u00a0 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)\r\n\u00a0 \u00a0 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)\r\n\u00a0 \u00a0 at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)\r\n\u00a0 \u00a0 at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:96)\r\n\u00a0 \u00a0 at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:75)\r\n\u00a0 \u00a0 at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99)\r\n\u00a0 \u00a0 at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79)\r\n\u00a0 \u00a0 at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75)\r\n\u00a0 \u00a0 at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61)\r\n\u00a0 \u00a0 at java.base@11.0.16/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\u00a0 \u00a0 at java.base@11.0.16/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\u00a0 \u00a0 at java.base@11.0.16/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\u00a0 \u00a0 at java.base@11.0.16/java.lang.reflect.Method.invoke(Method.java:566)\r\n\u00a0 \u00a0 at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)\r\n\u00a0 \u00a0 at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\r\n\u00a0 \u00a0 at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)\r\n\u00a0 \u00a0 at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)\r\n\u00a0 \u00a0 at com.sun.proxy.$Proxy2.stop(Unknown Source)\r\n\u00a0 \u00a0 at org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193)\r\n\u00a0 \u00a0 at org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129)\r\n\u00a0 \u00a0 at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100)\r\n\u00a0 \u00a0 at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60)\r\n\u00a0 \u00a0 at org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56)\r\n\u00a0 \u00a0 at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:133)\r\n\u00a0 \u00a0 at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:71)\r\n\u00a0 \u00a0 at app//worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69)\r\n\u00a0 \u00a0 at app//worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74)\r\nCaused by: java.lang.IllegalArgumentException: Multiple finally clauses added: DoFinally[[Log[finally]]] and DoFinally[[Log[finally]]]\r\n\u00a0 \u00a0 at org.apache.camel.model.TryDefinition.checkInitialized(TryDefinition.java:225)\r\n\u00a0 \u00a0 at org.apache.camel.model.TryDefinition.preCreateProcessor(TryDefinition.java:207)\r\n\u00a0 \u00a0 at org.apache.camel.reifier.ProcessorReifier.preCreateProcessor(ProcessorReifier.java:870)\r\n\u00a0 \u00a0 at org.apache.camel.reifier.ProcessorReifier.makeProcessor(ProcessorReifier.java:838)\r\n\u00a0 \u00a0 at org.apache.camel.reifier.ProcessorReifier.addRoutes(ProcessorReifier.java:588)\r\n\u00a0 \u00a0 at org.apache.camel.reifier.RouteReifier.doCreateRoute(RouteReifier.java:236)\r\n\u00a0 \u00a0 ... 94 more\r\n{noformat}\r\nThe test succeeds if I skip using AdviceWith.\r\n\r\nI see there was a change to the TryDefinition class in 3.18.1 (CAMEL-18288) but I'm not sure that's the cause.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.14023444056510925
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006511739920824766
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0053853183053433895
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e1aef4d395ee221bb29d",
        "key": "REEF-194",
        "id": "12779631",
        "description": "The {{Org.Apache.REEF.Bridge}} project depends on the existence of the C++ bridge parts as well as the Java side in a JAR. We should expose this as projects and NuGets to the .NET build system.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02748757414519787
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.07590437680482864
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004764721728861332
                }
            }
        },
        "comments": [
            {
                "author_name": "markus.weimer",
                "id": "14355977",
                "body": "[~chris.douglas] and I spoke offline. It is probably fine to keep the JAR in our NuGets. I suggest to do the following:\n\n # Make a NuGet for our native and managed bridge DLLs. Probably {{Org.Apache.REEF.Bridge.dll}}\n # Make a NuGet that contains *only* the shaded JAR {{reef-bridge-java-0.11.0-incubating-SNAPSHOT-shaded.jar}}\n\nThat way we cleanly separate our code from the code we redistribute.\n\n[~chris.douglas], does this sound like a clean plan? Any Apache rules we need to be aware off when it comes to 3rd party binaries in our binary drops?"
            },
            {
                "author_name": "cdouglas",
                "id": "14355998",
                "body": "From a licensing perspective, that should be [OK|www.apache.org/dev/licensing-howto.html]. Developing on REEF might be easier if dependencies could be downloaded and cached, but (AIUI) this is not prohibited.\n\nThe difficulty is verification. Project members can easily verify source, but verifying jars is impractical. Since REEF is building this artifact itself, I suppose the validation could be by construction."
            },
            {
                "author_name": "juliaw",
                "id": "14361337",
                "body": "Change to PR #117\nhttps://github.com/apache/incubator-reef/pull/117"
            },
            {
                "author_name": "hudson",
                "id": "14361342",
                "body": "FAILURE: Integrated in Reef-pull-request-ubuntu #322 (See [https://builds.apache.org/job/Reef-pull-request-ubuntu/322/])\n[REEF-194]  Remove 3rd party libraries from REEF Client Nuget (jwang98052: rev 0c440744b8c3e06b5d8c4da5888ceb67e6d4dfc6)\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.csproj\n* lang/cs/Org.Apache.REEF.Jar/Org.Apache.REEF.Jar.csproj\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.nuspec\n* lang/reef-bridge/pom.xml\n* lang/cs/Org.Apache.REEF.sln\n* lang/cs/Org.Apache.REEF.Jar/Properties/AssemblyInfo.cs\n* lang/cpp/reef-bridge-clr/pom.xml\n* lang/cs/Org.Apache.REEF.Jar/Org.Apache.REEF.Jar.nuspec\n* lang/cs/Org.Apache.REEF.Bridge/Properties/AssemblyInfo.cs\n"
            },
            {
                "author_name": "hudson",
                "id": "14361346",
                "body": "FAILURE: Integrated in Reef-pull-request-windows #162 (See [https://builds.apache.org/job/Reef-pull-request-windows/162/])\n[REEF-194]  Remove 3rd party libraries from REEF Client Nuget (jwang98052: rev 0c440744b8c3e06b5d8c4da5888ceb67e6d4dfc6)\n* lang/cs/Org.Apache.REEF.Jar/Org.Apache.REEF.Jar.csproj\n* lang/cpp/reef-bridge-clr/pom.xml\n* lang/reef-bridge/pom.xml\n* lang/cs/Org.Apache.REEF.sln\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.nuspec\n* lang/cs/Org.Apache.REEF.Bridge/Properties/AssemblyInfo.cs\n* lang/cs/Org.Apache.REEF.Jar/Properties/AssemblyInfo.cs\n* lang/cs/Org.Apache.REEF.Jar/Org.Apache.REEF.Jar.nuspec\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.csproj\n"
            },
            {
                "author_name": "juliaw",
                "id": "14367876",
                "body": "This Jira is to make a NuGet for our native and managed bridge DLL - Org.Apache.REEF.Bridge.dll. The change would cover:\n\nMove files in lang\\cpp module into Org.Apache.REEF.sln as a project Org.Apache.REEF.Bridge . The dependency on Driver.dll should be set within Org.Apache.REEF.Bridge.sln\nCreate NuGet for the Org.Apache.REEF.Bridge.dll\nFrom REEF.Client, reference jar file from lang\\java\\reef-bridge-java to remove the dependency on lang\\reef-bridge \nAs the jar file doesn't contain the clr dll any more, modify libLoader to load clr dll properly. \nRemove lang\\cpp and lang\\reef-bridge \nTest REEF.client for E2E. "
            },
            {
                "author_name": "juliaw",
                "id": "14367890",
                "body": "PR #117 is created for it. \n\nhttps://github.com/apache/incubator-reef/pull/117"
            },
            {
                "author_name": "hudson",
                "id": "14367918",
                "body": "SUCCESS: Integrated in Reef-pull-request-ubuntu #331 (See [https://builds.apache.org/job/Reef-pull-request-ubuntu/331/])\n[REEF-194]  Provide all needed dependencies for the bridge as NuGets (jwang98052: rev 275422f4c20d13883b8d3dfba742084d55f01d8e)\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/ILogger.cs\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ContextMessageClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/SuspendedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.nuspec\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.sln\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.cpp\n* lang/cs/build.props\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ReadMe.txt\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.h\n* lang/cs/Org.Apache.REEF.Bridge/app.ico\n* lang/cs/Org.Apache.REEF.Bridge/ActiveContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Org.Apache.REEF.Bridge.Clr.csproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.h\n* lang/reef-bridge/.gitignore\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj\n* lang/cs/Org.Apache.REEF.Bridge/FailedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ReadMe.txt\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/resource.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Properties/AssemblyInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.user\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.h\n* lang/cs/Org.Apache.REEF.Bridge/FailedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/SuspendedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/ILogger.cs\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.cpp\n* lang/cs/Org.Apache.REEF.sln\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/IInteropReturnInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/HttpServerClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.h\n* lang/cs/Org.Apache.REEF.Driver/Constants.cs\n* lang/cs/.gitignore\n* lang/cs/Org.Apache.REEF.Client/CLRBridgeClient.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ContextMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ClosedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.cpp\n* lang/cs/Org.Apache.REEF.Bridge/RunningTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.h\n* lang/java/reef-common/src/main/java/org/apache/reef/runtime/common/files/REEFFileNames.java\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ActiveContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.h\n* lang/cs/Org.Apache.REEF.Bridge/Clr2JavaImpl.h\n* lang/cs/Org.Apache.REEF.Bridge.JAR/Org.Apache.REEF.Bridge.JAR.csproj\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.filters\n* lang/reef-bridge/pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/EvaluatorRequestorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropAssemblies.h\n* lang/cpp/.gitignore\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/HttpServerClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.h\n* lang/cs/Org.Apache.REEF.Bridge/CommonUtilities.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/EvaluatorRequestorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/Org.Apache.REEF.Driver.csproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.cpp\n* pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/app.rc\n* lang/cs/pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/IInteropReturnInfo.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ClosedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ManagedLogger.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/RunningTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CommonUtilities.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Client/Org.Apache.REEF.Client.csproj\n* lang/cs/Org.Apache.REEF.Bridge/InteropAssemblies.h\n* lang/java/reef-bridge-java/src/main/java/org/apache/reef/javabridge/LibLoader.java\n"
            },
            {
                "author_name": "hudson",
                "id": "14367932",
                "body": "SUCCESS: Integrated in Reef-pull-request-windows #172 (See [https://builds.apache.org/job/Reef-pull-request-windows/172/])\n[REEF-194]  Provide all needed dependencies for the bridge as NuGets (jwang98052: rev 275422f4c20d13883b8d3dfba742084d55f01d8e)\n* lang/cpp/reef-bridge-clr/pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ReadMe.txt\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/TaskMessageClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ActiveContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropAssemblies.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.h\n* lang/cs/Org.Apache.REEF.Bridge/ActiveContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/RunningTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CommonUtilities.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/IInteropReturnInfo.cs\n* lang/cs/.gitignore\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ContextMessageClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/EvaluatorRequestorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.h\n* lang/cs/Org.Apache.REEF.Bridge/EvaluatorRequestorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/Org.Apache.REEF.Driver.csproj\n* lang/cs/Org.Apache.REEF.Bridge/HttpServerClr2Java.cpp\n* lang/reef-bridge/pom.xml\n* pom.xml\n* lang/cs/pom.xml\n* lang/cs/build.props\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.nuspec\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ReadMe.txt\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropAssemblies.h\n* lang/cpp/.gitignore\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.h\n* lang/cs/Org.Apache.REEF.Bridge/Clr2JavaImpl.h\n* lang/cs/Org.Apache.REEF.Client/CLRBridgeClient.cs\n* lang/java/reef-bridge-java/src/main/java/org/apache/reef/javabridge/LibLoader.java\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.h\n* lang/cs/Org.Apache.REEF.Bridge/ClosedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ClosedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.h\n* lang/cs/Org.Apache.REEF.Driver/Constants.cs\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Client/Org.Apache.REEF.Client.csproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/ILogger.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge.JAR/Org.Apache.REEF.Bridge.JAR.csproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.sln\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/HttpServerClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.h\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyUtil.cpp\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/IInteropReturnInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/SuspendedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Org.Apache.REEF.Bridge.Clr.csproj\n* lang/cs/Org.Apache.REEF.Bridge/app.ico\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/ILogger.cs\n* lang/cs/Org.Apache.REEF.Bridge/CommonUtilities.cpp\n* lang/cs/Org.Apache.REEF.Bridge/resource.h\n* lang/reef-bridge/.gitignore\n* lang/cs/Org.Apache.REEF.Bridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj\n* lang/java/reef-common/src/main/java/org/apache/reef/runtime/common/files/REEFFileNames.java\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.h\n* lang/cs/Org.Apache.REEF.Bridge/ContextMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ManagedLogger.cpp\n* lang/cs/Org.Apache.REEF.Bridge/app.rc\n* lang/cs/Org.Apache.REEF.Bridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.h\n* lang/cs/Org.Apache.REEF.sln\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.user\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/SuspendedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/RunningTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Properties/AssemblyInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/FailedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.h\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.h\n"
            },
            {
                "author_name": "hudson",
                "id": "14368083",
                "body": "SUCCESS: Integrated in Reef-pull-request-ubuntu #332 (See [https://builds.apache.org/job/Reef-pull-request-ubuntu/332/])\n[REEF-194]  Provide all needed dependencies for the bridge as NuGets (jwang98052: rev 275422f4c20d13883b8d3dfba742084d55f01d8e)\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/RunningTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.h\n* lang/cs/Org.Apache.REEF.Bridge/ContextMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/EvaluatorRequestorClr2Java.cpp\n* lang/reef-bridge/.gitignore\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ContextMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.user\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.h\n* lang/cpp/.gitignore\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.nuspec\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.h\n* lang/cs/Org.Apache.REEF.Driver/Org.Apache.REEF.Driver.csproj\n* lang/cs/Org.Apache.REEF.Bridge/SuspendedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/ILogger.cs\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Properties/AssemblyInfo.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.h\n* lang/cs/pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/CompletedEvaluatorClr2Java.cpp\n* lang/reef-bridge/pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ClosedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/EvaluatorRequestorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/IInteropReturnInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/RunningTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.h\n* lang/cs/Org.Apache.REEF.Bridge/app.rc\n* lang/cs/build.props\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.cpp\n* lang/cs/Org.Apache.REEF.Driver/Constants.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.cpp\n* lang/cs/Org.Apache.REEF.Bridge/HttpServerClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/app.ico\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.filters\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj\n* lang/java/reef-bridge-java/src/main/java/org/apache/reef/javabridge/LibLoader.java\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.cpp\n* lang/cs/Org.Apache.REEF.Client/CLRBridgeClient.cs\n* lang/cs/Org.Apache.REEF.Bridge/FailedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.sln\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ReadMe.txt\n* lang/cs/Org.Apache.REEF.Bridge/ClosedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Org.Apache.REEF.Bridge.Clr.csproj\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropAssemblies.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ManagedLogger.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.cpp\n* lang/java/reef-common/src/main/java/org/apache/reef/runtime/common/files/REEFFileNames.java\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Client/Org.Apache.REEF.Client.csproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/ILogger.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ActiveContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropAssemblies.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Clr2JavaImpl.h\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.h\n* lang/cpp/reef-bridge-clr/pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/ActiveContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ReadMe.txt\n* lang/cs/Org.Apache.REEF.Bridge.JAR/Org.Apache.REEF.Bridge.JAR.csproj\n* lang/cs/.gitignore\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/IInteropReturnInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/CompletedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/HttpServerClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/SuspendedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedEvaluatorClr2Java.cpp\n* pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CommonUtilities.cpp\n* lang/cs/Org.Apache.REEF.sln\n* lang/cs/Org.Apache.REEF.Bridge/resource.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CommonUtilities.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.cpp\n"
            },
            {
                "author_name": "hudson",
                "id": "14368246",
                "body": "UNSTABLE: Integrated in Reef-pull-request-ubuntu #333 (See [https://builds.apache.org/job/Reef-pull-request-ubuntu/333/])\n[REEF-194]  Provide all needed dependencies for the bridge as NuGets (jwang98052: rev 275422f4c20d13883b8d3dfba742084d55f01d8e)\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.h\n* lang/cs/Org.Apache.REEF.Bridge/ContextMessageClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ManagedLogger.cpp\n* lang/cs/Org.Apache.REEF.Driver/Constants.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/EvaluatorRequestorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/IInteropReturnInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/FailedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ReadMe.txt\n* lang/java/reef-bridge-java/src/main/java/org/apache/reef/javabridge/LibLoader.java\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.h\n* lang/cs/.gitignore\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.cpp\n* pom.xml\n* lang/cs/build.props\n* lang/java/reef-common/src/main/java/org/apache/reef/runtime/common/files/REEFFileNames.java\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Org.Apache.REEF.Bridge.Clr.csproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CommonUtilities.cpp\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/ILogger.cs\n* lang/cpp/reef-bridge-clr/pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/RunningTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/resource.h\n* lang/cs/pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ClosedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ContextMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.h\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.nuspec\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropAssemblies.h\n* lang/cs/Org.Apache.REEF.sln\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.sln\n* lang/cs/Org.Apache.REEF.Bridge/Clr2JavaImpl.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.h\n* lang/cs/Org.Apache.REEF.Bridge/app.ico\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.h\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Properties/AssemblyInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/FailedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/HttpServerClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.h\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.h\n* lang/reef-bridge/.gitignore\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/SuspendedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj\n* lang/cs/Org.Apache.REEF.Bridge/EvaluatorRequestorClr2Java.cpp\n* lang/cpp/.gitignore\n* lang/cs/Org.Apache.REEF.Bridge/InteropAssemblies.h\n* lang/cs/Org.Apache.REEF.Bridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/Org.Apache.REEF.Driver.csproj\n* lang/cs/Org.Apache.REEF.Bridge/CompletedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/IInteropReturnInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/app.rc\n* lang/cs/Org.Apache.REEF.Bridge.JAR/Org.Apache.REEF.Bridge.JAR.csproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedEvaluatorClr2Java.cpp\n* lang/reef-bridge/pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ActiveContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/ILogger.cs\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.h\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/HttpServerClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CommonUtilities.cpp\n* lang/cs/Org.Apache.REEF.Client/CLRBridgeClient.cs\n* lang/cs/Org.Apache.REEF.Bridge/SuspendedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ClosedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Client/Org.Apache.REEF.Client.csproj\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.user\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ReadMe.txt\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/RunningTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ActiveContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.h\n"
            },
            {
                "author_name": "hudson",
                "id": "14368280",
                "body": "UNSTABLE: Integrated in Reef-pull-request-windows #173 (See [https://builds.apache.org/job/Reef-pull-request-windows/173/])\n[REEF-194]  Provide all needed dependencies for the bridge as NuGets (jwang98052: rev 275422f4c20d13883b8d3dfba742084d55f01d8e)\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedContextClr2Java.cpp\n* lang/cpp/.gitignore\n* lang/cs/Org.Apache.REEF.Bridge/ContextMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ClosedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/Constants.cs\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.h\n* lang/cs/Org.Apache.REEF.Bridge/TaskMessageClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CommonUtilities.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.h\n* lang/cs/Org.Apache.REEF.Client/Org.Apache.REEF.Client.csproj\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.cpp\n* lang/cs/Org.Apache.REEF.Bridge/resource.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/EvaluatorRequestorClr2Java.cpp\n* lang/cs/pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/TaskMessageClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ReadMe.txt\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj\n* lang/cs/Org.Apache.REEF.Bridge/RunningTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.h\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Properties/AssemblyInfo.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/SuspendedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ClosedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/HttpServerClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Driver/Org.Apache.REEF.Driver.csproj\n* lang/cs/Org.Apache.REEF.Bridge/app.ico\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ActiveContextClr2Java.cpp\n* lang/java/reef-bridge-java/src/main/java/org/apache/reef/javabridge/LibLoader.java\n* lang/cs/Org.Apache.REEF.Client/CLRBridgeClient.cs\n* lang/cs/.gitignore\n* lang/cs/build.props\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/RunningTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.h\n* lang/cs/Org.Apache.REEF.Bridge/Clr2JavaImpl.h\n* lang/reef-bridge/pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.user\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/IInteropReturnInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.nuspec\n* lang/cs/Org.Apache.REEF.Bridge/EvaluatorRequestorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/HttpServerClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedEvaluatorClr2Java.cpp\n* lang/reef-bridge/.gitignore\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/SuspendedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/app.rc\n* lang/cs/Org.Apache.REEF.Bridge/CommonUtilities.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyUtil.cpp\n* pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ManagedLogger.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Org.Apache.REEF.Bridge.Clr.csproj\n* lang/java/reef-common/src/main/java/org/apache/reef/runtime/common/files/REEFFileNames.java\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.h\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropAssemblies.h\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.h\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/ILogger.cs\n* lang/cpp/reef-bridge-clr/pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.sln\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/IInteropReturnInfo.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ContextMessageClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.h\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyUtil.cpp\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/ILogger.cs\n* lang/cs/Org.Apache.REEF.sln\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ActiveContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ReadMe.txt\n* lang/cs/Org.Apache.REEF.Bridge.JAR/Org.Apache.REEF.Bridge.JAR.csproj\n* lang/cs/Org.Apache.REEF.Bridge/InteropAssemblies.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.h\n"
            },
            {
                "author_name": "hudson",
                "id": "14370033",
                "body": "SUCCESS: Integrated in Reef-pull-request-ubuntu #334 (See [https://builds.apache.org/job/Reef-pull-request-ubuntu/334/])\n[REEF-194]  Provide all needed dependencies for the bridge as NuGets (jwang98052: rev 275422f4c20d13883b8d3dfba742084d55f01d8e)\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/SuspendedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/EvaluatorRequestorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/HttpServerClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj\n* lang/java/reef-bridge-java/src/main/java/org/apache/reef/javabridge/LibLoader.java\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ReadMe.txt\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/IInteropReturnInfo.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.sln\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.h\n* lang/reef-bridge/pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/RunningTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.h\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.user\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropLogger.h\n* pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj\n* lang/cs/Org.Apache.REEF.Bridge/ContextMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/JavaClrBridge.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.cpp\n* lang/cs/Org.Apache.REEF.Client/CLRBridgeClient.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/Clr2JavaImpl.h\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyUtil.cpp\n* lang/cs/Org.Apache.REEF.Driver/Org.Apache.REEF.Driver.csproj\n* lang/cs/Org.Apache.REEF.Bridge/ReadMe.txt\n* lang/cs/Org.Apache.REEF.Bridge/FailedTaskClr2Java.cpp\n* lang/java/reef-common/src/main/java/org/apache/reef/runtime/common/files/REEFFileNames.java\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.h\n* lang/cs/Org.Apache.REEF.Bridge/SuspendedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AssemblyUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CommonUtilities.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Org.Apache.REEF.Bridge.Clr.csproj\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ContextMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.vcxproj.filters\n* lang/cpp/.gitignore\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/BinaryUtil.cpp\n* lang/cs/Org.Apache.REEF.Bridge/AssemblyInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Org.Apache.REEF.Bridge.nuspec\n* lang/cpp/reef-bridge-clr/pom.xml\n* lang/cs/Org.Apache.REEF.Bridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cs/pom.xml\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropReturnInfo.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ClosedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/interface/ILogger.cs\n* lang/cs/Org.Apache.REEF.Driver/Constants.cs\n* lang/cs/.gitignore\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/ILogger.cs\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.vcxproj.filters\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ClosedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/ActiveContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.h\n* lang/cs/Org.Apache.REEF.Bridge/InteropLogger.h\n* lang/cs/Org.Apache.REEF.Driver/InteropInterface/IInteropReturnInfo.cs\n* lang/cs/Org.Apache.REEF.Bridge/TaskMessageClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge.JAR/Org.Apache.REEF.Bridge.JAR.csproj\n* lang/cs/Org.Apache.REEF.Bridge/InteropAssemblies.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CompletedEvaluatorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/FailedContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/AllocatedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/CSharp/CSharp/ClrHandler/Properties/AssemblyInfo.cs\n* lang/cs/build.props\n* lang/cs/Org.Apache.REEF.Bridge/Stdafx.cpp\n* lang/cs/Org.Apache.REEF.sln\n* lang/cs/Org.Apache.REEF.Bridge/app.ico\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.cpp\n* lang/cs/Org.Apache.REEF.Bridge/HttpServerClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/RunningTaskClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ActiveContextClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/JavaClrBridge.h\n* lang/cs/Org.Apache.REEF.Bridge/InteropUtil.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/ManagedLogger.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropUtil.cpp\n* lang/reef-bridge/.gitignore\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedContextClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/CompletedEvaluatorClr2Java.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/BinaryUtil.h\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/CommonUtilities.cpp\n* lang/cs/Org.Apache.REEF.Bridge/EvaluatorRequestorClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/InteropReturnInfo.cpp\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/FailedTaskClr2Java.cpp\n* lang/cs/Org.Apache.REEF.Bridge/Clr2JavaImpl.h\n* lang/cs/Org.Apache.REEF.Client/Org.Apache.REEF.Client.csproj\n* lang/cs/Org.Apache.REEF.Bridge/resource.h\n* lang/cs/Org.Apache.REEF.Bridge/app.rc\n* lang/cpp/reef-bridge-clr/src/main/Cpp/CppBridge/JavaClrBridge/InteropAssemblies.h\n"
            },
            {
                "author_name": "markus.weimer",
                "id": "14483551",
                "body": "All sub-items are done, so this is done :-)"
            }
        ],
        "comments_predictions": [
            [
                830699,
                "REEF-194",
                "[~chris.douglas] and I spoke offline. It is probably fine to keep the JAR in our NuGets. I suggest to do the following:\n\n # Make a NuGet for our native and managed bridge DLLs. Probably {{Org.Apache.REEF.Bridge.dll}}\n # Make a NuGet that contains *only* the shaded JAR {{reef-bridge-java-0.11.0-incubating-SNAPSHOT-shaded.jar}}\n\nThat way we cleanly separate our code from the code we redistribute.\n\n[~chris.douglas], does this sound like a clean plan? Any Apache rules we need to be aware off when it comes to 3rd party binaries in our binary drops?",
                {
                    "property": {
                        "confidence": 0.0044419667683541775,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.013117462396621704,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0087082264944911,
                        "prediction": false
                    }
                }
            ],
            [
                830700,
                "REEF-194",
                "From a licensing perspective, that should be [OK|www.apache.org/dev/licensing-howto.html]. Developing on REEF might be easier if dependencies could be downloaded and cached, but (AIUI) this is not prohibited.\n\nThe difficulty is verification. Project members can easily verify source, but verifying jars is impractical. Since REEF is building this artifact itself, I suppose the validation could be by construction.",
                {
                    "property": {
                        "confidence": 0.006508976686745882,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006006120704114437,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02198493294417858,
                        "prediction": false
                    }
                }
            ],
            [
                830704,
                "REEF-194",
                "This Jira is to make a NuGet for our native and managed bridge DLL - Org.Apache.REEF.Bridge.dll. The change would cover:\n\nMove files in lang\\cpp module into Org.Apache.REEF.sln as a project Org.Apache.REEF.Bridge . The dependency on Driver.dll should be set within Org.Apache.REEF.Bridge.sln\nCreate NuGet for the Org.Apache.REEF.Bridge.dll\nFrom REEF.Client, reference jar file from lang\\java\\reef-bridge-java to remove the dependency on lang\\reef-bridge \nAs the jar file doesn't contain the clr dll any more, modify libLoader to load clr dll properly. \nRemove lang\\cpp and lang\\reef-bridge \nTest REEF.client for E2E. ",
                {
                    "property": {
                        "confidence": 0.0025933512952178717,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.02820749394595623,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02045370824635029,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5fe83f4d395ee2220633f",
        "key": "HIVE-21764",
        "id": "13234518",
        "description": "REPL DUMP fetches the events from NOTIFICATION_LOG table based on regular expression + inclusion/exclusion list. So, in case of rename table event, the event will be ignored if old table doesn't match the pattern but the new table should be bootstrapped. REPL DUMP should have a mechanism to detect such tables and automatically bootstrap with incremental replication.Also, if renamed table is excluded from replication policy, then need to drop the old table at target as well.\u00a0\r\n\r\nThere are 4 scenarios that needs to be handled.\r\n # Both new name and old name satisfies the table name pattern filter.\r\n ## No need to do anything. The incremental event for rename should take care of the replication.\r\n # Both the names does not satisfy the table name pattern filter.\r\n ## Both the names are not in the scope of the policy and thus nothing needs to be done.\r\n # New name satisfies the pattern but the old name does not.\r\n ## The table will not be present at the target.\r\n ## Rename event handler for dump should detect this case and add the new table name to the list of table for bootstrap.\r\n ## All the events related to the table (new name) should be ignored.\r\n ## If there is a drop event for the table (with new name), then remove the table from the list of tables to be bootstrapped.\r\n ## In case of rename (double rename)\r\n ### If the new name satisfies the table pattern, then add the new name to the list of tables to be bootstrapped and remove the old name from the list of tables to be bootstrapped.\r\n ### If the new name does not satisfies then just removed the table name from the list of tables to be bootstrapped.\r\n # New name does not satisfies the pattern but the old name satisfies.\r\n ## Change the rename event to a drop event.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006475065369158983
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.7834129929542542
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.020440131425857544
                }
            }
        },
        "comments": [
            {
                "author_name": "hiveqa",
                "id": "16868287",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 37s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 24s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 48s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 27s{color} | {color:green} master passed {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  2m 37s{color} | {color:blue} standalone-metastore/metastore-common in master has 31 extant Findbugs warnings. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  1m 11s{color} | {color:blue} standalone-metastore/metastore-server in master has 184 extant Findbugs warnings. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  4m  8s{color} | {color:blue} ql in master has 2253 extant Findbugs warnings. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 41s{color} | {color:blue} itests/hive-unit in master has 2 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 47s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 30s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m 52s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 43s{color} | {color:red} ql: The patch generated 4 new + 39 unchanged - 0 fixed = 43 total (was 39) {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 17s{color} | {color:red} itests/hive-unit: The patch generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  9m 11s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 41s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 46m 19s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2+deb8u5 (2017-09-19) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-17666/dev-support/hive-personality.sh |\r\n| git revision | master / c3d0502 |\r\n| Default Java | 1.8.0_111 |\r\n| findbugs | v3.0.0 |\r\n| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-17666/yetus/diff-checkstyle-ql.txt |\r\n| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-17666/yetus/diff-checkstyle-itests_hive-unit.txt |\r\n| modules | C: standalone-metastore/metastore-common standalone-metastore/metastore-server ql itests/hive-unit U: . |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-17666/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hiveqa",
                "id": "16868298",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12972285/HIVE-21764.01.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:green}SUCCESS:{color} +1 due to 16174 tests passed\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/17666/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/17666/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-17666/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12972285 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16869444",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 54s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 15s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 51s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 27s{color} | {color:green} master passed {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  2m 40s{color} | {color:blue} standalone-metastore/metastore-common in master has 31 extant Findbugs warnings. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  1m 10s{color} | {color:blue} standalone-metastore/metastore-server in master has 179 extant Findbugs warnings. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  4m  7s{color} | {color:blue} ql in master has 2254 extant Findbugs warnings. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 40s{color} | {color:blue} itests/hive-unit in master has 2 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 54s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 30s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 17s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 40s{color} | {color:red} ql: The patch generated 1 new + 39 unchanged - 0 fixed = 40 total (was 39) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  9m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 47s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 46m 50s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2+deb8u5 (2017-09-19) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-17686/dev-support/hive-personality.sh |\r\n| git revision | master / 9890919 |\r\n| Default Java | 1.8.0_111 |\r\n| findbugs | v3.0.0 |\r\n| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-17686/yetus/diff-checkstyle-ql.txt |\r\n| modules | C: standalone-metastore/metastore-common standalone-metastore/metastore-server ql itests/hive-unit U: . |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-17686/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hiveqa",
                "id": "16869453",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12972430/HIVE-21764.02.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 6 failed/errored test(s), 16339 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.ql.parse.TestTableLevelReplicationScenarios.testBasicReplaceReplPolicy (batchId=255)\norg.apache.hadoop.hive.ql.parse.TestTableLevelReplicationScenarios.testCaseInSensitiveNatureOfReplPolicy (batchId=255)\norg.apache.hadoop.hive.ql.parse.TestTableLevelReplicationScenarios.testIncorrectTablePolicyInReplDump (batchId=255)\norg.apache.hadoop.hive.ql.parse.TestTableLevelReplicationScenarios.testReplacePolicyOnBootstrapAcidTablesIncrementalPhase (batchId=255)\norg.apache.hadoop.hive.ql.parse.TestTableLevelReplicationScenarios.testReplacePolicyOnBootstrapExternalTablesIncrementalPhase (batchId=255)\norg.apache.hadoop.hive.ql.parse.TestTableLevelReplicationScenarios.testReplacePolicyWhenAcidTablesDisabledForRepl (batchId=255)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/17686/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/17686/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-17686/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 6 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12972430 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "16869834",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n|| || || || {color:brown} master Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 58s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 22s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 18s{color} | {color:green} master passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 16s{color} | {color:green} master passed {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  1m 13s{color} | {color:blue} standalone-metastore/metastore-server in master has 179 extant Findbugs warnings. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  4m  8s{color} | {color:blue} ql in master has 2254 extant Findbugs warnings. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m 42s{color} | {color:blue} itests/hive-unit in master has 2 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 47s{color} | {color:green} master passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 29s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 42s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green}  2m 17s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green}  2m 17s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 17s{color} | {color:red} standalone-metastore/metastore-server: The patch generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 22s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 47s{color} | {color:green} the patch passed {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black} 36m 57s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Optional Tests |  asflicense  javac  javadoc  findbugs  checkstyle  compile  |\r\n| uname | Linux hiveptest-server-upstream 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2+deb8u5 (2017-09-19) x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /data/hiveptest/working/yetus_PreCommit-HIVE-Build-17691/dev-support/hive-personality.sh |\r\n| git revision | master / 9890919 |\r\n| Default Java | 1.8.0_111 |\r\n| findbugs | v3.0.0 |\r\n| checkstyle | http://104.198.109.242/logs//PreCommit-HIVE-Build-17691/yetus/diff-checkstyle-standalone-metastore_metastore-server.txt |\r\n| modules | C: standalone-metastore/metastore-server ql itests/hive-unit U: . |\r\n| Console output | http://104.198.109.242/logs//PreCommit-HIVE-Build-17691/yetus.txt |\r\n| Powered by | Apache Yetus    http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "hiveqa",
                "id": "16869853",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12972455/HIVE-21764.03.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:green}SUCCESS:{color} +1 due to 16339 tests passed\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/17691/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/17691/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-17691/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.YetusPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12972455 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sankarh",
                "id": "16870052",
                "body": "+1,  [^HIVE-21764.03.patch] LGTM"
            },
            {
                "author_name": "maheshk114",
                "id": "16870507",
                "body": "[^HIVE-21764.03.patch]\u00a0committed to master. Thanks [~sankarh] for review."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d615b4f4d395ee22238923",
        "key": "EXTCDI-295",
        "id": "12560420",
        "description": null,
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d622d1f4d395ee22255c22",
        "key": "CAMEL-3753",
        "id": "12500499",
        "description": "Using durable subscribers, the clientId must be configured as well, so the broker knows who the client is.\nHowever some JMS providers mandates the client id to be configured on the JMS ConnectionFactory instead.\n\nSo we should relax this check in camel-jms\n\nSee nabble\nhttp://camel.465427.n5.nabble.com/Camel-GlassFish-and-durable-subscriber-tp3408634p3408634.html",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012328637763857841
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01614725962281227
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005525699816644192
                }
            }
        },
        "comments": [
            {
                "author_name": "davsclaus",
                "id": "13002949",
                "body": "trunk: 1078241."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d610a2f4d395ee2222e485",
        "key": "FLEX-29842",
        "id": "12590716",
        "description": "Steps to reproduce:\n1. record the application.\n2. you see no source is generated\n3.\n \n Actual Results:\n No script is genertated\n \n Expected Results:\n need to generate the script for flex controls identifycation\n \n Workaround (if any):",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13383886",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/FLEXENT-840\nOriginal Reporter: mvichu\nOriginal Resolution: Duplicate\nDiscoverability: High\nNumber of votes: 2\nReproducibility: Every Time\nSeverity: Usability Issue\nreporter: mvichu"
            },
            {
                "author_name": "adobejira",
                "id": "13383885",
                "body": "created: 2008-11-10 14:10:15.000\nupdated: 2011-06-29 23:26:46.000"
            },
            {
                "author_name": "adobejira",
                "id": "13383884",
                "body": "On 2008-11-17 04:22:24.043 svakil commented:\nHi  I think the reason you are facing this issue is because you are not compiling your flex application with automation swcs.Please refere this link http://labs.adobe.com/wiki/index.php/Flex_3:Release_Notes#Installing_and_Configuring_Flex_Automated_Testing\nOn 2008-11-17 04:33:40.299 svakil commented:\nPlease let me know if your issue still persists after trying the above option.\nOn 2009-03-10 04:29:58.227 avula12345 commented:\nEven i am also facing the same issue. Even after compiling the application with necessary automation libraries still my problem persiste. Please tell me any other solution."
            }
        ],
        "comments_predictions": [
            [
                2973358,
                "FLEX-29842",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/FLEXENT-840\nOriginal Reporter: mvichu\nOriginal Resolution: Duplicate\nDiscoverability: High\nNumber of votes: 2\nReproducibility: Every Time\nSeverity: Usability Issue\nreporter: mvichu",
                {
                    "property": {
                        "confidence": 0.00485091470181942,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.07532630115747452,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012581744231283665,
                        "prediction": false
                    }
                }
            ],
            [
                2973360,
                "FLEX-29842",
                "On 2008-11-17 04:22:24.043 svakil commented:\nHi  I think the reason you are facing this issue is because you are not compiling your flex application with automation swcs.Please refere this link http://labs.adobe.com/wiki/index.php/Flex_3:Release_Notes#Installing_and_Configuring_Flex_Automated_Testing\nOn 2008-11-17 04:33:40.299 svakil commented:\nPlease let me know if your issue still persists after trying the above option.\nOn 2009-03-10 04:29:58.227 avula12345 commented:\nEven i am also facing the same issue. Even after compiling the application with necessary automation libraries still my problem persiste. Please tell me any other solution.",
                {
                    "property": {
                        "confidence": 0.0040441593155264854,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008611036464571953,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.017472142353653908,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640743bec8b42db502d2b0e1",
        "key": "HIVE-19866",
        "id": "13165474",
        "description": "1) Memory needs to be accounted for.\r\n2) LRFU eviction doesn't need to maintain state between individual removals.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.011069304309785366
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009902547113597393
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008971664123237133
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "6407448e95dd29065733b383",
        "key": "HUDI-2634",
        "id": "13408652",
        "description": "Existing bootstrap code lists all files in the dataset and caches a FileStatus object for each file found. FileStatus object has many fields which take memory and most of these fields are not even used later as part of bootstrap.\r\n\r\nFor a very large production table, the bootstrap code fails with OOM and also leads to timeout as a very large number of executors are spawned.\r\n\r\nDataset has 1299 partitions and 12Million files.\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.016826728358864784
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.03830299153923988
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.3708079755306244
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f565f4d395ee221ef46e",
        "key": "KAFKA-6360",
        "id": "13124650",
        "description": "When a store is re-initialized it is first closed, before it is opened again. When this happens the segments in the {{Segments}} class are closed, but they are not removed from the list of segments. So when the store is re-initialized the old closed segments are used. This results in:\r\n{code}\r\n[2017-12-13 09:29:32,037] ERROR [streams-saak-test-client-StreamThread-3] task [1_3] Failed to flush state store KSTREAM-AGGREGATE-STATE-STORE-0000000024:  (org.apache.kafka.streams.processor.internals.ProcessorStateManager)\r\norg.apache.kafka.streams.errors.InvalidStateStoreException: Store KSTREAM-AGGREGATE-STATE-STORE-0000000024.1513080000000 is currently closed\r\n        at org.apache.kafka.streams.state.internals.RocksDBStore.validateStoreOpen(RocksDBStore.java:241)\r\n        at org.apache.kafka.streams.state.internals.RocksDBStore.put(RocksDBStore.java:289)\r\n        at org.apache.kafka.streams.state.internals.RocksDBSegmentedBytesStore.put(RocksDBSegmentedBytesStore.java:102)\r\n        at org.apache.kafka.streams.state.internals.RocksDBSessionStore.put(RocksDBSessionStore.java:122)\r\n        at org.apache.kafka.streams.state.internals.ChangeLoggingSessionBytesStore.put(ChangeLoggingSessionBytesStore.java:78)\r\n        at org.apache.kafka.streams.state.internals.ChangeLoggingSessionBytesStore.put(ChangeLoggingSessionBytesStore.java:33)\r\n        at org.apache.kafka.streams.state.internals.CachingSessionStore.putAndMaybeForward(CachingSessionStore.java:179)\r\n        at org.apache.kafka.streams.state.internals.CachingSessionStore.access$000(CachingSessionStore.java:38)\r\n        at org.apache.kafka.streams.state.internals.CachingSessionStore$1.apply(CachingSessionStore.java:88)\r\n        at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:142)\r\n        at org.apache.kafka.streams.state.internals.NamedCache.flush(NamedCache.java:100)\r\n        at org.apache.kafka.streams.state.internals.ThreadCache.flush(ThreadCache.java:127)\r\n        at org.apache.kafka.streams.state.internals.CachingSessionStore.flush(CachingSessionStore.java:196)\r\n{code}\r\n",
        "predictions": {},
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16290670",
                "body": "GitHub user dguy opened a pull request:\n\n    https://github.com/apache/kafka/pull/4324\n\n    KAFKA-6360: Clear RocksDB Segments when store is closed \n\n    Now that we support re-initializing state stores, we need to clear the segments when the store is closed so that they can be re-opened.\r\n    \r\n    ### Committer Checklist (excluded from commit message)\r\n    - [ ] Verify design and implementation \r\n    - [ ] Verify test coverage and CI build status\r\n    - [ ] Verify documentation (including upgrade notes)\r\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/dguy/kafka kafka-6360\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/kafka/pull/4324.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #4324\n    \n----\ncommit 4c84af7522d847f82b14e5b3b4c589b0223a5bd8\nAuthor: Damian Guy <damian.guy@gmail.com>\nDate:   2017-12-14T10:13:44Z\n\n    clear segments on close\n\n----\n"
            },
            {
                "author_name": "guozhang",
                "id": "16291262",
                "body": "Issue resolved by pull request 4324\n[https://github.com/apache/kafka/pull/4324]"
            },
            {
                "author_name": "githubbot",
                "id": "16291263",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/kafka/pull/4324\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d2edf4d395ee221838c0",
        "key": "ZEPPELIN-372",
        "id": "12908471",
        "description": "Exporting a notebook in a JSON format, which can later be used/imported in a different environment.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.05546822398900986
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.010866115801036358
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0036296125035732985
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "14979942",
                "body": "GitHub user prabhjyotsingh opened a pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376\n\n    ZEPPELIN-372 : Exporting a notebook\n\n    Exporting a notebook in a JSON format, which can later be used/imported in a different environment.\n    \n    <img width=\"203\" alt=\"screen shot 2015-10-29 at 12 29 41 pm\" src=\"https://cloud.githubusercontent.com/assets/674497/10812117/d6611b82-7e38-11e5-9074-d14eebf19e72.png\">\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/prabhjyotsingh/incubator-zeppelin ZEPPELIN-372\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/incubator-zeppelin/pull/376.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #376\n    \n----\ncommit 90bf37f2e1814b9ae422ee038d8577d5c75cc79a\nAuthor: Prabhjyot Singh <prabhjyotsingh@gmail.com>\nDate:   2015-10-29T06:58:37Z\n\n    ZEPPELIN-372 : Exporting a notebook in a JSON format, which can later be used/imported in a different environment.\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "14981033",
                "body": "Github user felixcheung commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-152285554\n  \n    should we have a test for export/import round tripping?\n"
            },
            {
                "author_name": "githubbot",
                "id": "14981944",
                "body": "Github user prabhjyotsingh commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-152422838\n  \n    Yes, I intend to write a selenium test case, once both are merged.\n"
            },
            {
                "author_name": "githubbot",
                "id": "14985290",
                "body": "Github user Leemoonsoo commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-153032636\n  \n    Tested and working well. Could you rebase and trigger CI?\n"
            },
            {
                "author_name": "githubbot",
                "id": "14986892",
                "body": "Github user corneadoug commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-153285794\n  \n    This was a merge, not a rebase\n"
            },
            {
                "author_name": "githubbot",
                "id": "14986948",
                "body": "Github user prabhjyotsingh closed the pull request at:\n\n    https://github.com/apache/incubator-zeppelin/pull/376\n"
            },
            {
                "author_name": "githubbot",
                "id": "14986950",
                "body": "GitHub user prabhjyotsingh reopened a pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376\n\n    ZEPPELIN-372 : Exporting a notebook\n\n    Exporting a notebook in a JSON format, which can later be used/imported in a different environment.\n    \n    <img width=\"203\" alt=\"screen shot 2015-10-29 at 12 29 41 pm\" src=\"https://cloud.githubusercontent.com/assets/674497/10812117/d6611b82-7e38-11e5-9074-d14eebf19e72.png\">\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/prabhjyotsingh/incubator-zeppelin ZEPPELIN-372\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/incubator-zeppelin/pull/376.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #376\n    \n----\ncommit 462e733f355d9e67113dc97d711e7928eb4dc27f\nAuthor: Prabhjyot Singh <prabhjyotsingh@gmail.com>\nDate:   2015-11-03T09:01:39Z\n\n    ZEPPELIN-372 : Exporting a notebook in a JSON format, which can later be used/imported in a different environment.\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "14991144",
                "body": "Github user Leemoonsoo commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-153959750\n  \n    Thanks for really useful feature.\n    Merge if there're no more discussions\n"
            },
            {
                "author_name": "githubbot",
                "id": "14994793",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/incubator-zeppelin/pull/376\n"
            },
            {
                "author_name": "githubbot",
                "id": "14995582",
                "body": "Github user corneadoug commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-154801136\n  \n    Too bad it doesn't work on Firefox and Safari\n"
            },
            {
                "author_name": "githubbot",
                "id": "14995611",
                "body": "GitHub user prabhjyotsingh opened a pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/408\n\n    ZEPPELIN-372 : fix for not working on Firefox and Safari\n\n    With reference to bug in https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-154801136\n    have made a fix, this should enable download on Firefox and Safari\n\n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/prabhjyotsingh/incubator-zeppelin ZEPPELIN-372_fix\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/incubator-zeppelin/pull/408.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #408\n    \n----\ncommit 91fd7f9053312a0d4cdecf2fa3afbdbee1fd2bb6\nAuthor: Prabhjyot Singh <prabhjyotsingh@gmail.com>\nDate:   2015-11-08T11:42:11Z\n\n    fix for not working on Firefox and Safari\n\n----\n"
            },
            {
                "author_name": "githubbot",
                "id": "14995612",
                "body": "Github user prabhjyotsingh commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-154810277\n  \n    @corneadoug thank you for finding this issue, have made another pr https://github.com/apache/incubator-zeppelin/pull/408 with the fix.\n"
            },
            {
                "author_name": "githubbot",
                "id": "14996049",
                "body": "Github user corneadoug commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/408#issuecomment-154930641\n  \n    Tested.\n    * Firefox good\n    * Safari download a file with name _Unknow_ but seems we can't do anything about it.\n    \n    Any chance to also have a IE version? (IE10+)\n"
            },
            {
                "author_name": "githubbot",
                "id": "14996347",
                "body": "Github user prabhjyotsingh commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/408#issuecomment-155024821\n  \n    @corneadoug thanks for the review, never thought of IE, have made a fix for Edge (Windows 10)\n"
            },
            {
                "author_name": "githubbot",
                "id": "14997970",
                "body": "Github user corneadoug commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/408#issuecomment-155294490\n  \n    I tried with IE10, but nothing happened\n"
            },
            {
                "author_name": "githubbot",
                "id": "14998062",
                "body": "Github user prabhjyotsingh commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/408#issuecomment-155321159\n  \n    @corneadoug sure that make sense, and have also refactored that as well, now any one can call it as a service as well.\n    Thanks.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15001797",
                "body": "Github user corneadoug commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/408#issuecomment-156024985\n  \n    Tested on: Firefox, Chrome, Opera, Safari, IE10\n    Good to Merge.\n    Will be merging tomorrow if there is no more discussions\n"
            },
            {
                "author_name": "githubbot",
                "id": "15003352",
                "body": "Github user corneadoug commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/408#issuecomment-156288853\n  \n    @prabhjyotsingh it seems I can't merge it directly, could you do a rebase?\n"
            },
            {
                "author_name": "githubbot",
                "id": "15006308",
                "body": "Github user asfgit closed the pull request at:\n\n    https://github.com/apache/incubator-zeppelin/pull/408\n"
            },
            {
                "author_name": "githubbot",
                "id": "15115312",
                "body": "Github user bpirvu commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-174528840\n  \n    Is there any documentation for this feature? I wasn't able to find it...\n"
            },
            {
                "author_name": "githubbot",
                "id": "15117820",
                "body": "Github user felixcheung commented on the pull request:\n\n    https://github.com/apache/incubator-zeppelin/pull/376#issuecomment-175193771\n  \n    @bpirvu - it's probably best if you email the dev list (https://zeppelin.incubator.apache.org/community.html) for questions like this in the future - PR once it is closed might not be monitored.\n\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640744b195dd29065733b7cc",
        "key": "BEAM-14189",
        "id": "13436169",
        "description": "This was created by mistake due to login session expiration. See BEAM-14187 for original.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02352657914161682
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007971699349582195
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00435546413064003
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5fc52f4d395ee222016e9",
        "key": "IGNITE-4957",
        "id": "13063781",
        "description": "When there are many caches deployed on server nodes and a query containing joins is executed on a client for the first time then it takes much time to complete compared to the following executions.\n\nIf caches aren't enabled locally then the first query tries to load all the missing caches by calling\n{{org.apache.ignite.internal.processors.cache.GridCacheProcessor#createMissingCaches}}\n{{createMissingCaches}} internally sends a request per each registered but not enabled cache.\nPerformance could be improved by performing a batch request.\n\nVisualVM results for the first join query run are below\n!first_run_from_client.png!",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0058051045052707195
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.03250708058476448
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.47964733839035034
                }
            }
        },
        "comments": [
            {
                "author_name": "asfedotov",
                "id": "15967558",
                "body": "First join query run on a client"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e26af4d395ee221be32f",
        "key": "QPID-4272",
        "id": "12605579",
        "description": null,
        "predictions": {},
        "comments": [
            {
                "author_name": "astitcher",
                "id": "13483013",
                "body": "With checkins r1401558-r1401561 this is now greatly improved, with the only significant duplication left in the client SslConnector.cpp and TCPConnector.cpp code."
            },
            {
                "author_name": "astitcher",
                "id": "13483016",
                "body": "There are only small amounts of duplicated code left"
            },
            {
                "author_name": "pmoravec",
                "id": "14613683",
                "body": "The duplicate code removal is fine, but it hides error code / description coming from SSL. Originally:\n\n{code}\ncpp/src/qpid/sys/ssl/SslIo.cpp:\nQPID_LOG(error, \"Error reading socket: \" << getErrorString(PR_GetError()));\n{code}\n\nnow:\n{code}\ncpp/src/qpid/sys/posix/AsynchIO.cpp:\nQPID_LOG(error, \"Error reading socket: \" << qpid::sys::strError(errno) << \"(\" << errno << \")\" );\n{code}\n\nThat means, most of nicely descripted SSL errors like:\n\n{code}\nError reading socket: SSL peer cannot verify your certificate. [-12271]\n{code}\n\nare hidden in generous:\n{code}\nError reading socket: Success(0)\n{code}\n\n\nCould be these SSL errors put back?"
            },
            {
                "author_name": "astitcher",
                "id": "14615588",
                "body": "I don't really see how reopening this resolved (nearly 3 years ago) piece of work is relevant.\n\nThe bug you are referring to here is QPID-6435. And it already has a link to this Issue. It could have been helpful to make this comment on that Issue, as it does give some extra information."
            },
            {
                "author_name": "astitcher",
                "id": "14615591",
                "body": "The reopening of this piece of work makes no sense - there is already a bug being tracked."
            },
            {
                "author_name": "pmoravec",
                "id": "14616348",
                "body": "Ah sorry, didnt know the new JIRA."
            }
        ],
        "comments_predictions": [
            [
                869239,
                "QPID-4272",
                "The duplicate code removal is fine, but it hides error code / description coming from SSL. Originally:\n\n{code}\ncpp/src/qpid/sys/ssl/SslIo.cpp:\nQPID_LOG(error, \"Error reading socket: \" << getErrorString(PR_GetError()));\n{code}\n\nnow:\n{code}\ncpp/src/qpid/sys/posix/AsynchIO.cpp:\nQPID_LOG(error, \"Error reading socket: \" << qpid::sys::strError(errno) << \"(\" << errno << \")\" );\n{code}\n\nThat means, most of nicely descripted SSL errors like:\n\n{code}\nError reading socket: SSL peer cannot verify your certificate. [-12271]\n{code}\n\nare hidden in generous:\n{code}\nError reading socket: Success(0)\n{code}\n\n\nCould be these SSL errors put back?",
                {
                    "property": {
                        "confidence": 0.006598414853215218,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0047555542550981045,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.015344124287366867,
                        "prediction": false
                    }
                }
            ],
            [
                869240,
                "QPID-4272",
                "I don't really see how reopening this resolved (nearly 3 years ago) piece of work is relevant.\n\nThe bug you are referring to here is QPID-6435. And it already has a link to this Issue. It could have been helpful to make this comment on that Issue, as it does give some extra information.",
                {
                    "property": {
                        "confidence": 0.005709552671760321,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0052545154467225075,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.021962104365229607,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640743e0342d895c2bd2b196",
        "key": "CALCITE-2959",
        "id": "13224234",
        "description": "Currently, the class {{RelFieldCollation}} is used to define _\"the ordering of one field of a RelNode whose output is to be sorted\"_. This representation can hold only \"simple\" fields. In case of struct fields, a projection needs to be applied in order to reference the struct field as a simple one. For example, given this table:\r\n{code}\r\nCREATE TYPE Address AS (\r\n  street VARCHAR(20) NOT NULL, \r\n  zipcode VARCHAR(20) NOT NULL,\r\n  city VARCHAR(20) NOT NULL);\r\n\r\nCREATE TABLE Person (\r\n  id VARCHAR(20) NOT NULL,\r\n  name VARCHAR(20) NOT NULL,\r\n  address Address NOT NULL);\r\n{code}\r\n\r\nWith a SQL query such as: \"{{SELECT p.name, p.address.city FROM Person p ORDER BY p.address.city}}\" the pseudo-plan generated would look like:\r\n{code}\r\nSort(1)  // --> Collation: [1]\r\n  Project(0=$1, 1=$2.city)\r\n    Scan(table=Person)\r\n{code}\r\n\r\nHowever, what would happen if we had a specific Scan operator that would guarantee us that the records would be scanned already ordered by address.city? Something like:\r\n{code}\r\nEnhancedScan(table=Person, sort=$2.city)  // --> Collation???\r\n{code}\r\nThe collation of such an operator cannot be represented with the current Calcite capabilities (RelFieldCollation), because it would not be a \"simple\" field, but a struct field, i.e. we would need a new collation abstraction to represent it, e.g. [2.city] or [2.2]\r\n\r\nI would like to open the discussion to see if / how we could find a solution to represent this case.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.005045471712946892
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.12695015966892242
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004652666859328747
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d3edf4d395ee221862d6",
        "key": "YARN-2595",
        "id": "12743769",
        "description": "2014-08-03 09:45:55,110 FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread \njava.lang.NullPointerException \nat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.writeAuditLog(RMAppManager.java:221) \nat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.finishApplication(RMAppManager.java:213) \nat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:480) \nat org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:71) \nat org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173) \nat org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106) \nat java.lang.Thread.run(Thread.java:662) \n2014-08-03 09:45:55,111 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=testos OPERATION=refreshAdminAcls TARGET=AdminService RESULT=SUCCESS ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.012606137432157993
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006882362999022007
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005510266870260239
                }
            }
        },
        "comments": [
            {
                "author_name": "devaraj",
                "id": "14146263",
                "body": "[~nishan] Thanks for reporting this issue. Can you also provide the resource manager log or at least some log content above this exception? Thanks.."
            },
            {
                "author_name": "nishan",
                "id": "14147320",
                "body": "Hi [~devaraj.k] Sorry i could not attach logs since the cluster is deleted. I will try to reproduce the same "
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640754445336c1673167fb31",
        "key": "INFRA-13477",
        "id": "13041004",
        "description": "The Apache Thrift project has a Travis CI build matrix with 24 builds:\n\nhttps://travis-ci.org/apache/thrift/builds/199234155\n\nSince we only have 30 concurrent executors, I recommend limiting concurrent builds to 5 or 10 (we have done 5 for Flink and Zeppelin).",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5dc7af4d395ee221aa607",
        "key": "SPARK-11892",
        "id": "12915003",
        "description": "Implement read/write for OneVsRest estimator and its model.\n\nWhen this is implemented, {{CrossValidatorReader.getUidMap}} should be updated as needed.",
        "predictions": {},
        "comments": [
            {
                "author_name": "yinxusen",
                "id": "15020440",
                "body": "I'll take this."
            },
            {
                "author_name": "yinxusen",
                "id": "15020458",
                "body": "The OneVsRest is dependent on SPARK-6791 since I need the modifications in DefaultParamsWriter, such as DefaultParamsWriter.saveMetadata(instance: Params, path: String, sc: SparkContext, extraMetadata: Option[JObject] = None,  paramMap: Option[JValue] = None).\n\nI'll give pull request after the SPARK-6791 merged."
            },
            {
                "author_name": "apachespark",
                "id": "15024582",
                "body": "User 'yinxusen' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/9934"
            },
            {
                "author_name": "josephkb",
                "id": "15220366",
                "body": "Issue resolved by pull request 9934\n[https://github.com/apache/spark/pull/9934]"
            }
        ],
        "comments_predictions": [
            [
                674227,
                "SPARK-11892",
                "The OneVsRest is dependent on SPARK-6791 since I need the modifications in DefaultParamsWriter, such as DefaultParamsWriter.saveMetadata(instance: Params, path: String, sc: SparkContext, extraMetadata: Option[JObject] = None,  paramMap: Option[JValue] = None).\n\nI'll give pull request after the SPARK-6791 merged.",
                {
                    "property": {
                        "confidence": 0.004742399323731661,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0052972943522036076,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.036023758351802826,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5edc6f4d395ee221dbcb1",
        "key": "MINIFI-407",
        "id": "13111498",
        "description": "The sample configurations in the System Administrator Guide (https://nifi.apache.org/minifi/system-admin-guide.html) need updated. MiNiFi complains about names/IDs when trying to use them in the latest MiNiFi.",
        "predictions": {},
        "comments": [
            {
                "author_name": "jzemerick",
                "id": "16280240",
                "body": "I tried the two example configs from https://nifi.apache.org/minifi/system-admin-guide.html with MiNiFi 0.2.1-SNAPSHOT and I could not reproduce what I was seeing before so the problem must have been on my end."
            }
        ],
        "comments_predictions": [
            [
                1353043,
                "MINIFI-407",
                "I tried the two example configs from https://nifi.apache.org/minifi/system-admin-guide.html with MiNiFi 0.2.1-SNAPSHOT and I could not reproduce what I was seeing before so the problem must have been on my end.",
                {
                    "property": {
                        "confidence": 0.0058961533941328526,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00529814139008522,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.015348325483500957,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "64074464d69a44c13533b09e",
        "key": "YUNIKORN-396",
        "id": "13325671",
        "description": "We need to add a checklist of things in the yunikorn-release repo, to make the release process easier for the next release manager. Docs should go to: https://github.com/apache/incubator-yunikorn-release/blob/master/docs/release-procedure.md",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d627a5f4d395ee2226114e",
        "key": "AVRO-2595",
        "id": "13262041",
        "description": "The avro.txipc module in lang/py imports zope.interface and twisted, but setup.py does not require either. The Dockerfile we use in Travis definitely doesn't have zope.interface, so that means this module is certainly untested. If anyone is using it in the wild, they must be directly installing zope.interface on their own.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.6291216015815735
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.02041112817823887
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005335033405572176
                }
            }
        },
        "comments": [
            {
                "author_name": "kojiromike",
                "id": "16950646",
                "body": "Zope.interface is a fairly useful and common third party thing, but Avro's python implementation has mostly avoided third party dependencies, and I'd just as soon keep it that way for whatever my opinion is worth."
            },
            {
                "author_name": "kojiromike",
                "id": "16950647",
                "body": "Then again, as we've begun implementing some extra compression algorithms that are implemented separately, we should follow the pattern of using extras_require \u2013 we could implement txipc that way as well."
            },
            {
                "author_name": "jira-bot",
                "id": "16985532",
                "body": "Commit e3e41dcd27822ac3fd4692291d1bbea4f8a294dc in avro's branch refs/heads/master from Michael A. Smith\n[ https://gitbox.apache.org/repos/asf?p=avro.git;h=e3e41dc ]\n\nAVRO-2595: Remove Unusable Py3 Txipc (#716)\n\nThe Py3 package will be superseded by python"
            },
            {
                "author_name": "hudson",
                "id": "16985540",
                "body": "SUCCESS: Integrated in Jenkins build AvroJava #782 (See [https://builds.apache.org/job/AvroJava/782/])\nAVRO-2595: Remove Unusable Py3 Txipc (#716) (fokko: [https://github.com/apache/avro/commit/e3e41dcd27822ac3fd4692291d1bbea4f8a294dc])\n* (delete) lang/py3/avro/tests/txsample_http_client.py\n* (delete) lang/py3/avro/tests/txsample_http_server.py\n* (delete) lang/py3/avro/txipc.py\n"
            },
            {
                "author_name": "jira-bot",
                "id": "17025718",
                "body": "Commit 4006a7643c28a658bf2585761f64b4095aa51a71 in avro's branch refs/heads/branch-1.9 from Michael A. Smith\n[ https://gitbox.apache.org/repos/asf?p=avro.git;h=4006a76 ]\n\nAVRO-2595: Remove Unusable Py3 Txipc (#716)\n\nThe Py3 package will be superseded by python"
            }
        ],
        "comments_predictions": [
            [
                3714057,
                "AVRO-2595",
                "Zope.interface is a fairly useful and common third party thing, but Avro's python implementation has mostly avoided third party dependencies, and I'd just as soon keep it that way for whatever my opinion is worth.",
                {
                    "property": {
                        "confidence": 0.006228005979210138,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.15159866213798523,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.005424202885478735,
                        "prediction": false
                    }
                }
            ],
            [
                3714058,
                "AVRO-2595",
                "Then again, as we've begun implementing some extra compression algorithms that are implemented separately, we should follow the pattern of using extras_require \u2013 we could implement txipc that way as well.",
                {
                    "property": {
                        "confidence": 0.003759461920708418,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.049360454082489014,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012438466772437096,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5ff9bf4d395ee22207a04",
        "key": "HIVE-15910",
        "id": "13042897",
        "description": "Hive UT currently uses Derby DB with storage on disk which have some practical problems.\n1. The run-time of Hive unit tests are high as need to operate on the disk quite often.\n2. It can cause conflict if multiple test cases operates on the same table name (such as table being created already exist).\n\nTo solve these problems, we shall use an in-memory storage option of Derby DB which can be even persisted if the test case demands that.\nhttps://db.apache.org/derby/docs/10.8/devguide/cdevdvlpinmemdb.html",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.7105086445808411
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.09153177589178085
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.39310523867607117
                }
            }
        },
        "comments": [
            {
                "author_name": "sankarh",
                "id": "15865652",
                "body": "Modified the JDBC url to use in-memory derby DB."
            },
            {
                "author_name": "sankarh",
                "id": "15865655",
                "body": "[~thejas] [~wzheng] \nCan you please review the patch and help to commit?"
            },
            {
                "author_name": "githubbot",
                "id": "15865657",
                "body": "GitHub user sankarh opened a pull request:\n\n    https://github.com/apache/hive/pull/147\n\n    HIVE-15910: Improvements in Hive Unit Test by using In-memory Derby DB\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/sankarh/hive HIVE-15910\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/hive/pull/147.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #147\n    \n----\ncommit 4c6596e94524eb8ac0066e1371ed6ceb2c650036\nAuthor: Sankar Hariappan <mailtosankarh@gmail.com>\nDate:   2017-02-14T11:39:02Z\n\n    HIVE-15910: Improvements in Hive Unit Test by using In-memory Derby DB\n\n----\n"
            },
            {
                "author_name": "hiveqa",
                "id": "15865748",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12852552/HIVE-15910.01.patch\n\n{color:red}ERROR:{color} -1 due to no test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 11 failed/errored test(s), 10238 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBaseMissingBuckets (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableNoBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableLegacy (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableNoBase (batchId=246)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3538/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3538/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3538/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 11 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12852552 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "thejas",
                "id": "15866271",
                "body": "[~wzheng] [~sankarh]\n\nTestWorker failures seem to be new and likely related to this change. \nWei, any thoughts on why it cause those to fail ? Are we spawning another process from those ?\nWe could change the config for those tests if necessary."
            },
            {
                "author_name": "wzheng",
                "id": "15866361",
                "body": "We do start new thread which is common for these tests. Let me debug the error and update you."
            },
            {
                "author_name": "wzheng",
                "id": "15866405",
                "body": "Btw TestWorker tests all passed locally. Keep looking.."
            },
            {
                "author_name": "wzheng",
                "id": "15866433",
                "body": "Submit patch 2 to see what's the extra stuff"
            },
            {
                "author_name": "hiveqa",
                "id": "15866715",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12852638/HIVE-15910.2.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 11 failed/errored test(s), 10238 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationDrops.testDropTable (batchId=210)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBaseMissingBuckets (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableNoBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableLegacy (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableNoBase (batchId=246)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3545/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3545/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3545/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 11 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12852638 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "wzheng",
                "id": "15868289",
                "body": "patch 3 for debugging"
            },
            {
                "author_name": "hiveqa",
                "id": "15868548",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12852873/HIVE-15910.3.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 15 failed/errored test(s), 10238 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_auto_join1] (batchId=3)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join31] (batchId=81)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multiMapJoin2] (batchId=152)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join31] (batchId=133)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBaseMissingBuckets (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableNoBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableLegacy (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableNoBase (batchId=246)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3573/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3573/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3573/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 15 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12852873 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "wzheng",
                "id": "15868776",
                "body": "patch 4 for debugging"
            },
            {
                "author_name": "hiveqa",
                "id": "15869009",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12852925/HIVE-15910.4.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 10238 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_auto_join1] (batchId=3)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join31] (batchId=81)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multiMapJoin2] (batchId=152)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join31] (batchId=133)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBaseMissingBuckets (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableNoBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableLegacy (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableNoBase (batchId=246)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3581/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3581/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3581/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 14 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12852925 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "hiveqa",
                "id": "15869058",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12852925/HIVE-15910.4.patch\n\n{color:green}SUCCESS:{color} +1 due to 1 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 14 failed/errored test(s), 10238 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_auto_join1] (batchId=3)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join31] (batchId=81)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multiMapJoin2] (batchId=152)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join31] (batchId=133)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorPartitionWithBaseMissingBuckets (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableNoBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.majorTableWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableLegacy (batchId=246)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorTableNoBase (batchId=246)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3582/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3582/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3582/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 14 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12852925 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "sankarh",
                "id": "15869432",
                "body": "[~wzheng] I was able to reproduce some of TestWorker failures locally and noticed that the failures are happening when you run the same test case twice where the second execution sees non-empty table's directory under compactor_test_tables. There is DELETEONEXIT hook added which doesn't work for some reason. The double run of test cases could be due to TestWorker2 which extends TestWorker.\nFixed this issue by adding directory cleanup before creating new table. Patch-05 is provided with this change.\nPlease have a check."
            },
            {
                "author_name": "hiveqa",
                "id": "15870004",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12853001/HIVE-15910.05.patch\n\n{color:green}SUCCESS:{color} +1 due to 2 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 10 failed/errored test(s), 10238 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_auto_join1] (batchId=3)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join31] (batchId=81)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multiMapJoin2] (batchId=152)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[vector_if_expr] (batchId=140)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query14] (batchId=223)\norg.apache.hadoop.hive.cli.TestPerfCliDriver.testCliDriver[query23] (batchId=223)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join31] (batchId=133)\norg.apache.hadoop.hive.ql.txn.compactor.TestWorker.minorPartitionWithBase (batchId=246)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3597/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3597/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3597/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 10 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12853001 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "wzheng",
                "id": "15870293",
                "body": "Thanks [~sankarh] for finding this out! It makes sense.\n\nSeems you missed adding that deleteTableDir call for minorPartitionWithBase :) Maybe it's better to add tearDown to TestWorker to perform delete. [~ekoifman]"
            },
            {
                "author_name": "thejas",
                "id": "15870372",
                "body": "Added a comment in github pull request. Its simpler to just delete the temp dir where all tables are being created.\nAlso realized, that  tmpdir.deleteOnExit() doesn't work unless the dir is empty. That call would be useless. \n"
            },
            {
                "author_name": "thejas",
                "id": "15870399",
                "body": "In addition, I think we should look at the methods called in CompactorTest constructor.\nCompactorTest constructor would be called for every test function. Ie it is equivalent of '@Before' and not '@BeforeClass' .\nIt seems like some what is done there makes more sense in a '@BeforeClass' , so that its just done once. But I haven't taken a very close look at the tests, so I am not sure. Maybe this should be addressed in a follow up jira, and not this one. \n\ncc [~ekoifman] [~wzheng] [~gates]\n{code}\n    ms = new HiveMetaStoreClient(conf);\n    txnHandler = TxnUtils.getTxnStore(conf);\n    tmpdir = new File(System.getProperty(\"java.io.tmpdir\") +\n        System.getProperty(\"file.separator\") + \"compactor_test_tables\");\n    tmpdir.mkdir();\n    tmpdir.deleteOnExit();\n{code}"
            },
            {
                "author_name": "gates",
                "id": "15870462",
                "body": "Getting a new TxnHandler each time is good, as that will be sure to clean up any state.  I agree the rest of the lines above could probably be moved to a @BeforeClass method.\n\n\n"
            },
            {
                "author_name": "sankarh",
                "id": "15871718",
                "body": "[~thejas] [~wzheng]\nAdded Patch-06 with temp directory creation using Files.createTempDirectory method and also added @After methods to delete the temp directory after each test case.\nPlease review the same.\n\nWill add a follow-up JIRA to handle the CompactorTest constructor issue."
            },
            {
                "author_name": "hiveqa",
                "id": "15871999",
                "body": "\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12853254/HIVE-15910.06.patch\n\n{color:green}SUCCESS:{color} +1 due to 4 test(s) being added or modified.\n\n{color:red}ERROR:{color} -1 due to 30 failed/errored test(s), 10244 tests executed\n*Failed tests:*\n{noformat}\nTestDerbyConnector - did not produce a TEST-*.xml file (likely timed out) (batchId=235)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[cbo_rp_auto_join1] (batchId=3)\norg.apache.hadoop.hive.cli.TestCliDriver.testCliDriver[join31] (batchId=81)\norg.apache.hadoop.hive.cli.TestEncryptedHDFSCliDriver.testCliDriver[encryption_join_with_different_encryption_keys] (batchId=159)\norg.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[multiMapJoin2] (batchId=152)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[create_external_acid] (batchId=86)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[create_not_acid] (batchId=86)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[create_view_failure1] (batchId=85)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[create_view_failure2] (batchId=85)\norg.apache.hadoop.hive.cli.TestNegativeCliDriver.testCliDriver[external1] (batchId=85)\norg.apache.hadoop.hive.cli.TestSparkCliDriver.testCliDriver[join31] (batchId=133)\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testAlterTable (batchId=194)\norg.apache.hadoop.hive.metastore.TestEmbeddedHiveMetaStore.testTransactionalValidation (batchId=194)\norg.apache.hadoop.hive.metastore.TestRemoteHiveMetaStore.testAlterTable (batchId=197)\norg.apache.hadoop.hive.metastore.TestRemoteHiveMetaStore.testTransactionalValidation (batchId=197)\norg.apache.hadoop.hive.metastore.TestSetUGIOnBothClientServer.testAlterTable (batchId=193)\norg.apache.hadoop.hive.metastore.TestSetUGIOnBothClientServer.testTransactionalValidation (batchId=193)\norg.apache.hadoop.hive.metastore.TestSetUGIOnOnlyClient.testAlterTable (batchId=191)\norg.apache.hadoop.hive.metastore.TestSetUGIOnOnlyClient.testTransactionalValidation (batchId=191)\norg.apache.hadoop.hive.metastore.TestSetUGIOnOnlyServer.testAlterTable (batchId=202)\norg.apache.hadoop.hive.metastore.TestSetUGIOnOnlyServer.testTransactionalValidation (batchId=202)\norg.apache.hadoop.hive.ql.security.TestMetastoreAuthorizationProvider.testSimplePrivileges (batchId=210)\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProvider.testSimplePrivileges (batchId=208)\norg.apache.hadoop.hive.ql.security.TestStorageBasedMetastoreAuthorizationProviderWithACL.testSimplePrivileges (batchId=220)\norg.apache.hive.hcatalog.api.TestHCatClient.testBasicDDLCommands (batchId=170)\norg.apache.hive.hcatalog.api.TestHCatClient.testTransportFailure (batchId=170)\norg.apache.hive.hcatalog.listener.TestDbNotificationListener.createTable (batchId=221)\norg.apache.hive.service.cli.TestEmbeddedThriftBinaryCLIService.testExecuteStatementAsync (batchId=213)\norg.apache.hive.service.cli.thrift.TestThriftCLIServiceWithBinary.testExecuteStatementAsync (batchId=213)\norg.apache.hive.service.cli.thrift.TestThriftCLIServiceWithHttp.testExecuteStatementAsync (batchId=213)\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/3627/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/3627/console\nTest logs: http://104.198.109.242/logs/PreCommit-HIVE-Build-3627/\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.TestCheckPhase\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests exited with: TestsFailedException: 30 tests failed\n{noformat}\n\nThis message is automatically generated.\n\nATTACHMENT ID: 12853254 - PreCommit-HIVE-Build"
            },
            {
                "author_name": "wzheng",
                "id": "15872741",
                "body": "The code change looks good. Btw, did we do any performance analysis for this change?"
            },
            {
                "author_name": "sankarh",
                "id": "15873736",
                "body": "[~wzheng]\nCurrently, I didn't check the performance impacts due to creation and deletion of temp dir for each test case. \nHowever, this can be tracked using another JIRA ticket to make the temp dir creation only once for whole of TestWorker."
            },
            {
                "author_name": "thejas",
                "id": "15875455",
                "body": "+1\n"
            },
            {
                "author_name": "thejas",
                "id": "15875461",
                "body": "Patch committed to master.\nThanks for the patch [~sankarh], and for the review [~wzheng]\n"
            },
            {
                "author_name": "sankarh",
                "id": "15875466",
                "body": "Thanks a lot [~thejas] and [~wzheng]!"
            },
            {
                "author_name": "githubbot",
                "id": "15875467",
                "body": "Github user sankarh closed the pull request at:\n\n    https://github.com/apache/hive/pull/147\n"
            }
        ],
        "comments_predictions": [
            [
                1929458,
                "HIVE-15910",
                "[~wzheng] [~sankarh]\n\nTestWorker failures seem to be new and likely related to this change. \nWei, any thoughts on why it cause those to fail ? Are we spawning another process from those ?\nWe could change the config for those tests if necessary.",
                {
                    "property": {
                        "confidence": 0.008046014234423637,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0036023790016770363,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02069973759353161,
                        "prediction": false
                    }
                }
            ],
            [
                1929468,
                "HIVE-15910",
                "[~wzheng] I was able to reproduce some of TestWorker failures locally and noticed that the failures are happening when you run the same test case twice where the second execution sees non-empty table's directory under compactor_test_tables. There is DELETEONEXIT hook added which doesn't work for some reason. The double run of test cases could be due to TestWorker2 which extends TestWorker.\nFixed this issue by adding directory cleanup before creating new table. Patch-05 is provided with this change.\nPlease have a check.",
                {
                    "property": {
                        "confidence": 0.005466744303703308,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0064580850303173065,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014501713216304779,
                        "prediction": false
                    }
                }
            ],
            [
                1929470,
                "HIVE-15910",
                "Thanks [~sankarh] for finding this out! It makes sense.\n\nSeems you missed adding that deleteTableDir call for minorPartitionWithBase :) Maybe it's better to add tearDown to TestWorker to perform delete. [~ekoifman]",
                {
                    "property": {
                        "confidence": 0.004458548501133919,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008159620687365532,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01194972638040781,
                        "prediction": false
                    }
                }
            ],
            [
                1929471,
                "HIVE-15910",
                "Added a comment in github pull request. Its simpler to just delete the temp dir where all tables are being created.\nAlso realized, that  tmpdir.deleteOnExit() doesn't work unless the dir is empty. That call would be useless. \n",
                {
                    "property": {
                        "confidence": 0.005473864730447531,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009259112179279327,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.00944066233932972,
                        "prediction": false
                    }
                }
            ],
            [
                1929472,
                "HIVE-15910",
                "In addition, I think we should look at the methods called in CompactorTest constructor.\nCompactorTest constructor would be called for every test function. Ie it is equivalent of '@Before' and not '@BeforeClass' .\nIt seems like some what is done there makes more sense in a '@BeforeClass' , so that its just done once. But I haven't taken a very close look at the tests, so I am not sure. Maybe this should be addressed in a follow up jira, and not this one. \n\ncc [~ekoifman] [~wzheng] [~gates]\n{code}\n    ms = new HiveMetaStoreClient(conf);\n    txnHandler = TxnUtils.getTxnStore(conf);\n    tmpdir = new File(System.getProperty(\"java.io.tmpdir\") +\n        System.getProperty(\"file.separator\") + \"compactor_test_tables\");\n    tmpdir.mkdir();\n    tmpdir.deleteOnExit();\n{code}",
                {
                    "property": {
                        "confidence": 0.005630054045468569,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005287615116685629,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01717476174235344,
                        "prediction": false
                    }
                }
            ],
            [
                1929474,
                "HIVE-15910",
                "[~thejas] [~wzheng]\nAdded Patch-06 with temp directory creation using Files.createTempDirectory method and also added @After methods to delete the temp directory after each test case.\nPlease review the same.\n\nWill add a follow-up JIRA to handle the CompactorTest constructor issue.",
                {
                    "property": {
                        "confidence": 0.004250568803399801,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007257124874740839,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.017054356634616852,
                        "prediction": false
                    }
                }
            ],
            [
                1929477,
                "HIVE-15910",
                "[~wzheng]\nCurrently, I didn't check the performance impacts due to creation and deletion of temp dir for each test case. \nHowever, this can be tracked using another JIRA ticket to make the temp dir creation only once for whole of TestWorker.",
                {
                    "property": {
                        "confidence": 0.005142723210155964,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011608019471168518,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008589866571128368,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640744b5016d21d91d33baab",
        "key": "ARROW-16234",
        "id": "13440455",
        "description": "Didn't see this in the library already so apologies if overlooked, but I think it would be nice to add a compute kernel for ranking. Here is a similar function in pandas:\r\n\r\n[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.rank.html]",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e906f4d395ee221cf844",
        "key": "OAK-2229",
        "id": "12750783",
        "description": "In some cases where index content is managed in external storage it would be helpful to allow Index implementation to distingusing between reindex and first time index\n\nFor more details refer to http://markmail.org/message/uua3plot5qpkaqt7",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0067198495380580425
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.37190675735473633
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.009501141496002674
                }
            }
        },
        "comments": [
            {
                "author_name": "stillalex",
                "id": "14185216",
                "body": "Isn't the check _before.equals(EmptyNodeState.MISSING_NODE)_ enough? \n(granted this should happen in the #enter method on the root IndexEditor)"
            },
            {
                "author_name": "chetanm",
                "id": "14185221",
                "body": "bq. Isn't the check before.equals(EmptyNodeState.MISSING_NODE) enough? \n\nThat would be much better!. Would this work for index present in non root location like /foo/oak:index/lucene also?"
            },
            {
                "author_name": "chetanm",
                "id": "14186405",
                "body": "Above approch would not help in query side detection. As discussed offline with [~alex.parvulescu] implemented the proposed approach with a slight change where a counter is used instead of time \n\nDone in trunk http://svn.apache.org/r1634779\n\n[~alex.parvulescu] can you have a look"
            },
            {
                "author_name": "chetanm",
                "id": "14191283",
                "body": "Merged to branch 1.0 with http://svn.apache.org/r1635661"
            },
            {
                "author_name": "stillalex",
                "id": "14195928",
                "body": "Bulk close for 1.0.8"
            }
        ],
        "comments_predictions": [
            [
                1182538,
                "OAK-2229",
                "Above approch would not help in query side detection. As discussed offline with [~alex.parvulescu] implemented the proposed approach with a slight change where a counter is used instead of time \n\nDone in trunk http://svn.apache.org/r1634779\n\n[~alex.parvulescu] can you have a look",
                {
                    "property": {
                        "confidence": 0.2161760777235031,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0028975121676921844,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.859279215335846,
                        "prediction": true
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5eccef4d395ee221d917c",
        "key": "MPH-40",
        "id": "12803325",
        "description": "Currently, this fragile post-processing is needed to make the content in a file generated with -Doutput=... parseable:\n\n        <move overwrite=\"true\" file=\"${deploy.effective.pom.xml.file}.tmp\" tofile=\"${deploy.effective.pom.xml.file}\">\n            <filterchain>\n                <replaceregex pattern=\"^(Created by:)\" replace='&lt;!--&#10;\\1' />\n                <replaceregex pattern=\"^&lt;.xml .*&gt;(&lt;project&gt;)\" replace='--&gt;&#10;\\1' />\n                <replaceregex pattern=\"^\\*+$\" replace='' />\n            </filterchain>\n        </move>\n\nSolution: Either add XML comments in the generation markup, or only output the XML proper to the output file, leaving the text out of it.",
        "predictions": {},
        "comments": [
            {
                "author_name": "siveton",
                "id": "14436446",
                "body": "We could make xml comments only if reactorProjects is empty. \nIf reactorProjects is not empty, the output file appends all effective poms in one file and thus it is an invalid xml file."
            },
            {
                "author_name": "jhermann",
                "id": "14436566",
                "body": "> We could make xml comments only if reactorProjects is empty. \nWell, that'd help for a certain number of cases.\n\n> If reactorProjects is not empty, the output file appends all effective poms in one file and thus it is an invalid xml file. \nThat can be solved by adding an outer root element around the POMs, which then allows to select the needed POMs by standard tools (XPath) instead of trickery that'll likely break in later releases. It certainly doesn't make automatic processing any harder, just the opposite."
            },
            {
                "author_name": "siveton",
                "id": "14436448",
                "body": "Fixed in [r688412|http://svn.apache.org/viewvc?rev=688412&view=rev], snapshot deployed.\n\nFor reactorProjects, I added a <projects/> tag as suggested."
            }
        ],
        "comments_predictions": [
            [
                1318609,
                "MPH-40",
                "> We could make xml comments only if reactorProjects is empty. \nWell, that'd help for a certain number of cases.\n\n> If reactorProjects is not empty, the output file appends all effective poms in one file and thus it is an invalid xml file. \nThat can be solved by adding an outer root element around the POMs, which then allows to select the needed POMs by standard tools (XPath) instead of trickery that'll likely break in later releases. It certainly doesn't make automatic processing any harder, just the opposite.",
                {
                    "property": {
                        "confidence": 0.005691938102245331,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009514609351754189,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012091332115232944,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d6119ef4d395ee22230204",
        "key": "FLEX-22291",
        "id": "12583165",
        "description": "Steps to reproduce:\n1.  run the attached application\n2.  click the button\n \n Actual Results:\n 2 RTEs\n \n Expected Results:\n no RTEs\n \n Workaround (if any):\n \n TypeError: Error #1009: Cannot access a property or method of a null object reference.\n\tat spark.components::VideoPlayer/getCurrentSkinState()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\VideoPlayer.as:1359]\n\tat spark.components.supportClasses::SkinnableComponent/commitProperties()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\supportClasses\\SkinnableComponent.as:424]\n\tat mx.core::UIComponent/validateProperties()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7736]\n\tat mx.managers::LayoutManager/validateProperties()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\managers\\LayoutManager.as:572]\n\tat mx.managers::LayoutManager/doPhasedInstantiation()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\managers\\LayoutManager.as:730]\n\tat mx.managers::LayoutManager/doPhasedInstantiationCallback()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\managers\\LayoutManager.as:1072]\n\tat flash.display::DisplayObjectContainer/addChildAt()\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::$addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6906]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6813]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1405]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1405]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1409]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1409]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1405]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1409]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1409]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat spark.skins.spark::VideoPlayerSkin/initialize()\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChild()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6792]\n\tat spark.components.supportClasses::SkinnableComponent/attachSkin()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\supportClasses\\SkinnableComponent.as:622]\n\tat spark.components.supportClasses::SkinnableComponent/validateSkinChange()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\supportClasses\\SkinnableComponent.as:403]\n\tat spark.components.supportClasses::SkinnableComponent/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\supportClasses\\SkinnableComponent.as:366]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\n\nTypeError: Error #1009: Cannot access a property or method of a null object reference.\n\tat spark.components.mediaClasses::ScrubBar/calculateAreaSize()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\mediaClasses\\ScrubBar.as:177]\n\tat spark.components.mediaClasses::ScrubBar/updateSkinDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\mediaClasses\\ScrubBar.as:191]\n\tat spark.components.supportClasses::TrackBase/addedToStageHandler()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\supportClasses\\TrackBase.as:512]\n\tat flash.display::DisplayObjectContainer/addChildAt()\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::$addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6906]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6813]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1405]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1405]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1409]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1409]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1405]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1409]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6815]\n\tat spark.components::Group/addDisplayObjectToDisplayList()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1816]\n\tat spark.components::Group/http://www.adobe.com/2006/flex/mx/internal::elementAdded()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:1409]\n\tat spark.components::Group/setMXMLContent()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:510]\n\tat spark.components::Group/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\Group.as:732]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat spark.skins.spark::VideoPlayerSkin/initialize()\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::UIComponent/addChild()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:6792]\n\tat spark.components.supportClasses::SkinnableComponent/attachSkin()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\supportClasses\\SkinnableComponent.as:622]\n\tat spark.components.supportClasses::SkinnableComponent/validateSkinChange()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\supportClasses\\SkinnableComponent.as:403]\n\tat spark.components.supportClasses::SkinnableComponent/createChildren()[E:\\dev\\trunk\\frameworks\\projects\\spark\\src\\spark\\components\\supportClasses\\SkinnableComponent.as:366]\n\tat mx.core::UIComponent/initialize()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7217]\n\tat mx.core::UIComponent/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\UIComponent.as:7108]\n\tat mx.core::Container/http://www.adobe.com/2006/flex/mx/internal::childAdded()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\Container.as:3943]\n\tat mx.core::Container/addChildAt()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\Container.as:2608]\n\tat mx.core::Container/addChild()[E:\\dev\\trunk\\frameworks\\projects\\framework\\src\\mx\\core\\Container.as:2526]",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13362115",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-24547\nOriginal Reporter: kawhite\nOriginal Resolution: Not a Bug\nDiscoverability: Medium\nNumber of votes: 0\nRegression: Yes\nReproducibility: Every Time\nResolved by: rfrishbe\nSeverity: Incorrectly Functioning\nreporter: kawhite"
            },
            {
                "author_name": "adobejira",
                "id": "13362114",
                "body": "created: 2009-12-04 09:42:51.000\nresolved: 2009-12-04 11:56:51.466\nupdated: 2009-12-09 15:06:35.000"
            },
            {
                "author_name": "adobejira",
                "id": "13362116",
                "body": "On 2009-12-04 11:56:51.611 rfrishbe commented:\nThis should be fixed in 12546.  I could not reproduce one of the RTEs, but after my fix the code seems to run correctly.\n\nI added a check in ScrubBar to make sure the thumb and track are around.  We do the same thing in the super.updateSkinDisplayList().\nOn 2009-12-09 15:06:35.067 kawhite commented:\nfixed in 12739"
            }
        ],
        "comments_predictions": [
            [
                2995605,
                "FLEX-22291",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-24547\nOriginal Reporter: kawhite\nOriginal Resolution: Not a Bug\nDiscoverability: Medium\nNumber of votes: 0\nRegression: Yes\nReproducibility: Every Time\nResolved by: rfrishbe\nSeverity: Incorrectly Functioning\nreporter: kawhite",
                {
                    "property": {
                        "confidence": 0.005098473746329546,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.06440494954586029,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008127868175506592,
                        "prediction": false
                    }
                }
            ],
            [
                2995607,
                "FLEX-22291",
                "On 2009-12-04 11:56:51.611 rfrishbe commented:\nThis should be fixed in 12546.  I could not reproduce one of the RTEs, but after my fix the code seems to run correctly.\n\nI added a check in ScrubBar to make sure the thumb and track are around.  We do the same thing in the super.updateSkinDisplayList().\nOn 2009-12-09 15:06:35.067 kawhite commented:\nfixed in 12739",
                {
                    "property": {
                        "confidence": 0.004906584043055773,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009637574665248394,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.00943025667220354,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640744b195dd29065733b7f4",
        "key": "YUNIKORN-1155",
        "id": "13436209",
        "description": "During the reproduction attempts of YUNIKORN-560, it turned out that when Yunikorn is restarted, the placeholder timeout is set again to 15 minutes, regardless of how much time the placeholder had already spent in pending/running state.\u00a0\r\n\r\nWe need to calculate how much time it has left depending on a creation timestamp.",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d620aff4d395ee222516e0",
        "key": "CARBONDATA-4087",
        "id": "13346399",
        "description": "For large data SELECT on array(varchar) throws exception-\r\n\r\n\"Error in Reading Data from Carbondata\" due to ArrayOutOfBounds\r\n\r\n\u00a0\r\n\r\nhttps://github.com/apache/carbondata/pull/4055",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d3edf4d395ee22186eb4",
        "key": "XW-599",
        "id": "12594589",
        "description": "Looks like the Container is instantiating an instance of the com.opensymphony.xwork2.conversion.XWorkConverter and this has an issue because in the constructor it tries to load all the custom converters, however, since the ObjectFactory is setup using setter injection and creating custom converters relies on the ObjectFactory, the constructor throws NullPointerExceptions. Here's the stack trace:\n\n\n\n        at com.opensymphony.xwork2.conversion.impl.XWorkConverter.createTypeConverter(XWorkConverter.java:729)\n\n        at com.opensymphony.xwork2.conversion.impl.XWorkConverter.loadConversionProperties(XWorkConverter.java:756)\n\n        at com.opensymphony.xwork2.conversion.impl.XWorkConverter.<init>(XWorkConverter.java:184)\n\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n\n        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)\n\n        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)\n\n        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)\n\n        at com.opensymphony.xwork2.inject.ContainerImpl$ConstructorInjector.construct(ContainerImpl.java:388)\n\n\n\nI'm going to put together a patch since I need a fix to keep working on some Struts2 stuff. I'll attach it if I get it working. I'm planning on just using constructor injection unless there are usages of the setter methods.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008604948408901691
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009859981946647167
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005203709937632084
                }
            }
        },
        "comments": [
            {
                "author_name": "voidmain",
                "id": "13395013",
                "body": "I fixed this for now by moving the initialization from the constructor into the setObjectFactory(ObjectFactory factory) method. Here's my code:\n\n\n\n    @Inject\n\n    public void setObjectFactory(ObjectFactory factory) {\n\n        this.objectFactory = factory;\n\n        try {\n\n            // note: this file is deprecated\n\n            loadConversionProperties(\"xwork-default-conversion.properties\");\n\n        } catch (Exception e) {\n\n        }\n\n\n\n        try {\n\n            loadConversionProperties(\"xwork-conversion.properties\");\n\n        } catch (Exception e) {\n\n        }\n\n    }\n\n\n\nThis really should be constructor injection, but I tried doing that and run into severe test case issues and didn't really figure them out easily from the code."
            },
            {
                "author_name": "voidmain",
                "id": "13395014",
                "body": "Okay, I tried to convert things over to constructor injection and ran into a nasty circular dependency, which should probably be removed, but it seems pretty tightly coupled right now. Here's the path:\n\n\n\nOgnlValueStackFactory -> XWorkConverter -> ObjectFactory -> OgnlUtil -> XWorkConverter\n\n\n\nThis prevents the XWorkConverter from being constructor injected, although that is the correct injection method since the ObjectFactory is required. So, it looks like my solution in the setObjectFactory method is the only way to get this working for now."
            },
            {
                "author_name": "voidmain",
                "id": "13395015",
                "body": "I have the fix ready to go and once Don adds me to SubVersion I'll commit it."
            },
            {
                "author_name": "rainerh",
                "id": "13395035",
                "body": "Patch applied by Don"
            }
        ],
        "comments_predictions": [
            [
                202994,
                "XW-599",
                "I fixed this for now by moving the initialization from the constructor into the setObjectFactory(ObjectFactory factory) method. Here's my code:\n\n\n\n    @Inject\n\n    public void setObjectFactory(ObjectFactory factory) {\n\n        this.objectFactory = factory;\n\n        try {\n\n            // note: this file is deprecated\n\n            loadConversionProperties(\"xwork-default-conversion.properties\");\n\n        } catch (Exception e) {\n\n        }\n\n\n\n        try {\n\n            loadConversionProperties(\"xwork-conversion.properties\");\n\n        } catch (Exception e) {\n\n        }\n\n    }\n\n\n\nThis really should be constructor injection, but I tried doing that and run into severe test case issues and didn't really figure them out easily from the code.",
                {
                    "property": {
                        "confidence": 0.005587735679000616,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005023105535656214,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.021080851554870605,
                        "prediction": false
                    }
                }
            ],
            [
                202995,
                "XW-599",
                "Okay, I tried to convert things over to constructor injection and ran into a nasty circular dependency, which should probably be removed, but it seems pretty tightly coupled right now. Here's the path:\n\n\n\nOgnlValueStackFactory -> XWorkConverter -> ObjectFactory -> OgnlUtil -> XWorkConverter\n\n\n\nThis prevents the XWorkConverter from being constructor injected, although that is the correct injection method since the ObjectFactory is required. So, it looks like my solution in the setObjectFactory method is the only way to get this working for now.",
                {
                    "property": {
                        "confidence": 0.005596868693828583,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006023510359227657,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013468042016029358,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640743edee41fa6647d2b430",
        "key": "LUCENE-9166",
        "id": "13281289",
        "description": "Test failures are missing the stacktrace. Worse yet, it tells you go to look at a separate (very long) filename which also has no stacktrace :(\r\n\r\nI know gradle tries really hard to be quiet and not say anything, but when a test fails, that isn't the time or place :)\r\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014189017936587334
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01937222294509411
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0035951139871031046
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d623eff4d395ee2225a005",
        "key": "BEANUTILS-246",
        "id": "12351858",
        "description": "deal with the property like vLan,and the method getVLan().\nException Unknow property",
        "predictions": {},
        "comments": [
            {
                "author_name": "bayard",
                "id": "12438462",
                "body": "See if \"VLan\" works for the property name. I think that if there are two uppercase characters in a row, that the bean spec means you should treat it like an acronym."
            },
            {
                "author_name": "bayard",
                "id": "12445740",
                "body": "Supporting vLan -> getVLan would break compliance with the bean spec. Marking this as wontfix."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5dc7af4d395ee221aab30",
        "key": "SPARK-10568",
        "id": "12863505",
        "description": "When I shut down a Java process that is running a SparkContext, it invokes a shutdown hook that eventually calls SparkContext.stop(), and inside SparkContext.stop() each individual component (DiskBlockManager, Scheduler Backend) is stopped. If an exception is thrown in stopping one of these components, none of the other components will be stopped cleanly either. This caused problems when I stopped a Java process running a Spark context in yarn-client mode, because not properly stopping YarnSchedulerBackend leads to problems.\n\nThe steps I ran are as follows:\n1. Create one job which fills the cluster\n2. Kick off another job which creates a Spark Context\n3. Kill the Java process with the Spark Context in #2\n4. The job remains in the YARN UI as ACCEPTED\n\nLooking in the logs we see the following:\n\n{code}\n2015-09-07 10:32:43,446 ERROR [Thread-3] o.a.s.u.Utils - Uncaught exception in thread Thread-3\njava.lang.NullPointerException: null\n        at org.apache.spark.storage.DiskBlockManager.org$apache$spark$storage$DiskBlockManager$$doStop(DiskBlockManager.scala:162) ~[spark-core_2.10-1.4.1.jar:1.4.1]\n        at org.apache.spark.storage.DiskBlockManager$$anonfun$addShutdownHook$1.apply$mcV$sp(DiskBlockManager.scala:144) ~[spark-core_2.10-1.4.1.jar:1.4.1]\n        at org.apache.spark.util.SparkShutdownHook.run(Utils.scala:2308) ~[spark-core_2.10-1.4.1.jar:1.4.1]\n{code}\n\nI think what's going on is that when we kill the application in the queued state, it tries to run the SparkContext.stop() method on the driver and stop each component. It dies trying to stop the DiskBlockManager because it hasn't been initialized yet - the application is still waiting to be scheduled by the Yarn RM - but YarnClient.stop() is not invoked as a result, leaving the application sticking around in the accepted state.\n\nBecause of what appears to be bugs in the YARN scheduler, entering this state makes it so that the YARN scheduler is unable to schedule any more jobs unless we manually remove this application via the YARN CLI. We can tackle the YARN stuck state separately, but ensuring that all components get at least some chance to stop when a SparkContext stops seems like a good idea. Of course we can still throw some exception and/or log exceptions for everything that goes wrong at the end of stopping the context.",
        "predictions": {},
        "comments": [
            {
                "author_name": "srowen",
                "id": "14741488",
                "body": "I think this is a duplicate of SPARK-10554? at least, the immediate issue is.\nIt's tough to know whether to fail fast or keep trying operations of other things in a failed state, which might just create more errors.\nIt might be most effective to identify common, impactful cases where shutdown needs to more reliably clean up. SPARK-10554 is one example and sounds like you have another YARN example. Maybe this should focus on the YARN issue?"
            },
            {
                "author_name": "mcheah",
                "id": "14741525",
                "body": "I'm more concerned about the general case which is that failing in one part of stop() doesn't allow for stopping anything else. We should fix the NPE in DiskBlockManager, yes, but we should probably make stopping more robust in the sense of at least trying to stop each component.\n\nSo we need to fix DiskBlockManager, but we also should look at handling uncaught exceptions from stopping each component more carefully."
            },
            {
                "author_name": "mcheah",
                "id": "14741526",
                "body": "Also I think the YARN issue is something more suited for discussing in the Apache YARN project."
            },
            {
                "author_name": "jzhang",
                "id": "14741621",
                "body": "Make sense to ensure each individual component is stopped in SparkContext.stop(). "
            },
            {
                "author_name": "srowen",
                "id": "14741978",
                "body": "Yeah I can imagine some relatively painless Scala code that iterates over a bunch of closures that shutdown things and log exceptions and continue in the face of failures.  Ideally we check if shutdown happens in the reverse order of initialization too.\n\nOK if the YARN issue is really outside Spark yes that's out of scope here."
            },
            {
                "author_name": "srowen",
                "id": "14877037",
                "body": "[~mcheah] are you working on a PR for this?"
            },
            {
                "author_name": "mcheah",
                "id": "14901164",
                "body": "Yup!"
            },
            {
                "author_name": "mcheah",
                "id": "14901382",
                "body": "Actually I think this was handled by https://issues.apache.org/jira/browse/SPARK-9446 and its associated PR https://github.com/apache/spark/pull/7756 and I didn't catch it because when I filed this I was looking at the 1.4.1 release code.\n\nSorry for the inconvenient duplicate. I suppose that SparkEnv.stop() isn't doing the same calls to Utils.tryLogNonFatalError for each of its components though. Maybe we can make this JIRA about cleaning up what's remaining?"
            },
            {
                "author_name": "srowen",
                "id": "14901396",
                "body": "Sure, if you have suggestions along those lines. I had imagined it was about calling some code to stop each component in a way that exceptions from one would not prevent the rest from executing."
            }
        ],
        "comments_predictions": [
            [
                679086,
                "SPARK-10568",
                "I think this is a duplicate of SPARK-10554? at least, the immediate issue is.\nIt's tough to know whether to fail fast or keep trying operations of other things in a failed state, which might just create more errors.\nIt might be most effective to identify common, impactful cases where shutdown needs to more reliably clean up. SPARK-10554 is one example and sounds like you have another YARN example. Maybe this should focus on the YARN issue?",
                {
                    "property": {
                        "confidence": 0.011464402079582214,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00269103841856122,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.17934781312942505,
                        "prediction": false
                    }
                }
            ],
            [
                679087,
                "SPARK-10568",
                "I'm more concerned about the general case which is that failing in one part of stop() doesn't allow for stopping anything else. We should fix the NPE in DiskBlockManager, yes, but we should probably make stopping more robust in the sense of at least trying to stop each component.\n\nSo we need to fix DiskBlockManager, but we also should look at handling uncaught exceptions from stopping each component more carefully.",
                {
                    "property": {
                        "confidence": 0.006418483331799507,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004228303674608469,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04110148921608925,
                        "prediction": false
                    }
                }
            ],
            [
                679090,
                "SPARK-10568",
                "Yeah I can imagine some relatively painless Scala code that iterates over a bunch of closures that shutdown things and log exceptions and continue in the face of failures.  Ideally we check if shutdown happens in the reverse order of initialization too.\n\nOK if the YARN issue is really outside Spark yes that's out of scope here.",
                {
                    "property": {
                        "confidence": 0.13381613790988922,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.002688552951440215,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.025770870968699455,
                        "prediction": false
                    }
                }
            ],
            [
                679093,
                "SPARK-10568",
                "Actually I think this was handled by https://issues.apache.org/jira/browse/SPARK-9446 and its associated PR https://github.com/apache/spark/pull/7756 and I didn't catch it because when I filed this I was looking at the 1.4.1 release code.\n\nSorry for the inconvenient duplicate. I suppose that SparkEnv.stop() isn't doing the same calls to Utils.tryLogNonFatalError for each of its components though. Maybe we can make this JIRA about cleaning up what's remaining?",
                {
                    "property": {
                        "confidence": 0.0038840225897729397,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010891339741647243,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011968635953962803,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d60bfaf4d395ee22224177",
        "key": "GEODE-1886",
        "id": "13004452",
        "description": "The instanceof checks added to EntryEventImpl for offheap have slowed down the performance of heap. This slow down will probably only be noticed when the cache operation is local. When the operations is distributed the network adds enough overhead that the extra time in the instanceof checks is not noticed.\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.00863325409591198
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.005377437453716993
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.046457964926958084
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "15497014",
                "body": "Commit b7518411d93ded8a8c83af6964ff74acb04a31ac in incubator-geode's branch refs/heads/develop from [~dschneider]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=b751841 ]\n\nGEODE-1886: optimize off-heap reference checks\n\nEntryEventImpl now tests the region's off-heap boolean\nbefore it will ask if the new/old value is an instanceof\nStoredObject.\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640746a026f1950e6981dc74",
        "key": "IGNITE-18152",
        "id": "13502336",
        "description": "Currently, in buildscripts/publishing-repos.gradle script creds reading made via gradle.properties and release manager should define username\\password in local gradle.properties file, but it doesn't work now, only with direct creds definition in script is working.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02025315910577774
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009784860536456108
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00344996084459126
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f46cf4d395ee221ee55f",
        "key": "KAFKA-10216",
        "id": "13314089",
        "description": "Currently listing partition reassignments requires Cluster Describe permission. This is quite annoying since it takes the user back to the days before KIP-352 where they cannot distinguish under-replicated partitions that are a result of reassignment. Since both the adding/removing replicas are visible in the replica set, I cannot think of a good reason a user should be unable to tell which is which. I suggest we change the permission to Topic Describe instead.",
        "predictions": {},
        "comments": [
            {
                "author_name": "cmccabe",
                "id": "17147971",
                "body": "+1"
            },
            {
                "author_name": "dajac",
                "id": "17229270",
                "body": "Small KIP to address this: https://cwiki.apache.org/confluence/display/KAFKA/KIP-685%3A+Loosen+permission+for+listing+reassignments"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "6407446395dd29065733b140",
        "key": "CAMEL-16173",
        "id": "13357787",
        "description": "In an attempt to ensure proper error handling once a Camel route would reach its configured Resilience4j Bulkhead limit, it was experienced that regardless of Bulkhead configuration, the limit was never upheld. Seemingly the Bulkhead has no effect within the circuit breaker.\r\n\r\nThe context in which the bug was experienced:\r\nSpring Boot 2.4.2, Apache Camel 3.7.1 (reproducer tested using 3.7.2 as well).\r\n\r\nA reproducer Maven project can be found here:\u00a0[sys-jdi/camel-bulkhead-test: Test of Resilience4J in Spring Boot application using Apache Camel.|https://github.com/sys-jdi/camel-bulkhead-test]\r\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.39423173666000366
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01944529265165329
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008741139434278011
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d3edf4d395ee221865d9",
        "key": "YARN-1787",
        "id": "12698803",
        "description": "yarn applicationattempt prints:\n{code}\nInvalid Command Usage : \nusage: application\n -appStates <States>             Works with -list to filter applications\n                                 based on input comma-separated list of\n                                 application states. The valid application\n                                 state can be one of the following:\n                                 ALL,NEW,NEW_SAVING,SUBMITTED,ACCEPTED,RUN\n                                 NING,FINISHED,FAILED,KILLED\n -appTypes <Types>               Works with -list to filter applications\n                                 based on input comma-separated list of\n                                 application types.\n -help                           Displays help for all commands.\n -kill <Application ID>          Kills the application.\n -list <arg>                     List application attempts for aplication\n                                 from AHS.\n -movetoqueue <Application ID>   Moves the application to a different\n                                 queue.\n -queue <Queue Name>             Works with the movetoqueue command to\n                                 specify which queue to move an\n                                 application to.\n -status <Application ID>        Prints the status of the application.\n{code}\n\nyarn container prints:\n{code}\nInvalid Command Usage : \nusage: application\n -appStates <States>             Works with -list to filter applications\n                                 based on input comma-separated list of\n                                 application states. The valid application\n                                 state can be one of the following:\n                                 ALL,NEW,NEW_SAVING,SUBMITTED,ACCEPTED,RUN\n                                 NING,FINISHED,FAILED,KILLED\n -appTypes <Types>               Works with -list to filter applications\n                                 based on input comma-separated list of\n                                 application types.\n -help                           Displays help for all commands.\n -kill <Application ID>          Kills the application.\n -list <arg>                     List application attempts for aplication\n                                 from AHS.\n -movetoqueue <Application ID>   Moves the application to a different\n                                 queue.\n -queue <Queue Name>             Works with the movetoqueue command to\n                                 specify which queue to move an\n                                 application to.\n -status <Application ID>        Prints the status of the application.\n{code}\n\nBoth commands print irrelevant yarn application usage information.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0049216533079743385
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.024127911776304245
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005961839575320482
                }
            }
        },
        "comments": [
            {
                "author_name": "zjshen",
                "id": "13921647",
                "body": "Fix the usage message and add corresponding test case. After the patch,\nyarn applicationattempt usage info will be:\n{code}\nusage: applicationattempt\n -help                              Displays help for all commands.\n -list <Application ID>             List application attempts for\n                                    aplication.\n -status <Application Attempt ID>   Prints the status of the application\n                                    attempt.\n{code}\nand yarn container usage info will be:\n{code}\nusage: container\n -help                            Displays help for all commands.\n -list <Application Attempt ID>   List containers for application attempt.\n -status <Container ID>           Prints the status of the container.\n{code}\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "13921654",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12632963/YARN-1787.1.patch\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-YARN-Build/3269//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "ozawa",
                "id": "13921694",
                "body": "[~zjshen], thank you for taking this JIRA. I tried to patch your modification, but failed. I attached rejected diff. Can you check it and update your patch?"
            },
            {
                "author_name": "hadoopqa",
                "id": "13921700",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12632974/ApplicationCLI.java.rej\n  against trunk revision .\n\n    {color:red}-1 patch{color}.  The patch command could not apply the patch.\n\nConsole output: https://builds.apache.org/job/PreCommit-YARN-Build/3270//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "zjshen",
                "id": "13921875",
                "body": "Upload a new patch, which rebase against the latest trunk"
            },
            {
                "author_name": "hadoopqa",
                "id": "13921983",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12633003/YARN-1787.2.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The following test timeouts occurred in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client:\n\norg.apache.hadoop.yarn.client.api.impl.TestNMClient\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-YARN-Build/3271//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-YARN-Build/3271//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "vinodkv",
                "id": "13923521",
                "body": "I am fairly sure you broke bin/yarn appliciation etc after the patch, can you please verify?\n\nThe patch looks fine overall other than bin/yarn changes.\n\nIdeally, we should split the CLI into separate classes for app, appattempts etc. Will file a ticket.\n\nThe other thing is that -queue <Queue Name> shouldn't be an option, it should just be an argument to -movetoqueue. Will file a ticket for that also.\n\n"
            },
            {
                "author_name": "zjshen",
                "id": "13923621",
                "body": "bq. I am fairly sure you broke bin/yarn appliciation etc after the patch, can you please verify?\nbq. The patch looks fine overall other than bin/yarn changes.\n\nThis patch doesn't modify bin/yarn. YARN-967 introduced the following trick in bin/yarn:\n{code}\n+  set -- $COMMAND $@\n{code}\nwhich takes \"application/applicationattempt/container\" as the first arg. So in ApplicationCLI, we need to parse one more arg.\n\nAccording to my local test, \"yarn application\" works fine after the patch, as well \"yarn applicationattempt\" and \"yarn container\".\n\nbq. Ideally, we should split the CLI into separate classes for app, appattempts etc. Will file a ticket.\n\nI've noticed this as well, and I agree it's the ideal solution. Unfortunately, the previous changes of getting/listing appattempt(s)/container(s) are all in the ApplicationCLI, therefore, I keep the change the same class. Another choice is to rename ApplicationCLI to some name that can indicate app, appattempt and container inclusively, but I'm not sure it is a compatible change or not, if users invoke ApplicationCLI programmatically instead of using shell script. Thoughts?\n\n\n"
            },
            {
                "author_name": "vinodkv",
                "id": "13924720",
                "body": "Tx for the clarification Zhijie. Let's track the remaining things that I noted separately.\n\nThe patch latest looks good to me, +1. Checking it in."
            },
            {
                "author_name": "vinodkv",
                "id": "13924722",
                "body": "Committed this to trunk, branch-2 and branch-2.4. Thanks Zhijie!"
            },
            {
                "author_name": "hudson",
                "id": "13924724",
                "body": "SUCCESS: Integrated in Hadoop-trunk-Commit #5289 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5289/])\nYARN-1787. Fixed help messages for applicationattempt and container sub-commands in bin/yarn. Contributed by Zhijie Shen. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575482)\n* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt\n* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/cli/ApplicationCLI.java\n* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/cli/TestYarnCLI.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13924802",
                "body": "SUCCESS: Integrated in Hadoop-Yarn-trunk #503 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/503/])\nYARN-1787. Fixed help messages for applicationattempt and container sub-commands in bin/yarn. Contributed by Zhijie Shen. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575482)\n* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt\n* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/cli/ApplicationCLI.java\n* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/cli/TestYarnCLI.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13924859",
                "body": "FAILURE: Integrated in Hadoop-Hdfs-trunk #1695 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1695/])\nYARN-1787. Fixed help messages for applicationattempt and container sub-commands in bin/yarn. Contributed by Zhijie Shen. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575482)\n* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt\n* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/cli/ApplicationCLI.java\n* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/cli/TestYarnCLI.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13924886",
                "body": "SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1720 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1720/])\nYARN-1787. Fixed help messages for applicationattempt and container sub-commands in bin/yarn. Contributed by Zhijie Shen. (vinodkv: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1575482)\n* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt\n* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/cli/ApplicationCLI.java\n* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/cli/TestYarnCLI.java\n"
            }
        ],
        "comments_predictions": [
            [
                176420,
                "YARN-1787",
                "Fix the usage message and add corresponding test case. After the patch,\nyarn applicationattempt usage info will be:\n{code}\nusage: applicationattempt\n -help                              Displays help for all commands.\n -list <Application ID>             List application attempts for\n                                    aplication.\n -status <Application Attempt ID>   Prints the status of the application\n                                    attempt.\n{code}\nand yarn container usage info will be:\n{code}\nusage: container\n -help                            Displays help for all commands.\n -list <Application Attempt ID>   List containers for application attempt.\n -status <Container ID>           Prints the status of the container.\n{code}\n",
                {
                    "property": {
                        "confidence": 0.004921065177768469,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005637007299810648,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.019820960238575935,
                        "prediction": false
                    }
                }
            ],
            [
                176426,
                "YARN-1787",
                "I am fairly sure you broke bin/yarn appliciation etc after the patch, can you please verify?\n\nThe patch looks fine overall other than bin/yarn changes.\n\nIdeally, we should split the CLI into separate classes for app, appattempts etc. Will file a ticket.\n\nThe other thing is that -queue <Queue Name> shouldn't be an option, it should just be an argument to -movetoqueue. Will file a ticket for that also.\n\n",
                {
                    "property": {
                        "confidence": 0.006370485294610262,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004850484896451235,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.017568817362189293,
                        "prediction": false
                    }
                }
            ],
            [
                176427,
                "YARN-1787",
                "bq. I am fairly sure you broke bin/yarn appliciation etc after the patch, can you please verify?\nbq. The patch looks fine overall other than bin/yarn changes.\n\nThis patch doesn't modify bin/yarn. YARN-967 introduced the following trick in bin/yarn:\n{code}\n+  set -- $COMMAND $@\n{code}\nwhich takes \"application/applicationattempt/container\" as the first arg. So in ApplicationCLI, we need to parse one more arg.\n\nAccording to my local test, \"yarn application\" works fine after the patch, as well \"yarn applicationattempt\" and \"yarn container\".\n\nbq. Ideally, we should split the CLI into separate classes for app, appattempts etc. Will file a ticket.\n\nI've noticed this as well, and I agree it's the ideal solution. Unfortunately, the previous changes of getting/listing appattempt(s)/container(s) are all in the ApplicationCLI, therefore, I keep the change the same class. Another choice is to rename ApplicationCLI to some name that can indicate app, appattempt and container inclusively, but I'm not sure it is a compatible change or not, if users invoke ApplicationCLI programmatically instead of using shell script. Thoughts?\n\n\n",
                {
                    "property": {
                        "confidence": 0.0070388163439929485,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004053336568176746,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02837034873664379,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "6407448aaa1c3d637833b545",
        "key": "ORC-833",
        "id": "13388215",
        "description": "{{RunLengthIntegerReaderV2#nextVector}} calculates the batch value explicitly on every loop.  Not sure if it actually matters, but probably more simple to pre-compute the batch size. Some other clean up as well.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.010280054993927479
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.00808034185320139
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0054147266782820225
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d601cbf4d395ee2220e65f",
        "key": "HDFS-4909",
        "id": "12653091",
        "description": "The revised protocol buffer support seems to be compiling for me when using the protobuf-c cross-compiler. However, I still cannot construct a library of the results. This may be a Hadoop issue, or could be an issue with the protobuf-c cross-compiler. What I see are a bunch of these when attempting to link the resulting .o files:\n\n/home/common/hadoop/hadoop-common/foo/obj/DatanodeProtocol.pb-c.o: In function `hadoop_hdfsreport_bad_blocks_request_proto_init':\nDatanodeProtocol.pb-c.c.text+0x2bb4): multiple definition of `hadoop_hdfsreport_bad_blocks_request_proto_init'\n/home/common/hadoop/hadoop-common/foo/obj/ClientNamenodeProtocol.pb-c.o:ClientNamenodeProtocol.pb-c.c.text+0x277d): first defined here\n\nFrom what I can see, this is caused by the\n\npackage hadoop.hdfs;\n\nline in the .proto files, when combined with the later\n\nimport \"hdfs.proto\";\n\nThis appears to bring a complete copy of the hdfs.proto file into the source code, which then recompiles it - leading to the duplicate symbols.\n\nI have attached an updated pcreate.pl script that illustrates the problem. Excluding the following .proto files allows all to be successfully built and linked:\n\nDatanodeProtocol\nClientNamenodeProtocol\nQJournalProtocol\n\nHTH\nRalph\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006987948436290026
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.019159987568855286
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005562281236052513
                }
            }
        },
        "comments": [
            {
                "author_name": "rhc",
                "id": "13684801",
                "body": "Must have installed protobuf-c to use."
            },
            {
                "author_name": "azuryy",
                "id": "13684847",
                "body": "please read BUILDING.txt before compiling. Thanks."
            },
            {
                "author_name": "rhc",
                "id": "13684861",
                "body": "I have read it - nothing in there pertains to this problem, that I can see.\n\nIs there something specific you are referring to?\n"
            },
            {
                "author_name": "azuryy",
                "id": "13684869",
                "body": "did you install protobuf before compiling?"
            },
            {
                "author_name": "rhc",
                "id": "13684872",
                "body": "Yes - this is a secondary JIRA filed at Arun and Aprit's request because they had closed the prior one once the compile worked, not realizing that the results failed to link. It is a problem in the .proto definitions of the three specified classes.\n"
            },
            {
                "author_name": "azuryy",
                "id": "13684888",
                "body": "yes,- this is HDFS-4866 releated. I've added reference."
            },
            {
                "author_name": "cnauroth",
                "id": "13685797",
                "body": "The full import of hdfs.proto causing duplicate definitions is the same reason that we've needed to use 4 separate protoc executions in the pom.xml.  We likely need some refactoring across all of the HDFS proto files to prevent the need for multiple protoc build steps and also prevent duplicate symbols at link time.  I don't yet know the full scope of this refactoring though."
            },
            {
                "author_name": "sureshms",
                "id": "13686021",
                "body": "I think we cannot block 2.1.0 for this. If we think changes we need to make are not going to need incompatible changes, I suggest making this Major priority instead of Blocker."
            },
            {
                "author_name": "acmurthy",
                "id": "13690295",
                "body": "Do we all agree that this *can* be fixed later in a compatible manner?"
            },
            {
                "author_name": "rhc.openmpi@gmail.com",
                "id": "13690310",
                "body": "Hi Arun\n\nOn road - up to you folks. Only made blocker as someone set that level on prior jira\n\nRalph\n\n\nSent from my iPhone\n\n\n"
            },
            {
                "author_name": "acmurthy",
                "id": "13690323",
                "body": "[~rhc] Thanks Ralph. I'm just trying to herd cats to get the release out... as you can imagine it's a tough job! *smile*\n\nFrankly, my inclination is to punt this from 2.1.0-beta *iff* this is something we can fix in a compatible manner down the road."
            },
            {
                "author_name": "cnauroth",
                "id": "13690362",
                "body": "{quote}\nFrankly, my inclination is to punt this from 2.1.0-beta iff this is something we can fix in a compatible manner down the road.\n{quote}\n\nYes, I expect we can fix this later and still retain compatibility.  The original problem reported in HDFS-4866 required a backwards-incompatible change in a protocol method name, so we really needed to get that one done before beta.  For this one, I expect we can fix the problem of duplicate symbols during protoc/link time by refactoring the proto definitions, but still retaining the same method names."
            },
            {
                "author_name": "sureshms",
                "id": "13690436",
                "body": "Lets get this done in 2.2.0\n"
            },
            {
                "author_name": "cmccabe",
                "id": "13971682",
                "body": "This patch changes the protobuf package which DatanodeProtocol, NamenodeProtocol, and QJournalProtocol reside in to match their names.  This avoids the name conflicts that were previously caused by putting everything into \"package hadoop.hdfs\".\n\nThis doesn't alter what gets sent over the wire at all, so there are no compatibility implications.  I have confirmed this for myself by running some servers with this patch against clients which do not have it.\n\nNo changes to the Java code are needed, since we manually specify which Java packages things should go in (the java package is different than the protobuf package).  Essentially, the protobuf package is irrelevant in the java code because it gets overridden by {{option java_package}}.\n\nIt does change some of the generated code a bit.  For example, {{internal_static_hadoop_hdfs_CommitBlockSynchronizationResponseProto_descriptor}} becomes {{internal_static_hadoop_hdfs_datanode_CommitBlockSynchronizationResponseProto_descriptor}}.  But this seems to all be internal stuff deep inside the PB generated code which doesn't get exposed to the outside world."
            },
            {
                "author_name": "cnauroth",
                "id": "13971726",
                "body": "Hi, Colin.  Thanks for doing this.  I remember when I looked at it a few months ago, I also thought we'd be able to simplify our build a little bit.  There are multiple protoc invocations right now, and that's just a workaround due to duplicate symbol inclusion when everything was in one protobuf namespace.  I just tried using a single protoc invocation with your patch, and sure enough, it worked.  I'm attaching patch v2, which is your patch plus the pom.xml change.\n\nI'm +1 for v2 of the patch pending Jenkins.\n"
            },
            {
                "author_name": "cmccabe",
                "id": "13971765",
                "body": "Nice.  It's good to see the pom file get simplified a little bit by this change.\n\n+1 for v2, pending jenkins"
            },
            {
                "author_name": "hadoopqa",
                "id": "13971870",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12640497/HDFS-4909.001.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:\n\n                  org.apache.hadoop.hdfs.server.namenode.ha.TestFailureToReadEdits\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/6676//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/6676//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "13971920",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12640508/HDFS-4909.002.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HDFS-Build/6678//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-HDFS-Build/6678//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "cmccabe",
                "id": "13972063",
                "body": "Tests aren't needed because this isn't a code change.  committed to 2.5"
            },
            {
                "author_name": "hudson",
                "id": "13972070",
                "body": "SUCCESS: Integrated in Hadoop-trunk-Commit #5528 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5528/])\nHDFS-4909. Avoid protocol buffer RPC namespace clashes (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1588091)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/pom.xml\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/NamenodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/QJournalProtocol.proto\n"
            },
            {
                "author_name": "hudson",
                "id": "13972837",
                "body": "FAILURE: Integrated in Hadoop-Yarn-trunk #543 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/543/])\nHDFS-4909. Avoid protocol buffer RPC namespace clashes (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1588091)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/pom.xml\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/NamenodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/QJournalProtocol.proto\n"
            },
            {
                "author_name": "hudson",
                "id": "13972970",
                "body": "SUCCESS: Integrated in Hadoop-Hdfs-trunk #1735 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1735/])\nHDFS-4909. Avoid protocol buffer RPC namespace clashes (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1588091)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/pom.xml\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/NamenodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/QJournalProtocol.proto\n"
            },
            {
                "author_name": "hudson",
                "id": "13973008",
                "body": "SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1760 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1760/])\nHDFS-4909. Avoid protocol buffer RPC namespace clashes (cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1588091)\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/CHANGES.txt\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/pom.xml\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/NamenodeProtocol.proto\n* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/proto/QJournalProtocol.proto\n"
            }
        ],
        "comments_predictions": [
            [
                2175125,
                "HDFS-4909",
                "Yes - this is a secondary JIRA filed at Arun and Aprit's request because they had closed the prior one once the compile worked, not realizing that the results failed to link. It is a problem in the .proto definitions of the three specified classes.\n",
                {
                    "property": {
                        "confidence": 0.00790826790034771,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0038189124315977097,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.029262669384479523,
                        "prediction": false
                    }
                }
            ],
            [
                2175127,
                "HDFS-4909",
                "The full import of hdfs.proto causing duplicate definitions is the same reason that we've needed to use 4 separate protoc executions in the pom.xml.  We likely need some refactoring across all of the HDFS proto files to prevent the need for multiple protoc build steps and also prevent duplicate symbols at link time.  I don't yet know the full scope of this refactoring though.",
                {
                    "property": {
                        "confidence": 0.020272227004170418,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00201799301430583,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.029737338423728943,
                        "prediction": false
                    }
                }
            ],
            [
                2175131,
                "HDFS-4909",
                "[~rhc] Thanks Ralph. I'm just trying to herd cats to get the release out... as you can imagine it's a tough job! *smile*\n\nFrankly, my inclination is to punt this from 2.1.0-beta *iff* this is something we can fix in a compatible manner down the road.",
                {
                    "property": {
                        "confidence": 0.004635840188711882,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.1379687339067459,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006301801651716232,
                        "prediction": false
                    }
                }
            ],
            [
                2175132,
                "HDFS-4909",
                "{quote}\nFrankly, my inclination is to punt this from 2.1.0-beta iff this is something we can fix in a compatible manner down the road.\n{quote}\n\nYes, I expect we can fix this later and still retain compatibility.  The original problem reported in HDFS-4866 required a backwards-incompatible change in a protocol method name, so we really needed to get that one done before beta.  For this one, I expect we can fix the problem of duplicate symbols during protoc/link time by refactoring the proto definitions, but still retaining the same method names.",
                {
                    "property": {
                        "confidence": 0.007352870889008045,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.003867092775180936,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023656468838453293,
                        "prediction": false
                    }
                }
            ],
            [
                2175134,
                "HDFS-4909",
                "This patch changes the protobuf package which DatanodeProtocol, NamenodeProtocol, and QJournalProtocol reside in to match their names.  This avoids the name conflicts that were previously caused by putting everything into \"package hadoop.hdfs\".\n\nThis doesn't alter what gets sent over the wire at all, so there are no compatibility implications.  I have confirmed this for myself by running some servers with this patch against clients which do not have it.\n\nNo changes to the Java code are needed, since we manually specify which Java packages things should go in (the java package is different than the protobuf package).  Essentially, the protobuf package is irrelevant in the java code because it gets overridden by {{option java_package}}.\n\nIt does change some of the generated code a bit.  For example, {{internal_static_hadoop_hdfs_CommitBlockSynchronizationResponseProto_descriptor}} becomes {{internal_static_hadoop_hdfs_datanode_CommitBlockSynchronizationResponseProto_descriptor}}.  But this seems to all be internal stuff deep inside the PB generated code which doesn't get exposed to the outside world.",
                {
                    "property": {
                        "confidence": 0.0056280470453202724,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004487688187509775,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03680581599473953,
                        "prediction": false
                    }
                }
            ],
            [
                2175135,
                "HDFS-4909",
                "Hi, Colin.  Thanks for doing this.  I remember when I looked at it a few months ago, I also thought we'd be able to simplify our build a little bit.  There are multiple protoc invocations right now, and that's just a workaround due to duplicate symbol inclusion when everything was in one protobuf namespace.  I just tried using a single protoc invocation with your patch, and sure enough, it worked.  I'm attaching patch v2, which is your patch plus the pom.xml change.\n\nI'm +1 for v2 of the patch pending Jenkins.\n",
                {
                    "property": {
                        "confidence": 0.0059034693986177444,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007315122056752443,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01513083465397358,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640754ac358c613a833338a8",
        "key": "SOLR-16415",
        "id": "13482121",
        "description": "When calling\u00a0 the DELETESTATUS API to clear all the stored statues as below\r\n\r\n[http://localhost:8983/solr/admin/collections?action=DELETESTATUS&flush=true]\r\n\r\nthrows exception\r\n\r\n\r\nKeeperErrorCode = Directory not empty for /overseer/collection-map-completed/mn-.auto_add_replicas\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:681) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:266) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:248) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.impl.LBSolrClient.doRequest(LBSolrClient.java:369) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.impl.LBSolrClient.request(LBSolrClient.java:297) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.impl.BaseCloudSolrClient.sendRequest(BaseCloudSolrClient.java:1171) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.impl.BaseCloudSolrClient.requestWithRetryOnStaleState(BaseCloudSolrClient.java:934) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.impl.BaseCloudSolrClient.request(BaseCloudSolrClient.java:866) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:214) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:231) ~[solr-solrj-8.11.1.jar!/:8.11.1 0b002b11819df70783e83ef36b42ed1223c14b50 - janhoy - 2021-12-14 13:50:57]\r\n\r\n\r\nAfter deleting the znode manually /overseer/collection-map-completed/mn-.auto_add_replicas , the api worked.\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006984973791986704
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.013293655589222908
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005496797151863575
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d609c4f4d395ee2221e73d",
        "key": "GROOVY-9542",
        "id": "13302992",
        "description": "([https://github.com/apache/groovy/runs/647840451?check_suite_focus=true])\r\n\r\n\u00a0\r\n\r\nWARNING: Illegal reflective access by org.codehaus.groovy.reflection.ReflectionUtils ([file:/home/runner/work/groovy/groovy/target/libs/groovy-raw-4.0.0-SNAPSHOT.jar|file://home/runner/work/groovy/groovy/target/libs/groovy-raw-4.0.0-SNAPSHOT.jar]) to constructor java.lang.AssertionError(java.lang.String) \r\n [397|https://github.com/apache/groovy/runs/647840451#step:5:397]> Task :groovy-test:test \r\n [398|https://github.com/apache/groovy/runs/647840451#step:5:398]WARNING: Please consider reporting this to the maintainers of org.codehaus.groovy.reflection.ReflectionUtils \r\n [399|https://github.com/apache/groovy/runs/647840451#step:5:399]WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations \r\n [400|https://github.com/apache/groovy/runs/647840451#step:5:400]WARNING: All illegal access operations will be denied in a future release",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.026057792827486992
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009855866432189941
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.007062290329486132
                }
            }
        },
        "comments": [
            {
                "author_name": "daniel_sun",
                "id": "17108413",
                "body": "{{AssertionError}} has two constructors to match the argument of {{String}} type: [[private AssertionError(java.lang.String)]] and [[public AssertionError(java.lang.Object)]]\r\n\r\nThe calculated distance of the former constructor is 0, so it is chosen and warning is emitted...\r\n\r\nBut it's dangerous to change the logic of choosing constructor, because constructors may have different logic even if they have compatible parameter types.\r\nHowever we have to change the logic... because the illegal acess will be forbidden in some futher Java release.\r\n\r\n\r\n"
            }
        ],
        "comments_predictions": [
            [
                2692814,
                "GROOVY-9542",
                "{{AssertionError}} has two constructors to match the argument of {{String}} type: [[private AssertionError(java.lang.String)]] and [[public AssertionError(java.lang.Object)]]\r\n\r\nThe calculated distance of the former constructor is 0, so it is chosen and warning is emitted...\r\n\r\nBut it's dangerous to change the logic of choosing constructor, because constructors may have different logic even if they have compatible parameter types.\r\nHowever we have to change the logic... because the illegal acess will be forbidden in some futher Java release.\r\n\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.005626518279314041,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00482550635933876,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.024631844833493233,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5eec0f4d395ee221df62f",
        "key": "MECLIPSE-578",
        "id": "12802708",
        "description": "The configuration parameter 'projectNameTemplate' is able to use the following strings to define the project name pattern: groupId, artifactId, version. When using a pattern ad '[artifactId]-[version]', it is needed to re-generate Eclipse files when changing the version. To avoide this re-generation, I think a new variable [branch] holding the SCM branch name or \"trunk\" should be added.",
        "predictions": {},
        "comments": [
            {
                "author_name": "chamerling",
                "id": "14435004",
                "body": "In fact we should be able to access to all the POM attributes so that we can define the template like we want.\nTags, trunk or branches is a good starting point"
            },
            {
                "author_name": "michael-o",
                "id": "14732870",
                "body": "This issue has been auto closed because it has been inactive for a long period of time. If you think this issue still applies, retest your problem with the most recent version of Maven and the affected component, reopen and post your results."
            }
        ],
        "comments_predictions": [
            [
                1404634,
                "MECLIPSE-578",
                "This issue has been auto closed because it has been inactive for a long period of time. If you think this issue still applies, retest your problem with the most recent version of Maven and the affected component, reopen and post your results.",
                {
                    "property": {
                        "confidence": 0.004360508173704147,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009980888105928898,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013815393671393394,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d910f4d395ee2219f6e0",
        "key": "SUREFIRE-730",
        "id": "12809727",
        "description": "JUnit4Listener determines succesful pass of a test via a single boolean flag on the class that is set when a test to \"true\" when a test is started, set to \"false\" when a test failed, and checked after a test finishes. If all the tests run in serial, this scheme works, but when the tests are all run in parallel, after the first failed test no other successful tests will be reported as having been run (because after the flag is set to \"fail\" nothing ever resets it - all the tests have already started).\n\nIt would be simple to fix this by changing the single failure flag to a hash map of tests to pass/fail flags, and such a change would greatly improve my quality of life.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.12714043259620667
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006161517929285765
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006253648083657026
                }
            }
        },
        "comments": [
            {
                "author_name": "krosenvold",
                "id": "14454949",
                "body": "Thanks a lot for this report, it's the root cause of a number of other bugs we have in the issue trackers. \n\nFixed with a slightly different patch and a unit test in r1095165. "
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e824f4d395ee221ce787",
        "key": "OAK-6535",
        "id": "13093380",
        "description": "Oak 1.6 added support for Lucene Hybrid Index (OAK-4412). That enables near real time (NRT) support for Lucene based indexes. It also had a limited support for sync indexes. This feature aims to improve that to next level and enable support for sync property indexes.\n\nMore details at https://wiki.apache.org/jackrabbit/Synchronous%20Lucene%20Property%20Indexes",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.9346069693565369
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.7885243892669678
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.08323650062084198
                }
            }
        },
        "comments": [
            {
                "author_name": "catholicon",
                "id": "16123026",
                "body": "Discussed a few ideas around this with [~chetanm] offline:\n# unique index pruning can probably be done by tying into what's being added into lucene structure (basically prune data from prop-index-tree which is added to lucene)... for non-unique ones, throwing away buckets at index cycle is still easier.\n# instead of each non-unique-prop-def having content-mirror-store-strategy buckets, we can have a single content-mirror-store-strategy at index level which can index values for each non-unique-property\n## this helps in purge logic a bit\n## assumes that values for multiple non-unique-prop changes would be more or less disjoint between consecutive async indexing cycle runs\n## while discussing this idea, it seemed that it would answer the open points on wiki \\[0] - but that's incorrect. Answering {{a='b' AND c='d'}} can't be done by this idea.\n\n[~chetanm], regarding point 2.3 above: assuming number of changes between consecutive async cycle runs remain moderate in the sense that there aren't HUGE FLAT structure: maybe we can have sorted traversal over content tree (on node-name) and hence solve the {{AND}} by skipping matches which aren't found in all the cursors. \n\n\\[0]: https://wiki.apache.org/jackrabbit/Synchronous%20Lucene%20Property%20Indexes#Open_Points"
            },
            {
                "author_name": "chetanm",
                "id": "16150257",
                "body": "Feature branch https://github.com/chetanmeh/jackrabbit-oak/compare/trunk...chetanmeh:OAK-6535\n\n# Add {{PropertyUpdateCallback}} which is invoked for each indexed property change (/)\n# PropertyUpdateCallback based on property index\n## For normal index\n### Value pattern support (/) \n## For unique index\n### Check for unique ness constraint (/) \n### Store the created time (/)\n# Cleanup support\n## Cleaner implementation (/)\n## Configure a periodic task (/)\n# Query Support\n## PropertyIndexLookup variant for hybrid (/)\n## Index Planner integration (/)\n## NodeType Index\n## Cursor union (/)\n## Reference Index\n## Integrate with query plan (/)\n## Relative property transform (/)\n# Benchmark (/)"
            },
            {
                "author_name": "chetanm",
                "id": "16179017",
                "body": "This feature is now ready for review\n\n* On github - See [here|https://github.com/chetanmeh/jackrabbit-oak/compare/trunk...chetanmeh:OAK-6535]\n* As single patch - See [here|^OAK-6535-v1.diff]\n* See [wiki|https://wiki.apache.org/jackrabbit/Synchronous%20Lucene%20Property%20Indexes] for more background\n\nh2. Implementation Details\n\n*Indexing*\n{{LuceneIndexEditor}} now supports a {{PropertyUpdateCallback}} which is invoked for each indexed property change. For this feature we provide a {{PropertyIndexUpdateCallback}} which performs the property index update as per property index type. \n\nFor non unique sync index it uses {{ContentMirrorStoreStrategy}} and for unique it uses {{UniqueIndexStoreStrategy}}. See wiki for storage format\n\nFor non unique indexes it disables default pruning\n\nFor unique index each index entry also stores a timestamp (as epoch time) in {{jcr:created}}. Notes its not of type Calendar\n\n*Query*\nOn query side {{IndexPlanner}} checks if the definition support sync indexes. If yes then it determine which sync index can be used. For a query only of the sync indexes can be used. It follows following rule\n\n* If any unique index is found then that is given preference\n* If multiple non unique sync indexes are found then first one is used\n\nIn case of unique index the entryCount is set to 1 such that this index reports almost lowest cost.\n\nPost planning the {{LucenePropertyIndex}} would see if planner has identified any sync index. If yes then it returns a concatenated iterator where iterator provided by property index (via {{HybridPropertyIndexLookup}}) comes first. \n\n*Cleanup*\n\nThis feature configures a {{PropertyIndexCleaner}} job which gets periodically triggered (default frequency every 10 min) and does following\n\n# First change the head bucket if there is any change in current head bucket state for non unique sync index. This is merged\n# For non unique sync index cleanup old orphan buckets\n# For unique index scan the index entries and remove those index entries whose {{jcr:created}} is older than lastIndexTo time of indexes indexer lane. That is those entries which have been moved to lucene index are removed. In doing this it also keeps a threshold which defaults to 1 hr\n\n*Misc Points*\n\n# Supports relative properties\n# -Supports non root indexes- Pending OAK-6714\n# Sync index would not be used if query has\n## sorting\n## fulltext constraints\n\nh2. Benchmark\n\nThe benchmark can be run via\n\n{noformat}\njava -DhybridIndexEnabled=true -DindexingMode=nrt -DsyncIndexing=true -jar oak-benchmark*.jar benchmark  HybridIndexTest Oak-Segment-Tar-DS\n{noformat}\n\nHere\n* hybridIndexEnabled=true, syncIndexing=true - Enables this feature i.e. 'foo' property indexed in hybrid mode\n* hybridIndexEnabled=true, syncIndexing=false - Enables just the NRT mode\n* hybridIndexEnabled=false, syncIndexing=false - Enables pure property index mode\n\n{noformat}\n# HybridIndexTest                  C     min     10%     50%     90%     max       N Searcher  Mutator  Indexed\nOak-Segment-Tar-DS                 1       4       6       7       9     527    7992 5385539     39400     49890      #nrt,oakCodec,sync\nOak-Segment-Tar-DS                 1       4       6       7      10     114    7462 6834075     34220     46362      #property\nOak-Segment-Tar-DS                 1       4       5       6       8     508    9063 4439786     47797     56844      #nrt,oakCodec\nnumOfIndexes: 10, refreshDeltaMillis: 1000, asyncInterval: 5, queueSize: 1000 , hybridIndexEnabled: true, indexingMode: nrt, useOakCodec: true, cleanerIntervalInSecs: 10, syncIndexing: true \n{noformat}\n\n\nh2. Pending Stuff\n\n*Open Items*\n\n# Support for nodetype index\n# Support for reference index \n\n*Points to discuss*\n\nApart from current impl design following aspects needs to be discussed\n\n# Frequency of the cleaner job - Currently it is scheduled to run every 10 mins\n# Threshold for unique index cleanup - Currently entries would be removed after 1 hr of them making into persisted lucene index. This is required as the recorded time in index entry would not be same time as commit is made. So its possible if lastIndexTo refers to T1 then an entry created at T0 (T0 < T1) actually got persisted to repository in time T2 (T2 > T1). So this threshold ensures that we do not remove those entries which have yet not made it to the persisted lucene index\n\n[~thomasm] [~catholicon] [~teofili] Please review the patch. I would keep this open for this week so that you get time. Plan to merge next week"
            },
            {
                "author_name": "catholicon",
                "id": "16189192",
                "body": "[~chetanm], reviewed modified files (added are left). A few notes:\n{noformat}\nLIPService.java\n+            tracker = new IndexTracker();\n{noformat}\nDo we require CoR for mounted stores and nrt?\n\nMaybe, I missed it somewhere...:\n* it seems we don't plan with prop idx when sort order is defined - that can be confusing... maybe a WARN?? (\"warn\", because it seems to me that query and def aren't in sync with each other)\n* I can't see how are we skipping over prox idx in presence of a full text clause (also, we should warn if/when we skip prop idx iteration)"
            },
            {
                "author_name": "chetanm",
                "id": "16189248",
                "body": "bq. Do we require CoR for mounted stores and nrt?\n\nNote that change here was just minor refactoring to pass AsyncIndexInfoService and not semantics were changed. That said CoR is enabled for mounted stores as its purpose is just to copy index blobs on file system. NRT is anyway local so uses FSDirectory directly \n\nbq. it seems we don't plan with prop idx when sort order is defined - that can be confusing... maybe a WARN?? (\"warn\", because it seems to me that query and def aren't in sync with each other)\n\nNo we still plan just that property index would not be used in that execution. This is consistent with current support for sorting (only supported for async). So not sure we need to add warning here\n\nbq. I can't see how are we skipping over prox idx in presence of a full text clause (also, we should warn if/when we skip prop idx iteration)\n\nThis was done in a later [commit|https://github.com/chetanmeh/jackrabbit-oak/blob/OAK-6535/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexPlanner.java#L294]. Would update the consolidated patch\n\n"
            },
            {
                "author_name": "chetanm",
                "id": "16189289",
                "body": "Thanks [~catholicon] for the review so far. I have merged the current branch to trunk today. We can do further updates directly in trunk now"
            },
            {
                "author_name": "chetanm",
                "id": "16189546",
                "body": "There is a potential issue for the initial setup. AsyncIndexUpdate would fail with merge exception for the first run because two tasks collide\n\n# IndexUpdate (as part of AsyncIndexUpdate) - Removing all hidden nodes for any index which needs to be reindexed and which would be the case for any lucene index on first start\n# Hybrid PropertyIndexUpdate - This would add nodes as hidden nodes prior to first reindex\n\nDue to above 2 first commit fails with deletedChangedNode exception. So we would need a way for IndexUpdate to ignore removing such property index nodes for the reindex case. This can possibly be done via adding some convention i.e. presence of some property on the hidden node \":property-index\"\n\nHowever we would still need to provide a way to properly clean the \":property-index\" for cases where index definition got changed but empty head buckets for properties which were earlier indexer were still present\n\n[~catholicon] Thoughts?\n\nUpdate - Tracking this in OAK-6781"
            },
            {
                "author_name": "chetanm",
                "id": "16241971",
                "body": "All planned work done. Resolving this as done"
            },
            {
                "author_name": "edivad",
                "id": "16283580",
                "body": "Bulk close 1.7.12"
            },
            {
                "author_name": "thomasm",
                "id": "16687564",
                "body": "[~chetanm] I couldn't find any documentation except for https://wiki.apache.org/jackrabbit/Synchronous%20Lucene%20Property%20Indexes - do you know if there is any?"
            }
        ],
        "comments_predictions": [
            [
                1162696,
                "OAK-6535",
                "Discussed a few ideas around this with [~chetanm] offline:\n# unique index pruning can probably be done by tying into what's being added into lucene structure (basically prune data from prop-index-tree which is added to lucene)... for non-unique ones, throwing away buckets at index cycle is still easier.\n# instead of each non-unique-prop-def having content-mirror-store-strategy buckets, we can have a single content-mirror-store-strategy at index level which can index values for each non-unique-property\n## this helps in purge logic a bit\n## assumes that values for multiple non-unique-prop changes would be more or less disjoint between consecutive async indexing cycle runs\n## while discussing this idea, it seemed that it would answer the open points on wiki \\[0] - but that's incorrect. Answering {{a='b' AND c='d'}} can't be done by this idea.\n\n[~chetanm], regarding point 2.3 above: assuming number of changes between consecutive async cycle runs remain moderate in the sense that there aren't HUGE FLAT structure: maybe we can have sorted traversal over content tree (on node-name) and hence solve the {{AND}} by skipping matches which aren't found in all the cursors. \n\n\\[0]: https://wiki.apache.org/jackrabbit/Synchronous%20Lucene%20Property%20Indexes#Open_Points",
                {
                    "property": {
                        "confidence": 0.014674495905637741,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.027122367173433304,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.38082900643348694,
                        "prediction": false
                    }
                }
            ],
            [
                1162697,
                "OAK-6535",
                "Feature branch https://github.com/chetanmeh/jackrabbit-oak/compare/trunk...chetanmeh:OAK-6535\n\n# Add {{PropertyUpdateCallback}} which is invoked for each indexed property change (/)\n# PropertyUpdateCallback based on property index\n## For normal index\n### Value pattern support (/) \n## For unique index\n### Check for unique ness constraint (/) \n### Store the created time (/)\n# Cleanup support\n## Cleaner implementation (/)\n## Configure a periodic task (/)\n# Query Support\n## PropertyIndexLookup variant for hybrid (/)\n## Index Planner integration (/)\n## NodeType Index\n## Cursor union (/)\n## Reference Index\n## Integrate with query plan (/)\n## Relative property transform (/)\n# Benchmark (/)",
                {
                    "property": {
                        "confidence": 0.004168326035141945,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.014726080931723118,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.3040562868118286,
                        "prediction": false
                    }
                }
            ],
            [
                1162698,
                "OAK-6535",
                "This feature is now ready for review\n\n* On github - See [here|https://github.com/chetanmeh/jackrabbit-oak/compare/trunk...chetanmeh:OAK-6535]\n* As single patch - See [here|^OAK-6535-v1.diff]\n* See [wiki|https://wiki.apache.org/jackrabbit/Synchronous%20Lucene%20Property%20Indexes] for more background\n\nh2. Implementation Details\n\n*Indexing*\n{{LuceneIndexEditor}} now supports a {{PropertyUpdateCallback}} which is invoked for each indexed property change. For this feature we provide a {{PropertyIndexUpdateCallback}} which performs the property index update as per property index type. \n\nFor non unique sync index it uses {{ContentMirrorStoreStrategy}} and for unique it uses {{UniqueIndexStoreStrategy}}. See wiki for storage format\n\nFor non unique indexes it disables default pruning\n\nFor unique index each index entry also stores a timestamp (as epoch time) in {{jcr:created}}. Notes its not of type Calendar\n\n*Query*\nOn query side {{IndexPlanner}} checks if the definition support sync indexes. If yes then it determine which sync index can be used. For a query only of the sync indexes can be used. It follows following rule\n\n* If any unique index is found then that is given preference\n* If multiple non unique sync indexes are found then first one is used\n\nIn case of unique index the entryCount is set to 1 such that this index reports almost lowest cost.\n\nPost planning the {{LucenePropertyIndex}} would see if planner has identified any sync index. If yes then it returns a concatenated iterator where iterator provided by property index (via {{HybridPropertyIndexLookup}}) comes first. \n\n*Cleanup*\n\nThis feature configures a {{PropertyIndexCleaner}} job which gets periodically triggered (default frequency every 10 min) and does following\n\n# First change the head bucket if there is any change in current head bucket state for non unique sync index. This is merged\n# For non unique sync index cleanup old orphan buckets\n# For unique index scan the index entries and remove those index entries whose {{jcr:created}} is older than lastIndexTo time of indexes indexer lane. That is those entries which have been moved to lucene index are removed. In doing this it also keeps a threshold which defaults to 1 hr\n\n*Misc Points*\n\n# Supports relative properties\n# -Supports non root indexes- Pending OAK-6714\n# Sync index would not be used if query has\n## sorting\n## fulltext constraints\n\nh2. Benchmark\n\nThe benchmark can be run via\n\n{noformat}\njava -DhybridIndexEnabled=true -DindexingMode=nrt -DsyncIndexing=true -jar oak-benchmark*.jar benchmark  HybridIndexTest Oak-Segment-Tar-DS\n{noformat}\n\nHere\n* hybridIndexEnabled=true, syncIndexing=true - Enables this feature i.e. 'foo' property indexed in hybrid mode\n* hybridIndexEnabled=true, syncIndexing=false - Enables just the NRT mode\n* hybridIndexEnabled=false, syncIndexing=false - Enables pure property index mode\n\n{noformat}\n# HybridIndexTest                  C     min     10%     50%     90%     max       N Searcher  Mutator  Indexed\nOak-Segment-Tar-DS                 1       4       6       7       9     527    7992 5385539     39400     49890      #nrt,oakCodec,sync\nOak-Segment-Tar-DS                 1       4       6       7      10     114    7462 6834075     34220     46362      #property\nOak-Segment-Tar-DS                 1       4       5       6       8     508    9063 4439786     47797     56844      #nrt,oakCodec\nnumOfIndexes: 10, refreshDeltaMillis: 1000, asyncInterval: 5, queueSize: 1000 , hybridIndexEnabled: true, indexingMode: nrt, useOakCodec: true, cleanerIntervalInSecs: 10, syncIndexing: true \n{noformat}\n\n\nh2. Pending Stuff\n\n*Open Items*\n\n# Support for nodetype index\n# Support for reference index \n\n*Points to discuss*\n\nApart from current impl design following aspects needs to be discussed\n\n# Frequency of the cleaner job - Currently it is scheduled to run every 10 mins\n# Threshold for unique index cleanup - Currently entries would be removed after 1 hr of them making into persisted lucene index. This is required as the recorded time in index entry would not be same time as commit is made. So its possible if lastIndexTo refers to T1 then an entry created at T0 (T0 < T1) actually got persisted to repository in time T2 (T2 > T1). So this threshold ensures that we do not remove those entries which have yet not made it to the persisted lucene index\n\n[~thomasm] [~catholicon] [~teofili] Please review the patch. I would keep this open for this week so that you get time. Plan to merge next week",
                {
                    "property": {
                        "confidence": 0.009633202105760574,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.7721923589706421,
                        "prediction": true
                    },
                    "existence": {
                        "confidence": 0.3673100173473358,
                        "prediction": false
                    }
                }
            ],
            [
                1162699,
                "OAK-6535",
                "[~chetanm], reviewed modified files (added are left). A few notes:\n{noformat}\nLIPService.java\n+            tracker = new IndexTracker();\n{noformat}\nDo we require CoR for mounted stores and nrt?\n\nMaybe, I missed it somewhere...:\n* it seems we don't plan with prop idx when sort order is defined - that can be confusing... maybe a WARN?? (\"warn\", because it seems to me that query and def aren't in sync with each other)\n* I can't see how are we skipping over prox idx in presence of a full text clause (also, we should warn if/when we skip prop idx iteration)",
                {
                    "property": {
                        "confidence": 0.005555999465286732,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0055327871814370155,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01611950993537903,
                        "prediction": false
                    }
                }
            ],
            [
                1162700,
                "OAK-6535",
                "bq. Do we require CoR for mounted stores and nrt?\n\nNote that change here was just minor refactoring to pass AsyncIndexInfoService and not semantics were changed. That said CoR is enabled for mounted stores as its purpose is just to copy index blobs on file system. NRT is anyway local so uses FSDirectory directly \n\nbq. it seems we don't plan with prop idx when sort order is defined - that can be confusing... maybe a WARN?? (\"warn\", because it seems to me that query and def aren't in sync with each other)\n\nNo we still plan just that property index would not be used in that execution. This is consistent with current support for sorting (only supported for async). So not sure we need to add warning here\n\nbq. I can't see how are we skipping over prox idx in presence of a full text clause (also, we should warn if/when we skip prop idx iteration)\n\nThis was done in a later [commit|https://github.com/chetanmeh/jackrabbit-oak/blob/OAK-6535/oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexPlanner.java#L294]. Would update the consolidated patch\n\n",
                {
                    "property": {
                        "confidence": 0.0058029829524457455,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004071796778589487,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.07825946807861328,
                        "prediction": false
                    }
                }
            ],
            [
                1162702,
                "OAK-6535",
                "There is a potential issue for the initial setup. AsyncIndexUpdate would fail with merge exception for the first run because two tasks collide\n\n# IndexUpdate (as part of AsyncIndexUpdate) - Removing all hidden nodes for any index which needs to be reindexed and which would be the case for any lucene index on first start\n# Hybrid PropertyIndexUpdate - This would add nodes as hidden nodes prior to first reindex\n\nDue to above 2 first commit fails with deletedChangedNode exception. So we would need a way for IndexUpdate to ignore removing such property index nodes for the reindex case. This can possibly be done via adding some convention i.e. presence of some property on the hidden node \":property-index\"\n\nHowever we would still need to provide a way to properly clean the \":property-index\" for cases where index definition got changed but empty head buckets for properties which were earlier indexer were still present\n\n[~catholicon] Thoughts?\n\nUpdate - Tracking this in OAK-6781",
                {
                    "property": {
                        "confidence": 0.007330297492444515,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004420015029609203,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.20047111809253693,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d874f4d395ee2219c454",
        "key": "TAJO-1303",
        "id": "12767319",
        "description": "getVersion() of CheckHadoopRuntimeVersionRule.java assumes the pattern of Hadoop version as 'xx.xx.xx'.\nHowever, if CDH is used, version is expressed as 'xx.xx.xx-cdhxx.xx.xx'\nand getVersion() wrongly retrieves last digit of the version\nas 'xx-cdhxx.xx.xx' like '0-chd5.3.0'.\n\nI think getVersion() should check digit part of the Hadoop version string only. ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009226013906300068
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008410213515162468
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0053224642761051655
                }
            }
        },
        "comments": [
            {
                "author_name": "sirpkt",
                "id": "14276328",
                "body": "I changed getVersion to ignore non-digit part of hadoop version.\nI checked it works with CDH 5.3.0 cluster.\n\nIf you compile Tajo for CDH 5.3.0, you should add cloudera repository in pom.xml as following diff indicates:\n{code}\ndiff --git pom.xml pom.xml\nindex 8e5dd5e..b17ea68 100644\n--- pom.xml\n+++ pom.xml\n@@ -68,6 +68,10 @@\n         <enabled>false</enabled>\n       </snapshots>\n     </repository>\n+    <repository>\n+      <id>cloudera</id>\n+      <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>\n+    </repository>\n   </repositories>\n \n   <properties>\n{code}\n"
            },
            {
                "author_name": "ykrips",
                "id": "14276604",
                "body": "Thank you for reporting this issue. I did not notified that version string of hadoop common component is varied. Your patch works well on CDH, but could you add a patch for HDP? Version String of hadoop common project on HDP is also completely different from apache hadoop common component. I have found that the version string of HDP is *2.6.0.2.2.0.0-2041*, and we can use the first three part of this version string."
            },
            {
                "author_name": "sirpkt",
                "id": "14277964",
                "body": "Thank you for the comment, [~ykrips].\nI updated the patch to support HDP also.\nHowever, I didn't check it works with actual HDP cluster because I use only CDH and Apache clusters.\nIf you don't mind, would you check if it works on HDP?"
            },
            {
                "author_name": "ykrips",
                "id": "14277972",
                "body": "[~sirpkt] No problems. I will check it and will share the result."
            },
            {
                "author_name": "ykrips",
                "id": "14278260",
                "body": "+1 This patch works well on HDP 2.1.4.0 with hadoop 2.4.0."
            },
            {
                "author_name": "ykrips",
                "id": "14288495",
                "body": "Committed. Thank you for posting this patch."
            },
            {
                "author_name": "hudson",
                "id": "14288712",
                "body": "FAILURE: Integrated in Tajo-master-CODEGEN-build #201 (See [https://builds.apache.org/job/Tajo-master-CODEGEN-build/201/])\nTAJO-1303: CDH cannot pass hadoop version check test (jihun: rev 0024c75e9a36c6c90ab168f002101725f753f945)\n* tajo-common/src/main/java/org/apache/tajo/rule/base/CheckHadoopRuntimeVersionRule.java\n* CHANGES\n"
            },
            {
                "author_name": "hudson",
                "id": "14288714",
                "body": "SUCCESS: Integrated in Tajo-master-build #562 (See [https://builds.apache.org/job/Tajo-master-build/562/])\nTAJO-1303: CDH cannot pass hadoop version check test (jihun: rev 0024c75e9a36c6c90ab168f002101725f753f945)\n* tajo-common/src/main/java/org/apache/tajo/rule/base/CheckHadoopRuntimeVersionRule.java\n* CHANGES\n"
            }
        ],
        "comments_predictions": [
            [
                490984,
                "TAJO-1303",
                "I changed getVersion to ignore non-digit part of hadoop version.\nI checked it works with CDH 5.3.0 cluster.\n\nIf you compile Tajo for CDH 5.3.0, you should add cloudera repository in pom.xml as following diff indicates:\n{code}\ndiff --git pom.xml pom.xml\nindex 8e5dd5e..b17ea68 100644\n--- pom.xml\n+++ pom.xml\n@@ -68,6 +68,10 @@\n         <enabled>false</enabled>\n       </snapshots>\n     </repository>\n+    <repository>\n+      <id>cloudera</id>\n+      <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url>\n+    </repository>\n   </repositories>\n \n   <properties>\n{code}\n",
                {
                    "property": {
                        "confidence": 0.0056150504387915134,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005243908613920212,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016757268458604813,
                        "prediction": false
                    }
                }
            ],
            [
                490985,
                "TAJO-1303",
                "Thank you for reporting this issue. I did not notified that version string of hadoop common component is varied. Your patch works well on CDH, but could you add a patch for HDP? Version String of hadoop common project on HDP is also completely different from apache hadoop common component. I have found that the version string of HDP is *2.6.0.2.2.0.0-2041*, and we can use the first three part of this version string.",
                {
                    "property": {
                        "confidence": 0.005212504416704178,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005906598176807165,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.026436178013682365,
                        "prediction": false
                    }
                }
            ],
            [
                490986,
                "TAJO-1303",
                "Thank you for the comment, [~ykrips].\nI updated the patch to support HDP also.\nHowever, I didn't check it works with actual HDP cluster because I use only CDH and Apache clusters.\nIf you don't mind, would you check if it works on HDP?",
                {
                    "property": {
                        "confidence": 0.0038530384190380573,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03029501624405384,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008883349597454071,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d6149ff4d395ee222376ed",
        "key": "FELIX-1414",
        "id": "12431575",
        "description": "As of FELIX-950 (released with scr 1.0.8) and FELIX-1213 (not released yet) unary services bindings are replaced if a new service is registered with a higher service ranking than the already bound service.\n\nIt has been clarified in the OSGi dev list thread \"Questions on DS Spec\" [1] that a service once bound is only replaced if it ceaces to be a target either by the service being unregistered of the target filter not matching any longer. Service ranking is only obeyed upon first binding of a service to the component.\n\nTo fix we have to revert the fixes for FELIX-950 and FELIX-1213.\n\n\n[1] http://www.mail-archive.com/osgi-dev@mail.osgi.org/msg00883.html",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.010660836473107338
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.02308233268558979
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004549356177449226
                }
            }
        },
        "comments": [
            {
                "author_name": "fmeschbe",
                "id": "12737544",
                "body": "In Rev. 799629 removed the replacement of bound services for unary references if a service was registered with a higher ranking. As per the discussion on the OSGi list, a service once bound is never replaced unless the service ceases to be a target service (by unregistration or not matching the target any more).\n\nThis resolves this issue."
            },
            {
                "author_name": "fmeschbe",
                "id": "12737545",
                "body": "This issue invalidates FELIX-1213."
            },
            {
                "author_name": "fmeschbe",
                "id": "12787527",
                "body": "SCR 1.2.0 has been released. Close all issues."
            }
        ],
        "comments_predictions": [
            [
                3081640,
                "FELIX-1414",
                "In Rev. 799629 removed the replacement of bound services for unary references if a service was registered with a higher ranking. As per the discussion on the OSGi list, a service once bound is never replaced unless the service ceases to be a target service (by unregistration or not matching the target any more).\n\nThis resolves this issue.",
                {
                    "property": {
                        "confidence": 0.005485508590936661,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004639390390366316,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02469988912343979,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d61afcf4d395ee22246122",
        "key": "CONNECTORS-898",
        "id": "12696312",
        "description": "If a member of the ZK ensemble is down but there is still a majority of members active so that ZK is 'live' then when the agents startup any agents that try to connect to the missing member abort with:\n\nOpening socket connection to server overlorddev03/10.250.0.36:2181. Will not att\nempt to authenticate using SASL (unknown error)\n71 [main-SendThread(overlorddev03:2181)] WARN org.apache.zookeeper.ClientCnxn - \nSession 0x0 for server null, unexpected error, closing socket connection and att\nempting reconnect\njava.net.ConnectException: Connection refused\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735\n)\n        at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocket\nNIO.java:350)\n        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)\n\nfollowed by:\n\norg.apache.manifoldcf.core.interfaces.ManifoldCFException: Initialization failed: KeeperErrorCode = ConnectionLoss for /org.apache.manifoldcf.configuration\n        at org.apache.manifoldcf.core.system.ManifoldCF.initializeEnvironment(ManifoldCF.java:269)\n        at org.apache.manifoldcf.agents.system.ManifoldCF.initializeEnvironment(ManifoldCF.java:43)\n        at org.apache.manifoldcf.agents.BaseAgentsInitializationCommand.execute(BaseAgentsInitializationCommand.java:36)\n        at org.apache.manifoldcf.agents.AgentRun.main(AgentRun.java:93)\n\nThis has a knock affect to the other agents which then eventually fail with 'agents process could not start - shutting down'.  \n\nBesides exceptions of this type:\n\n5401 [main-SendThread(overlorddev03:2181)] INFO org.apache.zookeeper.ClientCnxn \n- Opening socket connection to server overlorddev03/10.250.0.36:2181. Will not a\nttempt to authenticate using SASL (unknown error)\n5403 [main-SendThread(overlorddev03:2181)] WARN org.apache.zookeeper.ClientCnxn \n- Session 0x0 for server null, unexpected error, closing socket connection and a\nttempting reconnect\njava.net.ConnectException: Connection refused\n        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735\n)\n        at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocket\nNIO.java:350)\n        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1068)\n5506 [main-SendThread(overlorddev04:2181)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server overlorddev04/10.250.0.46:2181. Will not attempt to authenticate using SASL (unknown error)\n5507 [main-SendThread(overlorddev04:2181)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to overlorddev04/10.250.0.46:2181, initiating session\n\nthe only other notable exception is:\n\n5509 [main-SendThread(overlorddev04:2181)] INFO org.apache.zookeeper.ClientCnxn \n- Session establishment complete on server overlorddev04/10.250.0.46:2181, sessi\nonid = 0x4444f2cb0590087, negotiated timeout = 8000\norg.apache.manifoldcf.core.interfaces.ManifoldCFException: KeeperErrorCode = Con\nnectionLoss for /org.apache.manifoldcf.flags-_AGENTRUN_\n        at org.apache.manifoldcf.core.lockmanager.ZooKeeperConnection.checkGlobalFlag(ZooKeeperConnection.java:499)\n        at org.apache.manifoldcf.core.lockmanager.ZooKeeperLockManager.checkGlobalFlag(ZooKeeperLockManager.java:787)\n        at org.apache.manifoldcf.agents.system.AgentsDaemon.runAgents(AgentsDaemon.java:110)\n        at org.apache.manifoldcf.agents.AgentRun.doExecute(AgentRun.java:64)\n        at org.apache.manifoldcf.agents.BaseAgentsInitializationCommand.execute(BaseAgentsInitializationCommand.java:37)\n        at org.apache.manifoldcf.agents.AgentRun.main(AgentRun.java:93)\n\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.005710556637495756
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01457007136195898
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006209270097315311
                }
            }
        },
        "comments": [
            {
                "author_name": "kwright@metacarta.com",
                "id": "13907392",
                "body": "What is the proposed fix for this?\n\n"
            },
            {
                "author_name": "kwright@metacarta.com",
                "id": "13907411",
                "body": "I have seen ConnectionLoss issues when zookeeper server is configured with too low a number for max connections.  See the zookeeper.cfg file with the example for ideas how to address, if that's what is happening.\n\nMy understanding is that zookeeper client is supposed to reconnect automatically when an ensemble member goes away.  The fact that it is not doing this seems like a zookeeper bug or configuration problem.  I've googled for similar error messages in conjunction with zookeeper but only found instances where it occurs in other packages, e.g. Hadoop and Apache Curator.  No solutions given.  So if you know what the actual problem/solution is, please let me know.\n"
            },
            {
                "author_name": "kwright@metacarta.com",
                "id": "13907435",
                "body": "Hadoop documentation indicates that a KeeperException of the ConnectionLoss variety is \"recoverable\", meaning I suppose that it might eventually succeed if retried (?).  I'll see whether this can be coded for 1.6, although I have limited means to test it.\n"
            },
            {
                "author_name": "kwright@metacarta.com",
                "id": "13907619",
                "body": "r1570364 (trunk), handling connection loss and session expiration.\n\nIf you go to trunk, please be aware that the schema has changed since 1.5.x, so you can't go back.  And, unfortunately, a 1.5.x patch would be difficult, because other work has already been done on the zookeeper lock handling for 1.6.\n"
            },
            {
                "author_name": "kwright@metacarta.com",
                "id": "13907715",
                "body": "Also, r1570391.  This fixes issues with error recovery in the locking functions.\n"
            },
            {
                "author_name": "gseaton",
                "id": "13908463",
                "body": "Karl,\n\nQuickly tested today (will thrash and bash more over then next few days) and it all works perfectly so far.  Excellent.\n\nZK connections had already been set to 500 as that was one of the first issues I hit when deploying on our new cluster.\n\nDo you anticipate any more schema changes as part of this cycle?"
            },
            {
                "author_name": "kwright@metacarta.com",
                "id": "13908561",
                "body": "No schema changes planned, but I can't predict the future either.\n"
            }
        ],
        "comments_predictions": [
            [
                3307854,
                "CONNECTORS-898",
                "I have seen ConnectionLoss issues when zookeeper server is configured with too low a number for max connections.  See the zookeeper.cfg file with the example for ideas how to address, if that's what is happening.\n\nMy understanding is that zookeeper client is supposed to reconnect automatically when an ensemble member goes away.  The fact that it is not doing this seems like a zookeeper bug or configuration problem.  I've googled for similar error messages in conjunction with zookeeper but only found instances where it occurs in other packages, e.g. Hadoop and Apache Curator.  No solutions given.  So if you know what the actual problem/solution is, please let me know.\n",
                {
                    "property": {
                        "confidence": 0.0041569918394088745,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0088953897356987,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013550366275012493,
                        "prediction": false
                    }
                }
            ],
            [
                3307855,
                "CONNECTORS-898",
                "Hadoop documentation indicates that a KeeperException of the ConnectionLoss variety is \"recoverable\", meaning I suppose that it might eventually succeed if retried (?).  I'll see whether this can be coded for 1.6, although I have limited means to test it.\n",
                {
                    "property": {
                        "confidence": 0.0055511146783828735,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005890339147299528,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014301637187600136,
                        "prediction": false
                    }
                }
            ],
            [
                3307856,
                "CONNECTORS-898",
                "r1570364 (trunk), handling connection loss and session expiration.\n\nIf you go to trunk, please be aware that the schema has changed since 1.5.x, so you can't go back.  And, unfortunately, a 1.5.x patch would be difficult, because other work has already been done on the zookeeper lock handling for 1.6.\n",
                {
                    "property": {
                        "confidence": 0.004824831150472164,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009483191184699535,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011913815513253212,
                        "prediction": false
                    }
                }
            ],
            [
                3307858,
                "CONNECTORS-898",
                "Karl,\n\nQuickly tested today (will thrash and bash more over then next few days) and it all works perfectly so far.  Excellent.\n\nZK connections had already been set to 500 as that was one of the first issues I hit when deploying on our new cluster.\n\nDo you anticipate any more schema changes as part of this cycle?",
                {
                    "property": {
                        "confidence": 0.011272639967501163,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03644508868455887,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.010672222822904587,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d6119ef4d395ee2222fe4d",
        "key": "FLEX-23242",
        "id": "12584116",
        "description": "Steps to reproduce:\n1.text.setStyle(\"textAlign\",\"right\"); or text.setStyle(\"textAlign\",\"center\")\n2.text.validateNow();\n3.text.measureText(\" \").width; \n \n Actual Results:\n no matter how many spaces passed in, width always return 0. if you pass a string which ends in spaces, the width of these spaces will be ignored. (it can correctly processing the string begins with spaces)\n \n Expected Results:\n actual text width includes spaces\n \n Workaround (if any):\n to calculate the actual space width, you have to do something like text.measureText(string+\"A\").width - text.measureText(\"A\").width;",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13364872",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-25633\nOriginal Reporter: siliang.tang\nOriginal Resolution: Not a Bug\nDiscoverability: Medium\nNumber of votes: 0\nReproducibility: Every Time\nSeverity: Non Functioning\nreporter: siliang.tang"
            },
            {
                "author_name": "adobejira",
                "id": "13364873",
                "body": "created: 2010-02-23 16:40:53.000\nupdated: 2010-02-24 06:08:52.000"
            }
        ],
        "comments_predictions": [
            [
                2992819,
                "FLEX-23242",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-25633\nOriginal Reporter: siliang.tang\nOriginal Resolution: Not a Bug\nDiscoverability: Medium\nNumber of votes: 0\nReproducibility: Every Time\nSeverity: Non Functioning\nreporter: siliang.tang",
                {
                    "property": {
                        "confidence": 0.0038835464511066675,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.013963147066533566,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011424659751355648,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5e4cdf4d395ee221c542a",
        "key": "PARQUET-1401",
        "id": "13180488",
        "description": "Spark uses filterFileMetaData* methods in ParquetMetadataConverter class, that\u00a0 calculate the offset and total compressed size of a RowGroup data.\r\nThe offset calculation is done by extracting the ColumnMetaData of the first column, and using its offset fields.\r\nThe total compressed size calculation is done by running a loop over all column chunks in the RowGroup, and summing up the size values from each chunk's ColumnMetaData .\r\nIf one or more columns are hidden (encrypted with a key unavailable to the reader), these calculations can't be performed, because the column metadata is protected.\u00a0\r\n\u00a0\r\nBut: these calculations don't really need the individual column values. The results pertain to the whole RowGroup, not specific columns.\u00a0\r\nTherefore, we\u00a0will define two new optional fields in the RowGroup Thrift structure:\r\n\u00a0\r\n_optional i64 file_offset_\r\n_optional i64 total_compressed_size_\r\n\u00a0\r\nand calculate/set them upon file writing. Then, Spark will be able to query a file with hidden columns (of course, only if the query itself doesn't need the hidden columns - works with a masked version of them, or reads columns with available keys).\r\n\u00a0\r\nThese values can be set only for encrypted files (or for all files, to skip the loop upon reading). I've tested this, works fine in Spark writers and readers.\r\n\u00a0\r\nI've also checked other references to ColumnMetaData fields in parquet-mr. There are none - therefore, its the only change we need in parquet.thrift to handle hidden columns.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.00967144500464201
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.23185350000858307
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00431434391066432
                }
            }
        },
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16594930",
                "body": "gszadovszky closed pull request #104: PARQUET-1401: optional RowGroup fields for handling hidden columns\nURL: https://github.com/apache/parquet-format/pull/104\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/src/main/thrift/parquet.thrift b/src/main/thrift/parquet.thrift\nindex 3a265796..03ec4b29 100644\n--- a/src/main/thrift/parquet.thrift\n+++ b/src/main/thrift/parquet.thrift\n@@ -723,6 +723,13 @@ struct RowGroup {\n    * The sorting columns can be a subset of all the columns.\n    */\n   4: optional list<SortingColumn> sorting_columns\n+\n+  /** Byte offset from beginning of file to first page (data or dictionary)\n+   * in this row group **/\n+  5: optional i64 file_offset\n+\n+  /** Total byte size of all compressed column data in this row group **/\n+  6: optional i64 total_compressed_size\n }\n \n /** Empty struct to signal the order defined by the physical or logical type */\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16619679",
                "body": "wesm closed pull request #497: PARQUET-1401: optional RowGroup fields for handling hidden columns\nURL: https://github.com/apache/parquet-cpp/pull/497\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/src/parquet/parquet.thrift b/src/parquet/parquet.thrift\nindex aec8e542..bd1f7624 100644\n--- a/src/parquet/parquet.thrift\n+++ b/src/parquet/parquet.thrift\n@@ -724,6 +724,13 @@ struct RowGroup {\n    * The sorting columns can be a subset of all the columns.\n    */\n   4: optional list<SortingColumn> sorting_columns\n+\n+  /** Byte offset from beginning of file to first page (data or dictionary)\n+   * in this row group **/\n+  5: optional i64 file_offset\n+\n+  /** Total byte size of all compressed column data in this row group **/\n+  6: optional i64 total_compressed_size\n }\n \n /** Empty struct to signal the order defined by the physical or logical type */\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "6407469bdc5b3e8de781dd51",
        "key": "HIVE-26524",
        "id": "13480681",
        "description": "Calcite has a set of rules to remove sections of a query plan known never produces any rows. In some cases the whole plan can be removed. Such plans are represented with a single {{Values}} operators with no tuples. ex.:\r\n{code:java}\r\nselect y + 1 from (select a1 y, b1 z from t1 where b1 > 10) q WHERE 1=0\r\n{code}\r\n{code:java}\r\nHiveValues(tuples=[[]])\r\n{code}\r\nOther cases when plan has outer join or set operators some branches can be replaced with empty values moving forward in some cases the join/set operator can be removed\r\n{code:java}\r\nselect a2, b2 from t2 where 1=0\r\nunion\r\nselect a1, b1 from t1\r\n{code}\r\n{code:java}\r\nHiveAggregate(group=[{0, 1}])\r\n  HiveTableScan(table=[[default, t1]], table:alias=[t1])\r\n{code}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.014503463171422482
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.05709884688258171
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.002628944581374526
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d5c5f4d395ee22191728",
        "key": "TS-4289",
        "id": "12951665",
        "description": "For example, something like\n\n{code}\ncond %{HEADER:ATS-FOO} { \"A\", \"B\", \"C\"}\n{code}\n\nWhere {} denotes a group of possible \"values\", and values are strings, regexes etc. just as normal.",
        "predictions": {},
        "comments": [
            {
                "author_name": "zwoop",
                "id": "15202484",
                "body": "This becomes particularly useful once we land the Geo-IP additions to the plugin, such that you can do e.g.\n\n{code}\ncond %{GEO:COUNTRY} { \"US\", \"UK\", \"SE\" }\n...\n{code}\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d619f3f4d395ee22243220",
        "key": "CXF-2761",
        "id": "12461759",
        "description": "Take a look at the generated JS-Code, and especially at the variable item.\n\n{noformat}\nfunction ws_ejb_core_lunchroulette_de__userGetMeetingpoints_deserialize (cxfjsutils, element) {\n    var newobject = new ws_ejb_core_lunchroulette_de__userGetMeetingpoints();\n    cxfjsutils.trace('element: ' + cxfjsutils.traceElementName(element));\n    var curElement = cxfjsutils.getFirstElementChild(element);\n    var item;\n    cxfjsutils.trace('curElement: ' + cxfjsutils.traceElementName(curElement));\n    cxfjsutils.trace('processing session');\n    var value = null;\n    if (!cxfjsutils.isElementNil(curElement)) {\n     value = cxfjsutils.getNodeText(curElement);\n     item = value;\n    }\n    newobject.setSession(item);\n    if (curElement != null) {\n     curElement = cxfjsutils.getNextElementSibling(curElement);\n    }\n    cxfjsutils.trace('curElement: ' + cxfjsutils.traceElementName(curElement));\n    cxfjsutils.trace('processing filter');\n    var value = null;\n    if (!cxfjsutils.isElementNil(curElement)) {\n     item = ws_ejb_core_lunchroulette_de__filter_deserialize(cxfjsutils, curElement);\n    }\n    newobject.setFilter(item);\n    if (curElement != null) {\n     curElement = cxfjsutils.getNextElementSibling(curElement);\n    }\n    return newobject;\n}\n{noformat}\n\nIt is possible that item is filled with the value of the first \"element\" and not changed for the second element, and so the second vlement will get the value for the first element.\n\n\nEasy fix (in my opinion):\n{noformat}\n        utils.appendLine(\"newobject.\" + accessorName + \"(item);\");\n        utils.appendLine(\"var item = null;\");\n        if (!itemInfo.isArray()) {\n            utils.startIf(\"curElement != null\");\n            utils.appendLine(\"curElement = cxfjsutils.getNextElementSibling(curElement);\");\n            utils.endBlock();\n        }\n{noformat}\n\nLine 661 and following in SchemaJavascriptBuilder.java.\n\nThanks in advance,\nBj\u00f6rn",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.01431734673678875
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.012821655720472336
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0037550749257206917
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d61f58f4d395ee2224f391",
        "key": "CASSANDRA-8848",
        "id": "12776700",
        "description": "When decoding the binary protocol if a ProtocolException is thrown the streamID the request came in on is lost. This makes it very hard for drivers to correctly handle improper protocol implementations.\n\nIncluded is a test case which sends a frame with version 0x82 and op 0x9 which should return a ProtocolError indicating that PREPARE should be a client Request not a response.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008625666610896587
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009087071754038334
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005825314670801163
                }
            }
        },
        "comments": [
            {
                "author_name": "thobbs",
                "id": "14333862",
                "body": "Thanks for the patch, [~Zariel]!\n\nSince this issue appears to also affect 2.0 and 2.1, I've attached backported versions of the patch.  I also made the following changes:\n* Fix bugs where wrapped ErrorMessages were not actually thrown\n* Only catch ProtocolException instead of Throwable when looking up opcode\n* Add two test cases for other protocol errors\n* Minor code style and license header cleanup\n\nWould you mind reviewing the new patches?"
            },
            {
                "author_name": "Zariel",
                "id": "14335025",
                "body": "Looks good to me, do you want me to update the patch for trunk to match your changes?"
            },
            {
                "author_name": "thobbs",
                "id": "14340932",
                "body": "No, that's fine, it's easy to merge the 2.1 patch to trunk.\n\nI'll consider that a +1, then.  Committed as 5654e736.  Thanks again!"
            },
            {
                "author_name": "Zariel",
                "id": "14341456",
                "body": "thanks!"
            }
        ],
        "comments_predictions": [
            [
                3462133,
                "CASSANDRA-8848",
                "Thanks for the patch, [~Zariel]!\n\nSince this issue appears to also affect 2.0 and 2.1, I've attached backported versions of the patch.  I also made the following changes:\n* Fix bugs where wrapped ErrorMessages were not actually thrown\n* Only catch ProtocolException instead of Throwable when looking up opcode\n* Add two test cases for other protocol errors\n* Minor code style and license header cleanup\n\nWould you mind reviewing the new patches?",
                {
                    "property": {
                        "confidence": 0.004697103518992662,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03067905642092228,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.006612700875848532,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d376f4d395ee22184ef6",
        "key": "YARN-7792",
        "id": "13132992",
        "description": "This Jira is to run aggregated\u00a0YARN-6592 branch patch against trunk and check for any jenkins issues.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.004168434999883175
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.04554504156112671
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005615122150629759
                }
            }
        },
        "comments": [
            {
                "author_name": "sunilg",
                "id": "16335569",
                "body": "I will attach an aggregated patch to run against trunk after branch rebase."
            },
            {
                "author_name": "sunilg",
                "id": "16335589",
                "body": "rebased and attach v1 patch for jenkins (whole branch code)"
            },
            {
                "author_name": "genericqa",
                "id": "16335894",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 38 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 10s{color} | {color:red} root in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m  8s{color} | {color:red} root in trunk failed. {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-mapreduce-client-app in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  9s{color} | {color:red} hadoop-sls in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-api in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  9s{color} | {color:red} hadoop-yarn-applications-distributedshell in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-client in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-server-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-server-nodemanager in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  7s{color} | {color:red} hadoop-yarn-server-resourcemanager in trunk failed. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  1m 34s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  7s{color} | {color:red} hadoop-mapreduce-client-app in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  9s{color} | {color:red} hadoop-sls in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  7s{color} | {color:red} hadoop-yarn-api in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-applications-distributedshell in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-client in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  9s{color} | {color:red} hadoop-yarn-server-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  7s{color} | {color:red} hadoop-yarn-server-nodemanager in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-server-resourcemanager in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-mapreduce-client-app in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  7s{color} | {color:red} hadoop-sls in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  9s{color} | {color:red} hadoop-yarn in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-api in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-applications-distributedshell in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-client in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  6s{color} | {color:red} hadoop-yarn-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 10s{color} | {color:red} hadoop-yarn-server-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  7s{color} | {color:red} hadoop-yarn-server-nodemanager in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-server-resourcemanager in trunk failed. {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 32s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 44s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} cc {color} | {color:red} 13m 21s{color} | {color:red} root generated 7 new + 0 unchanged - 0 fixed = 7 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javac {color} | {color:red} 13m 21s{color} | {color:red} root generated 1241 new + 0 unchanged - 0 fixed = 1241 total (was 0) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 34s{color} | {color:orange} root: The patch generated 2476 new + 0 unchanged - 0 fixed = 2476 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 339 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  6s{color} | {color:red} The patch 3072 line(s) with tabs. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 14s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 41s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 4204 new + 0 unchanged - 0 fixed = 4204 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 36s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 4189 new + 0 unchanged - 0 fixed = 4189 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager generated 9 new + 0 unchanged - 0 fixed = 9 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 94m 13s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 44s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  3s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  4s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 18m  2s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 60m 24s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 37s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 27s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 41s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m  3s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 29s{color} | {color:red} The patch generated 8 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}299m  7s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907266/YARN-6592.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 871838509d2a 3.13.0-133-generic #182-Ubuntu SMP Tue Sep 19 15:49:21 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 6347b22 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvninstall-root.txt |\r\n| compile | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-compile-root.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-tools_hadoop-sls.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-tools_hadoop-sls.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-tools_hadoop-sls.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| cc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-compile-cc-root.txt |\r\n| javac | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-compile-javac-root.txt |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-checkstyle-root.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/whitespace-eol.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/whitespace-tabs.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19396/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 881 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19396/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "genericqa",
                "id": "16337020",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 28s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 38 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 20s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 19s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 40s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 25s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 25s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  1s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 31s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  7s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  7s{color} | {color:orange} root: The patch generated 164 new + 2309 unchanged - 38 fixed = 2473 total (was 2347) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 41s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 5 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 34s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m  5s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 49s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  7s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  9s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 15s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 69m 22s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 45s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 36s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  5s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 59s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}372m 21s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907266/YARN-6592.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux fa3565cfebbf 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 39b999a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/diff-checkstyle-root.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/whitespace-eol.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19416/testReport/ |\r\n| Max. process+thread count | 884 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19416/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "genericqa",
                "id": "16337021",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 31s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 38 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 16s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 36s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 41s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  9s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 27s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 28s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  2s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 33s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  2s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 35s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 35s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 35s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 10s{color} | {color:orange} root: The patch generated 164 new + 2309 unchanged - 38 fixed = 2473 total (was 2347) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 39s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 5 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 26s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 42s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 55s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 40s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  6s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  8s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 12s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 69m  6s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 18s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 33s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  0s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 54s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}372m 28s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907266/YARN-6592.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux e381da1c7d50 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 39b999a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/diff-checkstyle-root.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/whitespace-eol.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19417/testReport/ |\r\n| Max. process+thread count | 865 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19417/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "genericqa",
                "id": "16337031",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 38 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 53s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 24s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  4s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 32s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m 20s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  1s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 58s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 11m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  3s{color} | {color:orange} root: The patch generated 165 new + 2311 unchanged - 38 fixed = 2476 total (was 2349) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 5 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 42s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 18s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 35s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}124m 26s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 47s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 14s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 16s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 48s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 66m  2s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 26m  8s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 43s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 45s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 53s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}385m 33s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n|   | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907266/YARN-6592.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux bde0c9f823d9 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 39b999a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/diff-checkstyle-root.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/whitespace-eol.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19415/testReport/ |\r\n| Max. process+thread count | 887 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19415/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "asuresh",
                "id": "16338374",
                "body": "Updating patch after rebasing with trunk."
            },
            {
                "author_name": "genericqa",
                "id": "16338638",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 34s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 29s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 27s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 17s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 30s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m  4s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  5s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 37s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 43s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 28s{color} | {color:red} hadoop-yarn-api in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-server-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 18s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 16s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 16s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 22s{color} | {color:red} hadoop-mapreduce-client-app in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 15s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 13m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 18s{color} | {color:orange} root: The patch generated 142 new + 2431 unchanged - 44 fixed = 2573 total (was 2475) {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-server-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 24s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 25s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 26s{color} | {color:red} hadoop-mapreduce-client-app in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 19s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m  3s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 18s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 16s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 38s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 316 new + 4197 unchanged - 0 fixed = 4513 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 17s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 162 new + 4183 unchanged - 0 fixed = 4345 total (was 4183) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager generated 116 new + 4 unchanged - 0 fixed = 120 total (was 4) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 16s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client generated 25 new + 0 unchanged - 0 fixed = 25 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 13s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell generated 10 new + 0 unchanged - 0 fixed = 10 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 17s{color} | {color:red} hadoop-tools_hadoop-sls generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}105m 11s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 37s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 24s{color} | {color:red} hadoop-yarn-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 24s{color} | {color:red} hadoop-yarn-server-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 26s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 27s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 22s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 27s{color} | {color:red} hadoop-mapreduce-client-app in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 20s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}224m  2s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907579/YARN-7792.002.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 3804e84ebe54 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 0c559b2 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-tools_hadoop-sls.txt |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-checkstyle-root.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-tools_hadoop-sls.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-findbugs-hadoop-tools_hadoop-sls.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-tools_hadoop-sls.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-tools_hadoop-sls.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19441/testReport/ |\r\n| Max. process+thread count | 848 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19441/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "asuresh",
                "id": "16338742",
                "body": "Rebased with trunk and updated patch again"
            },
            {
                "author_name": "sunilg",
                "id": "16338751",
                "body": "Thanks [~asuresh]. I will keep a track of this today."
            },
            {
                "author_name": "genericqa",
                "id": "16339112",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 24s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 17s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 49s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 50s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m  4s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  3s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 52s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 16s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 14s{color} | {color:orange} root: The patch generated 142 new + 2431 unchanged - 44 fixed = 2573 total (was 2475) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 56s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 45s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 43s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 36s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}107m 36s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 42s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  7s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 13s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 21s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 69m  6s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 38s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 12m 47s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  0s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 57s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}376m  4s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907628/YARN-7792.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 21ccc3bbefce 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 59828be |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19459/testReport/ |\r\n| Max. process+thread count | 837 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19459/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "genericqa",
                "id": "16339113",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 24s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 16s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 48s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 54s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m 11s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  1s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 52s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 16s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 16s{color} | {color:orange} root: The patch generated 142 new + 2431 unchanged - 44 fixed = 2573 total (was 2475) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 58s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 44s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 44s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}108m  9s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 41s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  9s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  8s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 14s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 69m  1s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 26m 35s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 34s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 58s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 58s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}376m  4s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907628/YARN-7792.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 3983f25ea2ee 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 59828be |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19458/testReport/ |\r\n| Max. process+thread count | 863 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19458/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "sunilg",
                "id": "16339133",
                "body": "All javadoc errors reported here are just warning. {{mvn javadoc:javadoc}} came clean for me. I think its fine and we can go for merge as there are no major problems.\r\n\r\n\u00a0\r\n\r\ncc/[~asuresh] [~leftnoteasy]"
            },
            {
                "author_name": "genericqa",
                "id": "16339138",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 10s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 29s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 18s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 19s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 50s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  3s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 41s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 13m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 23s{color} | {color:orange} root: The patch generated 141 new + 2427 unchanged - 44 fixed = 2568 total (was 2471) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 29s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 55s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 30s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 44s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}121m 23s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 37s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  4s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  5s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 32s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 67m 32s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 27m 13s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 34s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 49s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 47s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}398m 57s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907628/YARN-7792.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 3cbd575775b0 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 59828be |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/patch-unit-hadoop-tools_hadoop-sls.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19460/testReport/ |\r\n| Max. process+thread count | 895 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19460/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "sunilg",
                "id": "16339410",
                "body": "These javadoc errors are false alert. {{link}} works fine when I checked in my local version.\r\n\r\n+1 for merge based on this report."
            },
            {
                "author_name": "asuresh",
                "id": "16340310",
                "body": "Yup - looks good to me too. Thanks [~sunilg]"
            },
            {
                "author_name": "jianhe",
                "id": "16342328",
                "body": "Some comments regarding config, (Don't know where to post these comments, so just paste here)\r\n - yarn.resourcemanager.placement-constraints.algorithm.pool-size\r\n\r\n - yarn.resourcemanager.placement-constraints.scheduler.pool-size\r\n\r\nThe naming \"pool-size\" confused me at first sight. I\u00a0understand\u00a0it after looking at the description/code. How about call it thread-pool-size to be more explicit ?\r\n - I must be doing something wrong, I tried to run distributed shell as below but it fails\r\n\r\n{code:java}\r\nhadoop-common jhe$ hadoop jar $HADOOP_HOME/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-$VERSION.jar -jar $HADOOP_HOME/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-$VERSION.jar -shell_command sleep -shell_args 10000 --placement_spec spec\r\nPicked up _JAVA_OPTIONS: -Djava.awt.headless=true\r\n18/01/26 23:05:46 INFO distributedshell.Client: Initializing Client\r\n18/01/26 23:05:46 INFO distributedshell.PlacementSpec: Parsing Placement Specs: [spec]\r\n18/01/26 23:05:46 INFO distributedshell.PlacementSpec: Parsing Spec: [spec]\r\n18/01/26 23:05:46 ERROR distributedshell.Client: Error running Client\r\njava.lang.ArrayIndexOutOfBoundsException: 1\r\n at org.apache.hadoop.yarn.applications.distributedshell.PlacementSpec.parse(PlacementSpec.java:85)\r\n at org.apache.hadoop.yarn.applications.distributedshell.Client.init(Client.java:431)\r\n at org.apache.hadoop.yarn.applications.distributedshell.Client.main(Client.java:248)\r\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n at java.lang.reflect.Method.invoke(Method.java:498)\r\n at org.apache.hadoop.util.RunJar.run(RunJar.java:239)\r\n at org.apache.hadoop.util.RunJar.main(RunJar.java:153)\r\n\r\n{code}\r\nwhere the spec is a file which has the content copied from the\u00a0document\u00a0\r\n\r\n\"zk=3,NOTIN,NODE,zk:hbase=5,IN,RACK,zk\"\u00a0\r\n\r\n\u00a0"
            },
            {
                "author_name": "asuresh",
                "id": "16342344",
                "body": "[~jianhe], thanks for taking it for a spin.\r\n\r\nbq. where the spec is a file which has the content copied from the document\r\nIt isnt meant to be read from a file. the spec is to be specified in the command line ifself like so:\r\n{code}\r\n.. -placement_spec zk=3,NOTIN,NODE,zk:hbase=5,IN,RACK,zk\r\n{code}"
            },
            {
                "author_name": "asuresh",
                "id": "16342346",
                "body": "bq. The naming \"pool-size\" confused me at first sight. I\u00a0understand\u00a0it after looking at the description/code. How about call it thread-pool-size to be more explicit\u00a0\r\nmakes sense - will change it. Like [~kkaranasos] mentioned, we have a config clean up task that we will take up after the merge. "
            },
            {
                "author_name": "jianhe",
                "id": "16342355",
                "body": "bq. It isnt meant to be read from a file. the spec is to be specified in the command line ifself like so:\r\nok.. somehow I got confused that it is a file. \r\n\r\nAlso, got a question about the onRequestsRejected API, is the AM expected to keep on retrying the requests? (BTW, RejectedSchedulingRequest#reason right now is not set, which makes AM no way to know why it's rejected).\r\n\r\nIIUC, previously, there isn't such a notion of rejecting resource requests due to transient states - requests that aren't satisfied due to user-limit, capacity etc. are just getting pending in RM. AM doesn't need to keep on retrying those requests."
            },
            {
                "author_name": "asuresh",
                "id": "16342363",
                "body": "bq. BTW, RejectedSchedulingRequest#reason right now is not set, which makes AM no way to know why it's rejected..\r\nIt is set by the PlacementProcessor in two situations.\r\n# when the algorithm cannot [place|https://github.com/apache/hadoop/blob/YARN-6592/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/processor/PlacementProcessor.java#L273-L275]\r\n# when a placed requests cannot be [scheduled|https://github.com/apache/hadoop/blob/YARN-6592/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/processor/PlacementProcessor.java#L286-L288] by the Scheduler - this has a retry of around 5 by default.\r\n\r\nbq. , previously, there isn't such a notion of rejecting resource requests due to transient states - requests that aren't satisfied due to user-limit, capacity etc. are just getting pending in RM. AM doesn't need to keep on retrying those requests.\r\nYup - Out take currently is to let the AM decide what to do if placement / scheduling was not successful. As we mentioned in the doc, currently we assume constraints are *hard*. If placement is not possible, we don't loosen the constraints. Out plan is to introduce the following in future work (we will open JIRAs in YARN-7812):\r\n# Support *soft* constraints: If retry is expired, send it down to the Scheduler as an ANY request.\r\n# Support for DELAYED_OR composite constraint: If the placement was not possible in x attempts, try the next Constraint.\r\n\r\n\r\n"
            },
            {
                "author_name": "jianhe",
                "id": "16342368",
                "body": "bq. It is set by the PlacementProcessor in two situations.\r\nOh, missed this.\r\nsounds good."
            },
            {
                "author_name": "genericqa",
                "id": "16345989",
                "body": "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 16m 17s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 29s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 34s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 24s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 40s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  8m 33s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 21m 32s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 11s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 28s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  9m 24s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 13m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 59s{color} | {color:orange} root: The patch generated 141 new + 2420 unchanged - 46 fixed = 2561 total (was 2466) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 34s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 34s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  9m  9s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 44s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 39s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m  7s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 45s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 15s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 20s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 31s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 63m 14s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 41s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 12m 43s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 12s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 25s{color} | {color:green} hadoop-yarn-site in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 58s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}393m 51s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.resourcemanager.webapp.TestRMWebServiceAppsNodelabel |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.resourcemanager.webapp.TestRMWebServiceAppsNodelabel |\r\n|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12908367/YARN-7792.004.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 4f733bdc8987 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 901d15a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19529/testReport/ |\r\n| Max. process+thread count | 861 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19529/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n"
            },
            {
                "author_name": "asuresh",
                "id": "16346052",
                "body": "{{TestRMWebServiceAppsNodelabel}} failure is unrelated\r\nThe remain tests run fine for me locally.\r\n"
            },
            {
                "author_name": "asuresh",
                "id": "16347054",
                "body": "Closing this. Since branch is merged with trunk"
            },
            {
                "author_name": "leftnoteasy",
                "id": "16406830",
                "body": "Removed fix version since this is not a committed patch."
            }
        ],
        "comments_predictions": [
            [
                93091,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 38 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 10s{color} | {color:red} root in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m  8s{color} | {color:red} root in trunk failed. {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-mapreduce-client-app in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  9s{color} | {color:red} hadoop-sls in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-api in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  9s{color} | {color:red} hadoop-yarn-applications-distributedshell in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-client in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-server-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-server-nodemanager in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m  7s{color} | {color:red} hadoop-yarn-server-resourcemanager in trunk failed. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  1m 34s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  7s{color} | {color:red} hadoop-mapreduce-client-app in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  9s{color} | {color:red} hadoop-sls in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  7s{color} | {color:red} hadoop-yarn-api in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-applications-distributedshell in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-client in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  9s{color} | {color:red} hadoop-yarn-server-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  7s{color} | {color:red} hadoop-yarn-server-nodemanager in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-server-resourcemanager in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-mapreduce-client-app in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  7s{color} | {color:red} hadoop-sls in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  9s{color} | {color:red} hadoop-yarn in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-api in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-applications-distributedshell in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-client in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  6s{color} | {color:red} hadoop-yarn-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 10s{color} | {color:red} hadoop-yarn-server-common in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  7s{color} | {color:red} hadoop-yarn-server-nodemanager in trunk failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m  8s{color} | {color:red} hadoop-yarn-server-resourcemanager in trunk failed. {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 32s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 44s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} cc {color} | {color:red} 13m 21s{color} | {color:red} root generated 7 new + 0 unchanged - 0 fixed = 7 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javac {color} | {color:red} 13m 21s{color} | {color:red} root generated 1241 new + 0 unchanged - 0 fixed = 1241 total (was 0) {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 34s{color} | {color:orange} root: The patch generated 2476 new + 0 unchanged - 0 fixed = 2476 total (was 0) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 339 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  6s{color} | {color:red} The patch 3072 line(s) with tabs. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 14s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 59s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 41s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 4204 new + 0 unchanged - 0 fixed = 4204 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 36s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 4189 new + 0 unchanged - 0 fixed = 4189 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager generated 9 new + 0 unchanged - 0 fixed = 9 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 94m 13s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 44s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  3s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  4s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 18m  2s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 60m 24s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 37s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 27s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 41s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m  3s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 29s{color} | {color:red} The patch generated 8 ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}299m  7s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907266/YARN-6592.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 871838509d2a 3.13.0-133-generic #182-Ubuntu SMP Tue Sep 19 15:49:21 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 6347b22 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvninstall-root.txt |\r\n| compile | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-compile-root.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-tools_hadoop-sls.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-tools_hadoop-sls.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-tools_hadoop-sls.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/branch-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| cc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-compile-cc-root.txt |\r\n| javac | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-compile-javac-root.txt |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-checkstyle-root.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/whitespace-eol.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/whitespace-tabs.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19396/testReport/ |\r\n| asflicense | https://builds.apache.org/job/PreCommit-YARN-Build/19396/artifact/out/patch-asflicense-problems.txt |\r\n| Max. process+thread count | 881 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19396/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.005971325561404228,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005288239568471909,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04469596594572067,
                        "prediction": false
                    }
                }
            ],
            [
                93092,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 28s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 38 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 20s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 19s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 40s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 25s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 25s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  1s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 31s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  7s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 33s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  7s{color} | {color:orange} root: The patch generated 164 new + 2309 unchanged - 38 fixed = 2473 total (was 2347) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 41s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 5 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 49s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 34s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m  5s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 49s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  7s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  9s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 15s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 69m 22s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 45s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 36s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  5s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 59s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}372m 21s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907266/YARN-6592.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux fa3565cfebbf 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 39b999a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/diff-checkstyle-root.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/whitespace-eol.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19416/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19416/testReport/ |\r\n| Max. process+thread count | 884 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19416/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004373121075332165,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006817288231104612,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.029042037203907967,
                        "prediction": false
                    }
                }
            ],
            [
                93093,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 31s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 38 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 16s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 36s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 41s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  9s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 27s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 28s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  2s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 33s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  2s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 35s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 35s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 35s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 10s{color} | {color:orange} root: The patch generated 164 new + 2309 unchanged - 38 fixed = 2473 total (was 2347) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 39s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 5 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 26s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 47s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 42s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}106m 55s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 40s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  6s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  8s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 12s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 69m  6s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 18s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 33s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  0s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 54s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}372m 28s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907266/YARN-6592.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux e381da1c7d50 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 39b999a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/diff-checkstyle-root.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/whitespace-eol.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19417/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19417/testReport/ |\r\n| Max. process+thread count | 865 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19417/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004454710986465216,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006683015730232,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.029477698728442192,
                        "prediction": false
                    }
                }
            ],
            [
                93094,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 38 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 53s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 24s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  4s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 32s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m 20s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  1s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 58s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m  4s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 11m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  3s{color} | {color:orange} root: The patch generated 165 new + 2311 unchanged - 38 fixed = 2476 total (was 2349) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 5 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 42s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 18s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 35s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}124m 26s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 47s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 14s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 16s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 48s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 66m  2s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 26m  8s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 43s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 45s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 53s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}385m 33s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n|   | hadoop.yarn.server.nodemanager.containermanager.linux.runtime.TestDockerContainerRuntime |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907266/YARN-6592.001.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux bde0c9f823d9 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 39b999a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/diff-checkstyle-root.txt |\r\n| whitespace | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/whitespace-eol.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19415/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19415/testReport/ |\r\n| Max. process+thread count | 887 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19415/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.00469135120511055,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006220151670277119,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03197848051786423,
                        "prediction": false
                    }
                }
            ],
            [
                93096,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 34s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 29s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 27s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 17s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 30s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m  4s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  5s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 37s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 43s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 28s{color} | {color:red} hadoop-yarn-api in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-server-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 18s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 16s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 16s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 22s{color} | {color:red} hadoop-mapreduce-client-app in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 15s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 13m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 57s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 18s{color} | {color:orange} root: The patch generated 142 new + 2431 unchanged - 44 fixed = 2573 total (was 2475) {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-server-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 24s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 25s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 26s{color} | {color:red} hadoop-mapreduce-client-app in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 19s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m  3s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 18s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 16s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 38s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 316 new + 4197 unchanged - 0 fixed = 4513 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 17s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 162 new + 4183 unchanged - 0 fixed = 4345 total (was 4183) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager generated 116 new + 4 unchanged - 0 fixed = 120 total (was 4) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 16s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client generated 25 new + 0 unchanged - 0 fixed = 25 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 13s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell generated 10 new + 0 unchanged - 0 fixed = 10 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 17s{color} | {color:red} hadoop-tools_hadoop-sls generated 4 new + 0 unchanged - 0 fixed = 4 total (was 0) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}105m 11s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 37s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 24s{color} | {color:red} hadoop-yarn-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 24s{color} | {color:red} hadoop-yarn-server-common in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 26s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 27s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 22s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 27s{color} | {color:red} hadoop-mapreduce-client-app in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 20s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 25s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}224m  2s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907579/YARN-7792.002.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 3804e84ebe54 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 0c559b2 |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| mvninstall | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvninstall-hadoop-tools_hadoop-sls.txt |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-checkstyle-root.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| mvnsite | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-mvnsite-hadoop-tools_hadoop-sls.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-findbugs-hadoop-tools_hadoop-sls.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/diff-javadoc-javadoc-hadoop-tools_hadoop-sls.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-app.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19441/artifact/out/patch-unit-hadoop-tools_hadoop-sls.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19441/testReport/ |\r\n| Max. process+thread count | 848 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19441/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.005669528618454933,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005276763811707497,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.031010333448648453,
                        "prediction": false
                    }
                }
            ],
            [
                93099,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 24s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 17s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 49s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 50s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m  4s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  3s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 52s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 16s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 40s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 14s{color} | {color:orange} root: The patch generated 142 new + 2431 unchanged - 44 fixed = 2573 total (was 2475) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 56s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 45s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 21s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 43s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 36s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}107m 36s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 42s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  7s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 13s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 21s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 69m  6s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 38s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 12m 47s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m  0s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 57s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}376m  4s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907628/YARN-7792.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 21ccc3bbefce 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 59828be |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19459/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19459/testReport/ |\r\n| Max. process+thread count | 837 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19459/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.0047877198085188866,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005930054467171431,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03308351710438728,
                        "prediction": false
                    }
                }
            ],
            [
                93100,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 24s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 16s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 48s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 54s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 19m 11s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  1s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 52s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 16s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 12m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 38s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 16s{color} | {color:orange} root: The patch generated 142 new + 2431 unchanged - 44 fixed = 2573 total (was 2475) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 58s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 44s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 44s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}108m  9s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 41s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  9s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  8s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 14s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 69m  1s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 26m 35s{color} | {color:red} hadoop-yarn-client in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 34s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 58s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 58s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}376m  4s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.client.api.impl.TestAMRMClient |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907628/YARN-7792.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 3983f25ea2ee 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 59828be |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19458/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-client.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19458/testReport/ |\r\n| Max. process+thread count | 863 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19458/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.00500893872231245,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005888394080102444,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.033126529306173325,
                        "prediction": false
                    }
                }
            ],
            [
                93101,
                "YARN-7792",
                "All javadoc errors reported here are just warning. {{mvn javadoc:javadoc}} came clean for me. I think its fine and we can go for merge as there are no major problems.\r\n\r\n\u00a0\r\n\r\ncc/[~asuresh] [~leftnoteasy]",
                {
                    "property": {
                        "confidence": 0.005916462279856205,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011449999175965786,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007167941424995661,
                        "prediction": false
                    }
                }
            ],
            [
                93102,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 10s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 29s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 18s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 19s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 50s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m  3s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 41s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 15s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 13m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 53s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 23s{color} | {color:orange} root: The patch generated 141 new + 2427 unchanged - 44 fixed = 2568 total (was 2471) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 29s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 55s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 30s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 44s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 19s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 37s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red}121m 23s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 37s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  4s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  5s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 32s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 67m 32s{color} | {color:green} hadoop-yarn-server-resourcemanager in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 27m 13s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 34s{color} | {color:green} hadoop-yarn-applications-distributedshell in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 49s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 47s{color} | {color:red} hadoop-sls in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}398m 57s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12907628/YARN-7792.003.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 3cbd575775b0 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 59828be |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19460/artifact/out/patch-unit-hadoop-tools_hadoop-sls.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19460/testReport/ |\r\n| Max. process+thread count | 895 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19460/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004887506365776062,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00585112813860178,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.03362837806344032,
                        "prediction": false
                    }
                }
            ],
            [
                93105,
                "YARN-7792",
                "Some comments regarding config, (Don't know where to post these comments, so just paste here)\r\n - yarn.resourcemanager.placement-constraints.algorithm.pool-size\r\n\r\n - yarn.resourcemanager.placement-constraints.scheduler.pool-size\r\n\r\nThe naming \"pool-size\" confused me at first sight. I\u00a0understand\u00a0it after looking at the description/code. How about call it thread-pool-size to be more explicit ?\r\n - I must be doing something wrong, I tried to run distributed shell as below but it fails\r\n\r\n{code:java}\r\nhadoop-common jhe$ hadoop jar $HADOOP_HOME/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-$VERSION.jar -jar $HADOOP_HOME/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-$VERSION.jar -shell_command sleep -shell_args 10000 --placement_spec spec\r\nPicked up _JAVA_OPTIONS: -Djava.awt.headless=true\r\n18/01/26 23:05:46 INFO distributedshell.Client: Initializing Client\r\n18/01/26 23:05:46 INFO distributedshell.PlacementSpec: Parsing Placement Specs: [spec]\r\n18/01/26 23:05:46 INFO distributedshell.PlacementSpec: Parsing Spec: [spec]\r\n18/01/26 23:05:46 ERROR distributedshell.Client: Error running Client\r\njava.lang.ArrayIndexOutOfBoundsException: 1\r\n at org.apache.hadoop.yarn.applications.distributedshell.PlacementSpec.parse(PlacementSpec.java:85)\r\n at org.apache.hadoop.yarn.applications.distributedshell.Client.init(Client.java:431)\r\n at org.apache.hadoop.yarn.applications.distributedshell.Client.main(Client.java:248)\r\n at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n at java.lang.reflect.Method.invoke(Method.java:498)\r\n at org.apache.hadoop.util.RunJar.run(RunJar.java:239)\r\n at org.apache.hadoop.util.RunJar.main(RunJar.java:153)\r\n\r\n{code}\r\nwhere the spec is a file which has the content copied from the\u00a0document\u00a0\r\n\r\n\"zk=3,NOTIN,NODE,zk:hbase=5,IN,RACK,zk\"\u00a0\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.004958116915076971,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00746407313272357,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012076207436621189,
                        "prediction": false
                    }
                }
            ],
            [
                93106,
                "YARN-7792",
                "[~jianhe], thanks for taking it for a spin.\r\n\r\nbq. where the spec is a file which has the content copied from the document\r\nIt isnt meant to be read from a file. the spec is to be specified in the command line ifself like so:\r\n{code}\r\n.. -placement_spec zk=3,NOTIN,NODE,zk:hbase=5,IN,RACK,zk\r\n{code}",
                {
                    "property": {
                        "confidence": 0.0044250343926250935,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006912523880600929,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01572447083890438,
                        "prediction": false
                    }
                }
            ],
            [
                93107,
                "YARN-7792",
                "bq. The naming \"pool-size\" confused me at first sight. I\u00a0understand\u00a0it after looking at the description/code. How about call it thread-pool-size to be more explicit\u00a0\r\nmakes sense - will change it. Like [~kkaranasos] mentioned, we have a config clean up task that we will take up after the merge. ",
                {
                    "property": {
                        "confidence": 0.005284756887704134,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00642819982022047,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018904417753219604,
                        "prediction": false
                    }
                }
            ],
            [
                93108,
                "YARN-7792",
                "bq. It isnt meant to be read from a file. the spec is to be specified in the command line ifself like so:\r\nok.. somehow I got confused that it is a file. \r\n\r\nAlso, got a question about the onRequestsRejected API, is the AM expected to keep on retrying the requests? (BTW, RejectedSchedulingRequest#reason right now is not set, which makes AM no way to know why it's rejected).\r\n\r\nIIUC, previously, there isn't such a notion of rejecting resource requests due to transient states - requests that aren't satisfied due to user-limit, capacity etc. are just getting pending in RM. AM doesn't need to keep on retrying those requests.",
                {
                    "property": {
                        "confidence": 0.005580481141805649,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0043319277465343475,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02808690443634987,
                        "prediction": false
                    }
                }
            ],
            [
                93109,
                "YARN-7792",
                "bq. BTW, RejectedSchedulingRequest#reason right now is not set, which makes AM no way to know why it's rejected..\r\nIt is set by the PlacementProcessor in two situations.\r\n# when the algorithm cannot [place|https://github.com/apache/hadoop/blob/YARN-6592/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/processor/PlacementProcessor.java#L273-L275]\r\n# when a placed requests cannot be [scheduled|https://github.com/apache/hadoop/blob/YARN-6592/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/constraint/processor/PlacementProcessor.java#L286-L288] by the Scheduler - this has a retry of around 5 by default.\r\n\r\nbq. , previously, there isn't such a notion of rejecting resource requests due to transient states - requests that aren't satisfied due to user-limit, capacity etc. are just getting pending in RM. AM doesn't need to keep on retrying those requests.\r\nYup - Out take currently is to let the AM decide what to do if placement / scheduling was not successful. As we mentioned in the doc, currently we assume constraints are *hard*. If placement is not possible, we don't loosen the constraints. Out plan is to introduce the following in future work (we will open JIRAs in YARN-7812):\r\n# Support *soft* constraints: If retry is expired, send it down to the Scheduler as an ANY request.\r\n# Support for DELAYED_OR composite constraint: If the placement was not possible in x attempts, try the next Constraint.\r\n\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004344726912677288,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006034975405782461,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.09623723477125168,
                        "prediction": false
                    }
                }
            ],
            [
                93111,
                "YARN-7792",
                "| (x) *{color:red}-1 overall{color}* |\r\n\\\\\r\n\\\\\r\n|| Vote || Subsystem || Runtime || Comment ||\r\n| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 16m 17s{color} | {color:blue} Docker mode activated. {color} |\r\n|| || || || {color:brown} Prechecks {color} ||\r\n| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |\r\n| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 41 new or modified test files. {color} |\r\n|| || || || {color:brown} trunk Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 29s{color} | {color:blue} Maven dependency ordering for branch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 34s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 24s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 40s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  8m 33s{color} | {color:green} trunk passed {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 21m 32s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site {color} |\r\n| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 11s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api in trunk has 1 extant Findbugs warnings. {color} |\r\n| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 28s{color} | {color:green} trunk passed {color} |\r\n|| || || || {color:brown} Patch Compile Tests {color} ||\r\n| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |\r\n| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  9m 24s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} cc {color} | {color:green} 13m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 20s{color} | {color:green} the patch passed {color} |\r\n| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 59s{color} | {color:orange} root: The patch generated 141 new + 2420 unchanged - 46 fixed = 2561 total (was 2466) {color} |\r\n| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 34s{color} | {color:green} the patch passed {color} |\r\n| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |\r\n| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |\r\n| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 34s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |\r\n| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site {color} |\r\n| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  9m  9s{color} | {color:green} the patch passed {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  1m 44s{color} | {color:red} hadoop-yarn-project_hadoop-yarn generated 7 new + 4197 unchanged - 0 fixed = 4204 total (was 4197) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |\r\n| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 39s{color} | {color:red} hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common generated 6 new + 4183 unchanged - 0 fixed = 4189 total (was 4183) {color} |\r\n|| || || || {color:brown} Other Tests {color} ||\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m  7s{color} | {color:red} hadoop-yarn in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 45s{color} | {color:green} hadoop-yarn-api in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 15s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 20s{color} | {color:green} hadoop-yarn-server-common in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 31s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 63m 14s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green} 26m 41s{color} | {color:green} hadoop-yarn-client in the patch passed. {color} |\r\n| {color:red}-1{color} | {color:red} unit {color} | {color:red} 12m 43s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 12s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 25s{color} | {color:green} hadoop-yarn-site in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 58s{color} | {color:green} hadoop-sls in the patch passed. {color} |\r\n| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |\r\n| {color:black}{color} | {color:black} {color} | {color:black}393m 51s{color} | {color:black} {color} |\r\n\\\\\r\n\\\\\r\n|| Reason || Tests ||\r\n| Failed junit tests | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.resourcemanager.webapp.TestRMWebServiceAppsNodelabel |\r\n|   | hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage |\r\n|   | hadoop.yarn.server.resourcemanager.webapp.TestRMWebServiceAppsNodelabel |\r\n|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |\r\n\\\\\r\n\\\\\r\n|| Subsystem || Report/Notes ||\r\n| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |\r\n| JIRA Issue | YARN-7792 |\r\n| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12908367/YARN-7792.004.patch |\r\n| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  xml  cc  |\r\n| uname | Linux 4f733bdc8987 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |\r\n| Build tool | maven |\r\n| Personality | /testptch/patchprocess/precommit/personality/provided.sh |\r\n| git revision | trunk / 901d15a |\r\n| maven | version: Apache Maven 3.3.9 |\r\n| Default Java | 1.8.0_151 |\r\n| findbugs | v3.1.0-RC1 |\r\n| findbugs | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api-warnings.html |\r\n| checkstyle | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/diff-checkstyle-root.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-api.txt |\r\n| javadoc | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/diff-javadoc-javadoc-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |\r\n| unit | https://builds.apache.org/job/PreCommit-YARN-Build/19529/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |\r\n|  Test Results | https://builds.apache.org/job/PreCommit-YARN-Build/19529/testReport/ |\r\n| Max. process+thread count | 861 (vs. ulimit of 5000) |\r\n| modules | C: hadoop-yarn-project/hadoop-yarn hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site hadoop-tools/hadoop-sls U: . |\r\n| Console output | https://builds.apache.org/job/PreCommit-YARN-Build/19529/console |\r\n| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |\r\n\r\n\r\nThis message was automatically generated.\r\n\r\n",
                {
                    "property": {
                        "confidence": 0.004438608884811401,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006416729185730219,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.030247598886489868,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d609c4f4d395ee2221fb01",
        "key": "GROOVY-4452",
        "id": "12815364",
        "description": "The current syntax for {{@GrabResolver}} is:\n{code}\n@GrabResolver(name='some name', root='http://some/url')\n{code}\nIt would be good to have a shorthand syntax using a value attribute, i.e.:\n{code}\n@GrabResolver('http://some/url')\n{code}\nwould be a shorthand for:\n{code}\n@GrabResolver(name='http://some/url', root='http://some/url')\n{code}\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.021361129358410835
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.017589781433343887
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004691217560321093
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d608b7f4d395ee2221b4fd",
        "key": "HADOOP-12384",
        "id": "12841523",
        "description": "Because CLI is using CommandWithDestination.java which add \"._COPYING_\" to the tail of file name when it does the copy. For blobstore like S3 and Swift, to create \"._COPYING_\" file and rename it is expensive. \"-direct\" flag can allow user to avoiding the \"._COPYING_\" file.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006680803373456001
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01990976557135582
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0047283717431128025
                }
            }
        },
        "comments": [
            {
                "author_name": "andreina",
                "id": "14611517",
                "body": "I would like to work on this. \n[~airbots], Please reassign if you have already started working on this."
            },
            {
                "author_name": "airbots",
                "id": "14611534",
                "body": "Not a problem, [~joeandrewkey], feel free to take. I don't have time to work on it recently. "
            },
            {
                "author_name": "airbots",
                "id": "14611537",
                "body": "Sorry for the spam, [~joeandrewkey]. I mean [~andreina]. :)"
            },
            {
                "author_name": "andreina",
                "id": "14704600",
                "body": "Attached a patch .\nPlease review. "
            },
            {
                "author_name": "hadoopqa",
                "id": "14729060",
                "body": "\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  16m 52s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 41s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 53s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   1m  5s | The applied patch generated  5 new checkstyle issues (total was 60, now 64). |\n| {color:red}-1{color} | whitespace |   0m  0s | The patch has 3  line(s) that end in whitespace. Use git apply --whitespace=fix. |\n| {color:green}+1{color} | install |   1m 27s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   1m 53s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |\n| {color:red}-1{color} | common tests |  22m  9s | Tests failed in hadoop-common. |\n| | |  61m 59s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed unit tests | hadoop.cli.TestCLI |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12751456/HDFS-8698.1.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / b469ac5 |\n| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/12279/artifact/patchprocess/diffcheckstylehadoop-common.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/12279/artifact/patchprocess/whitespace.txt |\n| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12279/artifact/patchprocess/testrun_hadoop-common.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/12279/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/12279/console |\n\n\nThis message was automatically generated."
            },
            {
                "author_name": "airbots",
                "id": "14729434",
                "body": "Hi [~andreina], can you update the patch?"
            },
            {
                "author_name": "andreina",
                "id": "14730652",
                "body": "Updated the patch\nPlease review."
            },
            {
                "author_name": "hadoopqa",
                "id": "14730697",
                "body": "\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  16m 39s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 2 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 41s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |   9m 50s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |\n| {color:red}-1{color} | checkstyle |   1m  9s | The applied patch generated  5 new checkstyle issues (total was 60, now 64). |\n| {color:red}-1{color} | whitespace |   0m  0s | The patch has 2  line(s) that end in whitespace. Use git apply --whitespace=fix. |\n| {color:green}+1{color} | install |   1m 28s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   1m 50s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |\n| {color:green}+1{color} | common tests |  22m 49s | Tests passed in hadoop-common. |\n| | |  62m 27s | |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12754181/HDFS-8698.2.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / 40d222e |\n| checkstyle |  https://builds.apache.org/job/PreCommit-HDFS-Build/12306/artifact/patchprocess/diffcheckstylehadoop-common.txt |\n| whitespace | https://builds.apache.org/job/PreCommit-HDFS-Build/12306/artifact/patchprocess/whitespace.txt |\n| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12306/artifact/patchprocess/testrun_hadoop-common.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/12306/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/12306/console |\n\n\nThis message was automatically generated."
            },
            {
                "author_name": "andreina",
                "id": "14733655",
                "body": "Updated the patch.\nPlease review."
            },
            {
                "author_name": "hadoopqa",
                "id": "14733745",
                "body": "\\\\\n\\\\\n| (x) *{color:red}-1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  17m  1s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 2 new or modified test files. |\n| {color:green}+1{color} | javac |   8m  6s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |  10m  3s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 25s | The applied patch does not increase the total number of release audit warnings. |\n| {color:green}+1{color} | checkstyle |   1m 12s | There were no new checkstyle issues. |\n| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 30s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   1m 56s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |\n| {color:red}-1{color} | common tests |  22m 18s | Tests failed in hadoop-common. |\n| | |  63m  9s | |\n\\\\\n\\\\\n|| Reason || Tests ||\n| Failed unit tests | hadoop.http.TestHttpServer |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12754485/HDFS-8698.3.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / 1dbd8e3 |\n| hadoop-common test log | https://builds.apache.org/job/PreCommit-HDFS-Build/12329/artifact/patchprocess/testrun_hadoop-common.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/12329/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/12329/console |\n\n\nThis message was automatically generated."
            },
            {
                "author_name": "andreina",
                "id": "14734162",
                "body": "TestCase failures are not related to this patch.\nPlease review."
            },
            {
                "author_name": "vinayakumarb",
                "id": "14734786",
                "body": "+1. Changes looks good."
            },
            {
                "author_name": "vinayakumarb",
                "id": "14734813",
                "body": "Thanks for reporting [~airbots]. \nThanks for the contribution [~andreina].\n\nCommitted to trunk and branch-2."
            },
            {
                "author_name": "hudson",
                "id": "14734825",
                "body": "FAILURE: Integrated in Hadoop-trunk-Commit #8414 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8414/])\nHADOOP-12384. Add '-direct' flag option for fs copy so that user can choose not to create '._COPYING_' file (Contributed by J.Andreina) (vinayakumarb: rev 090d26652c04916a1ede4ca55e7f2ca4fc5f6249)\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java\n* hadoop-common-project/hadoop-common/src/test/resources/testConf.xml\n"
            },
            {
                "author_name": "hadoopqa",
                "id": "14734910",
                "body": "\\\\\n\\\\\n| (/) *{color:green}+1 overall{color}* |\n\\\\\n\\\\\n|| Vote || Subsystem || Runtime || Comment ||\n| {color:blue}0{color} | pre-patch |  15m  1s | Pre-patch trunk compilation is healthy. |\n| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |\n| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 2 new or modified test files. |\n| {color:green}+1{color} | javac |   7m 58s | There were no new javac warning messages. |\n| {color:green}+1{color} | javadoc |  10m  1s | There were no new javadoc warning messages. |\n| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |\n| {color:green}+1{color} | checkstyle |   1m  5s | There were no new checkstyle issues. |\n| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |\n| {color:green}+1{color} | install |   1m 27s | mvn install still works. |\n| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |\n| {color:green}+1{color} | findbugs |   1m 43s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |\n| {color:green}+1{color} | common tests |  22m 51s | Tests passed in hadoop-common. |\n| | |  61m  5s | |\n\\\\\n\\\\\n|| Subsystem || Report/Notes ||\n| Patch URL | http://issues.apache.org/jira/secure/attachment/12754485/HDFS-8698.3.patch |\n| Optional Tests | javadoc javac unit findbugs checkstyle |\n| git revision | trunk / 435f935 |\n| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7614/artifact/patchprocess/testrun_hadoop-common.txt |\n| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7614/testReport/ |\n| Java | 1.7.0_55 |\n| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |\n| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7614/console |\n\n\nThis message was automatically generated."
            },
            {
                "author_name": "hudson",
                "id": "14734993",
                "body": "SUCCESS: Integrated in Hadoop-Yarn-trunk #1093 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/1093/])\nHADOOP-12384. Add '-direct' flag option for fs copy so that user can choose not to create '._COPYING_' file (Contributed by J.Andreina) (vinayakumarb: rev 090d26652c04916a1ede4ca55e7f2ca4fc5f6249)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java\n* hadoop-common-project/hadoop-common/src/test/resources/testConf.xml\n* hadoop-common-project/hadoop-common/CHANGES.txt\n"
            },
            {
                "author_name": "hudson",
                "id": "14735022",
                "body": "FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #343 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/343/])\nHADOOP-12384. Add '-direct' flag option for fs copy so that user can choose not to create '._COPYING_' file (Contributed by J.Andreina) (vinayakumarb: rev 090d26652c04916a1ede4ca55e7f2ca4fc5f6249)\n* hadoop-common-project/hadoop-common/src/test/resources/testConf.xml\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n"
            },
            {
                "author_name": "hudson",
                "id": "14735054",
                "body": "SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #362 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/362/])\nHADOOP-12384. Add '-direct' flag option for fs copy so that user can choose not to create '._COPYING_' file (Contributed by J.Andreina) (vinayakumarb: rev 090d26652c04916a1ede4ca55e7f2ca4fc5f6249)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java\n* hadoop-common-project/hadoop-common/src/test/resources/testConf.xml\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\n"
            },
            {
                "author_name": "hudson",
                "id": "14735075",
                "body": "FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #355 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/355/])\nHADOOP-12384. Add '-direct' flag option for fs copy so that user can choose not to create '._COPYING_' file (Contributed by J.Andreina) (vinayakumarb: rev 090d26652c04916a1ede4ca55e7f2ca4fc5f6249)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\n* hadoop-common-project/hadoop-common/src/test/resources/testConf.xml\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n"
            },
            {
                "author_name": "hudson",
                "id": "14735162",
                "body": "FAILURE: Integrated in Hadoop-Mapreduce-trunk #2305 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2305/])\nHADOOP-12384. Add '-direct' flag option for fs copy so that user can choose not to create '._COPYING_' file (Contributed by J.Andreina) (vinayakumarb: rev 090d26652c04916a1ede4ca55e7f2ca4fc5f6249)\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-common-project/hadoop-common/src/test/resources/testConf.xml\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\n"
            },
            {
                "author_name": "hudson",
                "id": "14735193",
                "body": "SUCCESS: Integrated in Hadoop-Hdfs-trunk #2282 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2282/])\nHADOOP-12384. Add '-direct' flag option for fs copy so that user can choose not to create '._COPYING_' file (Contributed by J.Andreina) (vinayakumarb: rev 090d26652c04916a1ede4ca55e7f2ca4fc5f6249)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CommandWithDestination.java\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java\n* hadoop-common-project/hadoop-common/src/test/resources/testConf.xml\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d620aff4d395ee2225146e",
        "key": "CASSANDRA-395",
        "id": "12434219",
        "description": "sample failure:\n\n    [junit] Testcase: testAntiCompaction1(org.apache.cassandra.db.BootstrapTest):       Caused an ERROR\n    [junit] /home/jonathan/projects/cassandra/git-trunk/build/test/cassandra/data/Keyspace1/Standard1-2-Data.db (No such file or directory)                                                                                               \n    [junit] java.io.FileNotFoundException: /home/jonathan/projects/cassandra/git-trunk/build/test/cassandra/data/Keyspace1/Standard1-2-Data.db (No such file or directory)                                                                \n    [junit]     at java.io.RandomAccessFile.open(Native Method)                                                      \n    [junit]     at java.io.RandomAccessFile.<init>(RandomAccessFile.java:212)                                        \n    [junit]     at java.io.RandomAccessFile.<init>(RandomAccessFile.java:98)                                         \n    [junit]     at org.apache.cassandra.io.BufferedRandomAccessFile.<init>(BufferedRandomAccessFile.java:142)        \n    [junit]     at org.apache.cassandra.io.FileStruct.<init>(FileStruct.java:49)                                     \n    [junit]     at org.apache.cassandra.io.SSTableReader.getFileStruct(SSTableReader.java:321)                       \n    [junit]     at org.apache.cassandra.db.ColumnFamilyStore.initializePriorityQueue(ColumnFamilyStore.java:655)     \n    [junit]     at org.apache.cassandra.db.ColumnFamilyStore.doFileAntiCompaction(ColumnFamilyStore.java:911)        \n    [junit]     at org.apache.cassandra.db.ColumnFamilyStore.doAntiCompaction(ColumnFamilyStore.java:814)            \n    [junit]     at org.apache.cassandra.db.BootstrapTest.testAntiCompaction(BootstrapTest.java:63)                   \n    [junit]     at org.apache.cassandra.db.BootstrapTest.testAntiCompaction1(BootstrapTest.java:72)                  \n\nI have seen someone else mention this on IRC too.  Most of the time, the test passes.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.045836325734853745
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.005330346524715424
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0077752661891281605
                }
            }
        },
        "comments": [
            {
                "author_name": "sandeep_tata",
                "id": "12748627",
                "body": "Ah this is a fun bug -- looks like this happens if the following sequence occurs:\n\n1. Call to flush memtable\n2. Compaction submitted (from storeLocation after flushing memtable) but not yet completed.\n3. CFS.doAntiCompaction reads keys from ssTables_\n4. Compaction completes\n5. SSTableReader.getApproximateKeyCount(files) now points to files that don't exist!\n\nWe have to prevent compaction from messing up the list of files that anticompaction needs to work on to build the new file.\nI didn't expect this would happen in a short Junit test. Need to see why compaction is getting triggered.\n"
            },
            {
                "author_name": "sandeep_tata",
                "id": "12748629",
                "body": "Quick Fix: Change MemtableObjectCountInMillions to 0.0002. This allows memtables to be bigger and avoids kicking off a compaction before the anticompaction can complete. BootstrapTest will no longer exhibit intermittent failures. (verified)\n\nBut that's just a band-aid -- the real solution is to synchronize compaction & anticompaction correctly."
            },
            {
                "author_name": "sandeep_tata",
                "id": "12748635",
                "body": "Patch to call doAntiCompaction in the tests the same way we do in the actual code -- by submitting it to the MinorCompactionManager so it serializes with other compaction tasks.\n\nRan the tests a 200 times -- I don't see failures anymore."
            },
            {
                "author_name": "jbellis",
                "id": "12748658",
                "body": "excellent.  committed"
            },
            {
                "author_name": "hudson",
                "id": "12748846",
                "body": "Integrated in Cassandra #180 (See [http://hudson.zones.apache.org/hudson/job/Cassandra/180/])\n    call doAntiCompaction in the tests the same way we do in the actual code -- by submitting it to the MinorCompactionManager so it serializes with other compaction tasks.  patch by Sandeep Tata; reviewed by jbellis for \n"
            }
        ],
        "comments_predictions": [
            [
                3524244,
                "CASSANDRA-395",
                "Ah this is a fun bug -- looks like this happens if the following sequence occurs:\n\n1. Call to flush memtable\n2. Compaction submitted (from storeLocation after flushing memtable) but not yet completed.\n3. CFS.doAntiCompaction reads keys from ssTables_\n4. Compaction completes\n5. SSTableReader.getApproximateKeyCount(files) now points to files that don't exist!\n\nWe have to prevent compaction from messing up the list of files that anticompaction needs to work on to build the new file.\nI didn't expect this would happen in a short Junit test. Need to see why compaction is getting triggered.\n",
                {
                    "property": {
                        "confidence": 0.004735216032713652,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006590274162590504,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016705894842743874,
                        "prediction": false
                    }
                }
            ],
            [
                3524245,
                "CASSANDRA-395",
                "Quick Fix: Change MemtableObjectCountInMillions to 0.0002. This allows memtables to be bigger and avoids kicking off a compaction before the anticompaction can complete. BootstrapTest will no longer exhibit intermittent failures. (verified)\n\nBut that's just a band-aid -- the real solution is to synchronize compaction & anticompaction correctly.",
                {
                    "property": {
                        "confidence": 0.008406885899603367,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0035725559573620558,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023022808134555817,
                        "prediction": false
                    }
                }
            ],
            [
                3524246,
                "CASSANDRA-395",
                "Patch to call doAntiCompaction in the tests the same way we do in the actual code -- by submitting it to the MinorCompactionManager so it serializes with other compaction tasks.\n\nRan the tests a 200 times -- I don't see failures anymore.",
                {
                    "property": {
                        "confidence": 0.00557193998247385,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0064811911433935165,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.012506095692515373,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d610a2f4d395ee2222c6e4",
        "key": "FLINK-2036",
        "id": "12830675",
        "description": "The KafkaITCase currently creates a lot of LocalStreamExecution environments. It would be more desirable to use TestStreamEnvironments and maybe reuse some them if it is possible.\n\nI have started working on this [1], but some tests fail with the TestStreamEnvironment. A pair of additional eyes would come in handy.\n\n[1] https://github.com/mbalassi/flink/commit/0df13dc91fb16efe5bedd1917a5a5e1c8615b1ed",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.14763641357421875
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.005044042598456144
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00940077006816864
                }
            }
        },
        "comments": [
            {
                "author_name": "aljoscha",
                "id": "14550062",
                "body": "[~rmetzger] This should be resolved with your recent work in the KafkaITCase, correct?\n"
            },
            {
                "author_name": "rmetzger",
                "id": "14550068",
                "body": "No, this is still an open issue.\nI am recreating new environments because its not possible to reuse a StreamExecutionEnvironment for submitting multiple (different!) topologies. I've added the {{StreamGraph.clear()}} method, while trying to fix this, but I still got unexpected behavior.\nThis should be not too hard to fix, I just was not caring enough about this issue. I have to see when I have time to work on this issue.\nIf somebody else is interested in fixing this, please assign it to yourself. I'll keep myself assigned to remember the issue."
            },
            {
                "author_name": "mbalassi",
                "id": "14550076",
                "body": "You can submit multiple different topologies, but then you have no guarantee on the execution order. If I understand correctly that is the issue in your case. Is it different from the batch solution?"
            },
            {
                "author_name": "rmetzger",
                "id": "15844686",
                "body": "Closing ... The tests are now reusing a remote exec env. "
            }
        ],
        "comments_predictions": [
            [
                2943183,
                "FLINK-2036",
                "No, this is still an open issue.\nI am recreating new environments because its not possible to reuse a StreamExecutionEnvironment for submitting multiple (different!) topologies. I've added the {{StreamGraph.clear()}} method, while trying to fix this, but I still got unexpected behavior.\nThis should be not too hard to fix, I just was not caring enough about this issue. I have to see when I have time to work on this issue.\nIf somebody else is interested in fixing this, please assign it to yourself. I'll keep myself assigned to remember the issue.",
                {
                    "property": {
                        "confidence": 0.007312120869755745,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004073098301887512,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018737955018877983,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5ebd9f4d395ee221d7114",
        "key": "MTOMCAT-84",
        "id": "12521810",
        "description": "Instead of emitting \"Reloading app\", it emits \"Redeploying app\". I have patched the issue.",
        "predictions": {},
        "comments": [
            {
                "author_name": "olamy",
                "id": "13812623",
                "body": "we use tomcat manager reload url so the message looks correct for me."
            },
            {
                "author_name": "kkolinko",
                "id": "13813376",
                "body": "Where is the patch? I get an error trying to download it as if it has been deleted.\n\nI think the issue is that ReloadMojo in Tomcat 6 plugin uses wrong message key.\n\n        getLog().info( messagesProvider.getMessage( \"RedeployMojo.redeployApp\", ...\n\nIt should use its own \"ReloadMojo.reloadingApp\".\n\n"
            },
            {
                "author_name": "michael-o",
                "id": "13813759",
                "body": "[~olamy], I don't think so.\n\n[~kkolinko], I have reuploaded the patch. I have signed ASF license months ago."
            },
            {
                "author_name": "olamy",
                "id": "13814393",
                "body": "patch applied.\nThanks"
            },
            {
                "author_name": "hudson",
                "id": "13814470",
                "body": "SUCCESS: Integrated in TomcatMavenPlugin-mvn3.x #267 (See [https://builds.apache.org/job/TomcatMavenPlugin-mvn3.x/267/])\n[MTOMCAT-84] tomcat:reload logs the wrong message\nSubmitted by Michael Osipov. (olamy: http://svn.apache.org/viewvc/?view=rev&rev=1539191)\n* /tomcat/maven-plugin/trunk/tomcat6-maven-plugin/src/main/java/org/apache/tomcat/maven/plugin/tomcat6/ReloadMojo.java\n"
            }
        ],
        "comments_predictions": [
            [
                1294359,
                "MTOMCAT-84",
                "Where is the patch? I get an error trying to download it as if it has been deleted.\n\nI think the issue is that ReloadMojo in Tomcat 6 plugin uses wrong message key.\n\n        getLog().info( messagesProvider.getMessage( \"RedeployMojo.redeployApp\", ...\n\nIt should use its own \"ReloadMojo.reloadingApp\".\n\n",
                {
                    "property": {
                        "confidence": 0.003968000877648592,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.027121545746922493,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007456340827047825,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5f83bf4d395ee221f71a8",
        "key": "IOTDB-1677",
        "id": "13401003",
        "description": "While run \"mvn package ....\"\u00a0 i\r\n\r\nModule iotdb-distribution can\u00a0not generate file apache-iotdb-0.12.2-client-cpp-linux-x86_64-bin.zip.sha512 .\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.023146627470850945
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009534217417240143
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0034407731145620346
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d61297f4d395ee222335ca",
        "key": "FLEX-9036",
        "id": "12569906",
        "description": "This bug was imported from another system and requires review from a project committer before some of the details can be marked public. For more information about historical bugs, please read: [Why are some bugs missing information?|https://bugs.adobe.com/confluence/display/ADOBE/Why+are+some+bugs+missing+information]\n\nYou can request a review of this bug report by sending an e-mail to: [Request Public Review for This Bug|mailto:jira_support@adobe.com?subject=Bug%20Review%20Request%20-%20SDK-9094&amp;body=Please%20review%20this%20historical%20bug%20report%20and%20consider%20making%20additional%20information%20public.%20%20I%20understand%20that%20my%20request%20(including%20this%20e-mail)%20may%20be%20included%20as%20part%20of%20the%20public%20history%20in%20the%20bug%20comments.%0D%0A%0D%0AAdditional Information: ]\n\nPlease be sure to include the bug number in your request.",
        "predictions": {},
        "comments": [
            {
                "author_name": "adobejira",
                "id": "13323293",
                "body": "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-9094\nOriginal Reporter: martine\nOriginal Resolution: Not a Bug\nNeeds Release Note: No\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nSeverity: Incorrectly Functioning\nreporter: martine"
            },
            {
                "author_name": "adobejira",
                "id": "13323294",
                "body": "created: 2006-05-18 10:21:13.000\nresolved: 2007-06-04 10:08:55.019\nupdated: 2007-06-04 10:08:55.000"
            },
            {
                "author_name": "adobejira",
                "id": "13323295",
                "body": "On 2007-05-12 15:11:33.156 customware commented:\nMilestone ID = null\nMilestone = null\nBuild ID = 18840\nBuild = 139487_Flex\nFix Build ID = null\nFix Build = null\nOn 2007-05-12 15:11:33.156 customware commented:\nMove from BugDB issue number 171536"
            }
        ],
        "comments_predictions": [
            [
                3034721,
                "FLEX-9036",
                "Adobe Bug URL: http://bugs.adobe.com/jira/browse/SDK-9094\nOriginal Reporter: martine\nOriginal Resolution: Not a Bug\nNeeds Release Note: No\nNumber of votes: 0\nRegression: No\nReproducibility: Every Time\nSeverity: Incorrectly Functioning\nreporter: martine",
                {
                    "property": {
                        "confidence": 0.003779512131586671,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.08250689506530762,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008046154864132404,
                        "prediction": false
                    }
                }
            ],
            [
                3034723,
                "FLEX-9036",
                "On 2007-05-12 15:11:33.156 customware commented:\nMilestone ID = null\nMilestone = null\nBuild ID = 18840\nBuild = 139487_Flex\nFix Build ID = null\nFix Build = null\nOn 2007-05-12 15:11:33.156 customware commented:\nMove from BugDB issue number 171536",
                {
                    "property": {
                        "confidence": 0.004253244027495384,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01157951820641756,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011232765391469002,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640743eec8b42db502d2b1dd",
        "key": "FINERACT-849",
        "id": "13289628",
        "description": "In line with the rationale for choosing EclipseLink as the ORM replacement for Hibernate in FineractCN, we have broad consensus across the community to swap out OpenJPA with EclipseLink.\r\n\r\nOpenJPA seems to have reached its end of life with community activity withering and the trade-offs between Hibernate and EclipseLink are much lower. We also have community members who are migrating Fineract 1.x to PostGreSQL and would benefit from the increased performance with EclipseLink. ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.8024461269378662
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.07154105603694916
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.19255051016807556
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d62e56f4d395ee2226e0be",
        "key": "AMBARI-19457",
        "id": "13033637",
        "description": "Rest Api to fetch list of Hive jobs is returning an empty json\n\napi:- http://172.22.122.64:8080/api/v1/views/HIVE/versions/1.5.0/instances/AUTO_HIVE_INSTANCE/jobs/\n{code}\n[ ]\n{code}\n\nwhile api to request individual job id is working fine\nhttp://172.22.122.64:8080/api/v1/views/HIVE/versions/1.5.0/instances/AUTO_HIVE_INSTANCE/jobs/1\n{code}\n{\"job\":{\"owner\":\"admin\",\"dataBase\":\"default\",\"statusDir\":\"/user/admin/hive/jobs/hive-job-1-2017-01-11_05-53\",\"queryFile\":\"/user/admin/hive/jobs/hive-job-1-2017-01-11_05-53/query.hql\",\"globalSettings\":\"\",\"dagId\":\"\",\"title\":\"Worksheet\",\"duration\":0,\"referrer\":\"job\",\"logFile\":\"/user/admin/hive/jobs/hive-job-1-2017-01-11_05-53/logs\",\"id\":\"1\",\"applicationId\":\"\",\"dateSubmitted\":1484113992368,\"status\":\"SUCCEEDED\"}}\n{code}\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008312204852700233
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.02192872017621994
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004504912067204714
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5ff9bf4d395ee222093bd",
        "key": "HIVE-9274",
        "id": "12765255",
        "description": "When creating a new table using a storage handler via the STORED BY clause, for example using the HBaseStorageHandler, the input and output formats are set to null instead of the correct formats:\n\nCREATE TABLE hbase_table_1(key int, value string) \nSTORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\nWITH SERDEPROPERTIES (\"hbase.columns.mapping\" = \":key,cf1:val\")\nTBLPROPERTIES (\"hbase.table.name\" = \"xyz\");\n\ndescribe formatted hbase_table_1:\n# Storage Information\nSerDe Library:          org.apache.hadoop.hive.hbase.HBaseSerDe\nInputFormat:            null\nOutputFormat:           null\n\nIn older Hive versions, it would set the correct formats.\n\nCould it be related to the changes in HIVE-5976?\n\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.013688609004020691
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.00941983051598072
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004093526862561703
                }
            }
        },
        "comments": [
            {
                "author_name": "tfriedr",
                "id": "14270096",
                "body": "Looks like this behavior has changed due to HIVE-6584. In DDLTask the input and output format classes are only persisted when explicitly specified. I wonder if the documentation in https://cwiki.apache.org/confluence/display/Hive/StorageHandlers should be updated (under open issues: \"Names of helper classes such as input format and output format are saved into the metastore based on what the storage handler returns during CREATE TABLE; it would be better to leave these null in case they are changed later as part of a handler upgrade\")."
            }
        ],
        "comments_predictions": [
            [
                1976720,
                "HIVE-9274",
                "Looks like this behavior has changed due to HIVE-6584. In DDLTask the input and output format classes are only persisted when explicitly specified. I wonder if the documentation in https://cwiki.apache.org/confluence/display/Hive/StorageHandlers should be updated (under open issues: \"Names of helper classes such as input format and output format are saved into the metastore based on what the storage handler returns during CREATE TABLE; it would be better to leave these null in case they are changed later as part of a handler upgrade\").",
                {
                    "property": {
                        "confidence": 0.004399542696774006,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007412035018205643,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01759941875934601,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5dbb7f4d395ee221a6f5b",
        "key": "SPARK-25946",
        "id": "13196369",
        "description": "ASM 7.x has the official support of JDK 11.",
        "predictions": {},
        "comments": [
            {
                "author_name": "apachespark",
                "id": "16675913",
                "body": "User 'dbtsai' has created a pull request for this issue:\nhttps://github.com/apache/spark/pull/22953"
            },
            {
                "author_name": "dbtsai",
                "id": "16676176",
                "body": "Issue resolved by pull request 22953\n[https://github.com/apache/spark/pull/22953]"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640753d5e76fd27a5f92e128",
        "key": "COUCHDB-2868",
        "id": "12910639",
        "description": "The current implementation of couch_db_plugin_tests appends the test module to the application environment's list of configured epi plugins during setup, and then removes itself before saving the original list on teardown. This means that any configured plugins can in principle interfere with the test suite, which happens in a downstream build.",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e1aef4d395ee221ba3ae",
        "key": "ROL-797",
        "id": "12420855",
        "description": "Better referer spam filters",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006072026211768389
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0548495352268219
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005008962471038103
                }
            }
        },
        "comments": [
            {
                "author_name": "gmazza",
                "id": "13546374",
                "body": "Unclear what is needed; please try with a later version of Roller (JIRA entered against Roller 1.2)."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640754ba177d638861333a2e",
        "key": "SOLR-14782",
        "id": "13324851",
        "description": "h1. Description\r\n\r\nif the elevate.xml contains a entry with spaces:\r\n\r\n<{color:#0033b3}query {color}{color:#174ad4}text{color}{color:#067d17}=\"aaa bbb\"{color}><{color:#0033b3}doc {color}{color:#174ad4}id{color}{color:#067d17}=\"core2docId2\" {color}/></{color:#0033b3}query{color}>\r\n\r\nand the Solr query term is escaped:\r\n\r\n{{?q=aaa&#92;+bbb}}\r\n\r\nthe Solr search itself handels this correctly, but the elevate component \"QueryElevationComponent\" does not unescape the query term bevor the lookup in the elevate.xml.\r\n\r\nResult is that the entry is not elevated.\r\n\r\nA also valid (not escaped) query like:\r\n\r\n{{?q=aaa%20bbb}}\r\n\r\nis working.\r\nh1. Technical Notes\r\n\r\nsee:\r\norg.apache.solr.handler.component.QueryElevationComponent.MapElevationProvider#getElevationForQuery\r\n\r\n\u00a0",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.006901984568685293
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.014433084987103939
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004536452237516642
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640754097c2d549cedd7cf69",
        "key": "GERONIMO-84",
        "id": "11983",
        "description": "The README.txt needs to be amended with new instructions on how to start the server.  \n\nSpecifically, \"maven run\" will not start the server.  Could we change the command to \"maven run:main\" to reflect Dain's recent changes?\n\nMany thanks.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.025474971160292625
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009252022951841354
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0037844362668693066
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d60e54f4d395ee22227d8f",
        "key": "FLINK-20843",
        "id": "13348930",
        "description": "https://dev.azure.com/aljoschakrettek/Flink/_build/results?buildId=493&view=logs&j=6e55a443-5252-5db5-c632-109baf464772&t=9df6efca-61d0-513a-97ad-edb76d85786a&l=9432",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.02015855349600315
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0053902314975857735
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005864362698048353
                }
            }
        },
        "comments": [
            {
                "author_name": "mapohl",
                "id": "17258251",
                "body": "I close this one in favor of FLINK-20309."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d602f3f4d395ee222108bc",
        "key": "HDDS-2068",
        "id": "13254192",
        "description": "We started to use a generic pattern where we have only one method in the grpc service and the main message contains all the required common information (eg. tracing).\r\n\r\nStorageContainerDatanodeProtocolService is not yet migrated to this approach. To make our generic debug tool more powerful and unify our protocols I suggest to transform this protocol as well.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.003980256151407957
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.23046153783798218
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.23192700743675232
                }
            }
        },
        "comments": [
            {
                "author_name": "aengineer",
                "id": "16943078",
                "body": "Committed to the trunk."
            },
            {
                "author_name": "hudson",
                "id": "16943086",
                "body": "SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #17439 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/17439/])\nHDDS-2068. Make StorageContainerDatanodeProtocolService message based (aengineer: rev e8ae632d4c4f13788b0c42dbf297c8f7b9d889f3)\n* (edit) hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/protocolPB/StorageContainerDatanodeProtocolClientSideTranslatorPB.java\n* (edit) hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/scm/ScmProtocolBlockLocationInsight.java\n* (add) hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/scm/ScmProtocolDatanodeInsight.java\n* (edit) hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/server/SCMDatanodeProtocolServer.java\n* (edit) hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/SCMTestUtils.java\n* (edit) hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/BaseInsightSubCommand.java\n* (edit) hadoop-hdds/container-service/src/main/proto/StorageContainerDatanodeProtocol.proto\n* (edit) hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/protocolPB/StorageContainerDatanodeProtocolServerSideTranslatorPB.java\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e662f4d395ee221c8f77",
        "key": "OOZIE-1604",
        "id": "12677694",
        "description": "<java-opts>, <java-opt> in java action is not added to yarn.app.mapreduce.am.command-opts properly in uber mode.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.00821716245263815
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.014445558190345764
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004183839075267315
                }
            }
        },
        "comments": [
            {
                "author_name": "rohini",
                "id": "13825687",
                "body": "+1 to https://reviews.apache.org/r/15546/diff/1/"
            },
            {
                "author_name": "hadoopqa",
                "id": "13826000",
                "body": "Testing JIRA OOZIE-1604\n\nCleaning local svn workspace\n\n----------------------------\n\n{color:green}+1 PATCH_APPLIES{color}\n{color:green}+1 CLEAN{color}\n{color:green}+1 RAW_PATCH_ANALYSIS{color}\n.    {color:green}+1{color} the patch does not introduce any @author tags\n.    {color:green}+1{color} the patch does not introduce any tabs\n.    {color:green}+1{color} the patch does not introduce any trailing spaces\n.    {color:green}+1{color} the patch does not introduce any line longer than 132\n.    {color:green}+1{color} the patch does adds/modifies 1 testcase(s)\n{color:green}+1 RAT{color}\n.    {color:green}+1{color} the patch does not seem to introduce new RAT warnings\n{color:green}+1 JAVADOC{color}\n.    {color:green}+1{color} the patch does not seem to introduce new Javadoc warnings\n{color:green}+1 COMPILE{color}\n.    {color:green}+1{color} HEAD compiles\n.    {color:green}+1{color} patch compiles\n.    {color:green}+1{color} the patch does not seem to introduce new javac warnings\n{color:green}+1 BACKWARDS_COMPATIBILITY{color}\n.    {color:green}+1{color} the patch does not change any JPA Entity/Colum/Basic/Lob/Transient annotations\n.    {color:green}+1{color} the patch does not modify JPA files\n{color:green}+1 TESTS{color}\n.    Tests run: 1361\n{color:green}+1 DISTRO{color}\n.    {color:green}+1{color} distro tarball builds with the patch \n\n----------------------------\n{color:green}*+1 Overall result, good!, no -1s*{color}\n\n\nThe full output of the test-patch run is available at\n\n.   https://builds.apache.org/job/oozie-trunk-precommit-build/895/"
            },
            {
                "author_name": "egashira",
                "id": "13826016",
                "body": "committed to trunk, thanks for review. "
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d63051f4d395ee22273b25",
        "key": "AIRFLOW-3190",
        "id": "13190896",
        "description": "Enforce Flake8 over the entire project",
        "predictions": {},
        "comments": [
            {
                "author_name": "githubbot",
                "id": "16646512",
                "body": "Fokko opened a new pull request #4035: [AIRFLOW-3190] Make flake8 compliant\nURL: https://github.com/apache/incubator-airflow/pull/4035\n \n \n   Enforce Flake8 over the entire project\r\n   \r\n   Make sure you have checked _all_ steps below.\r\n   \r\n   ### Jira\r\n   \r\n   - [x] My PR addresses the following [Airflow Jira](https://issues.apache.org/jira/browse/AIRFLOW/) issues and references them in the PR title. For example, \"\\[AIRFLOW-3190\\] My Airflow PR\"\r\n     - https://issues.apache.org/jira/browse/AIRFLOW-3190\r\n     - In case you are fixing a typo in the documentation you can prepend your commit with \\[AIRFLOW-3190\\], code changes always need a Jira issue.\n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "githubbot",
                "id": "16648456",
                "body": "kaxil closed pull request #4035: [AIRFLOW-3190] Make flake8 compliant\nURL: https://github.com/apache/incubator-airflow/pull/4035\n \n \n   \n\nThis is a PR merged from a forked repository.\nAs GitHub hides the original diff on merge, it is displayed below for\nthe sake of provenance:\n\nAs this is a foreign pull request (from a fork), the diff is supplied\nbelow (as it won't show otherwise due to GitHub magic):\n\ndiff --git a/.flake8 b/.flake8\nnew file mode 100644\nindex 0000000000..2723df1f10\n--- /dev/null\n+++ b/.flake8\n@@ -0,0 +1,3 @@\n+[flake8]\n+max-line-length = 110\n+ignore = E731\ndiff --git a/.github/PULL_REQUEST_TEMPLATE.md b/.github/PULL_REQUEST_TEMPLATE.md\nindex 90452d954b..f7f69ac0b3 100644\n--- a/.github/PULL_REQUEST_TEMPLATE.md\n+++ b/.github/PULL_REQUEST_TEMPLATE.md\n@@ -31,4 +31,4 @@ Make sure you have checked _all_ steps below.\n \n ### Code Quality\n \n-- [ ] Passes `git diff upstream/master -u -- \"*.py\" | flake8 --diff`\n+- [ ] Passes `flake8`\ndiff --git a/airflow/contrib/hooks/gcp_dataproc_hook.py b/airflow/contrib/hooks/gcp_dataproc_hook.py\nindex ca86f08795..e068d65cbe 100644\n--- a/airflow/contrib/hooks/gcp_dataproc_hook.py\n+++ b/airflow/contrib/hooks/gcp_dataproc_hook.py\n@@ -78,8 +78,7 @@ def wait_for_done(self):\n     def raise_error(self, message=None):\n         job_state = self.job['status']['state']\n         # We always consider ERROR to be an error state.\n-        if ((self.job_error_states and job_state in self.job_error_states)\n-                or 'ERROR' == job_state):\n+        if (self.job_error_states and job_state in self.job_error_states) or 'ERROR' == job_state:\n             ex_message = message or (\"Google DataProc job has state: %s\" % job_state)\n             ex_details = (str(self.job['status']['details'])\n                           if 'details' in self.job['status']\ndiff --git a/airflow/jobs.py b/airflow/jobs.py\nindex 3922939a86..0bcb131c72 100644\n--- a/airflow/jobs.py\n+++ b/airflow/jobs.py\n@@ -203,10 +203,10 @@ def run(self):\n                 self._execute()\n                 # In case of max runs or max duration\n                 self.state = State.SUCCESS\n-            except SystemExit as e:\n+            except SystemExit:\n                 # In case of ^C or SIGTERM\n                 self.state = State.SUCCESS\n-            except Exception as e:\n+            except Exception:\n                 self.state = State.FAILED\n                 raise\n             finally:\n@@ -424,7 +424,7 @@ def start(self):\n     def terminate(self, sigkill=False):\n         \"\"\"\n         Terminate (and then kill) the process launched to process the file.\n-        \n+\n         :param sigkill: whether to issue a SIGKILL if SIGTERM doesn't work.\n         :type sigkill: bool\n         \"\"\"\n@@ -453,7 +453,7 @@ def pid(self):\n     def exit_code(self):\n         \"\"\"\n         After the process is finished, this can be called to get the return code\n-        \n+\n         :return: the exit code of the process\n         :rtype: int\n         \"\"\"\n@@ -465,7 +465,7 @@ def exit_code(self):\n     def done(self):\n         \"\"\"\n         Check if the process launched to process this file is done.\n-        \n+\n         :return: whether the process is finished running\n         :rtype: bool\n         \"\"\"\n@@ -2033,7 +2033,7 @@ def _update_counters(self, ti_status):\n         \"\"\"\n         Updates the counters per state of the tasks that were running. Can re-add\n         to tasks to run in case required.\n-        \n+\n         :param ti_status: the internal status of the backfill job tasks\n         :type ti_status: BackfillJob._DagRunTaskStatus\n         \"\"\"\n@@ -2078,7 +2078,7 @@ def _manage_executor_state(self, running):\n         \"\"\"\n         Checks if the executor agrees with the state of task instances\n         that are running\n-        \n+\n         :param running: dict of key, task to verify\n         \"\"\"\n         executor = self.executor\n@@ -2110,7 +2110,7 @@ def _get_dag_run(self, run_date, session=None):\n         Returns a dag run for the given run date, which will be matched to an existing\n         dag run if available or create a new dag run otherwise. If the max_active_runs\n         limit is reached, this function will return None.\n-        \n+\n         :param run_date: the execution date for the dag run\n         :type run_date: datetime\n         :param session: the database session object\n@@ -2170,7 +2170,7 @@ def _task_instances_for_dag_run(self, dag_run, session=None):\n         \"\"\"\n         Returns a map of task instance key to task instance object for the tasks to\n         run in the given dag run.\n-        \n+\n         :param dag_run: the dag run to get the tasks from\n         :type dag_run: models.DagRun\n         :param session: the database session object\n@@ -2236,7 +2236,7 @@ def _process_backfill_task_instances(self,\n         Process a set of task instances from a set of dag runs. Special handling is done\n         to account for different task instance states that could be present when running\n         them in a backfill process.\n-        \n+\n         :param ti_status: the internal status of the job\n         :type ti_status: BackfillJob._DagRunTaskStatus\n         :param executor: the executor to run the task instances\n@@ -2474,7 +2474,7 @@ def _execute_for_run_dates(self, run_dates, ti_status, executor, pickle_id,\n         Computes the dag runs and their respective task instances for\n         the given run dates and executes the task instances.\n         Returns a list of execution dates of the dag runs that were executed.\n-        \n+\n         :param run_dates: Execution dates for dag runs\n         :type run_dates: list\n         :param ti_status: internal BackfillJob status structure to tis track progress\ndiff --git a/airflow/utils/db.py b/airflow/utils/db.py\nindex 6b2f3a639a..3cff4bb4c9 100644\n--- a/airflow/utils/db.py\n+++ b/airflow/utils/db.py\n@@ -268,7 +268,7 @@ def initdb(rbac=False):\n     merge_conn(\n         models.Connection(\n             conn_id='qubole_default', conn_type='qubole',\n-            host= 'localhost'))\n+            host='localhost'))\n     merge_conn(\n         models.Connection(\n             conn_id='segment_default', conn_type='segment',\ndiff --git a/airflow/utils/log/file_processor_handler.py b/airflow/utils/log/file_processor_handler.py\nindex f39dffe0c9..cc7a8bd843 100644\n--- a/airflow/utils/log/file_processor_handler.py\n+++ b/airflow/utils/log/file_processor_handler.py\n@@ -116,7 +116,7 @@ def _symlink_latest_log_directory(self):\n                         os.unlink(latest_log_directory_path)\n                         os.symlink(log_directory, latest_log_directory_path)\n                 elif (os.path.isdir(latest_log_directory_path) or\n-                          os.path.isfile(latest_log_directory_path)):\n+                      os.path.isfile(latest_log_directory_path)):\n                     logging.warning(\n                         \"%s already exists as a dir/file. Skip creating symlink.\",\n                         latest_log_directory_path\ndiff --git a/airflow/utils/sqlalchemy.py b/airflow/utils/sqlalchemy.py\nindex 76c112785f..7e97371319 100644\n--- a/airflow/utils/sqlalchemy.py\n+++ b/airflow/utils/sqlalchemy.py\n@@ -37,12 +37,10 @@\n utc = pendulum.timezone('UTC')\n \n \n-def setup_event_handlers(\n-        engine,\n-        reconnect_timeout_seconds,\n-        initial_backoff_seconds=0.2,\n-        max_backoff_seconds=120):\n-\n+def setup_event_handlers(engine,\n+                         reconnect_timeout_seconds,\n+                         initial_backoff_seconds=0.2,\n+                         max_backoff_seconds=120):\n     @event.listens_for(engine, \"engine_connect\")\n     def ping_connection(connection, branch):\n         \"\"\"\n@@ -100,7 +98,6 @@ def ping_connection(connection, branch):\n                 # restore \"close with result\"\n                 connection.should_close_with_result = save_should_close_with_result\n \n-\n     @event.listens_for(engine, \"connect\")\n     def connect(dbapi_connection, connection_record):\n         connection_record.info['pid'] = os.getpid()\ndiff --git a/airflow/utils/trigger_rule.py b/airflow/utils/trigger_rule.py\nindex ae51d6a301..7fdcbc8ca8 100644\n--- a/airflow/utils/trigger_rule.py\n+++ b/airflow/utils/trigger_rule.py\n@@ -31,6 +31,7 @@ class TriggerRule(object):\n     DUMMY = 'dummy'\n \n     _ALL_TRIGGER_RULES = {}\n+\n     @classmethod\n     def is_valid(cls, trigger_rule):\n         return trigger_rule in cls.all_triggers()\ndiff --git a/airflow/utils/weight_rule.py b/airflow/utils/weight_rule.py\nindex b920ef4022..f34856be83 100644\n--- a/airflow/utils/weight_rule.py\n+++ b/airflow/utils/weight_rule.py\n@@ -28,6 +28,7 @@ class WeightRule(object):\n     ABSOLUTE = 'absolute'\n \n     _ALL_WEIGHT_RULES = {}\n+\n     @classmethod\n     def is_valid(cls, weight_rule):\n         return weight_rule in cls.all_weight_rules()\ndiff --git a/airflow/www/views.py b/airflow/www/views.py\nindex 0aef2281e7..a89e2847f3 100644\n--- a/airflow/www/views.py\n+++ b/airflow/www/views.py\n@@ -682,12 +682,12 @@ def dag_details(self, session=None):\n         title = \"DAG details\"\n \n         TI = models.TaskInstance\n-        states = (\n-            session.query(TI.state, sqla.func.count(TI.dag_id))\n-                .filter(TI.dag_id == dag_id)\n-                .group_by(TI.state)\n-                .all()\n-        )\n+        states = session\\\n+            .query(TI.state, sqla.func.count(TI.dag_id))\\\n+            .filter(TI.dag_id == dag_id)\\\n+            .group_by(TI.state)\\\n+            .all()\n+\n         return self.render(\n             'airflow/dag_details.html',\n             dag=dag, title=title, states=states, State=State)\n@@ -1192,12 +1192,12 @@ def dagrun_clear(self):\n     @provide_session\n     def blocked(self, session=None):\n         DR = models.DagRun\n-        dags = (\n-            session.query(DR.dag_id, sqla.func.count(DR.id))\n-                .filter(DR.state == State.RUNNING)\n-                .group_by(DR.dag_id)\n-                .all()\n-        )\n+        dags = session\\\n+            .query(DR.dag_id, sqla.func.count(DR.id))\\\n+            .filter(DR.state == State.RUNNING)\\\n+            .group_by(DR.dag_id)\\\n+            .all()\n+\n         payload = []\n         for dag_id, active_dag_runs in dags:\n             max_active_runs = 0\n@@ -1454,8 +1454,8 @@ def recurse_nodes(task, visited):\n                 children_key = \"_children\"\n \n             def set_duration(tid):\n-                if (isinstance(tid, dict) and tid.get(\"state\") == State.RUNNING and\n-                            tid[\"start_date\"] is not None):\n+                if isinstance(tid, dict) and tid.get(\"state\") == State.RUNNING \\\n+                        and tid[\"start_date\"] is not None:\n                     d = timezone.utcnow() - pendulum.parse(tid[\"start_date\"])\n                     tid[\"duration\"] = d.total_seconds()\n                 return tid\n@@ -1482,9 +1482,7 @@ def set_duration(tid):\n         data = {\n             'name': '[DAG]',\n             'children': [recurse_nodes(t, set()) for t in dag.roots],\n-            'instances': [\n-                dag_runs.get(d) or {'execution_date': d.isoformat()}\n-                for d in dates],\n+            'instances': [dag_runs.get(d) or {'execution_date': d.isoformat()} for d in dates],\n         }\n \n         # minimize whitespace as this can be huge for bigger dags\n@@ -2338,13 +2336,10 @@ class SlaMissModelView(wwwutils.SuperUserMixin, ModelViewOnly):\n \n @provide_session\n def _connection_ids(session=None):\n-    return [\n-            (c.conn_id, c.conn_id)\n-            for c in (\n-                session.query(models.Connection.conn_id)\n-                    .group_by(models.Connection.conn_id)\n-            )\n-    ]\n+    return [(c.conn_id, c.conn_id) for c in (\n+        session\n+            .query(models.Connection.conn_id)\n+            .group_by(models.Connection.conn_id))]\n \n \n class ChartModelView(wwwutils.DataProfilingMixin, AirflowModelView):\n@@ -3144,20 +3139,16 @@ def get_query(self):\n         \"\"\"\n         Default filters for model\n         \"\"\"\n-        return (\n-            super(DagModelView, self)\n-                .get_query()\n-                .filter(or_(models.DagModel.is_active, models.DagModel.is_paused))\n-                .filter(~models.DagModel.is_subdag)\n-        )\n+        return super(DagModelView, self)\\\n+            .get_query()\\\n+            .filter(or_(models.DagModel.is_active, models.DagModel.is_paused))\\\n+            .filter(~models.DagModel.is_subdag)\n \n     def get_count_query(self):\n         \"\"\"\n         Default filters for model\n         \"\"\"\n-        return (\n-            super(DagModelView, self)\n-                .get_count_query()\n-                .filter(models.DagModel.is_active)\n-                .filter(~models.DagModel.is_subdag)\n-        )\n+        return super(DagModelView, self)\\\n+            .get_count_query()\\\n+            .filter(models.DagModel.is_active)\\\n+            .filter(~models.DagModel.is_subdag)\ndiff --git a/airflow/www_rbac/views.py b/airflow/www_rbac/views.py\nindex e6e505c41a..e7db7c651c 100644\n--- a/airflow/www_rbac/views.py\n+++ b/airflow/www_rbac/views.py\n@@ -2111,7 +2111,7 @@ def varimport(self):\n                     suc_count += 1\n             flash(\"{} variable(s) successfully updated.\".format(suc_count))\n             if fail_count:\n-                flash(\"{} variables(s) failed to be updated.\".format(fail_count), 'error')\n+                flash(\"{} variable(s) failed to be updated.\".format(fail_count), 'error')\n             self.update_redirect()\n             return redirect(self.get_redirect())\n \n@@ -2353,7 +2353,7 @@ def action_clear(self, tis, session=None):\n             self.update_redirect()\n             return redirect(self.get_redirect())\n \n-        except Exception as ex:\n+        except Exception:\n             flash('Failed to clear task instances', 'error')\n \n     @provide_session\ndiff --git a/scripts/ci/flake8-diff.sh b/scripts/ci/flake8-diff.sh\ndeleted file mode 100755\nindex 376be9bc0f..0000000000\n--- a/scripts/ci/flake8-diff.sh\n+++ /dev/null\n@@ -1,164 +0,0 @@\n-#!/usr/bin/env bash\n-\n-# Copyright (c) 2007\u20132017 The scikit-learn developers.\n-# All rights reserved.\n-#\n-# Redistribution and use in source and binary forms, with or without\n-# modification, are permitted provided that the following conditions are met:\n-#\n-# 1. Redistributions of source code must retain the above copyright notice, this\n-#    list of conditions and the following disclaimer.\n-# 2. Redistributions in binary form must reproduce the above copyright notice,\n-#    this list of conditions and the following disclaimer in the documentation\n-#    and/or other materials provided with the distribution.\n-# 3. Neither the name of the Scikit-learn Developers  nor the names of\n-#    its contributors may be used to endorse or promote products\n-#    derived from this software without specific prior written\n-#    permission.\n-#\n-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n-# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n-# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\n-# ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n-# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n-# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n-# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n-# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n-\n-# This script is used in Travis to check that PRs do not add obvious\n-# flake8 violations. It relies on two things:\n-#   - find common ancestor between branch and\n-#     apache/incubator-airflow remote\n-#   - run flake8 --diff on the diff between the branch and the common\n-#     ancestor\n-#\n-# Additional features:\n-#   - the line numbers in Travis match the local branch on the PR\n-#     author machine.\n-#   - ./build_tools/travis/flake8_diff.sh can be run locally for quick\n-#     turn-around\n-\n-set -e\n-# pipefail is necessary to propagate exit codes\n-set -o pipefail\n-\n-PROJECT=apache/incubator-airflow\n-PROJECT_URL=https://github.com/$PROJECT.git\n-\n-# Find the remote with the project name (upstream in most cases)\n-REMOTE=$(git remote -v | grep $PROJECT | cut -f1 | head -1 || echo '')\n-\n-# Add a temporary remote if needed. For example this is necessary when\n-# Travis is configured to run in a fork. In this case 'origin' is the\n-# fork and not the reference repo we want to diff against.\n-if [[ -z \"$REMOTE\" ]]; then\n-    TMP_REMOTE=tmp_reference_upstream\n-    REMOTE=$TMP_REMOTE\n-    git remote add $REMOTE $PROJECT_URL\n-fi\n-\n-echo \"Remotes:\"\n-echo '--------------------------------------------------------------------------------'\n-git remote --verbose\n-\n-# Travis does the git clone with a limited depth (50 at the time of\n-# writing). This may not be enough to find the common ancestor with\n-# $REMOTE/master so we unshallow the git checkout\n-if [[ -a .git/shallow ]]; then\n-    echo -e '\\nTrying to unshallow the repo:'\n-    echo '--------------------------------------------------------------------------------'\n-    git fetch --unshallow\n-fi\n-\n-if [[ \"$TRAVIS\" == \"true\" ]]; then\n-    if [[ \"$TRAVIS_PULL_REQUEST\" == \"false\" ]]\n-    then\n-        # In main repo, using TRAVIS_COMMIT_RANGE to test the commits\n-        # that were pushed into a branch\n-        if [[ \"$PROJECT\" == \"$TRAVIS_REPO_SLUG\" ]]; then\n-            if [[ -z \"$TRAVIS_COMMIT_RANGE\" ]]; then\n-                echo \"New branch, no commit range from Travis so passing this test by convention\"\n-                exit 0\n-            fi\n-            COMMIT_RANGE=$TRAVIS_COMMIT_RANGE\n-        fi\n-    else\n-        # We want to fetch the code as it is in the PR branch and not\n-        # the result of the merge into master. This way line numbers\n-        # reported by Travis will match with the local code.\n-        LOCAL_BRANCH_REF=travis_pr_$TRAVIS_PULL_REQUEST\n-        # In Travis the PR target is always origin\n-        git fetch origin pull/$TRAVIS_PULL_REQUEST/head:refs/$LOCAL_BRANCH_REF\n-    fi\n-fi\n-\n-# If not using the commit range from Travis we need to find the common\n-# ancestor between $LOCAL_BRANCH_REF and $REMOTE/master\n-if [[ -z \"$COMMIT_RANGE\" ]]; then\n-    if [[ -z \"$LOCAL_BRANCH_REF\" ]]; then\n-        LOCAL_BRANCH_REF=$(git rev-parse --abbrev-ref HEAD)\n-    fi\n-    echo -e \"\\nLast 2 commits in $LOCAL_BRANCH_REF:\"\n-    echo '--------------------------------------------------------------------------------'\n-    git --no-pager log -2 $LOCAL_BRANCH_REF\n-\n-    REMOTE_MASTER_REF=\"$REMOTE/master\"\n-    # Make sure that $REMOTE_MASTER_REF is a valid reference\n-    echo -e \"\\nFetching $REMOTE_MASTER_REF\"\n-    echo '--------------------------------------------------------------------------------'\n-    git fetch $REMOTE master:refs/remotes/$REMOTE_MASTER_REF\n-    LOCAL_BRANCH_SHORT_HASH=$(git rev-parse --short $LOCAL_BRANCH_REF)\n-    REMOTE_MASTER_SHORT_HASH=$(git rev-parse --short $REMOTE_MASTER_REF)\n-\n-    COMMIT=$(git merge-base $LOCAL_BRANCH_REF $REMOTE_MASTER_REF) || \\\n-        echo \"No common ancestor found for $(git show $LOCAL_BRANCH_REF -q) and $(git show $REMOTE_MASTER_REF -q)\"\n-\n-    if [ -z \"$COMMIT\" ]; then\n-        exit 1\n-    fi\n-\n-    COMMIT_SHORT_HASH=$(git rev-parse --short $COMMIT)\n-\n-    echo -e \"\\nCommon ancestor between $LOCAL_BRANCH_REF ($LOCAL_BRANCH_SHORT_HASH)\"\\\n-         \"and $REMOTE_MASTER_REF ($REMOTE_MASTER_SHORT_HASH) is $COMMIT_SHORT_HASH:\"\n-    echo '--------------------------------------------------------------------------------'\n-    git --no-pager show --no-patch $COMMIT_SHORT_HASH\n-\n-    COMMIT_RANGE=\"$COMMIT_SHORT_HASH..$LOCAL_BRANCH_SHORT_HASH\"\n-\n-    if [[ -n \"$TMP_REMOTE\" ]]; then\n-        git remote remove $TMP_REMOTE\n-    fi\n-\n-else\n-    echo \"Got the commit range from Travis: $COMMIT_RANGE\"\n-fi\n-\n-echo -e '\\nRunning flake8 on the diff in the range' \"$COMMIT_RANGE\" \\\n-     \"($(git rev-list $COMMIT_RANGE | wc -l) commit(s)):\"\n-echo '--------------------------------------------------------------------------------'\n-\n-MODIFIED_FILES=\"$(git diff --name-only $COMMIT_RANGE || echo \"no_match\")\"\n-\n-check_files() {\n-    files=\"$1\"\n-    shift\n-    options=\"$*\"\n-    if [ -n \"$files\" ]; then\n-        # Conservative approach: diff without context (--unified=0) so that code\n-        # that was not changed does not create failures\n-        git diff --unified=0 $COMMIT_RANGE -- $files | flake8 --diff --show-source $options\n-    fi\n-}\n-\n-if [[ \"$MODIFIED_FILES\" == \"no_match\" ]]; then\n-    echo \"No file outside ignored locations has been modified\"\n-else\n-\n-    check_files \"$(echo \"$MODIFIED_FILES\" | grep -v ^examples)\"\n-    check_files \"$(echo \"$MODIFIED_FILES\" | grep ^examples)\" \\\n-        --config ./examples/.flake8\n-fi\n-echo -e \"No problem detected by flake8\\n\"\ndiff --git a/setup.py b/setup.py\nindex 76f55ab01b..b1376bb5bb 100644\n--- a/setup.py\n+++ b/setup.py\n@@ -45,8 +45,7 @@ def verify_gpl_dependency():\n     if os.getenv(\"READTHEDOCS\") == \"True\":\n         os.environ[\"SLUGIFY_USES_TEXT_UNIDECODE\"] = \"yes\"\n \n-    if (not os.getenv(\"AIRFLOW_GPL_UNIDECODE\")\n-            and not os.getenv(\"SLUGIFY_USES_TEXT_UNIDECODE\") == \"yes\"):\n+    if not os.getenv(\"AIRFLOW_GPL_UNIDECODE\") and not os.getenv(\"SLUGIFY_USES_TEXT_UNIDECODE\") == \"yes\":\n         raise RuntimeError(\"By default one of Airflow's dependencies installs a GPL \"\n                            \"dependency (unidecode). To avoid this dependency set \"\n                            \"SLUGIFY_USES_TEXT_UNIDECODE=yes in your environment when you \"\ndiff --git a/tests/api/__init__.py b/tests/api/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/api/__init__.py\n+++ b/tests/api/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/api/client/__init__.py b/tests/api/client/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/api/client/__init__.py\n+++ b/tests/api/client/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/api/common/__init__.py b/tests/api/common/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/api/common/__init__.py\n+++ b/tests/api/common/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/api/common/experimental/__init__.py b/tests/api/common/experimental/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/api/common/experimental/__init__.py\n+++ b/tests/api/common/experimental/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/api/common/experimental/mark_tasks.py b/tests/api/common/experimental/mark_tasks.py\nindex 9bba91bee0..304e261b98 100644\n--- a/tests/api/common/experimental/mark_tasks.py\n+++ b/tests/api/common/experimental/mark_tasks.py\n@@ -72,7 +72,7 @@ def tearDown(self):\n     def snapshot_state(self, dag, execution_dates):\n         TI = models.TaskInstance\n         tis = self.session.query(TI).filter(\n-            TI.dag_id==dag.dag_id,\n+            TI.dag_id == dag.dag_id,\n             TI.execution_date.in_(execution_dates)\n         ).all()\n \n@@ -84,7 +84,7 @@ def verify_state(self, dag, task_ids, execution_dates, state, old_tis):\n         TI = models.TaskInstance\n \n         tis = self.session.query(TI).filter(\n-            TI.dag_id==dag.dag_id,\n+            TI.dag_id == dag.dag_id,\n             TI.execution_date.in_(execution_dates)\n         ).all()\n \n@@ -95,9 +95,8 @@ def verify_state(self, dag, task_ids, execution_dates, state, old_tis):\n                 self.assertEqual(ti.state, state)\n             else:\n                 for old_ti in old_tis:\n-                    if (old_ti.task_id == ti.task_id\n-                            and old_ti.execution_date == ti.execution_date):\n-                            self.assertEqual(ti.state, old_ti.state)\n+                    if old_ti.task_id == ti.task_id and old_ti.execution_date == ti.execution_date:\n+                        self.assertEqual(ti.state, old_ti.state)\n \n     def test_mark_tasks_now(self):\n         # set one task to success but do not commit\n@@ -435,19 +434,19 @@ def test_set_state_without_commit(self):\n         self._verify_task_instance_states_remain_default(dr)\n \n     def test_set_state_with_multiple_dagruns(self):\n-        dr1 = self.dag2.create_dagrun(\n+        self.dag2.create_dagrun(\n             run_id='manual__' + datetime.now().isoformat(),\n             state=State.FAILED,\n             execution_date=self.execution_dates[0],\n             session=self.session\n         )\n-        dr2 = self.dag2.create_dagrun(\n+        self.dag2.create_dagrun(\n             run_id='manual__' + datetime.now().isoformat(),\n             state=State.FAILED,\n             execution_date=self.execution_dates[1],\n             session=self.session\n         )\n-        dr3 = self.dag2.create_dagrun(\n+        self.dag2.create_dagrun(\n             run_id='manual__' + datetime.now().isoformat(),\n             state=State.RUNNING,\n             execution_date=self.execution_dates[2],\n@@ -468,13 +467,11 @@ def count_dag_tasks(dag):\n         self._verify_dag_run_state(self.dag2, self.execution_dates[1], State.SUCCESS)\n \n         # Make sure other dag status are not changed\n-        dr1 = models.DagRun.find(dag_id=self.dag2.dag_id,\n-                                 execution_date=self.execution_dates[0])\n-        dr1 = dr1[0]\n+        models.DagRun.find(dag_id=self.dag2.dag_id,\n+                           execution_date=self.execution_dates[0])\n         self._verify_dag_run_state(self.dag2, self.execution_dates[0], State.FAILED)\n-        dr3 = models.DagRun.find(dag_id=self.dag2.dag_id,\n-                                 execution_date=self.execution_dates[2])\n-        dr3 = dr3[0]\n+        models.DagRun.find(dag_id=self.dag2.dag_id,\n+                           execution_date=self.execution_dates[2])\n         self._verify_dag_run_state(self.dag2, self.execution_dates[2], State.RUNNING)\n \n     def test_set_dag_run_state_edge_cases(self):\ndiff --git a/tests/contrib/hooks/test_databricks_hook.py b/tests/contrib/hooks/test_databricks_hook.py\nindex 090f46caeb..597c881929 100644\n--- a/tests/contrib/hooks/test_databricks_hook.py\n+++ b/tests/contrib/hooks/test_databricks_hook.py\n@@ -127,6 +127,7 @@ def terminate_cluster_endpoint(host):\n     \"\"\"\n     return 'https://{}/api/2.0/clusters/delete'.format(host)\n \n+\n def create_valid_response_mock(content):\n     response = mock.MagicMock()\n     response.json.return_value = content\n@@ -143,13 +144,11 @@ def create_post_side_effect(exception, status_code=500):\n         return response\n \n \n-def setup_mock_requests(\n-        mock_requests,\n-        exception,\n-        status_code=500,\n-        error_count=None,\n-        response_content=None):\n-\n+def setup_mock_requests(mock_requests,\n+                        exception,\n+                        status_code=500,\n+                        error_count=None,\n+                        response_content=None):\n     side_effect = create_post_side_effect(exception, status_code)\n \n     if error_count is None:\n@@ -165,6 +164,7 @@ class DatabricksHookTest(unittest.TestCase):\n     \"\"\"\n     Tests for DatabricksHook.\n     \"\"\"\n+\n     @db.provide_session\n     def setUp(self, session=None):\n         conn = session.query(Connection) \\\n@@ -191,21 +191,19 @@ def test_init_bad_retry_limit(self):\n             DatabricksHook(retry_limit=0)\n \n     def test_do_api_call_retries_with_retryable_error(self):\n-        for exception in [\n-                requests_exceptions.ConnectionError,\n-                requests_exceptions.SSLError,\n-                requests_exceptions.Timeout,\n-                requests_exceptions.ConnectTimeout,\n-                requests_exceptions.HTTPError]:\n-            with mock.patch(\n-                'airflow.contrib.hooks.databricks_hook.requests') as mock_requests, \\\n-                    mock.patch.object(self.hook.log, 'error') as mock_errors:\n-                setup_mock_requests(mock_requests, exception)\n-\n-                with self.assertRaises(AirflowException):\n-                    self.hook._do_api_call(SUBMIT_RUN_ENDPOINT, {})\n-\n-                self.assertEquals(mock_errors.call_count, self.hook.retry_limit)\n+        for exception in [requests_exceptions.ConnectionError,\n+                          requests_exceptions.SSLError,\n+                          requests_exceptions.Timeout,\n+                          requests_exceptions.ConnectTimeout,\n+                          requests_exceptions.HTTPError]:\n+            with mock.patch('airflow.contrib.hooks.databricks_hook.requests') as mock_requests:\n+                with mock.patch.object(self.hook.log, 'error') as mock_errors:\n+                    setup_mock_requests(mock_requests, exception)\n+\n+                    with self.assertRaises(AirflowException):\n+                        self.hook._do_api_call(SUBMIT_RUN_ENDPOINT, {})\n+\n+                    self.assertEquals(mock_errors.call_count, self.hook.retry_limit)\n \n     @mock.patch('airflow.contrib.hooks.databricks_hook.requests')\n     def test_do_api_call_does_not_retry_with_non_retryable_error(self, mock_requests):\n@@ -220,56 +218,52 @@ def test_do_api_call_does_not_retry_with_non_retryable_error(self, mock_requests\n             mock_errors.assert_not_called()\n \n     def test_do_api_call_succeeds_after_retrying(self):\n-        for exception in [\n-                requests_exceptions.ConnectionError,\n-                requests_exceptions.SSLError,\n-                requests_exceptions.Timeout,\n-                requests_exceptions.ConnectTimeout,\n-                requests_exceptions.HTTPError]:\n-            with mock.patch(\n-                'airflow.contrib.hooks.databricks_hook.requests') as mock_requests, \\\n-                    mock.patch.object(self.hook.log, 'error') as mock_errors:\n-                setup_mock_requests(\n-                    mock_requests,\n-                    exception,\n-                    error_count=2,\n-                    response_content={'run_id': '1'}\n-                )\n-\n-                response = self.hook._do_api_call(SUBMIT_RUN_ENDPOINT, {})\n-\n-                self.assertEquals(mock_errors.call_count, 2)\n-                self.assertEquals(response, {'run_id': '1'})\n+        for exception in [requests_exceptions.ConnectionError,\n+                          requests_exceptions.SSLError,\n+                          requests_exceptions.Timeout,\n+                          requests_exceptions.ConnectTimeout,\n+                          requests_exceptions.HTTPError]:\n+            with mock.patch('airflow.contrib.hooks.databricks_hook.requests') as mock_requests:\n+                with mock.patch.object(self.hook.log, 'error') as mock_errors:\n+                    setup_mock_requests(\n+                        mock_requests,\n+                        exception,\n+                        error_count=2,\n+                        response_content={'run_id': '1'}\n+                    )\n+\n+                    response = self.hook._do_api_call(SUBMIT_RUN_ENDPOINT, {})\n+\n+                    self.assertEquals(mock_errors.call_count, 2)\n+                    self.assertEquals(response, {'run_id': '1'})\n \n     @mock.patch('airflow.contrib.hooks.databricks_hook.sleep')\n     def test_do_api_call_waits_between_retries(self, mock_sleep):\n         retry_delay = 5\n         self.hook = DatabricksHook(retry_delay=retry_delay)\n \n-        for exception in [\n-                requests_exceptions.ConnectionError,\n-                requests_exceptions.SSLError,\n-                requests_exceptions.Timeout,\n-                requests_exceptions.ConnectTimeout,\n-                requests_exceptions.HTTPError]:\n-            with mock.patch(\n-                'airflow.contrib.hooks.databricks_hook.requests') as mock_requests, \\\n-                    mock.patch.object(self.hook.log, 'error'):\n-                mock_sleep.reset_mock()\n-                setup_mock_requests(mock_requests, exception)\n+        for exception in [requests_exceptions.ConnectionError,\n+                          requests_exceptions.SSLError,\n+                          requests_exceptions.Timeout,\n+                          requests_exceptions.ConnectTimeout,\n+                          requests_exceptions.HTTPError]:\n+            with mock.patch('airflow.contrib.hooks.databricks_hook.requests') as mock_requests:\n+                with mock.patch.object(self.hook.log, 'error'):\n+                    mock_sleep.reset_mock()\n+                    setup_mock_requests(mock_requests, exception)\n \n-                with self.assertRaises(AirflowException):\n-                    self.hook._do_api_call(SUBMIT_RUN_ENDPOINT, {})\n+                    with self.assertRaises(AirflowException):\n+                        self.hook._do_api_call(SUBMIT_RUN_ENDPOINT, {})\n \n-                self.assertEquals(len(mock_sleep.mock_calls), self.hook.retry_limit - 1)\n-                mock_sleep.assert_called_with(retry_delay)\n+                    self.assertEquals(len(mock_sleep.mock_calls), self.hook.retry_limit - 1)\n+                    mock_sleep.assert_called_with(retry_delay)\n \n     @mock.patch('airflow.contrib.hooks.databricks_hook.requests')\n     def test_submit_run(self, mock_requests):\n         mock_requests.post.return_value.json.return_value = {'run_id': '1'}\n         json = {\n-          'notebook_task': NOTEBOOK_TASK,\n-          'new_cluster': NEW_CLUSTER\n+            'notebook_task': NOTEBOOK_TASK,\n+            'new_cluster': NEW_CLUSTER\n         }\n         run_id = self.hook.submit_run(json)\n \n@@ -407,6 +401,7 @@ class DatabricksHookTokenTest(unittest.TestCase):\n     \"\"\"\n     Tests for DatabricksHook when auth is done with token.\n     \"\"\"\n+\n     @db.provide_session\n     def setUp(self, session=None):\n         conn = session.query(Connection) \\\n@@ -424,8 +419,8 @@ def test_submit_run(self, mock_requests):\n         status_code_mock = mock.PropertyMock(return_value=200)\n         type(mock_requests.post.return_value).status_code = status_code_mock\n         json = {\n-          'notebook_task': NOTEBOOK_TASK,\n-          'new_cluster': NEW_CLUSTER\n+            'notebook_task': NOTEBOOK_TASK,\n+            'new_cluster': NEW_CLUSTER\n         }\n         run_id = self.hook.submit_run(json)\n \ndiff --git a/tests/contrib/hooks/test_emr_hook.py b/tests/contrib/hooks/test_emr_hook.py\nindex edb2dbb049..07c20e69cf 100644\n--- a/tests/contrib/hooks/test_emr_hook.py\n+++ b/tests/contrib/hooks/test_emr_hook.py\n@@ -24,7 +24,6 @@\n from airflow import configuration\n from airflow.contrib.hooks.emr_hook import EmrHook\n \n-\n try:\n     from moto import mock_emr\n except ImportError:\n@@ -54,5 +53,6 @@ def test_create_job_flow_uses_the_emr_config_to_create_a_cluster(self):\n \n         self.assertEqual(client.list_clusters()['Clusters'][0]['Id'], cluster['JobFlowId'])\n \n+\n if __name__ == '__main__':\n     unittest.main()\ndiff --git a/tests/contrib/hooks/test_gcp_mlengine_hook.py b/tests/contrib/hooks/test_gcp_mlengine_hook.py\nindex c3bc7a9c0d..f986354503 100644\n--- a/tests/contrib/hooks/test_gcp_mlengine_hook.py\n+++ b/tests/contrib/hooks/test_gcp_mlengine_hook.py\n@@ -185,8 +185,7 @@ def test_list_versions(self):\n                 self._SERVICE_URI_PREFIX, project, model_name), 'GET',\n              None),\n         ] + [\n-            ('{}projects/{}/models/{}/versions?alt=json&pageToken={}'\n-             '&pageSize=100'.format(\n+            ('{}projects/{}/models/{}/versions?alt=json&pageToken={}&pageSize=100'.format(\n                 self._SERVICE_URI_PREFIX, project, model_name, ix), 'GET',\n              None) for ix in range(len(versions) - 1)\n         ]\ndiff --git a/tests/contrib/hooks/test_jdbc_hook.py b/tests/contrib/hooks/test_jdbc_hook.py\nindex fd4a4fc337..3f708997d9 100644\n--- a/tests/contrib/hooks/test_jdbc_hook.py\n+++ b/tests/contrib/hooks/test_jdbc_hook.py\n@@ -19,6 +19,7 @@\n #\n \n import unittest\n+import json\n \n from mock import Mock\n from mock import patch\n@@ -29,7 +30,7 @@\n from airflow.utils import db\n \n jdbc_conn_mock = Mock(\n-        name=\"jdbc_conn\"\n+    name=\"jdbc_conn\"\n )\n \n \n@@ -37,10 +38,11 @@ class TestJdbcHook(unittest.TestCase):\n     def setUp(self):\n         configuration.load_test_config()\n         db.merge_conn(\n-                models.Connection(\n-                        conn_id='jdbc_default', conn_type='jdbc',\n-                        host='jdbc://localhost/', port=443,\n-                        extra='{\"extra__jdbc__drv_path\": \"/path1/test.jar,/path2/t.jar2\", \"extra__jdbc__drv_clsname\": \"com.driver.main\"}'))\n+            models.Connection(\n+                conn_id='jdbc_default', conn_type='jdbc',\n+                host='jdbc://localhost/', port=443,\n+                extra=json.dumps({\"extra__jdbc__drv_path\": \"/path1/test.jar,/path2/t.jar2\",\n+                                  \"extra__jdbc__drv_clsname\": \"com.driver.main\"})))\n \n     @patch(\"airflow.hooks.jdbc_hook.jaydebeapi.connect\", autospec=True,\n            return_value=jdbc_conn_mock)\ndiff --git a/tests/contrib/hooks/test_jira_hook.py b/tests/contrib/hooks/test_jira_hook.py\nindex 029a452990..378c379d55 100644\n--- a/tests/contrib/hooks/test_jira_hook.py\n+++ b/tests/contrib/hooks/test_jira_hook.py\n@@ -29,7 +29,7 @@\n from airflow.utils import db\n \n jira_client_mock = Mock(\n-        name=\"jira_client\"\n+    name=\"jira_client\"\n )\n \n \n@@ -37,10 +37,10 @@ class TestJiraHook(unittest.TestCase):\n     def setUp(self):\n         configuration.load_test_config()\n         db.merge_conn(\n-                models.Connection(\n-                        conn_id='jira_default', conn_type='jira',\n-                        host='https://localhost/jira/', port=443,\n-                        extra='{\"verify\": \"False\", \"project\": \"AIRFLOW\"}'))\n+            models.Connection(\n+                conn_id='jira_default', conn_type='jira',\n+                host='https://localhost/jira/', port=443,\n+                extra='{\"verify\": \"False\", \"project\": \"AIRFLOW\"}'))\n \n     @patch(\"airflow.contrib.hooks.jira_hook.JIRA\", autospec=True,\n            return_value=jira_client_mock)\ndiff --git a/tests/contrib/hooks/test_spark_sql_hook.py b/tests/contrib/hooks/test_spark_sql_hook.py\nindex 47ccd618b3..f76768efcd 100644\n--- a/tests/contrib/hooks/test_spark_sql_hook.py\n+++ b/tests/contrib/hooks/test_spark_sql_hook.py\n@@ -35,8 +35,8 @@ def get_after(sentinel, iterable):\n     next(truncated)\n     return next(truncated)\n \n-class TestSparkSqlHook(unittest.TestCase):\n \n+class TestSparkSqlHook(unittest.TestCase):\n     _config = {\n         'conn_id': 'spark_default',\n         'executor_cores': 4,\n@@ -98,7 +98,8 @@ def test_spark_process_runcmd(self, mock_popen):\n                 hook.run_query()\n                 mock_debug.assert_called_with(\n                     'Spark-Sql cmd: %s',\n-                    ['spark-sql', '-e', 'SELECT 1', '--master', 'yarn', '--name', 'default-name', '--verbose', '--queue', 'default']\n+                    ['spark-sql', '-e', 'SELECT 1', '--master', 'yarn', '--name', 'default-name', '--verbose',\n+                     '--queue', 'default']\n                 )\n                 mock_info.assert_called_with(\n                     'Spark-sql communicates using stdout'\n@@ -107,7 +108,8 @@ def test_spark_process_runcmd(self, mock_popen):\n         # Then\n         self.assertEqual(\n             mock_popen.mock_calls[0],\n-            call(['spark-sql', '-e', 'SELECT 1', '--master', 'yarn', '--name', 'default-name', '--verbose', '--queue', 'default'], stderr=-2, stdout=-1)\n+            call(['spark-sql', '-e', 'SELECT 1', '--master', 'yarn', '--name', 'default-name', '--verbose',\n+                  '--queue', 'default'], stderr=-2, stdout=-1)\n         )\n \n \ndiff --git a/tests/contrib/hooks/test_sqoop_hook.py b/tests/contrib/hooks/test_sqoop_hook.py\nindex 649500a364..8bef5a4937 100644\n--- a/tests/contrib/hooks/test_sqoop_hook.py\n+++ b/tests/contrib/hooks/test_sqoop_hook.py\n@@ -98,7 +98,8 @@ def test_popen(self, mock_popen):\n         mock_popen.return_value.stdout = StringIO(u'stdout')\n         mock_popen.return_value.stderr = StringIO(u'stderr')\n         mock_popen.return_value.returncode = 0\n-        mock_popen.return_value.communicate.return_value = [StringIO(u'stdout\\nstdout'), StringIO(u'stderr\\nstderr')]\n+        mock_popen.return_value.communicate.return_value = \\\n+            [StringIO(u'stdout\\nstdout'), StringIO(u'stderr\\nstderr')]\n \n         # When\n         hook = SqoopHook(conn_id='sqoop_test')\n@@ -163,7 +164,7 @@ def test_submit(self):\n             self.assertIn(\"-files {}\".format(self._config_json['files']), cmd)\n \n         if self._config_json['archives']:\n-            self.assertIn( \"-archives {}\".format(self._config_json['archives']), cmd)\n+            self.assertIn(\"-archives {}\".format(self._config_json['archives']), cmd)\n \n         self.assertIn(\"--hcatalog-database {}\".format(self._config['hcatalog_database']), cmd)\n         self.assertIn(\"--hcatalog-table {}\".format(self._config['hcatalog_table']), cmd)\n@@ -173,7 +174,7 @@ def test_submit(self):\n             self.assertIn(\"--verbose\", cmd)\n \n         if self._config['num_mappers']:\n-            self.assertIn( \"--num-mappers {}\".format(self._config['num_mappers']), cmd)\n+            self.assertIn(\"--num-mappers {}\".format(self._config['num_mappers']), cmd)\n \n         for key, value in self._config['properties'].items():\n             self.assertIn(\"-D {}={}\".format(key, value), cmd)\n@@ -301,7 +302,8 @@ def test_import_cmd(self):\n \n     def test_get_export_format_argument(self):\n         \"\"\"\n-        Tests to verify the hook get format function is building correct Sqoop command with correct format type.\n+        Tests to verify the hook get format function is building\n+        correct Sqoop command with correct format type.\n         \"\"\"\n         hook = SqoopHook()\n         self.assertIn(\"--as-avrodatafile\",\ndiff --git a/tests/contrib/operators/__init__.py b/tests/contrib/operators/__init__.py\nindex 331c28ef9a..b7f8352944 100644\n--- a/tests/contrib/operators/__init__.py\n+++ b/tests/contrib/operators/__init__.py\n@@ -17,4 +17,3 @@\n # specific language governing permissions and limitations\n # under the License.\n #\n-\ndiff --git a/tests/contrib/operators/test_awsbatch_operator.py b/tests/contrib/operators/test_awsbatch_operator.py\nindex 273edd5630..4808574f23 100644\n--- a/tests/contrib/operators/test_awsbatch_operator.py\n+++ b/tests/contrib/operators/test_awsbatch_operator.py\n@@ -33,7 +33,6 @@\n     except ImportError:\n         mock = None\n \n-\n RESPONSE_WITHOUT_FAILURES = {\n     \"jobName\": \"51455483-c62c-48ac-9b88-53a6a725baa3\",\n     \"jobId\": \"8ba9d676-4108-4474-9dca-8bbac1da9b19\"\n@@ -58,7 +57,6 @@ def setUp(self, aws_hook_mock):\n             region_name='eu-west-1')\n \n     def test_init(self):\n-\n         self.assertEqual(self.batch.job_name, '51455483-c62c-48ac-9b88-53a6a725baa3')\n         self.assertEqual(self.batch.job_queue, 'queue')\n         self.assertEqual(self.batch.job_definition, 'hello-world')\n@@ -76,13 +74,13 @@ def test_template_fields_overrides(self):\n     @mock.patch.object(AWSBatchOperator, '_wait_for_task_ended')\n     @mock.patch.object(AWSBatchOperator, '_check_success_task')\n     def test_execute_without_failures(self, check_mock, wait_mock):\n-\n         client_mock = self.aws_hook_mock.return_value.get_client_type.return_value\n         client_mock.submit_job.return_value = RESPONSE_WITHOUT_FAILURES\n \n         self.batch.execute(None)\n \n-        self.aws_hook_mock.return_value.get_client_type.assert_called_once_with('batch', region_name='eu-west-1')\n+        self.aws_hook_mock.return_value.get_client_type.assert_called_once_with('batch',\n+                                                                                region_name='eu-west-1')\n         client_mock.submit_job.assert_called_once_with(\n             jobQueue='queue',\n             jobName='51455483-c62c-48ac-9b88-53a6a725baa3',\n@@ -95,14 +93,14 @@ def test_execute_without_failures(self, check_mock, wait_mock):\n         self.assertEqual(self.batch.jobId, '8ba9d676-4108-4474-9dca-8bbac1da9b19')\n \n     def test_execute_with_failures(self):\n-\n         client_mock = self.aws_hook_mock.return_value.get_client_type.return_value\n         client_mock.submit_job.return_value = \"\"\n \n         with self.assertRaises(AirflowException):\n             self.batch.execute(None)\n \n-        self.aws_hook_mock.return_value.get_client_type.assert_called_once_with('batch', region_name='eu-west-1')\n+        self.aws_hook_mock.return_value.get_client_type.assert_called_once_with('batch',\n+                                                                                region_name='eu-west-1')\n         client_mock.submit_job.assert_called_once_with(\n             jobQueue='queue',\n             jobName='51455483-c62c-48ac-9b88-53a6a725baa3',\n@@ -111,7 +109,6 @@ def test_execute_with_failures(self):\n         )\n \n     def test_wait_end_tasks(self):\n-\n         client_mock = mock.Mock()\n         self.batch.jobId = '8ba9d676-4108-4474-9dca-8bbac1da9b19'\n         self.batch.client = client_mock\ndiff --git a/tests/contrib/operators/test_databricks_operator.py b/tests/contrib/operators/test_databricks_operator.py\nindex 75602efb7d..af62a3e4c3 100644\n--- a/tests/contrib/operators/test_databricks_operator.py\n+++ b/tests/contrib/operators/test_databricks_operator.py\n@@ -132,9 +132,9 @@ def test_init_with_specified_run_name(self):\n         Test the initializer with a specified run_name.\n         \"\"\"\n         json = {\n-          'new_cluster': NEW_CLUSTER,\n-          'notebook_task': NOTEBOOK_TASK,\n-          'run_name': RUN_NAME\n+            'new_cluster': NEW_CLUSTER,\n+            'notebook_task': NOTEBOOK_TASK,\n+            'run_name': RUN_NAME\n         }\n         op = DatabricksSubmitRunOperator(task_id=TASK_ID, json=json)\n         expected = databricks_operator._deep_string_coerce({\n@@ -167,8 +167,8 @@ def test_init_with_merging(self):\n \n     def test_init_with_templating(self):\n         json = {\n-          'new_cluster': NEW_CLUSTER,\n-          'notebook_task': TEMPLATED_NOTEBOOK_TASK,\n+            'new_cluster': NEW_CLUSTER,\n+            'notebook_task': TEMPLATED_NOTEBOOK_TASK,\n         }\n         dag = DAG('test', start_date=datetime.now())\n         op = DatabricksSubmitRunOperator(dag=dag, task_id=TASK_ID, json=json)\n@@ -196,8 +196,8 @@ def test_exec_success(self, db_mock_class):\n         Test the execute function in case where the run is successful.\n         \"\"\"\n         run = {\n-          'new_cluster': NEW_CLUSTER,\n-          'notebook_task': NOTEBOOK_TASK,\n+            'new_cluster': NEW_CLUSTER,\n+            'notebook_task': NOTEBOOK_TASK,\n         }\n         op = DatabricksSubmitRunOperator(task_id=TASK_ID, json=run)\n         db_mock = db_mock_class.return_value\n@@ -227,8 +227,8 @@ def test_exec_failure(self, db_mock_class):\n         Test the execute function in case where the run failed.\n         \"\"\"\n         run = {\n-          'new_cluster': NEW_CLUSTER,\n-          'notebook_task': NOTEBOOK_TASK,\n+            'new_cluster': NEW_CLUSTER,\n+            'notebook_task': NOTEBOOK_TASK,\n         }\n         op = DatabricksSubmitRunOperator(task_id=TASK_ID, json=run)\n         db_mock = db_mock_class.return_value\ndiff --git a/tests/contrib/operators/test_dataproc_operator.py b/tests/contrib/operators/test_dataproc_operator.py\nindex 60c1268ee7..7141a03140 100644\n--- a/tests/contrib/operators/test_dataproc_operator.py\n+++ b/tests/contrib/operators/test_dataproc_operator.py\n@@ -114,7 +114,7 @@ def setUp(self):\n         self.dataproc_operators = []\n         self.mock_conn = Mock()\n         for labels in self.labels:\n-             self.dataproc_operators.append(\n+            self.dataproc_operators.append(\n                 DataprocClusterCreateOperator(\n                     task_id=TASK_ID,\n                     cluster_name=CLUSTER_NAME,\n@@ -140,7 +140,7 @@ def setUp(self):\n                     auto_delete_time=AUTO_DELETE_TIME,\n                     auto_delete_ttl=AUTO_DELETE_TTL\n                 )\n-             )\n+            )\n         self.dag = DAG(\n             'test_dag',\n             default_args={\n@@ -214,7 +214,7 @@ def test_build_cluster_data(self):\n             # set to the dataproc operator.\n             merged_labels = {}\n             merged_labels.update(self.labels[suffix])\n-            merged_labels.update({'airflow-version': 'v' + version.replace('.', '-').replace('+','-')})\n+            merged_labels.update({'airflow-version': 'v' + version.replace('.', '-').replace('+', '-')})\n             self.assertTrue(re.match(r'[a-z]([-a-z0-9]*[a-z0-9])?',\n                                      cluster_data['labels']['airflow-version']))\n             self.assertEqual(cluster_data['labels'], merged_labels)\n@@ -299,8 +299,7 @@ def test_init_with_custom_image(self):\n                          expected_custom_image_url)\n \n     def test_cluster_name_log_no_sub(self):\n-        with patch('airflow.contrib.operators.dataproc_operator.DataProcHook') \\\n-                as mock_hook:\n+        with patch('airflow.contrib.operators.dataproc_operator.DataProcHook') as mock_hook:\n             mock_hook.return_value.get_conn = self.mock_conn\n             dataproc_task = DataprocClusterCreateOperator(\n                 task_id=TASK_ID,\n@@ -311,13 +310,12 @@ def test_cluster_name_log_no_sub(self):\n                 dag=self.dag\n             )\n             with patch.object(dataproc_task.log, 'info') as mock_info:\n-                with self.assertRaises(TypeError) as _:\n+                with self.assertRaises(TypeError):\n                     dataproc_task.execute(None)\n                 mock_info.assert_called_with('Creating cluster: %s', CLUSTER_NAME)\n \n     def test_cluster_name_log_sub(self):\n-        with patch('airflow.contrib.operators.dataproc_operator.DataProcHook') \\\n-                as mock_hook:\n+        with patch('airflow.contrib.operators.dataproc_operator.DataProcHook') as mock_hook:\n             mock_hook.return_value.get_conn = self.mock_conn\n             dataproc_task = DataprocClusterCreateOperator(\n                 task_id=TASK_ID,\n@@ -336,13 +334,11 @@ def test_cluster_name_log_sub(self):\n                 setattr(dataproc_task, 'cluster_name', rendered)\n                 with self.assertRaises(TypeError):\n                     dataproc_task.execute(None)\n-                mock_info.assert_called_with('Creating cluster: %s',\n-                                             u'smoke-cluster-testnodash')\n+                mock_info.assert_called_with('Creating cluster: %s', u'smoke-cluster-testnodash')\n \n     def test_build_cluster_data_internal_ip_only_without_subnetwork(self):\n \n         def create_cluster_with_invalid_internal_ip_only_setup():\n-\n             # Given\n             create_cluster = DataprocClusterCreateOperator(\n                 task_id=TASK_ID,\n@@ -361,8 +357,7 @@ def create_cluster_with_invalid_internal_ip_only_setup():\n             create_cluster_with_invalid_internal_ip_only_setup()\n \n         self.assertEqual(str(cm.exception),\n-                         \"Set internal_ip_only to true only when\"\n-                         \" you pass a subnetwork_uri.\")\n+                         \"Set internal_ip_only to true only when you pass a subnetwork_uri.\")\n \n \n class DataprocClusterScaleOperatorTest(unittest.TestCase):\n@@ -406,8 +401,7 @@ def test_cluster_name_log_no_sub(self):\n                 mock_info.assert_called_with('Scaling cluster: %s', CLUSTER_NAME)\n \n     def test_cluster_name_log_sub(self):\n-        with patch('airflow.contrib.operators.dataproc_operator.DataProcHook') \\\n-                as mock_hook:\n+        with patch('airflow.contrib.operators.dataproc_operator.DataProcHook') as mock_hook:\n             mock_hook.return_value.get_conn = self.mock_conn\n             dataproc_task = DataprocClusterScaleOperator(\n                 task_id=TASK_ID,\n@@ -427,22 +421,21 @@ def test_cluster_name_log_sub(self):\n                 setattr(dataproc_task, 'cluster_name', rendered)\n                 with self.assertRaises(TypeError):\n                     dataproc_task.execute(None)\n-                mock_info.assert_called_with('Scaling cluster: %s',\n-                                             u'smoke-cluster-testnodash')\n+                mock_info.assert_called_with('Scaling cluster: %s', u'smoke-cluster-testnodash')\n \n \n class DataprocClusterDeleteOperatorTest(unittest.TestCase):\n     # Unit test for the DataprocClusterDeleteOperator\n     def setUp(self):\n         self.mock_execute = Mock()\n-        self.mock_execute.execute = Mock(return_value={'done' : True})\n+        self.mock_execute.execute = Mock(return_value={'done': True})\n         self.mock_get = Mock()\n         self.mock_get.get = Mock(return_value=self.mock_execute)\n         self.mock_operations = Mock()\n         self.mock_operations.get = Mock(return_value=self.mock_get)\n         self.mock_regions = Mock()\n         self.mock_regions.operations = Mock(return_value=self.mock_operations)\n-        self.mock_projects=Mock()\n+        self.mock_projects = Mock()\n         self.mock_projects.regions = Mock(return_value=self.mock_regions)\n         self.mock_conn = Mock()\n         self.mock_conn.projects = Mock(return_value=self.mock_projects)\ndiff --git a/tests/contrib/operators/test_ecs_operator.py b/tests/contrib/operators/test_ecs_operator.py\nindex 3b0f03351d..5f8c220260 100644\n--- a/tests/contrib/operators/test_ecs_operator.py\n+++ b/tests/contrib/operators/test_ecs_operator.py\n@@ -34,14 +34,14 @@\n     except ImportError:\n         mock = None\n \n-\n RESPONSE_WITHOUT_FAILURES = {\n     \"failures\": [],\n     \"tasks\": [\n         {\n             \"containers\": [\n                 {\n-                    \"containerArn\": \"arn:aws:ecs:us-east-1:012345678910:container/e1ed7aac-d9b2-4315-8726-d2432bf11868\",\n+                    \"containerArn\":\n+                        \"arn:aws:ecs:us-east-1:012345678910:container/e1ed7aac-d9b2-4315-8726-d2432bf11868\",\n                     \"lastStatus\": \"PENDING\",\n                     \"name\": \"wordpress\",\n                     \"taskArn\": \"arn:aws:ecs:us-east-1:012345678910:task/d8c67b3c-ac87-4ffe-a847-4785bc3a8b55\"\n@@ -85,7 +85,6 @@ def setUp(self, aws_hook_mock):\n         )\n \n     def test_init(self):\n-\n         self.assertEqual(self.ecs.region_name, 'eu-west-1')\n         self.assertEqual(self.ecs.task_definition, 't')\n         self.assertEqual(self.ecs.aws_conn_id, None)\n@@ -101,13 +100,13 @@ def test_template_fields_overrides(self):\n     @mock.patch.object(ECSOperator, '_wait_for_task_ended')\n     @mock.patch.object(ECSOperator, '_check_success_task')\n     def test_execute_without_failures(self, check_mock, wait_mock):\n-\n         client_mock = self.aws_hook_mock.return_value.get_client_type.return_value\n         client_mock.run_task.return_value = RESPONSE_WITHOUT_FAILURES\n \n         self.ecs.execute(None)\n \n-        self.aws_hook_mock.return_value.get_client_type.assert_called_once_with('ecs', region_name='eu-west-1')\n+        self.aws_hook_mock.return_value.get_client_type.assert_called_once_with('ecs',\n+                                                                                region_name='eu-west-1')\n         client_mock.run_task.assert_called_once_with(\n             cluster='c',\n             launchType='EC2',\n@@ -131,10 +130,10 @@ def test_execute_without_failures(self, check_mock, wait_mock):\n \n         wait_mock.assert_called_once_with()\n         check_mock.assert_called_once_with()\n-        self.assertEqual(self.ecs.arn, 'arn:aws:ecs:us-east-1:012345678910:task/d8c67b3c-ac87-4ffe-a847-4785bc3a8b55')\n+        self.assertEqual(self.ecs.arn,\n+                         'arn:aws:ecs:us-east-1:012345678910:task/d8c67b3c-ac87-4ffe-a847-4785bc3a8b55')\n \n     def test_execute_with_failures(self):\n-\n         client_mock = self.aws_hook_mock.return_value.get_client_type.return_value\n         resp_failures = deepcopy(RESPONSE_WITHOUT_FAILURES)\n         resp_failures['failures'].append('dummy error')\n@@ -143,7 +142,8 @@ def test_execute_with_failures(self):\n         with self.assertRaises(AirflowException):\n             self.ecs.execute(None)\n \n-        self.aws_hook_mock.return_value.get_client_type.assert_called_once_with('ecs', region_name='eu-west-1')\n+        self.aws_hook_mock.return_value.get_client_type.assert_called_once_with('ecs',\n+                                                                                region_name='eu-west-1')\n         client_mock.run_task.assert_called_once_with(\n             cluster='c',\n             launchType='EC2',\n@@ -166,7 +166,6 @@ def test_execute_with_failures(self):\n         )\n \n     def test_wait_end_tasks(self):\n-\n         client_mock = mock.Mock()\n         self.ecs.arn = 'arn'\n         self.ecs.client = client_mock\ndiff --git a/tests/contrib/operators/test_emr_terminate_job_flow_operator.py b/tests/contrib/operators/test_emr_terminate_job_flow_operator.py\nindex a4d43407c7..d25b02adb5 100644\n--- a/tests/contrib/operators/test_emr_terminate_job_flow_operator.py\n+++ b/tests/contrib/operators/test_emr_terminate_job_flow_operator.py\n@@ -44,10 +44,8 @@ def setUp(self):\n         # Mock out the emr_client creator\n         self.boto3_session_mock = MagicMock(return_value=mock_emr_session)\n \n-\n     def test_execute_terminates_the_job_flow_and_does_not_error(self):\n         with patch('boto3.session.Session', self.boto3_session_mock):\n-\n             operator = EmrTerminateJobFlowOperator(\n                 task_id='test_task',\n                 job_flow_id='j-8989898989',\n@@ -56,5 +54,6 @@ def test_execute_terminates_the_job_flow_and_does_not_error(self):\n \n             operator.execute(None)\n \n+\n if __name__ == '__main__':\n     unittest.main()\ndiff --git a/tests/contrib/operators/test_hipchat_operator.py b/tests/contrib/operators/test_hipchat_operator.py\nindex 71c93c9259..dbfb227d1d 100644\n--- a/tests/contrib/operators/test_hipchat_operator.py\n+++ b/tests/contrib/operators/test_hipchat_operator.py\n@@ -47,7 +47,7 @@ def test_execute(self, request_mock):\n \n         operator = HipChatAPISendRoomNotificationOperator(\n             task_id='test_hipchat_success',\n-            owner = 'airflow',\n+            owner='airflow',\n             token='abc123',\n             room_id='room_id',\n             message='hello world!'\ndiff --git a/tests/contrib/operators/test_hive_to_dynamodb_operator.py b/tests/contrib/operators/test_hive_to_dynamodb_operator.py\nindex 9ef3809593..ab86e05517 100644\n--- a/tests/contrib/operators/test_hive_to_dynamodb_operator.py\n+++ b/tests/contrib/operators/test_hive_to_dynamodb_operator.py\n@@ -20,17 +20,18 @@\n \n import json\n import unittest\n+import datetime\n \n import mock\n import pandas as pd\n \n from airflow import configuration, DAG\n-\n-configuration.load_test_config()\n-import datetime\n from airflow.contrib.hooks.aws_dynamodb_hook import AwsDynamoDBHook\n+\n import airflow.contrib.operators.hive_to_dynamodb\n \n+configuration.load_test_config()\n+\n DEFAULT_DATE = datetime.datetime(2015, 1, 1)\n DEFAULT_DATE_ISO = DEFAULT_DATE.isoformat()\n DEFAULT_DATE_DS = DEFAULT_DATE_ISO[:10]\n@@ -67,9 +68,8 @@ def test_get_conn_returns_a_boto3_connection(self):\n     @unittest.skipIf(mock_dynamodb2 is None, 'mock_dynamodb2 package not present')\n     @mock_dynamodb2\n     def test_get_records_with_schema(self, get_results_mock):\n-\n         # this table needs to be created in production\n-        table = self.hook.get_conn().create_table(\n+        self.hook.get_conn().create_table(\n             TableName='test_airflow',\n             KeySchema=[\n                 {\n@@ -108,9 +108,8 @@ def test_get_records_with_schema(self, get_results_mock):\n     @unittest.skipIf(mock_dynamodb2 is None, 'mock_dynamodb2 package not present')\n     @mock_dynamodb2\n     def test_pre_process_records_with_schema(self, get_results_mock):\n-\n-         # this table needs to be created in production\n-        table = self.hook.get_conn().create_table(\n+        # this table needs to be created in production\n+        self.hook.get_conn().create_table(\n             TableName='test_airflow',\n             KeySchema=[\n                 {\n@@ -141,8 +140,7 @@ def test_pre_process_records_with_schema(self, get_results_mock):\n         operator.execute(None)\n \n         table = self.hook.get_conn().Table('test_airflow')\n-        table.meta.client.get_waiter(\n-            'table_exists').wait(TableName='test_airflow')\n+        table.meta.client.get_waiter('table_exists').wait(TableName='test_airflow')\n         self.assertEqual(table.item_count, 1)\n \n \ndiff --git a/tests/contrib/operators/test_jira_operator_test.py b/tests/contrib/operators/test_jira_operator_test.py\nindex a358d3019f..2509038a36 100644\n--- a/tests/contrib/operators/test_jira_operator_test.py\n+++ b/tests/contrib/operators/test_jira_operator_test.py\n@@ -31,7 +31,7 @@\n \n DEFAULT_DATE = timezone.datetime(2017, 1, 1)\n jira_client_mock = Mock(\n-        name=\"jira_client_for_test\"\n+    name=\"jira_client_for_test\"\n )\n \n minimal_test_ticket = {\n@@ -54,14 +54,14 @@ def setUp(self):\n         args = {\n             'owner': 'airflow',\n             'start_date': DEFAULT_DATE\n-            }\n+        }\n         dag = DAG('test_dag_id', default_args=args)\n         self.dag = dag\n         db.merge_conn(\n-                models.Connection(\n-                        conn_id='jira_default', conn_type='jira',\n-                        host='https://localhost/jira/', port=443,\n-                        extra='{\"verify\": \"False\", \"project\": \"AIRFLOW\"}'))\n+            models.Connection(\n+                conn_id='jira_default', conn_type='jira',\n+                host='https://localhost/jira/', port=443,\n+                extra='{\"verify\": \"False\", \"project\": \"AIRFLOW\"}'))\n \n     @patch(\"airflow.contrib.hooks.jira_hook.JIRA\",\n            autospec=True, return_value=jira_client_mock)\ndiff --git a/tests/contrib/operators/test_mlengine_operator_utils.py b/tests/contrib/operators/test_mlengine_operator_utils.py\nindex 09f0071e21..a072265041 100644\n--- a/tests/contrib/operators/test_mlengine_operator_utils.py\n+++ b/tests/contrib/operators/test_mlengine_operator_utils.py\n@@ -36,7 +36,6 @@\n \n \n class CreateEvaluateOpsTest(unittest.TestCase):\n-\n     INPUT_MISSING_ORIGIN = {\n         'dataFormat': 'TEXT',\n         'inputPaths': ['gs://legal-bucket/fake-input-path/*'],\n@@ -89,7 +88,6 @@ def testSuccessfulRun(self):\n \n         with patch('airflow.contrib.operators.mlengine_operator.'\n                    'MLEngineHook') as mock_mlengine_hook:\n-\n             success_message = self.SUCCESS_MESSAGE_MISSING_INPUT.copy()\n             success_message['predictionInput'] = input_with_model\n             hook_instance = mock_mlengine_hook.return_value\n@@ -107,7 +105,6 @@ def testSuccessfulRun(self):\n \n         with patch('airflow.contrib.operators.dataflow_operator.'\n                    'DataFlowHook') as mock_dataflow_hook:\n-\n             hook_instance = mock_dataflow_hook.return_value\n             hook_instance.start_python_dataflow.return_value = None\n             summary.execute(None)\n@@ -126,7 +123,6 @@ def testSuccessfulRun(self):\n \n         with patch('airflow.contrib.operators.mlengine_operator_utils.'\n                    'GoogleCloudStorageHook') as mock_gcs_hook:\n-\n             hook_instance = mock_gcs_hook.return_value\n             hook_instance.download.return_value = '{\"err\": 0.9, \"count\": 9}'\n             result = validate.execute({})\n@@ -159,27 +155,25 @@ def testFailures(self):\n         }\n \n         with self.assertRaisesRegexp(AirflowException, 'Missing model origin'):\n-            _ = create_evaluate_ops(**other_params_but_models)\n+            create_evaluate_ops(**other_params_but_models)\n \n         with self.assertRaisesRegexp(AirflowException, 'Ambiguous model origin'):\n-            _ = create_evaluate_ops(model_uri='abc', model_name='cde',\n-                                    **other_params_but_models)\n+            create_evaluate_ops(model_uri='abc', model_name='cde', **other_params_but_models)\n \n         with self.assertRaisesRegexp(AirflowException, 'Ambiguous model origin'):\n-            _ = create_evaluate_ops(model_uri='abc', version_name='vvv',\n-                                    **other_params_but_models)\n+            create_evaluate_ops(model_uri='abc', version_name='vvv', **other_params_but_models)\n \n         with self.assertRaisesRegexp(AirflowException,\n                                      '`metric_fn` param must be callable'):\n             params = other_params_but_models.copy()\n             params['metric_fn_and_keys'] = (None, ['abc'])\n-            _ = create_evaluate_ops(model_uri='gs://blah', **params)\n+            create_evaluate_ops(model_uri='gs://blah', **params)\n \n         with self.assertRaisesRegexp(AirflowException,\n                                      '`validate_fn` param must be callable'):\n             params = other_params_but_models.copy()\n             params['validate_fn'] = None\n-            _ = create_evaluate_ops(model_uri='gs://blah', **params)\n+            create_evaluate_ops(model_uri='gs://blah', **params)\n \n \n if __name__ == '__main__':\ndiff --git a/tests/contrib/operators/test_qubole_operator.py b/tests/contrib/operators/test_qubole_operator.py\nindex bf61262bb3..c0894c0ba7 100644\n--- a/tests/contrib/operators/test_qubole_operator.py\n+++ b/tests/contrib/operators/test_qubole_operator.py\n@@ -35,9 +35,9 @@\n     except ImportError:\n         mock = None\n \n-DAG_ID=\"qubole_test_dag\"\n-TASK_ID=\"test_task\"\n-DEFAULT_CONN=\"qubole_default\"\n+DAG_ID = \"qubole_test_dag\"\n+TASK_ID = \"test_task\"\n+DEFAULT_CONN = \"qubole_default\"\n TEMPLATE_CONN = \"my_conn_id\"\n DEFAULT_DATE = datetime(2017, 1, 1)\n \n@@ -60,7 +60,7 @@ def test_init_with_template_connection(self):\n                                   qubole_conn_id=\"{{ dag_run.conf['qubole_conn_id'] }}\")\n \n         result = task.render_template('qubole_conn_id', \"{{ qubole_conn_id }}\",\n-                                      {'qubole_conn_id' : TEMPLATE_CONN})\n+                                      {'qubole_conn_id': TEMPLATE_CONN})\n         self.assertEqual(task.task_id, TASK_ID)\n         self.assertEqual(result, TEMPLATE_CONN)\n \n@@ -93,26 +93,22 @@ def test_hyphen_args_note_id(self):\n         dag = DAG(DAG_ID, start_date=DEFAULT_DATE)\n \n         with dag:\n-            task = QuboleOperator(task_id=TASK_ID, command_type='sparkcmd',\n-                                  note_id=\"123\", dag=dag)\n-        self.assertEqual(task.get_hook().create_cmd_args({'run_id':'dummy'})[0],\n-                         \"--note-id=123\")\n+            task = QuboleOperator(task_id=TASK_ID, command_type='sparkcmd', note_id=\"123\", dag=dag)\n+\n+        self.assertEqual(task.get_hook().create_cmd_args({'run_id': 'dummy'})[0], \"--note-id=123\")\n \n     def test_position_args_parameters(self):\n         dag = DAG(DAG_ID, start_date=DEFAULT_DATE)\n \n         with dag:\n             task = QuboleOperator(task_id=TASK_ID, command_type='pigcmd',\n-                          parameters=\"key1=value1 key2=value2\", dag=dag)\n+                                  parameters=\"key1=value1 key2=value2\", dag=dag)\n \n-        self.assertEqual(task.get_hook().create_cmd_args({'run_id':'dummy'})[1],\n-                         \"key1=value1\")\n-        self.assertEqual(task.get_hook().create_cmd_args({'run_id':'dummy'})[2],\n-                         \"key2=value2\")\n+        self.assertEqual(task.get_hook().create_cmd_args({'run_id': 'dummy'})[1], \"key1=value1\")\n+        self.assertEqual(task.get_hook().create_cmd_args({'run_id': 'dummy'})[2], \"key2=value2\")\n \n-        task = QuboleOperator(task_id=TASK_ID, command_type='hadoopcmd',\n-                          sub_command=\"s3distcp --src s3n://airflow/source_hadoopcmd \" +\n-                                      \"--dest s3n://airflow/destination_hadoopcmd\", dag=dag)\n+        cmd = \"s3distcp --src s3n://airflow/source_hadoopcmd --dest s3n://airflow/destination_hadoopcmd\"\n+        task = QuboleOperator(task_id=TASK_ID, command_type='hadoopcmd', dag=dag, sub_command=cmd)\n \n         self.assertEqual(task.get_hook().create_cmd_args({'run_id': 'dummy'})[1],\n                          \"s3distcp\")\n@@ -124,5 +120,3 @@ def test_position_args_parameters(self):\n                          \"--dest\")\n         self.assertEqual(task.get_hook().create_cmd_args({'run_id': 'dummy'})[5],\n                          \"s3n://airflow/destination_hadoopcmd\")\n-\n-\ndiff --git a/tests/contrib/operators/test_sftp_operator.py b/tests/contrib/operators/test_sftp_operator.py\nindex bf4525e311..7a450c0844 100644\n--- a/tests/contrib/operators/test_sftp_operator.py\n+++ b/tests/contrib/operators/test_sftp_operator.py\n@@ -42,6 +42,7 @@ def reset(dag_id=TEST_DAG_ID):\n     session.commit()\n     session.close()\n \n+\n reset()\n \n \n@@ -79,12 +80,12 @@ def test_pickle_file_transfer_put(self):\n \n         # put test file to remote\n         put_test_task = SFTPOperator(\n-                task_id=\"test_sftp\",\n-                ssh_hook=self.hook,\n-                local_filepath=self.test_local_filepath,\n-                remote_filepath=self.test_remote_filepath,\n-                operation=SFTPOperation.PUT,\n-                dag=self.dag\n+            task_id=\"test_sftp\",\n+            ssh_hook=self.hook,\n+            local_filepath=self.test_local_filepath,\n+            remote_filepath=self.test_remote_filepath,\n+            operation=SFTPOperation.PUT,\n+            dag=self.dag\n         )\n         self.assertIsNotNone(put_test_task)\n         ti2 = TaskInstance(task=put_test_task, execution_date=timezone.utcnow())\n@@ -92,18 +93,18 @@ def test_pickle_file_transfer_put(self):\n \n         # check the remote file content\n         check_file_task = SSHOperator(\n-                task_id=\"test_check_file\",\n-                ssh_hook=self.hook,\n-                command=\"cat {0}\".format(self.test_remote_filepath),\n-                do_xcom_push=True,\n-                dag=self.dag\n+            task_id=\"test_check_file\",\n+            ssh_hook=self.hook,\n+            command=\"cat {0}\".format(self.test_remote_filepath),\n+            do_xcom_push=True,\n+            dag=self.dag\n         )\n         self.assertIsNotNone(check_file_task)\n         ti3 = TaskInstance(task=check_file_task, execution_date=timezone.utcnow())\n         ti3.run()\n         self.assertEqual(\n-                ti3.xcom_pull(task_ids='test_check_file', key='return_value').strip(),\n-                test_local_file_content)\n+            ti3.xcom_pull(task_ids='test_check_file', key='return_value').strip(),\n+            test_local_file_content)\n \n     def test_json_file_transfer_put(self):\n         configuration.conf.set(\"core\", \"enable_xcom_pickling\", \"False\")\n@@ -116,12 +117,12 @@ def test_json_file_transfer_put(self):\n \n         # put test file to remote\n         put_test_task = SFTPOperator(\n-                task_id=\"test_sftp\",\n-                ssh_hook=self.hook,\n-                local_filepath=self.test_local_filepath,\n-                remote_filepath=self.test_remote_filepath,\n-                operation=SFTPOperation.PUT,\n-                dag=self.dag\n+            task_id=\"test_sftp\",\n+            ssh_hook=self.hook,\n+            local_filepath=self.test_local_filepath,\n+            remote_filepath=self.test_remote_filepath,\n+            operation=SFTPOperation.PUT,\n+            dag=self.dag\n         )\n         self.assertIsNotNone(put_test_task)\n         ti2 = TaskInstance(task=put_test_task, execution_date=timezone.utcnow())\n@@ -129,19 +130,18 @@ def test_json_file_transfer_put(self):\n \n         # check the remote file content\n         check_file_task = SSHOperator(\n-                task_id=\"test_check_file\",\n-                ssh_hook=self.hook,\n-                command=\"cat {0}\".format(self.test_remote_filepath),\n-                do_xcom_push=True,\n-                dag=self.dag\n+            task_id=\"test_check_file\",\n+            ssh_hook=self.hook,\n+            command=\"cat {0}\".format(self.test_remote_filepath),\n+            do_xcom_push=True,\n+            dag=self.dag\n         )\n         self.assertIsNotNone(check_file_task)\n         ti3 = TaskInstance(task=check_file_task, execution_date=timezone.utcnow())\n         ti3.run()\n         self.assertEqual(\n-                ti3.xcom_pull(task_ids='test_check_file', key='return_value').strip(),\n-                b64encode(test_local_file_content).decode('utf-8'))\n-\n+            ti3.xcom_pull(task_ids='test_check_file', key='return_value').strip(),\n+            b64encode(test_local_file_content).decode('utf-8'))\n \n     def test_pickle_file_transfer_get(self):\n         configuration.conf.set(\"core\", \"enable_xcom_pickling\", \"True\")\n@@ -151,12 +151,12 @@ def test_pickle_file_transfer_get(self):\n \n         # create a test file remotely\n         create_file_task = SSHOperator(\n-                task_id=\"test_create_file\",\n-                ssh_hook=self.hook,\n-                command=\"echo '{0}' > {1}\".format(test_remote_file_content,\n-                                                  self.test_remote_filepath),\n-                do_xcom_push=True,\n-                dag=self.dag\n+            task_id=\"test_create_file\",\n+            ssh_hook=self.hook,\n+            command=\"echo '{0}' > {1}\".format(test_remote_file_content,\n+                                              self.test_remote_filepath),\n+            do_xcom_push=True,\n+            dag=self.dag\n         )\n         self.assertIsNotNone(create_file_task)\n         ti1 = TaskInstance(task=create_file_task, execution_date=timezone.utcnow())\n@@ -164,12 +164,12 @@ def test_pickle_file_transfer_get(self):\n \n         # get remote file to local\n         get_test_task = SFTPOperator(\n-                task_id=\"test_sftp\",\n-                ssh_hook=self.hook,\n-                local_filepath=self.test_local_filepath,\n-                remote_filepath=self.test_remote_filepath,\n-                operation=SFTPOperation.GET,\n-                dag=self.dag\n+            task_id=\"test_sftp\",\n+            ssh_hook=self.hook,\n+            local_filepath=self.test_local_filepath,\n+            remote_filepath=self.test_remote_filepath,\n+            operation=SFTPOperation.GET,\n+            dag=self.dag\n         )\n         self.assertIsNotNone(get_test_task)\n         ti2 = TaskInstance(task=get_test_task, execution_date=timezone.utcnow())\n@@ -189,12 +189,12 @@ def test_json_file_transfer_get(self):\n \n         # create a test file remotely\n         create_file_task = SSHOperator(\n-                task_id=\"test_create_file\",\n-                ssh_hook=self.hook,\n-                command=\"echo '{0}' > {1}\".format(test_remote_file_content,\n-                                                  self.test_remote_filepath),\n-                do_xcom_push=True,\n-                dag=self.dag\n+            task_id=\"test_create_file\",\n+            ssh_hook=self.hook,\n+            command=\"echo '{0}' > {1}\".format(test_remote_file_content,\n+                                              self.test_remote_filepath),\n+            do_xcom_push=True,\n+            dag=self.dag\n         )\n         self.assertIsNotNone(create_file_task)\n         ti1 = TaskInstance(task=create_file_task, execution_date=timezone.utcnow())\n@@ -202,12 +202,12 @@ def test_json_file_transfer_get(self):\n \n         # get remote file to local\n         get_test_task = SFTPOperator(\n-                task_id=\"test_sftp\",\n-                ssh_hook=self.hook,\n-                local_filepath=self.test_local_filepath,\n-                remote_filepath=self.test_remote_filepath,\n-                operation=SFTPOperation.GET,\n-                dag=self.dag\n+            task_id=\"test_sftp\",\n+            ssh_hook=self.hook,\n+            local_filepath=self.test_local_filepath,\n+            remote_filepath=self.test_remote_filepath,\n+            operation=SFTPOperation.GET,\n+            dag=self.dag\n         )\n         self.assertIsNotNone(get_test_task)\n         ti2 = TaskInstance(task=get_test_task, execution_date=timezone.utcnow())\n@@ -218,7 +218,7 @@ def test_json_file_transfer_get(self):\n         with open(self.test_local_filepath, 'r') as f:\n             content_received = f.read()\n         self.assertEqual(content_received.strip(),\n-            test_remote_file_content.encode('utf-8').decode('utf-8'))\n+                         test_remote_file_content.encode('utf-8').decode('utf-8'))\n \n     def test_arg_checking(self):\n         from airflow.exceptions import AirflowException\ndiff --git a/tests/contrib/operators/test_spark_sql_operator.py b/tests/contrib/operators/test_spark_sql_operator.py\nindex b0c956931f..bbe6868dc7 100644\n--- a/tests/contrib/operators/test_spark_sql_operator.py\n+++ b/tests/contrib/operators/test_spark_sql_operator.py\n@@ -28,7 +28,6 @@\n \n \n class TestSparkSqlOperator(unittest.TestCase):\n-\n     _config = {\n         'sql': 'SELECT 22',\n         'conn_id': 'spark_special_conn_id',\n@@ -74,5 +73,6 @@ def test_execute(self):\n         self.assertEqual(self._config['num_executors'], operator._num_executors)\n         self.assertEqual(self._config['yarn_queue'], operator._yarn_queue)\n \n+\n if __name__ == '__main__':\n     unittest.main()\ndiff --git a/tests/contrib/operators/test_sqoop_operator.py b/tests/contrib/operators/test_sqoop_operator.py\nindex 5a235c487f..e3cf32fdae 100644\n--- a/tests/contrib/operators/test_sqoop_operator.py\n+++ b/tests/contrib/operators/test_sqoop_operator.py\n@@ -111,7 +111,7 @@ def test_execute(self):\n         self.assertEqual(self._config['extra_export_options'], operator.extra_export_options)\n \n         # the following are meant to be more of examples\n-        sqoop_import_op = SqoopOperator(\n+        SqoopOperator(\n             task_id='sqoop_import_using_table',\n             cmd_type='import',\n             conn_id='sqoop_default',\n@@ -125,12 +125,13 @@ def test_execute(self):\n             dag=self.dag\n         )\n \n-        sqoop_import_op_qry = SqoopOperator(\n+        SqoopOperator(\n             task_id='sqoop_import_using_query',\n             cmd_type='import',\n             conn_id='sqoop_default',\n             query='select name, age from company where $CONDITIONS',\n-            split_by='age', # the mappers will pass in values to the $CONDITIONS based on the field you select to split by\n+            split_by='age',\n+            # the mappers will pass in values to the $CONDITIONS based on the field you select to split by\n             verbose=True,\n             num_mappers=None,\n             hcatalog_database='default',\n@@ -140,7 +141,7 @@ def test_execute(self):\n             dag=self.dag\n         )\n \n-        sqoop_import_op_with_partition = SqoopOperator(\n+        SqoopOperator(\n             task_id='sqoop_import_with_partition',\n             cmd_type='import',\n             conn_id='sqoop_default',\n@@ -157,7 +158,7 @@ def test_execute(self):\n             dag=self.dag\n         )\n \n-        sqoop_export_op_name = SqoopOperator(\n+        SqoopOperator(\n             task_id='sqoop_export_tablename',\n             cmd_type='export',\n             conn_id='sqoop_default',\n@@ -170,7 +171,7 @@ def test_execute(self):\n             dag=self.dag\n         )\n \n-        sqoop_export_op_path = SqoopOperator(\n+        SqoopOperator(\n             task_id='sqoop_export_tablepath',\n             cmd_type='export',\n             conn_id='sqoop_default',\ndiff --git a/tests/contrib/operators/test_ssh_operator.py b/tests/contrib/operators/test_ssh_operator.py\nindex 1a2c788596..00c4be679b 100644\n--- a/tests/contrib/operators/test_ssh_operator.py\n+++ b/tests/contrib/operators/test_ssh_operator.py\n@@ -40,6 +40,7 @@ def reset(dag_id=TEST_DAG_ID):\n     session.commit()\n     session.close()\n \n+\n reset()\n \n \n@@ -79,17 +80,17 @@ def test_hook_created_correctly(self):\n     def test_json_command_execution(self):\n         configuration.conf.set(\"core\", \"enable_xcom_pickling\", \"False\")\n         task = SSHOperator(\n-                task_id=\"test\",\n-                ssh_hook=self.hook,\n-                command=\"echo -n airflow\",\n-                do_xcom_push=True,\n-                dag=self.dag,\n+            task_id=\"test\",\n+            ssh_hook=self.hook,\n+            command=\"echo -n airflow\",\n+            do_xcom_push=True,\n+            dag=self.dag,\n         )\n \n         self.assertIsNotNone(task)\n \n         ti = TaskInstance(\n-                task=task, execution_date=timezone.utcnow())\n+            task=task, execution_date=timezone.utcnow())\n         ti.run()\n         self.assertIsNotNone(ti.duration)\n         self.assertEqual(ti.xcom_pull(task_ids='test', key='return_value'),\n@@ -98,17 +99,17 @@ def test_json_command_execution(self):\n     def test_pickle_command_execution(self):\n         configuration.conf.set(\"core\", \"enable_xcom_pickling\", \"True\")\n         task = SSHOperator(\n-                task_id=\"test\",\n-                ssh_hook=self.hook,\n-                command=\"echo -n airflow\",\n-                do_xcom_push=True,\n-                dag=self.dag,\n+            task_id=\"test\",\n+            ssh_hook=self.hook,\n+            command=\"echo -n airflow\",\n+            do_xcom_push=True,\n+            dag=self.dag,\n         )\n \n         self.assertIsNotNone(task)\n \n         ti = TaskInstance(\n-                task=task, execution_date=timezone.utcnow())\n+            task=task, execution_date=timezone.utcnow())\n         ti.run()\n         self.assertIsNotNone(ti.duration)\n         self.assertEqual(ti.xcom_pull(task_ids='test', key='return_value'), b'airflow')\ndiff --git a/tests/contrib/operators/test_vertica_to_mysql.py b/tests/contrib/operators/test_vertica_to_mysql.py\nindex 615f111f84..c76c4d5dcc 100644\n--- a/tests/contrib/operators/test_vertica_to_mysql.py\n+++ b/tests/contrib/operators/test_vertica_to_mysql.py\n@@ -30,14 +30,14 @@ def mock_get_conn():\n     commit_mock = mock.MagicMock(\n     )\n     cursor_mock = mock.MagicMock(\n-        execute     = [],\n-        fetchall    = [['1', '2', '3']],\n-        description =  ['a', 'b', 'c'],\n-        iterate     = [['1', '2', '3']],\n+        execute=[],\n+        fetchall=[['1', '2', '3']],\n+        description=['a', 'b', 'c'],\n+        iterate=[['1', '2', '3']],\n     )\n     conn_mock = mock.MagicMock(\n-        commit      = commit_mock,\n-        cursor      = cursor_mock,\n+        commit=commit_mock,\n+        cursor=cursor_mock,\n     )\n     return conn_mock\n \ndiff --git a/tests/contrib/sensors/test_emr_job_flow_sensor.py b/tests/contrib/sensors/test_emr_job_flow_sensor.py\nindex 606cd84c32..5b33cb5bb4 100644\n--- a/tests/contrib/sensors/test_emr_job_flow_sensor.py\n+++ b/tests/contrib/sensors/test_emr_job_flow_sensor.py\n@@ -42,7 +42,8 @@\n         'Status': {\n             'State': 'STARTING',\n             'StateChangeReason': {},\n-            'Timeline': {'CreationDateTime': datetime.datetime(2016, 6, 27, 21, 5, 2, 348000, tzinfo=tzlocal())}\n+            'Timeline': {\n+                'CreationDateTime': datetime.datetime(2016, 6, 27, 21, 5, 2, 348000, tzinfo=tzlocal())}\n         },\n         'Tags': [\n             {'Key': 'app', 'Value': 'analytics'},\n@@ -74,7 +75,8 @@\n         'Status': {\n             'State': 'TERMINATED',\n             'StateChangeReason': {},\n-            'Timeline': {'CreationDateTime': datetime.datetime(2016, 6, 27, 21, 5, 2, 348000, tzinfo=tzlocal())}\n+            'Timeline': {\n+                'CreationDateTime': datetime.datetime(2016, 6, 27, 21, 5, 2, 348000, tzinfo=tzlocal())}\n         },\n         'Tags': [\n             {'Key': 'app', 'Value': 'analytics'},\n@@ -107,10 +109,8 @@ def setUp(self):\n         # Mock out the emr_client creator\n         self.boto3_session_mock = MagicMock(return_value=mock_emr_session)\n \n-\n     def test_execute_calls_with_the_job_flow_id_until_it_reaches_a_terminal_state(self):\n         with patch('boto3.session.Session', self.boto3_session_mock):\n-\n             operator = EmrJobFlowSensor(\n                 task_id='test_task',\n                 poke_interval=2,\ndiff --git a/tests/contrib/sensors/test_jira_sensor_test.py b/tests/contrib/sensors/test_jira_sensor_test.py\nindex 561b4babd1..32aa235851 100644\n--- a/tests/contrib/sensors/test_jira_sensor_test.py\n+++ b/tests/contrib/sensors/test_jira_sensor_test.py\n@@ -67,13 +67,13 @@ def setUp(self):\n     def test_issue_label_set(self, jira_mock):\n         jira_mock.return_value.issue.return_value = minimal_test_ticket\n \n-        ticket_label_sensor = JiraTicketSensor(task_id='search-ticket-test',\n-                                               ticket_id='TEST-1226',\n-                                               field_checker_func=\n-                                               TestJiraSensor.field_checker_func,\n-                                               timeout=518400,\n-                                               poke_interval=10,\n-                                               dag=self.dag)\n+        ticket_label_sensor = JiraTicketSensor(\n+            task_id='search-ticket-test',\n+            ticket_id='TEST-1226',\n+            field_checker_func=TestJiraSensor.field_checker_func,\n+            timeout=518400,\n+            poke_interval=10,\n+            dag=self.dag)\n \n         ticket_label_sensor.run(start_date=DEFAULT_DATE,\n                                 end_date=DEFAULT_DATE, ignore_ti_state=True)\ndiff --git a/tests/contrib/utils/__init__.py b/tests/contrib/utils/__init__.py\nindex 331c28ef9a..b7f8352944 100644\n--- a/tests/contrib/utils/__init__.py\n+++ b/tests/contrib/utils/__init__.py\n@@ -17,4 +17,3 @@\n # specific language governing permissions and limitations\n # under the License.\n #\n-\ndiff --git a/tests/core.py b/tests/core.py\nindex 918e9b4d49..91e2b069f5 100644\n--- a/tests/core.py\n+++ b/tests/core.py\n@@ -917,11 +917,11 @@ def test_task_fail_duration(self):\n         session = settings.Session()\n         try:\n             p.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE, ignore_ti_state=True)\n-        except:\n+        except Exception:\n             pass\n         try:\n             f.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE, ignore_ti_state=True)\n-        except:\n+        except Exception:\n             pass\n         p_fails = session.query(models.TaskFail).filter_by(\n             task_id='pass_sleepy',\n@@ -931,10 +931,9 @@ def test_task_fail_duration(self):\n             task_id='fail_sleepy',\n             dag_id=self.dag.dag_id,\n             execution_date=DEFAULT_DATE).all()\n-        print(f_fails)\n+\n         self.assertEqual(0, len(p_fails))\n         self.assertEqual(1, len(f_fails))\n-        # C\n         self.assertGreaterEqual(sum([f.duration for f in f_fails]), 3)\n \n     def test_dag_stats(self):\n@@ -1624,7 +1623,7 @@ def _wait_pidfile(self, pidfile):\n             try:\n                 with open(pidfile) as f:\n                     return int(f.read())\n-            except:\n+            except Exception:\n                 sleep(1)\n \n     def test_cli_webserver_foreground(self):\n@@ -1734,7 +1733,7 @@ def test_csrf_acceptance(self):\n     def test_xss(self):\n         try:\n             self.app.get(\"/admin/airflow/tree?dag_id=<script>alert(123456)</script>\")\n-        except:\n+        except Exception:\n             # exception is expected here since dag doesnt exist\n             pass\n         response = self.app.get(\"/admin/log\", follow_redirects=True)\n@@ -2185,7 +2184,7 @@ def setUp(self):\n         configuration.conf.set(\"webserver\", \"auth_backend\", \"airflow.contrib.auth.backends.ldap_auth\")\n         try:\n             configuration.conf.add_section(\"ldap\")\n-        except:\n+        except Exception:\n             pass\n         configuration.conf.set(\"ldap\", \"uri\", \"ldap://openldap:389\")\n         configuration.conf.set(\"ldap\", \"user_filter\", \"objectClass=*\")\n@@ -2272,7 +2271,7 @@ def setUp(self):\n         configuration.conf.set(\"webserver\", \"auth_backend\", \"airflow.contrib.auth.backends.ldap_auth\")\n         try:\n             configuration.conf.add_section(\"ldap\")\n-        except:\n+        except Exception:\n             pass\n         configuration.conf.set(\"ldap\", \"uri\", \"ldap://openldap:389\")\n         configuration.conf.set(\"ldap\", \"user_filter\", \"objectClass=*\")\n@@ -2611,6 +2610,7 @@ def test_get_ha_client(self, mock_get_connections):\n         client = HDFSHook().get_conn()\n         self.assertIsInstance(client, snakebite.client.HAClient)\n \n+\n send_email_test = mock.Mock()\n \n \ndiff --git a/tests/dags/test_cli_triggered_dags.py b/tests/dags/test_cli_triggered_dags.py\nindex f625e18475..9f53ca4c3a 100644\n--- a/tests/dags/test_cli_triggered_dags.py\n+++ b/tests/dags/test_cli_triggered_dags.py\n@@ -42,14 +42,15 @@ def success(ti=None, *args, **kwargs):\n \n # DAG tests that tasks ignore all dependencies\n \n-dag1 = DAG(dag_id='test_run_ignores_all_dependencies', default_args=dict(depends_on_past=True, **default_args))\n+dag1 = DAG(dag_id='test_run_ignores_all_dependencies',\n+           default_args=dict(depends_on_past=True, **default_args))\n dag1_task1 = PythonOperator(\n     task_id='test_run_dependency_task',\n     python_callable=fail,\n-    dag=dag1,)\n+    dag=dag1)\n dag1_task2 = PythonOperator(\n     task_id='test_run_dependent_task',\n     python_callable=success,\n     provide_context=True,\n-    dag=dag1,)\n+    dag=dag1)\n dag1_task1.set_downstream(dag1_task2)\ndiff --git a/tests/dags/test_example_bash_operator.py b/tests/dags/test_example_bash_operator.py\nindex f9bd6c7863..a87db8dd7c 100644\n--- a/tests/dags/test_example_bash_operator.py\n+++ b/tests/dags/test_example_bash_operator.py\n@@ -46,7 +46,7 @@\n for i in range(3):\n     i = str(i)\n     task = BashOperator(\n-        task_id='runme_'+i,\n+        task_id='runme_' + i,\n         bash_command='echo \"{{ task_instance_key_str }}\" && sleep 1',\n         dag=dag)\n     task.set_downstream(run_this)\ndiff --git a/tests/dags/test_issue_1225.py b/tests/dags/test_issue_1225.py\nindex 8009f48904..0450cf470f 100644\n--- a/tests/dags/test_issue_1225.py\n+++ b/tests/dags/test_issue_1225.py\n@@ -37,9 +37,11 @@\n     start_date=DEFAULT_DATE,\n     owner='airflow')\n \n+\n def fail():\n     raise ValueError('Expected failure.')\n \n+\n def delayed_fail():\n     \"\"\"\n     Delayed failure to make sure that processes are running before the error\n@@ -50,6 +52,7 @@ def delayed_fail():\n     time.sleep(5)\n     raise ValueError('Expected failure.')\n \n+\n # DAG tests backfill with pooled tasks\n # Previously backfill would queue the task but never run it\n dag1 = DAG(dag_id='test_backfill_pooled_task_dag', default_args=default_args)\ndiff --git a/tests/dags/test_retry_handling_job.py b/tests/dags/test_retry_handling_job.py\nindex 39c29a8d61..d8e314dbab 100644\n--- a/tests/dags/test_retry_handling_job.py\n+++ b/tests/dags/test_retry_handling_job.py\n@@ -24,7 +24,7 @@\n default_args = {\n     'owner': 'airflow',\n     'depends_on_past': False,\n-    'start_date': datetime(2016,10,5,19),\n+    'start_date': datetime(2016, 10, 5, 19),\n     'email': ['airflow@example.com'],\n     'email_on_failure': False,\n     'email_on_retry': False,\n@@ -38,4 +38,3 @@\n     task_id='test_retry_handling_op',\n     bash_command='exit 1',\n     dag=dag)\n-\ndiff --git a/tests/executors/test_base_executor.py b/tests/executors/test_base_executor.py\nindex f640a75e01..d3032cd640 100644\n--- a/tests/executors/test_base_executor.py\n+++ b/tests/executors/test_base_executor.py\n@@ -42,4 +42,3 @@ def test_get_event_buffer(self):\n         self.assertEqual(len(executor.get_event_buffer((\"my_dag1\",))), 1)\n         self.assertEqual(len(executor.get_event_buffer()), 2)\n         self.assertEqual(len(executor.event_buffer), 0)\n-\ndiff --git a/tests/executors/test_celery_executor.py b/tests/executors/test_celery_executor.py\nindex f1b6a429fa..380201d30a 100644\n--- a/tests/executors/test_celery_executor.py\n+++ b/tests/executors/test_celery_executor.py\n@@ -48,7 +48,7 @@ def test_celery_integration(self):\n             # errors are propagated for some reason\n             try:\n                 executor.execute_async(key='fail', command=fail_command)\n-            except:\n+            except Exception:\n                 pass\n             executor.running['success'] = True\n             executor.running['fail'] = True\ndiff --git a/tests/executors/test_executor.py b/tests/executors/test_executor.py\nindex 23dd8d691c..aab66644b8 100644\n--- a/tests/executors/test_executor.py\n+++ b/tests/executors/test_executor.py\n@@ -26,6 +26,7 @@ class TestExecutor(BaseExecutor):\n     \"\"\"\n     TestExecutor is used for unit testing purposes.\n     \"\"\"\n+\n     def __init__(self, do_update=False, *args, **kwargs):\n         self.do_update = do_update\n         self._running = []\n@@ -58,4 +59,3 @@ def terminate(self):\n \n     def end(self):\n         self.sync()\n-\ndiff --git a/tests/executors/test_local_executor.py b/tests/executors/test_local_executor.py\nindex 59cb09c74e..2a29ee2cd5 100644\n--- a/tests/executors/test_local_executor.py\n+++ b/tests/executors/test_local_executor.py\n@@ -44,7 +44,7 @@ def execution_parallelism(self, parallelism=0):\n         # errors are propagated for some reason\n         try:\n             executor.execute_async(key='fail', command=fail_command)\n-        except:\n+        except Exception:\n             pass\n \n         executor.running['fail'] = True\ndiff --git a/tests/hooks/__init__.py b/tests/hooks/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/hooks/__init__.py\n+++ b/tests/hooks/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/hooks/test_docker_hook.py b/tests/hooks/test_docker_hook.py\nindex b8a0132e50..dd7ed4d44d 100644\n--- a/tests/hooks/test_docker_hook.py\n+++ b/tests/hooks/test_docker_hook.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n@@ -101,7 +101,7 @@ def test_get_conn_with_standard_config(self, _):\n             )\n             client = hook.get_conn()\n             self.assertIsNotNone(client)\n-        except:\n+        except Exception:\n             self.fail('Could not get connection from Airflow')\n \n     def test_get_conn_with_extra_config(self, _):\n@@ -113,7 +113,7 @@ def test_get_conn_with_extra_config(self, _):\n             )\n             client = hook.get_conn()\n             self.assertIsNotNone(client)\n-        except:\n+        except Exception:\n             self.fail('Could not get connection from Airflow')\n \n     def test_conn_with_standard_config_passes_parameters(self, _):\n@@ -157,7 +157,7 @@ def test_conn_with_broken_config_missing_username_fails(self, _):\n             )\n         )\n         with self.assertRaises(AirflowException):\n-            hook = DockerHook(\n+            DockerHook(\n                 docker_conn_id='docker_without_username',\n                 base_url='unix://var/run/docker.sock',\n                 version='auto'\n@@ -173,7 +173,7 @@ def test_conn_with_broken_config_missing_host_fails(self, _):\n             )\n         )\n         with self.assertRaises(AirflowException):\n-            hook = DockerHook(\n+            DockerHook(\n                 docker_conn_id='docker_without_host',\n                 base_url='unix://var/run/docker.sock',\n                 version='auto'\ndiff --git a/tests/hooks/test_postgres_hook.py b/tests/hooks/test_postgres_hook.py\nindex 3e71f60f5b..f937c26782 100644\n--- a/tests/hooks/test_postgres_hook.py\n+++ b/tests/hooks/test_postgres_hook.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/hooks/test_slack_hook.py b/tests/hooks/test_slack_hook.py\nindex 46f8946411..73193dff8c 100644\n--- a/tests/hooks/test_slack_hook.py\n+++ b/tests/hooks/test_slack_hook.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/jobs.py b/tests/jobs.py\nindex 9dcd15fbe6..9b265724b6 100644\n--- a/tests/jobs.py\n+++ b/tests/jobs.py\n@@ -1294,7 +1294,7 @@ def test_process_executor_events(self):\n         dag = DAG(dag_id=dag_id, start_date=DEFAULT_DATE)\n         dag2 = DAG(dag_id=dag_id2, start_date=DEFAULT_DATE)\n         task1 = DummyOperator(dag=dag, task_id=task_id_1)\n-        task2 = DummyOperator(dag=dag2, task_id=task_id_1)\n+        DummyOperator(dag=dag2, task_id=task_id_1)\n \n         dagbag1 = self._make_simple_dag_bag([dag])\n         dagbag2 = self._make_simple_dag_bag([dag2])\n@@ -1470,7 +1470,7 @@ def test_find_executable_task_instances_pool(self):\n             TI(task2, dr1.execution_date),\n             TI(task1, dr2.execution_date),\n             TI(task2, dr2.execution_date)\n-            ])\n+        ])\n         for ti in tis:\n             ti.state = State.SCHEDULED\n             session.merge(ti)\n@@ -1849,8 +1849,12 @@ def test_execute_task_instances(self):\n         session.commit()\n \n         self.assertEqual(State.RUNNING, dr1.state)\n-        self.assertEqual(2, DAG.get_num_task_instances(dag_id, dag.task_ids,\n-            states=[State.RUNNING], session=session))\n+        self.assertEqual(\n+            2,\n+            DAG.get_num_task_instances(\n+                dag_id, dag.task_ids, states=[State.RUNNING], session=session\n+            )\n+        )\n \n         # create second dag run\n         dr2 = scheduler.create_dag_run(dag)\n@@ -1874,8 +1878,12 @@ def test_execute_task_instances(self):\n         ti2.refresh_from_db()\n         ti3.refresh_from_db()\n         ti4.refresh_from_db()\n-        self.assertEqual(3, DAG.get_num_task_instances(dag_id, dag.task_ids,\n-            states=[State.RUNNING, State.QUEUED], session=session))\n+        self.assertEqual(\n+            3,\n+            DAG.get_num_task_instances(\n+                dag_id, dag.task_ids, states=[State.RUNNING, State.QUEUED], session=session\n+            )\n+        )\n         self.assertEqual(State.RUNNING, ti1.state)\n         self.assertEqual(State.RUNNING, ti2.state)\n         six.assertCountEqual(self, [State.QUEUED, State.SCHEDULED], [ti3.state, ti4.state])\n@@ -1922,43 +1930,26 @@ def test_execute_task_instances_limit(self):\n     @unittest.skipUnless(\"INTEGRATION\" in os.environ,\n                          \"The test is flaky with nondeterministic result\")\n     def test_change_state_for_tis_without_dagrun(self):\n-        dag1 = DAG(\n-            dag_id='test_change_state_for_tis_without_dagrun',\n-            start_date=DEFAULT_DATE)\n+        dag1 = DAG(dag_id='test_change_state_for_tis_without_dagrun', start_date=DEFAULT_DATE)\n \n-        DummyOperator(\n-            task_id='dummy',\n-            dag=dag1,\n-            owner='airflow')\n-        DummyOperator(\n-            task_id='dummy_b',\n-            dag=dag1,\n-            owner='airflow')\n+        DummyOperator(task_id='dummy', dag=dag1, owner='airflow')\n \n-        dag2 = DAG(\n-            dag_id='test_change_state_for_tis_without_dagrun_dont_change',\n-            start_date=DEFAULT_DATE)\n+        DummyOperator(task_id='dummy_b', dag=dag1, owner='airflow')\n \n-        DummyOperator(\n-            task_id='dummy',\n-            dag=dag2,\n-            owner='airflow')\n+        dag2 = DAG(dag_id='test_change_state_for_tis_without_dagrun_dont_change', start_date=DEFAULT_DATE)\n \n-        dag3 = DAG(\n-            dag_id='test_change_state_for_tis_without_dagrun_no_dagrun',\n-            start_date=DEFAULT_DATE)\n+        DummyOperator(task_id='dummy', dag=dag2, owner='airflow')\n \n-        DummyOperator(\n-            task_id='dummy',\n-            dag=dag3,\n-            owner='airflow')\n+        dag3 = DAG(dag_id='test_change_state_for_tis_without_dagrun_no_dagrun', start_date=DEFAULT_DATE)\n+\n+        DummyOperator(task_id='dummy', dag=dag3, owner='airflow')\n \n         session = settings.Session()\n         dr1 = dag1.create_dagrun(run_id=DagRun.ID_PREFIX,\n-                               state=State.RUNNING,\n-                               execution_date=DEFAULT_DATE,\n-                               start_date=DEFAULT_DATE,\n-                               session=session)\n+                                 state=State.RUNNING,\n+                                 execution_date=DEFAULT_DATE,\n+                                 start_date=DEFAULT_DATE,\n+                                 session=session)\n \n         dr2 = dag2.create_dagrun(run_id=DagRun.ID_PREFIX,\n                                  state=State.RUNNING,\n@@ -2344,7 +2335,7 @@ def test_scheduler_do_not_schedule_removed_task(self):\n         dag = DAG(\n             dag_id='test_scheduler_do_not_schedule_removed_task',\n             start_date=DEFAULT_DATE)\n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2374,7 +2365,7 @@ def test_scheduler_do_not_schedule_too_early(self):\n         dag = DAG(\n             dag_id='test_scheduler_do_not_schedule_too_early',\n             start_date=timezone.datetime(2200, 1, 1))\n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2400,7 +2391,7 @@ def test_scheduler_do_not_run_finished(self):\n         dag = DAG(\n             dag_id='test_scheduler_do_not_run_finished',\n             start_date=DEFAULT_DATE)\n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2436,7 +2427,7 @@ def test_scheduler_add_new_task(self):\n             dag_id='test_scheduler_add_new_task',\n             start_date=DEFAULT_DATE)\n \n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2456,7 +2447,7 @@ def test_scheduler_add_new_task(self):\n         tis = dr.get_task_instances()\n         self.assertEquals(len(tis), 1)\n \n-        dag_task2 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy2',\n             dag=dag,\n             owner='airflow')\n@@ -2476,7 +2467,7 @@ def test_scheduler_verify_max_active_runs(self):\n             start_date=DEFAULT_DATE)\n         dag.max_active_runs = 1\n \n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2505,7 +2496,7 @@ def test_scheduler_fail_dagrun_timeout(self):\n             start_date=DEFAULT_DATE)\n         dag.dagrun_timeout = datetime.timedelta(seconds=60)\n \n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2532,8 +2523,11 @@ def test_scheduler_fail_dagrun_timeout(self):\n \n     def test_scheduler_verify_max_active_runs_and_dagrun_timeout(self):\n         \"\"\"\n-        Test if a a dagrun will not be scheduled if max_dag_runs has been reached and dagrun_timeout is not reached\n-        Test if a a dagrun will be scheduled if max_dag_runs has been reached but dagrun_timeout is also reached\n+        Test if a a dagrun will not be scheduled if max_dag_runs\n+        has been reached and dagrun_timeout is not reached\n+\n+        Test if a a dagrun will be scheduled if max_dag_runs has\n+        been reached but dagrun_timeout is also reached\n         \"\"\"\n         dag = DAG(\n             dag_id='test_scheduler_verify_max_active_runs_and_dagrun_timeout',\n@@ -2541,7 +2535,7 @@ def test_scheduler_verify_max_active_runs_and_dagrun_timeout(self):\n         dag.max_active_runs = 1\n         dag.dagrun_timeout = datetime.timedelta(seconds=60)\n \n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2677,7 +2671,7 @@ def test_scheduler_auto_align(self):\n             start_date=timezone.datetime(2016, 1, 1, 10, 10, 0),\n             schedule_interval=\"4 5 * * *\"\n         )\n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2699,7 +2693,7 @@ def test_scheduler_auto_align(self):\n             start_date=timezone.datetime(2016, 1, 1, 10, 10, 0),\n             schedule_interval=\"10 10 * * *\"\n         )\n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2730,7 +2724,7 @@ def test_scheduler_reschedule(self):\n         dag = DAG(\n             dag_id='test_scheduler_reschedule',\n             start_date=DEFAULT_DATE)\n-        dag_task1 = DummyOperator(\n+        DummyOperator(\n             task_id='dummy',\n             dag=dag,\n             owner='airflow')\n@@ -2775,7 +2769,8 @@ def test_scheduler_sla_miss_callback(self):\n         # Mock the callback function so we can verify that it was not called\n         sla_callback = MagicMock()\n \n-        # Create dag with a start of 2 days ago, but an sla of 1 day ago so we'll already have an sla_miss on the books\n+        # Create dag with a start of 2 days ago, but an sla of 1 day\n+        # ago so we'll already have an sla_miss on the books\n         test_start_date = days_ago(2)\n         dag = DAG(dag_id='test_sla_miss',\n                   sla_miss_callback=sla_callback,\n@@ -2982,8 +2977,8 @@ def test_retry_handling_job(self):\n         scheduler.run()\n \n         session = settings.Session()\n-        ti = session.query(TI).filter(TI.dag_id==dag.dag_id,\n-                                      TI.task_id==dag_task1.task_id).first()\n+        ti = session.query(TI).filter(TI.dag_id == dag.dag_id,\n+                                      TI.task_id == dag_task1.task_id).first()\n \n         # make sure the counter has increased\n         self.assertEqual(ti.try_number, 2)\n@@ -3043,7 +3038,8 @@ def test_dag_get_active_runs(self):\n         \"\"\"\n \n         now = timezone.utcnow()\n-        six_hours_ago_to_the_hour = (now - datetime.timedelta(hours=6)).replace(minute=0, second=0, microsecond=0)\n+        six_hours_ago_to_the_hour = \\\n+            (now - datetime.timedelta(hours=6)).replace(minute=0, second=0, microsecond=0)\n \n         START_DATE = six_hours_ago_to_the_hour\n         DAG_NAME1 = 'get_active_runs_test'\n@@ -3086,7 +3082,7 @@ def test_dag_get_active_runs(self):\n \n         try:\n             running_date = running_dates[0]\n-        except:\n+        except Exception as _:\n             running_date = 'Except'\n \n         self.assertEqual(execution_date, running_date, 'Running Date must match Execution Date')\n@@ -3169,7 +3165,6 @@ def setup_dag(dag_id, schedule_interval, start_date, catchup):\n         dr = scheduler.create_dag_run(dag4)\n         self.assertIsNotNone(dr)\n \n-\n     def test_add_unparseable_file_before_sched_start_creates_import_error(self):\n         try:\n             dags_folder = mkdtemp()\ndiff --git a/tests/models.py b/tests/models.py\nindex 1479b63ec4..f2d36a263b 100644\n--- a/tests/models.py\n+++ b/tests/models.py\n@@ -636,10 +636,10 @@ def test_dagstats_crud(self):\n             default_args={'owner': 'owner1'})\n \n         with dag:\n-            op1 = DummyOperator(task_id='A')\n+            DummyOperator(task_id='A')\n \n         now = timezone.utcnow()\n-        dr = dag.create_dagrun(\n+        dag.create_dagrun(\n             run_id='manual__' + now.isoformat(),\n             execution_date=now,\n             start_date=now,\n@@ -914,8 +914,8 @@ def test_dagrun_no_deadlock_with_depends_on_past(self):\n         dag = DAG('test_dagrun_no_deadlock',\n                   start_date=DEFAULT_DATE)\n         with dag:\n-            op1 = DummyOperator(task_id='dop', depends_on_past=True)\n-            op2 = DummyOperator(task_id='tc', task_concurrency=1)\n+            DummyOperator(task_id='dop', depends_on_past=True)\n+            DummyOperator(task_id='tc', task_concurrency=1)\n \n         dag.clear()\n         dr = dag.create_dagrun(run_id='test_dagrun_no_deadlock_1',\n@@ -927,9 +927,9 @@ def test_dagrun_no_deadlock_with_depends_on_past(self):\n                                 execution_date=DEFAULT_DATE + datetime.timedelta(days=1),\n                                 start_date=DEFAULT_DATE + datetime.timedelta(days=1))\n         ti1_op1 = dr.get_task_instance(task_id='dop')\n-        ti2_op1 = dr2.get_task_instance(task_id='dop')\n+        dr2.get_task_instance(task_id='dop')\n         ti2_op1 = dr.get_task_instance(task_id='tc')\n-        ti2_op2 = dr.get_task_instance(task_id='tc')\n+        dr.get_task_instance(task_id='tc')\n         ti1_op1.set_state(state=State.RUNNING, session=session)\n         dr.update_state()\n         dr2.update_state()\n@@ -1130,7 +1130,7 @@ def test_get_task_instance_on_empty_dagrun(self):\n             dag_id='test_get_task_instance_on_empty_dagrun',\n             start_date=timezone.datetime(2017, 1, 1)\n         )\n-        dag_task1 = ShortCircuitOperator(\n+        ShortCircuitOperator(\n             task_id='test_short_circuit_false',\n             dag=dag,\n             python_callable=lambda: False)\n@@ -1160,10 +1160,8 @@ def test_get_latest_runs(self):\n         dag = DAG(\n             dag_id='test_latest_runs_1',\n             start_date=DEFAULT_DATE)\n-        dag_1_run_1 = self.create_dag_run(dag,\n-                                          execution_date=timezone.datetime(2015, 1, 1))\n-        dag_1_run_2 = self.create_dag_run(dag,\n-                                          execution_date=timezone.datetime(2015, 1, 2))\n+        self.create_dag_run(dag, execution_date=timezone.datetime(2015, 1, 1))\n+        self.create_dag_run(dag, execution_date=timezone.datetime(2015, 1, 2))\n         dagruns = models.DagRun.get_latest_runs(session)\n         session.close()\n         for dagrun in dagruns:\n@@ -1315,9 +1313,9 @@ def process_file(self, filepath, only_if_updated=True, safe_mode=True):\n                 super(TestDagBag, self).process_file(filepath, only_if_updated, safe_mode)\n \n         dagbag = TestDagBag(include_examples=True)\n-        processed_files = dagbag.process_file_calls\n+        dagbag.process_file_calls\n \n-        # Should not call process_file agani, since it's already loaded during init.\n+        # Should not call process_file again, since it's already loaded during init.\n         self.assertEqual(1, dagbag.process_file_calls)\n         self.assertIsNotNone(dagbag.get_dag(dag_id))\n         self.assertEqual(1, dagbag.process_file_calls)\ndiff --git a/tests/operators/__init__.py b/tests/operators/__init__.py\nindex 4924560599..114d189da1 100644\n--- a/tests/operators/__init__.py\n+++ b/tests/operators/__init__.py\n@@ -16,4 +16,3 @@\n # KIND, either express or implied.  See the License for the\n # specific language governing permissions and limitations\n # under the License.\n-\ndiff --git a/tests/operators/docker_operator.py b/tests/operators/docker_operator.py\nindex a216d9bd50..ea90c53c28 100644\n--- a/tests/operators/docker_operator.py\n+++ b/tests/operators/docker_operator.py\n@@ -237,5 +237,6 @@ def test_execute_with_docker_conn_id_use_hook(self, operator_client_mock,\n             'Image was not pulled using operator client'\n         )\n \n+\n if __name__ == \"__main__\":\n     unittest.main()\ndiff --git a/tests/operators/latest_only_operator.py b/tests/operators/latest_only_operator.py\nindex ffce39f569..7a4efa11b5 100644\n--- a/tests/operators/latest_only_operator.py\n+++ b/tests/operators/latest_only_operator.py\n@@ -91,7 +91,7 @@ def test_skipping(self):\n         self.assertEqual({\n             timezone.datetime(2016, 1, 1): 'success',\n             timezone.datetime(2016, 1, 1, 12): 'success',\n-            timezone.datetime(2016, 1, 2): 'success', },\n+            timezone.datetime(2016, 1, 2): 'success'},\n             exec_date_to_latest_state)\n \n         downstream_instances = get_task_instances('downstream')\n@@ -100,7 +100,7 @@ def test_skipping(self):\n         self.assertEqual({\n             timezone.datetime(2016, 1, 1): 'skipped',\n             timezone.datetime(2016, 1, 1, 12): 'skipped',\n-            timezone.datetime(2016, 1, 2): 'success',},\n+            timezone.datetime(2016, 1, 2): 'success'},\n             exec_date_to_downstream_state)\n \n         downstream_instances = get_task_instances('downstream_2')\n@@ -109,7 +109,7 @@ def test_skipping(self):\n         self.assertEqual({\n             timezone.datetime(2016, 1, 1): 'skipped',\n             timezone.datetime(2016, 1, 1, 12): 'skipped',\n-            timezone.datetime(2016, 1, 2): 'success',},\n+            timezone.datetime(2016, 1, 2): 'success'},\n             exec_date_to_downstream_state)\n \n     def test_skipping_dagrun(self):\n@@ -126,21 +126,21 @@ def test_skipping_dagrun(self):\n         downstream_task.set_upstream(latest_task)\n         downstream_task2.set_upstream(downstream_task)\n \n-        dr1 = self.dag.create_dagrun(\n+        self.dag.create_dagrun(\n             run_id=\"manual__1\",\n             start_date=timezone.utcnow(),\n             execution_date=DEFAULT_DATE,\n             state=State.RUNNING\n         )\n \n-        dr2 = self.dag.create_dagrun(\n+        self.dag.create_dagrun(\n             run_id=\"manual__2\",\n             start_date=timezone.utcnow(),\n             execution_date=timezone.datetime(2016, 1, 1, 12),\n             state=State.RUNNING\n         )\n \n-        dr2 = self.dag.create_dagrun(\n+        self.dag.create_dagrun(\n             run_id=\"manual__3\",\n             start_date=timezone.utcnow(),\n             execution_date=END_DATE,\n@@ -157,7 +157,7 @@ def test_skipping_dagrun(self):\n         self.assertEqual({\n             timezone.datetime(2016, 1, 1): 'success',\n             timezone.datetime(2016, 1, 1, 12): 'success',\n-            timezone.datetime(2016, 1, 2): 'success', },\n+            timezone.datetime(2016, 1, 2): 'success'},\n             exec_date_to_latest_state)\n \n         downstream_instances = get_task_instances('downstream')\n@@ -166,7 +166,7 @@ def test_skipping_dagrun(self):\n         self.assertEqual({\n             timezone.datetime(2016, 1, 1): 'skipped',\n             timezone.datetime(2016, 1, 1, 12): 'skipped',\n-            timezone.datetime(2016, 1, 2): 'success',},\n+            timezone.datetime(2016, 1, 2): 'success'},\n             exec_date_to_downstream_state)\n \n         downstream_instances = get_task_instances('downstream_2')\n@@ -175,5 +175,5 @@ def test_skipping_dagrun(self):\n         self.assertEqual({\n             timezone.datetime(2016, 1, 1): 'skipped',\n             timezone.datetime(2016, 1, 1, 12): 'skipped',\n-            timezone.datetime(2016, 1, 2): 'success',},\n+            timezone.datetime(2016, 1, 2): 'success'},\n             exec_date_to_downstream_state)\ndiff --git a/tests/operators/python_operator.py b/tests/operators/python_operator.py\nindex 735a4d78c6..afc2a1383a 100644\n--- a/tests/operators/python_operator.py\n+++ b/tests/operators/python_operator.py\n@@ -275,8 +275,8 @@ def test_without_dag_run(self):\n         value = False\n         dag = DAG('shortcircuit_operator_test_without_dag_run',\n                   default_args={\n-                       'owner': 'airflow',\n-                       'start_date': DEFAULT_DATE\n+                      'owner': 'airflow',\n+                      'start_date': DEFAULT_DATE\n                   },\n                   schedule_interval=INTERVAL)\n         short_op = ShortCircuitOperator(task_id='make_choice',\n@@ -330,8 +330,8 @@ def test_with_dag_run(self):\n         value = False\n         dag = DAG('shortcircuit_operator_test_with_dag_run',\n                   default_args={\n-                       'owner': 'airflow',\n-                       'start_date': DEFAULT_DATE\n+                      'owner': 'airflow',\n+                      'start_date': DEFAULT_DATE\n                   },\n                   schedule_interval=INTERVAL)\n         short_op = ShortCircuitOperator(task_id='make_choice',\ndiff --git a/tests/operators/s3_to_hive_operator.py b/tests/operators/s3_to_hive_operator.py\nindex 21ef29e25b..bafa3eb191 100644\n--- a/tests/operators/s3_to_hive_operator.py\n+++ b/tests/operators/s3_to_hive_operator.py\n@@ -18,6 +18,7 @@\n # under the License.\n \n import unittest\n+\n try:\n     from unittest import mock\n except ImportError:\n@@ -31,7 +32,7 @@\n from collections import OrderedDict\n from airflow.exceptions import AirflowException\n from tempfile import NamedTemporaryFile, mkdtemp\n-import gzip\n+from gzip import GzipFile\n import bz2\n import shutil\n import filecmp\n@@ -85,39 +86,31 @@ def setUp(self):\n                 self._set_fn(f_txt_h.name, '.txt', True)\n                 f_txt_h.writelines([header, line1, line2])\n             fn_gz = self._get_fn('.txt', True) + \".gz\"\n-            with gzip.GzipFile(filename=fn_gz,\n-                               mode=\"wb\") as f_gz_h:\n+            with GzipFile(filename=fn_gz, mode=\"wb\") as f_gz_h:\n                 self._set_fn(fn_gz, '.gz', True)\n                 f_gz_h.writelines([header, line1, line2])\n             fn_gz_upper = self._get_fn('.txt', True) + \".GZ\"\n-            with gzip.GzipFile(filename=fn_gz_upper,\n-                               mode=\"wb\") as f_gz_upper_h:\n+            with GzipFile(filename=fn_gz_upper, mode=\"wb\") as f_gz_upper_h:\n                 self._set_fn(fn_gz_upper, '.GZ', True)\n                 f_gz_upper_h.writelines([header, line1, line2])\n             fn_bz2 = self._get_fn('.txt', True) + '.bz2'\n-            with bz2.BZ2File(filename=fn_bz2,\n-                             mode=\"wb\") as f_bz2_h:\n+            with bz2.BZ2File(filename=fn_bz2, mode=\"wb\") as f_bz2_h:\n                 self._set_fn(fn_bz2, '.bz2', True)\n                 f_bz2_h.writelines([header, line1, line2])\n             # create sample txt, bz and bz2 without header\n-            with NamedTemporaryFile(mode='wb+',\n-                                    dir=self.tmp_dir,\n-                                    delete=False) as f_txt_nh:\n+            with NamedTemporaryFile(mode='wb+', dir=self.tmp_dir, delete=False) as f_txt_nh:\n                 self._set_fn(f_txt_nh.name, '.txt', False)\n                 f_txt_nh.writelines([line1, line2])\n             fn_gz = self._get_fn('.txt', False) + \".gz\"\n-            with gzip.GzipFile(filename=fn_gz,\n-                               mode=\"wb\") as f_gz_nh:\n+            with GzipFile(filename=fn_gz, mode=\"wb\") as f_gz_nh:\n                 self._set_fn(fn_gz, '.gz', False)\n                 f_gz_nh.writelines([line1, line2])\n             fn_gz_upper = self._get_fn('.txt', False) + \".GZ\"\n-            with gzip.GzipFile(filename=fn_gz_upper,\n-                               mode=\"wb\") as f_gz_upper_nh:\n+            with GzipFile(filename=fn_gz_upper, mode=\"wb\") as f_gz_upper_nh:\n                 self._set_fn(fn_gz_upper, '.GZ', False)\n                 f_gz_upper_nh.writelines([line1, line2])\n             fn_bz2 = self._get_fn('.txt', False) + '.bz2'\n-            with bz2.BZ2File(filename=fn_bz2,\n-                             mode=\"wb\") as f_bz2_nh:\n+            with bz2.BZ2File(filename=fn_bz2, mode=\"wb\") as f_bz2_nh:\n                 self._set_fn(fn_bz2, '.bz2', False)\n                 f_bz2_nh.writelines([line1, line2])\n         # Base Exception so it catches Keyboard Interrupt\n@@ -156,15 +149,13 @@ def _check_file_equality(fn_1, fn_2, ext):\n         # causes filecmp to return False even if contents are identical\n         # Hence decompress to test for equality\n         if ext.lower() == '.gz':\n-            with gzip.GzipFile(fn_1, 'rb') as f_1,\\\n-                 NamedTemporaryFile(mode='wb') as f_txt_1,\\\n-                 gzip.GzipFile(fn_2, 'rb') as f_2,\\\n-                 NamedTemporaryFile(mode='wb') as f_txt_2:\n-                shutil.copyfileobj(f_1, f_txt_1)\n-                shutil.copyfileobj(f_2, f_txt_2)\n-                f_txt_1.flush()\n-                f_txt_2.flush()\n-                return filecmp.cmp(f_txt_1.name, f_txt_2.name, shallow=False)\n+            with GzipFile(fn_1, 'rb') as f_1, NamedTemporaryFile(mode='wb') as f_txt_1:\n+                with GzipFile(fn_2, 'rb') as f_2, NamedTemporaryFile(mode='wb') as f_txt_2:\n+                    shutil.copyfileobj(f_1, f_txt_1)\n+                    shutil.copyfileobj(f_2, f_txt_2)\n+                    f_txt_1.flush()\n+                    f_txt_2.flush()\n+                    return filecmp.cmp(f_txt_1.name, f_txt_2.name, shallow=False)\n         else:\n             return filecmp.cmp(fn_1, fn_2, shallow=False)\n \n@@ -179,20 +170,20 @@ def test_bad_parameters(self):\n     def test__get_top_row_as_list(self):\n         self.kwargs['delimiter'] = '\\t'\n         fn_txt = self._get_fn('.txt', True)\n-        header_list = S3ToHiveTransfer(**self.kwargs).\\\n+        header_list = S3ToHiveTransfer(**self.kwargs). \\\n             _get_top_row_as_list(fn_txt)\n         self.assertEqual(header_list, ['Sno', 'Some,Text'],\n                          msg=\"Top row from file doesnt matched expected value\")\n \n         self.kwargs['delimiter'] = ','\n-        header_list = S3ToHiveTransfer(**self.kwargs).\\\n+        header_list = S3ToHiveTransfer(**self.kwargs). \\\n             _get_top_row_as_list(fn_txt)\n         self.assertEqual(header_list, ['Sno\\tSome', 'Text'],\n                          msg=\"Top row from file doesnt matched expected value\")\n \n     def test__match_headers(self):\n         self.kwargs['field_dict'] = OrderedDict([('Sno', 'BIGINT'),\n-                                                ('Some,Text', 'STRING')])\n+                                                 ('Some,Text', 'STRING')])\n         self.assertTrue(S3ToHiveTransfer(**self.kwargs).\n                         _match_headers(['Sno', 'Some,Text']),\n                         msg=\"Header row doesnt match expected value\")\n@@ -250,8 +241,7 @@ def test_execute(self, mock_hiveclihook):\n             # file parameter to HiveCliHook.load_file is compared\n             # against expected file output\n             mock_hiveclihook().load_file.side_effect = \\\n-                lambda *args, **kwargs: \\\n-                self.assertTrue(\n+                lambda *args, **kwargs: self.assertTrue(\n                     self._check_file_equality(args[0], op_fn, ext),\n                     msg='{0} output file not as expected'.format(ext))\n             # Execute S3ToHiveTransfer\ndiff --git a/tests/operators/subdag_operator.py b/tests/operators/subdag_operator.py\nindex af47c5cfd5..bba6f17194 100644\n--- a/tests/operators/subdag_operator.py\n+++ b/tests/operators/subdag_operator.py\n@@ -85,7 +85,7 @@ def test_subdag_pools(self):\n         session.add(pool_10)\n         session.commit()\n \n-        dummy_1 = DummyOperator(task_id='dummy', dag=subdag, pool='test_pool_1')\n+        DummyOperator(task_id='dummy', dag=subdag, pool='test_pool_1')\n \n         self.assertRaises(\n             AirflowException,\n@@ -116,8 +116,7 @@ def test_subdag_pools_no_possible_conflict(self):\n         session.add(pool_10)\n         session.commit()\n \n-        dummy_1 = DummyOperator(\n-            task_id='dummy', dag=subdag, pool='test_pool_10')\n+        DummyOperator(task_id='dummy', dag=subdag, pool='test_pool_10')\n \n         mock_session = Mock()\n         SubDagOperator(\ndiff --git a/tests/plugins/test_plugin.py b/tests/plugins/test_plugin.py\nindex f507bdd585..7b8bc4f61c 100644\n--- a/tests/plugins/test_plugin.py\n+++ b/tests/plugins/test_plugin.py\n@@ -30,10 +30,12 @@\n from airflow.sensors.base_sensor_operator import BaseSensorOperator\n from airflow.executors.base_executor import BaseExecutor\n \n+\n # Will show up under airflow.hooks.test_plugin.PluginHook\n class PluginHook(BaseHook):\n     pass\n \n+\n # Will show up under airflow.operators.test_plugin.PluginOperator\n class PluginOperator(BaseOperator):\n     pass\n@@ -48,22 +50,27 @@ class PluginSensorOperator(BaseSensorOperator):\n class PluginExecutor(BaseExecutor):\n     pass\n \n+\n # Will show up under airflow.macros.test_plugin.plugin_macro\n def plugin_macro():\n     pass\n \n+\n # Creating a flask admin BaseView\n class TestView(BaseView):\n     @expose('/')\n     def test(self):\n-        # in this example, put your test_plugin/test.html template at airflow/plugins/templates/test_plugin/test.html\n+        # in this example, put your test_plugin/test.html\n+        # template at airflow/plugins/templates/test_plugin/test.html\n         return self.render(\"test_plugin/test.html\", content=\"Hello galaxy!\")\n+\n+\n v = TestView(category=\"Test Plugin\", name=\"Test View\")\n \n # Creating a flask blueprint to intergrate the templates and static folder\n bp = Blueprint(\n     \"test_plugin\", __name__,\n-    template_folder='templates', # registers airflow/plugins/templates as a Jinja template folder\n+    template_folder='templates',  # registers airflow/plugins/templates as a Jinja template folder\n     static_folder='static',\n     static_url_path='/static/test_plugin')\n \ndiff --git a/tests/plugins_manager.py b/tests/plugins_manager.py\nindex 39da5ce448..9f939c37a0 100644\n--- a/tests/plugins_manager.py\n+++ b/tests/plugins_manager.py\n@@ -28,7 +28,7 @@\n from flask_admin.menu import MenuLink, MenuView\n \n from airflow.hooks.base_hook import BaseHook\n-from airflow.models import  BaseOperator\n+from airflow.models import BaseOperator\n from airflow.sensors.base_sensor_operator import BaseSensorOperator\n from airflow.executors.base_executor import BaseExecutor\n from airflow.www.app import cached_app\ndiff --git a/tests/sensors/test_sql_sensor.py b/tests/sensors/test_sql_sensor.py\nindex 5b52f3b654..03ea115356 100644\n--- a/tests/sensors/test_sql_sensor.py\n+++ b/tests/sensors/test_sql_sensor.py\n@@ -40,8 +40,8 @@ def setUp(self):\n         }\n         self.dag = DAG(TEST_DAG_ID, default_args=args)\n \n-    @unittest.skipUnless('mysql' in configuration.conf.get('core', 'sql_alchemy_conn'),\n-                        \"this is a mysql test\")\n+    @unittest.skipUnless(\n+        'mysql' in configuration.conf.get('core', 'sql_alchemy_conn'), \"this is a mysql test\")\n     def test_sql_sensor_mysql(self):\n         t = SqlSensor(\n             task_id='sql_sensor_check',\n@@ -51,8 +51,8 @@ def test_sql_sensor_mysql(self):\n         )\n         t.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE, ignore_ti_state=True)\n \n-    @unittest.skipUnless('postgresql' in configuration.conf.get('core', 'sql_alchemy_conn'),\n-                        \"this is a postgres test\")\n+    @unittest.skipUnless(\n+        'postgresql' in configuration.conf.get('core', 'sql_alchemy_conn'), \"this is a postgres test\")\n     def test_sql_sensor_postgres(self):\n         t = SqlSensor(\n             task_id='sql_sensor_check',\n@@ -70,9 +70,7 @@ def test_sql_sensor_postgres_poke(self, mock_hook):\n             sql=\"SELECT 1\",\n         )\n \n-        mock_get_records = (\n-            mock_hook.get_connection.return_value\n-            .get_hook.return_value.get_records)\n+        mock_get_records = mock_hook.get_connection.return_value.get_hook.return_value.get_records\n \n         mock_get_records.return_value = []\n         self.assertFalse(t.poke(None))\ndiff --git a/tests/task/task_runner/__init__.py b/tests/task/task_runner/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/task/task_runner/__init__.py\n+++ b/tests/task/task_runner/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/test_logging_config.py b/tests/test_logging_config.py\nindex b568a88cb2..324e33a3ac 100644\n--- a/tests/test_logging_config.py\n+++ b/tests/test_logging_config.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n@@ -148,7 +148,7 @@ def __enter__(self):\n         return self.settings_file\n \n     def __exit__(self, *exc_info):\n-        #shutil.rmtree(self.settings_root)\n+        # shutil.rmtree(self.settings_root)\n         # Reset config\n         conf.set('core', 'logging_config_class', '')\n         sys.path.remove(self.settings_root)\ndiff --git a/tests/ti_deps/deps/test_runnable_exec_date_dep.py b/tests/ti_deps/deps/test_runnable_exec_date_dep.py\nindex 8f59b43ba4..16057c8108 100644\n--- a/tests/ti_deps/deps/test_runnable_exec_date_dep.py\n+++ b/tests/ti_deps/deps/test_runnable_exec_date_dep.py\n@@ -25,6 +25,7 @@\n from airflow.ti_deps.deps.runnable_exec_date_dep import RunnableExecDateDep\n from airflow.utils.timezone import datetime\n \n+\n class RunnableExecDateDepTest(unittest.TestCase):\n \n     def _get_task_instance(self, execution_date, dag_end_date=None, task_end_date=None):\ndiff --git a/tests/ti_deps/deps/test_task_concurrency.py b/tests/ti_deps/deps/test_task_concurrency.py\nindex 940bfca361..ad3c0d9ea0 100644\n--- a/tests/ti_deps/deps/test_task_concurrency.py\n+++ b/tests/ti_deps/deps/test_task_concurrency.py\n@@ -52,4 +52,3 @@ def test_reached_concurrency(self):\n         self.assertTrue(TaskConcurrencyDep().is_met(ti=ti, dep_context=dep_context))\n         ti.get_num_running_task_instances = lambda x: 2\n         self.assertFalse(TaskConcurrencyDep().is_met(ti=ti, dep_context=dep_context))\n-\ndiff --git a/tests/utils.py b/tests/utils.py\nindex 00f126c5da..f670e41183 100644\n--- a/tests/utils.py\n+++ b/tests/utils.py\n@@ -62,6 +62,7 @@ def test_gcs_url_parse(self):\n             glog.parse_gcs_url('gs://bucket/'),\n             ('bucket', ''))\n \n+\n class OperatorResourcesTest(unittest.TestCase):\n \n     def setUp(self):\ndiff --git a/tests/utils/test_dates.py b/tests/utils/test_dates.py\nindex 84ffb4d7d8..85613d0791 100644\n--- a/tests/utils/test_dates.py\n+++ b/tests/utils/test_dates.py\n@@ -33,26 +33,22 @@ def test_days_ago(self):\n \n         self.assertTrue(dates.days_ago(0) == today_midnight)\n \n-        self.assertTrue(\n-            dates.days_ago(100) == today_midnight + timedelta(days=-100))\n-\n-        self.assertTrue(\n-            dates.days_ago(0, hour=3) == today_midnight + timedelta(hours=3))\n-        self.assertTrue(\n-            dates.days_ago(0, minute=3)\n-            == today_midnight + timedelta(minutes=3))\n-        self.assertTrue(\n-            dates.days_ago(0, second=3)\n-            == today_midnight + timedelta(seconds=3))\n-        self.assertTrue(\n-            dates.days_ago(0, microsecond=3)\n-            == today_midnight + timedelta(microseconds=3))\n+        self.assertTrue(dates.days_ago(100) == today_midnight + timedelta(days=-100))\n+\n+        self.assertTrue(dates.days_ago(0, hour=3) == today_midnight + timedelta(hours=3))\n+        self.assertTrue(dates.days_ago(0, minute=3) == today_midnight + timedelta(minutes=3))\n+        self.assertTrue(dates.days_ago(0, second=3) == today_midnight + timedelta(seconds=3))\n+        self.assertTrue(dates.days_ago(0, microsecond=3) == today_midnight + timedelta(microseconds=3))\n \n     def test_parse_execution_date(self):\n         execution_date_str_wo_ms = '2017-11-02 00:00:00'\n         execution_date_str_w_ms = '2017-11-05 16:18:30.989729'\n         bad_execution_date_str = '2017-11-06TXX:00:00Z'\n \n-        self.assertEqual(timezone.datetime(2017, 11, 2, 0, 0, 0), dates.parse_execution_date(execution_date_str_wo_ms))\n-        self.assertEqual(timezone.datetime(2017, 11, 5, 16, 18, 30, 989729), dates.parse_execution_date(execution_date_str_w_ms))\n+        self.assertEqual(\n+            timezone.datetime(2017, 11, 2, 0, 0, 0),\n+            dates.parse_execution_date(execution_date_str_wo_ms))\n+        self.assertEqual(\n+            timezone.datetime(2017, 11, 5, 16, 18, 30, 989729),\n+            dates.parse_execution_date(execution_date_str_w_ms))\n         self.assertRaises(ValueError, dates.parse_execution_date, bad_execution_date_str)\ndiff --git a/tests/utils/test_log_handlers.py b/tests/utils/test_log_handlers.py\nindex ffd6df4b04..72a5793f7e 100644\n--- a/tests/utils/test_log_handlers.py\n+++ b/tests/utils/test_log_handlers.py\n@@ -169,14 +169,18 @@ def setUp(self):\n         self.ti = TaskInstance(task=task, execution_date=DEFAULT_DATE)\n \n     def test_python_formatting(self):\n-        expected_filename = 'dag_for_testing_filename_rendering/task_for_testing_filename_rendering/%s/42.log' % DEFAULT_DATE.isoformat()\n+        expected_filename = \\\n+            'dag_for_testing_filename_rendering/task_for_testing_filename_rendering/%s/42.log' \\\n+            % DEFAULT_DATE.isoformat()\n \n         fth = FileTaskHandler('', '{dag_id}/{task_id}/{execution_date}/{try_number}.log')\n         rendered_filename = fth._render_filename(self.ti, 42)\n         self.assertEqual(expected_filename, rendered_filename)\n \n     def test_jinja_rendering(self):\n-        expected_filename = 'dag_for_testing_filename_rendering/task_for_testing_filename_rendering/%s/42.log' % DEFAULT_DATE.isoformat()\n+        expected_filename = \\\n+            'dag_for_testing_filename_rendering/task_for_testing_filename_rendering/%s/42.log' \\\n+            % DEFAULT_DATE.isoformat()\n \n         fth = FileTaskHandler('', '{{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log')\n         rendered_filename = fth._render_filename(self.ti, 42)\ndiff --git a/tests/utils/test_logging_mixin.py b/tests/utils/test_logging_mixin.py\nindex df7423092f..fa8c589a9e 100644\n--- a/tests/utils/test_logging_mixin.py\n+++ b/tests/utils/test_logging_mixin.py\n@@ -120,4 +120,3 @@ def test_encoding(self):\n \n         log = StreamLogWriter(logger, 1)\n         self.assertFalse(log.encoding)\n-\ndiff --git a/tests/utils/test_timezone.py b/tests/utils/test_timezone.py\nindex 92fd54ec7a..07e0befcb8 100644\n--- a/tests/utils/test_timezone.py\n+++ b/tests/utils/test_timezone.py\n@@ -24,8 +24,8 @@\n from airflow.utils import timezone\n \n CET = pendulum.timezone(\"Europe/Paris\")\n-EAT = pendulum.timezone('Africa/Nairobi')      # Africa/Nairobi\n-ICT = pendulum.timezone('Asia/Bangkok')      # Asia/Bangkok\n+EAT = pendulum.timezone('Africa/Nairobi')  # Africa/Nairobi\n+ICT = pendulum.timezone('Asia/Bangkok')  # Asia/Bangkok\n UTC = timezone.utc\n \n \n@@ -69,4 +69,3 @@ def test_make_aware(self):\n             datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT))\n         with self.assertRaises(ValueError):\n             timezone.make_aware(datetime.datetime(2011, 9, 1, 13, 20, 30, tzinfo=EAT), EAT)\n-\ndiff --git a/tests/www/__init__.py b/tests/www/__init__.py\nindex 4924560599..114d189da1 100644\n--- a/tests/www/__init__.py\n+++ b/tests/www/__init__.py\n@@ -16,4 +16,3 @@\n # KIND, either express or implied.  See the License for the\n # specific language governing permissions and limitations\n # under the License.\n-\ndiff --git a/tests/www/api/__init__.py b/tests/www/api/__init__.py\nindex 4924560599..114d189da1 100644\n--- a/tests/www/api/__init__.py\n+++ b/tests/www/api/__init__.py\n@@ -16,4 +16,3 @@\n # KIND, either express or implied.  See the License for the\n # specific language governing permissions and limitations\n # under the License.\n-\ndiff --git a/tests/www/api/experimental/__init__.py b/tests/www/api/experimental/__init__.py\nindex 4924560599..114d189da1 100644\n--- a/tests/www/api/experimental/__init__.py\n+++ b/tests/www/api/experimental/__init__.py\n@@ -16,4 +16,3 @@\n # KIND, either express or implied.  See the License for the\n # specific language governing permissions and limitations\n # under the License.\n-\ndiff --git a/tests/www/api/experimental/test_kerberos_endpoints.py b/tests/www/api/experimental/test_kerberos_endpoints.py\nindex 63a1557432..b305e19b21 100644\n--- a/tests/www/api/experimental/test_kerberos_endpoints.py\n+++ b/tests/www/api/experimental/test_kerberos_endpoints.py\n@@ -37,14 +37,14 @@ def setUp(self):\n         configuration.load_test_config()\n         try:\n             configuration.conf.add_section(\"api\")\n-        except:\n+        except Exception:\n             pass\n         configuration.conf.set(\"api\",\n                                \"auth_backend\",\n                                \"airflow.api.auth.backend.kerberos_auth\")\n         try:\n             configuration.conf.add_section(\"kerberos\")\n-        except:\n+        except Exception:\n             pass\n         configuration.conf.set(\"kerberos\",\n                                \"keytab\",\ndiff --git a/tests/www/test_validators.py b/tests/www/test_validators.py\nindex 0180b734cc..e6242632f2 100644\n--- a/tests/www/test_validators.py\n+++ b/tests/www/test_validators.py\n@@ -92,6 +92,5 @@ def test_validation_raises_custom_message(self):\n         )\n \n \n-\n if __name__ == '__main__':\n     unittest.main()\ndiff --git a/tests/www_rbac/__init__.py b/tests/www_rbac/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/www_rbac/__init__.py\n+++ b/tests/www_rbac/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/www_rbac/api/__init__.py b/tests/www_rbac/api/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/www_rbac/api/__init__.py\n+++ b/tests/www_rbac/api/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/www_rbac/api/experimental/__init__.py b/tests/www_rbac/api/experimental/__init__.py\nindex 4067cc78ee..114d189da1 100644\n--- a/tests/www_rbac/api/experimental/__init__.py\n+++ b/tests/www_rbac/api/experimental/__init__.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/www_rbac/api/experimental/test_kerberos_endpoints.py b/tests/www_rbac/api/experimental/test_kerberos_endpoints.py\nindex 54bbd865b3..788613b504 100644\n--- a/tests/www_rbac/api/experimental/test_kerberos_endpoints.py\n+++ b/tests/www_rbac/api/experimental/test_kerberos_endpoints.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/www_rbac/test_utils.py b/tests/www_rbac/test_utils.py\nindex 68d1744ab8..84bf6ce8ae 100644\n--- a/tests/www_rbac/test_utils.py\n+++ b/tests/www_rbac/test_utils.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/www_rbac/test_validators.py b/tests/www_rbac/test_validators.py\nindex d7709c4ee7..b50e88de11 100644\n--- a/tests/www_rbac/test_validators.py\n+++ b/tests/www_rbac/test_validators.py\n@@ -7,9 +7,9 @@\n # to you under the Apache License, Version 2.0 (the\n # \"License\"); you may not use this file except in compliance\n # with the License.  You may obtain a copy of the License at\n-# \n+#\n #   http://www.apache.org/licenses/LICENSE-2.0\n-# \n+#\n # Unless required by applicable law or agreed to in writing,\n # software distributed under the License is distributed on an\n # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\ndiff --git a/tests/www_rbac/test_views.py b/tests/www_rbac/test_views.py\nindex a952b9874c..18af9541df 100644\n--- a/tests/www_rbac/test_views.py\n+++ b/tests/www_rbac/test_views.py\n@@ -173,7 +173,7 @@ def test_xss_prevention(self):\n         self.assertNotIn(\"<img src='' onerror='alert(1);'>\",\n                          resp.data.decode(\"utf-8\"))\n \n-    def test_import_variables(self):\n+    def test_import_variables_failed(self):\n         content = '{\"str_key\": \"str_value\"}'\n \n         with mock.patch('airflow.models.Variable.set') as set_mock:\n@@ -192,7 +192,7 @@ def test_import_variables(self):\n                                     follow_redirects=True)\n             self.check_content_in_response('1 variable(s) failed to be updated.', resp)\n \n-    def test_import_variables(self):\n+    def test_import_variables_success(self):\n         self.assertEqual(self.session.query(models.Variable).count(), 0)\n \n         content = ('{\"str_key\": \"str_value\", \"int_key\": 60,'\ndiff --git a/tox.ini b/tox.ini\nindex 17bfeb6ec2..6a55df6e5d 100644\n--- a/tox.ini\n+++ b/tox.ini\n@@ -26,10 +26,6 @@ find_links =\n     {homedir}/.wheelhouse\n     {homedir}/.pip-cache\n \n-[flake8]\n-max-line-length = 90\n-ignore = E731,W503\n-\n [testenv]\n deps =\n     wheel\n@@ -72,5 +68,4 @@ basepython = python3\n deps =\n     flake8\n \n-commands =\n-    {toxinidir}/scripts/ci/flake8-diff.sh\n+commands = flake8\n\n\n \n\n----------------------------------------------------------------\nThis is an automated message from the Apache Git Service.\nTo respond to the message, please log on GitHub and use the\nURL above to go to the specific comment.\n \nFor queries about this service, please contact Infrastructure at:\nusers@infra.apache.org\n"
            },
            {
                "author_name": "kaxilnaik",
                "id": "16648463",
                "body": "Resolved by https://github.com/apache/incubator-airflow/pull/4035"
            },
            {
                "author_name": "jira-bot",
                "id": "16747075",
                "body": "Commit a481f219651a711132657d8964bff80b9c86c633 in airflow's branch refs/heads/v1-10-test from Fokko Driesprong\n[ https://gitbox.apache.org/repos/asf?p=airflow.git;h=a481f21 ]\n\n[AIRFLOW-3190] Make flake8 compliant\n\nOne voilation that slipped in by PR that didn't rebase onto\nlatest master\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16747092",
                "body": "Commit c2a6eb8e2fdf520e9d9b272bc3bacd0d8d9c20e6 in airflow's branch refs/heads/v1-10-test from Fokko Driesprong\n[ https://gitbox.apache.org/repos/asf?p=airflow.git;h=c2a6eb8 ]\n\n[AIRFLOW-3190] Make flake8 compliant\n\nOne voilation that slipped in by PR that didn't rebase onto\nlatest master\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16747130",
                "body": "Commit e67015ae4e4741ba856ae8c58c672cb7a151c9f7 in airflow's branch refs/heads/v1-10-test from Fokko Driesprong\n[ https://gitbox.apache.org/repos/asf?p=airflow.git;h=e67015a ]\n\n[AIRFLOW-3190] Make flake8 compliant\n\nOne voilation that slipped in by PR that didn't rebase onto\nlatest master\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16747151",
                "body": "Commit 8af9658d52af9f9347ee26c142642347e318c85a in airflow's branch refs/heads/v1-10-test from Fokko Driesprong\n[ https://gitbox.apache.org/repos/asf?p=airflow.git;h=8af9658 ]\n\n[AIRFLOW-3190] Make flake8 compliant\n\nOne voilation that slipped in by PR that didn't rebase onto\nlatest master\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16747166",
                "body": "Commit 8af9658d52af9f9347ee26c142642347e318c85a in airflow's branch refs/heads/v1-10-stable from Fokko Driesprong\n[ https://gitbox.apache.org/repos/asf?p=airflow.git;h=8af9658 ]\n\n[AIRFLOW-3190] Make flake8 compliant\n\nOne voilation that slipped in by PR that didn't rebase onto\nlatest master\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16747177",
                "body": "Commit d50ff40a6542cd96a7fb1bb7b0ce687206d8523e in airflow's branch refs/heads/v1-10-test from Fokko Driesprong\n[ https://gitbox.apache.org/repos/asf?p=airflow.git;h=d50ff40 ]\n\n[AIRFLOW-3190] Make flake8 compliant\n\nOne voilation that slipped in by PR that didn't rebase onto\nlatest master\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16747184",
                "body": "Commit d50ff40a6542cd96a7fb1bb7b0ce687206d8523e in airflow's branch refs/heads/v1-10-stable from Fokko Driesprong\n[ https://gitbox.apache.org/repos/asf?p=airflow.git;h=d50ff40 ]\n\n[AIRFLOW-3190] Make flake8 compliant\n\nOne voilation that slipped in by PR that didn't rebase onto\nlatest master\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d60bfaf4d395ee22224138",
        "key": "GEODE-1949",
        "id": "13008626",
        "description": "The geode-rebalancer jar is not part of the binary distribution. That means that users that want to use the rebalancer must download it and it's dependencies from maven and add them to the server's classpath.\n\nI think the main reason not to include the rebalancer in the server's classpath is the dependency on quartz. But looking at the code, it looks like the only usage of quartz is a one line validation that doesn't need to be there. We should remove the dependency on quartz and include the rebalancer in the geode server's classpath by default.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.03267154470086098
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0114905321970582
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.00365198845975101
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "15536429",
                "body": "Commit 22afc3bd740241e53444dec2fd30ea39fa15c5dc in incubator-geode's branch refs/heads/develop from [~upthewaterspout]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=22afc3b ]\n\nGEODE-1949: Remove the dependency on quartz from the rebalancer\n\nThe geode-rebalancer does not need to depend on quartz, it is using\nspring-expression for all of the cron heavy lifting.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15536430",
                "body": "Commit 0a6e1a5339243b069a04d8010a869bfd1f4172c1 in incubator-geode's branch refs/heads/develop from [~upthewaterspout]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=0a6e1a5 ]\n\nGEODE-1949: Adding geode-rebalancer to the binary distribution\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15545977",
                "body": "Commit 22afc3bd740241e53444dec2fd30ea39fa15c5dc in incubator-geode's branch refs/heads/feature/e2e-testing from [~upthewaterspout]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=22afc3b ]\n\nGEODE-1949: Remove the dependency on quartz from the rebalancer\n\nThe geode-rebalancer does not need to depend on quartz, it is using\nspring-expression for all of the cron heavy lifting.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "15545978",
                "body": "Commit 0a6e1a5339243b069a04d8010a869bfd1f4172c1 in incubator-geode's branch refs/heads/feature/e2e-testing from [~upthewaterspout]\n[ https://git-wip-us.apache.org/repos/asf?p=incubator-geode.git;h=0a6e1a5 ]\n\nGEODE-1949: Adding geode-rebalancer to the binary distribution\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d610a2f4d395ee2222d681",
        "key": "FLEX-33431",
        "id": "12637496",
        "description": "Currently in et1 motorola device, if the app is in landscape mode and you focused on specific textinput, the type of keyboard shown is actually a landscape keyboard. When the landscape keyboard is shown, it will actually cover the whole flex layout view and you can't see anything ( where you focused-in ). If we can add this functionality wherein if we add prompt display to textinput and it will also be shown in the landscape keyboard. This will give us a more user friendly keyboard since we will know where we have focused and what data to enter to that specific textfield.",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d615b4f4d395ee2223a67d",
        "key": "DRILL-4789",
        "id": "12990965",
        "description": "We current have a default in-list size of 20. Instead of the magic number 20, we should make this configurable.\n\n{code}\nselect count * from table where col in (1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1);\n{code}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.007886256091296673
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.011911923065781593
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0050785960629582405
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d5e26af4d395ee221bceb6",
        "key": "RAMPART-217",
        "id": "12416421",
        "description": "Namespaces declared in the xpath element is not serialized. ",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d619f3f4d395ee22242280",
        "key": "CXF-6788",
        "id": "12940163",
        "description": "Sometimes not all of the logging data should be sent out. \nOne use case is a UserNameToken authentication where sensitive data is stored in the message body.\n\nThe user should be able to configure a filter class in the LoggingFeature. The class could have an interface of\nEvent filter(Event);\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.003288710955530405
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.09057504683732986
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008111742325127125
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "6407469bcc191512f881db8d",
        "key": "OFBIZ-12716",
        "id": "13505979",
        "description": "{color:#000000}Failed with the Manufacturing / MRP Run with the Table made of (Wood + Nails + Varnish) tutorial.{color}\r\n\r\nLook for \"Example Scenario\" at:\r\nhttps://cwiki.apache.org/confluence/display/OFBIZ/%5BWIP%5D+Getting+Started+with+Apache+OFBiz+Manufacturing+and+MRP+in+5+Easy+Steps\r\n\r\n\u00a0\r\n{noformat}\r\n====================================================\r\n\r\n2022-11-21 17:40:40,916 |jsse-nio-8443-exec-2 |ServiceDispatcher\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| Sync service [manufacturing/getLastSystemInfoNote] finished in [1] milliseconds\r\n\r\n2022-11-21 17:40:41,088 |jsse-nio-8443-exec-2 |ServerHitBin\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Visit delegatorName=default, ServerHitBin delegatorName=default\r\n\r\n2022-11-21 17:40:41,099 |jsse-nio-8443-exec-2 |ControlServlet\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| [[[FindInventoryEventPlan(Domain:[https://localhost|https://localhost/])] Request Done- total:0.268,since last([FindInventoryEve...):0.269]]\r\n\r\n2022-11-21 17:40:43,746 |jsse-nio-8443-exec-4 |LoginWorker\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |W| Received a null Security object from HttpServletRequest\r\n\r\n2022-11-21 17:40:43,750 |jsse-nio-8443-exec-4 |ControlServlet\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| [[[FindInventoryEventPlan(Domain:[https://localhost|https://localhost/])] Request Begun, encoding=[UTF-8]- total:0.0,since last(Begin):0.0]]\r\n\r\n2022-11-21 17:40:43,798 |jsse-nio-8443-exec-4 |ConfigXMLReader\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| controller loaded: 0.005s, 149 requests, 66 views in file:/Users/yannonghuang/ofbiz/ofbiz-framework/applications/manufacturing/webapp/manufacturing/WEB-INF/controller.xml\r\n\r\n2022-11-21 17:40:43,812 |jsse-nio-8443-exec-4 |ConfigXMLReader\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| controller loaded: 0.001s, 49 requests, 21 views in file:/Users/yannonghuang/ofbiz/ofbiz-framework/framework/common/webcommon/WEB-INF/common-controller.xml\r\n\r\n2022-11-21 17:40:43,822 |jsse-nio-8443-exec-4 |ConfigXMLReader\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| controller loaded: 0.0s, 0 requests, 0 views in file:/Users/yannonghuang/ofbiz/ofbiz-framework/framework/common/webcommon/WEB-INF/handlers-controller.xml\r\n\r\n2022-11-21 17:40:43,830 |jsse-nio-8443-exec-4 |ConfigXMLReader\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| controller loaded: 0.0s, 4 requests, 0 views in file:/Users/yannonghuang/ofbiz/ofbiz-framework/applications/commonext/webapp/WEB-INF/controller.xml\r\n\r\n2022-11-21 17:40:43,833 |jsse-nio-8443-exec-4 |JWTManager\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Internal single sign on is disabled.\r\n\r\n2022-11-21 17:40:43,842 |jsse-nio-8443-exec-4 |RequestHandler\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Rendering View [FindMrpPlannedEvents].\u00a0 Hidden sessionId by default.\r\n\r\n2022-11-21 17:40:43,849 |jsse-nio-8443-exec-4 |ServiceDispatcher\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| Sync service [manufacturing/getUserPreferenceGroup] finished in [2] milliseconds\r\n\r\n2022-11-21 17:40:43,961 |jsse-nio-8443-exec-4 |ScreenFactory\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0|I| Got 2 screens in 0.006s from: file:/Users/yannonghuang/ofbiz/ofbiz-framework/applications/manufacturing/widget/manufacturing/CommonScreens.xml\r\n\r\n2022-11-21 17:40:43,966 |jsse-nio-8443-exec-4 |ScreenFactory\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Got 1 screens in 0.004s from: file:/Users/yannonghuang/ofbiz/ofbiz-framework/applications/commonext/widget/CommonScreens.xml\r\n\r\n2022-11-21 17:40:44,001 |jsse-nio-8443-exec-4 |ServiceDispatcher\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| Sync service [manufacturing/getLastSystemInfoNote] finished in [14] milliseconds\r\n\r\n2022-11-21 17:40:44,008 |jsse-nio-8443-exec-4 |ScreenFactory\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Got 26 screens in 0.004s from: file:/Users/yannonghuang/ofbiz/ofbiz-framework/framework/common/widget/CommonScreens.xml\r\n\r\n2022-11-21 17:40:44,048 |jsse-nio-8443-exec-4 |ScreenFactory\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Got 25 screens in 0.007s from: file:/Users/yannonghuang/ofbiz/ofbiz-framework/themes/common-theme/widget/CommonScreens.xml\r\n\r\n2022-11-21 17:40:44,133 |jsse-nio-8443-exec-4 |ServerHitBin\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Visit delegatorName=default, ServerHitBin delegatorName=default\r\n\r\n2022-11-21 17:40:44,137 |jsse-nio-8443-exec-4 |ControlServlet\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| [[[FindInventoryEventPlan(Domain:[https://localhost|https://localhost/])] Request Done- total:0.387,since last([FindInventoryEve...):0.387]]\r\n\r\n2022-11-21 17:40:47,558 |jsse-nio-8443-exec-1 |LoginWorker\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |W| Received a null Security object from HttpServletRequest\r\n\r\n2022-11-21 17:40:47,560 |jsse-nio-8443-exec-1 |ControlServlet\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| [[[FindInventoryEventPlan(Domain:[https://localhost|https://localhost/])] Request Begun, encoding=[UTF-8]- total:0.0,since last(Begin):0.0]]\r\n\r\n2022-11-21 17:40:47,562 |jsse-nio-8443-exec-1 |JWTManager\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Internal single sign on is disabled.\r\n\r\n2022-11-21 17:40:47,576 |jsse-nio-8443-exec-1 |RequestHandler\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|I| Rendering View [FindMrpPlannedEvents].\u00a0 Hidden sessionId by default.\r\n\r\n2022-11-21 17:40:47,581 |jsse-nio-8443-exec-1 |ServiceDispatcher\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| Sync service [manufacturing/getUserPreferenceGroup] finished in [1] milliseconds\r\n\r\n2022-11-21 17:40:47,594 |jsse-nio-8443-exec-1 |ServiceDispatcher\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| Sync service [manufacturing/getLastSystemInfoNote] finished in [1] milliseconds\r\n\r\n2022-11-21 17:40:47,705 |jsse-nio-8443-exec-1 |ServerHitBin\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Visit delegatorName=default, ServerHitBin delegatorName=default\r\n\r\n2022-11-21 17:40:47,731 |jsse-nio-8443-exec-1 |ControlServlet\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| [[[FindInventoryEventPlan(Domain:[https://localhost|https://localhost/])] Request Done- total:0.171,since last([FindInventoryEve...):0.171]]\r\n\r\n2022-11-21 17:40:51,044 |OFBiz-JobQueue-0\u00a0\u00a0\u00a0\u00a0 |PersistedServiceJob\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Job\u00a0 [1669081224242] Id [10018] -- Next runtime: Wed Dec 31 15:59:59 PST 1969\r\n\r\nNov 21, 2022 5:40:51 PM java.io.ObjectInputStream filterCheck\r\n\r\nINFO: ObjectInputFilter REJECTED: null, array length: -1, nRefs: 501, depth: 6, bytes: 13065, ex: n/a\r\n\r\n2022-11-21 17:40:51,134 |OFBiz-JobQueue-0\u00a0\u00a0\u00a0\u00a0 |UtilObject\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |E| null\r\n\r\njava.io.InvalidClassException: filter status: REJECTED\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.filterCheck(ObjectInputStream.java:1356) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readHandle(ObjectInputStream.java:1824) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1657) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2454) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2378) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2236) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1692) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject(ObjectInputStream.java:508) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject(ObjectInputStream.java:466) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.util.HashMap.readObject(HashMap.java:1418) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at sun.reflect.GeneratedMethodAccessor377.invoke(Unknown Source) ~[?:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1185) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2345) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2236) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1692) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2454) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2378) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2236) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1692) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2454) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2378) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2236) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1692) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2454) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2378) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2236) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1692) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject(ObjectInputStream.java:508) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.io.ObjectInputStream.readObject(ObjectInputStream.java:466) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.base.util.UtilObject.getObjectException(UtilObject.java:96) ~[ofbiz.jar:?]\r\n\r\n\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0at org.apache.ofbiz.base.util.UtilObject.getObject(UtilObject.java:79) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserializeCustom(XmlSerializer.java:475) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserializeSingle(XmlSerializer.java:465) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserializeSingle(XmlSerializer.java:453) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserialize(XmlSerializer.java:128) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserialize(XmlSerializer.java:102) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.job.PersistedServiceJob.getContext(PersistedServiceJob.java:293) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.job.GenericServiceJob.exec(GenericServiceJob.java:70) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.job.AbstractJob.run(AbstractJob.java:87) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_351]\r\n\r\n2022-11-21 17:40:51,138 |OFBiz-JobQueue-0\u00a0\u00a0\u00a0\u00a0 |PersistedServiceJob\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |E| PersistedServiceJob.getContext(): Serialize Exception\r\n\r\norg.apache.ofbiz.entity.serialize.SerializeException: Problem deserializing object from byte array + cus-obj\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserializeCustom(XmlSerializer.java:481) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserializeSingle(XmlSerializer.java:465) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserializeSingle(XmlSerializer.java:453) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserialize(XmlSerializer.java:128) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.entity.serialize.XmlSerializer.deserialize(XmlSerializer.java:102) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.job.PersistedServiceJob.getContext(PersistedServiceJob.java:293) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.job.GenericServiceJob.exec(GenericServiceJob.java:70) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.job.AbstractJob.run(AbstractJob.java:87) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_351]\r\n\r\n2022-11-21 17:40:51,142 |OFBiz-JobQueue-0\u00a0\u00a0\u00a0\u00a0 |PersistedServiceJob\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |E| Job context is null\r\n\r\n2022-11-21 17:40:51,148 |OFBiz-JobQueue-0\u00a0 \u00a0\u00a0\u00a0|ServiceDispatcher\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| [[Sync service failed...- total:0.0,since last(Begin):0.001]] - 'default / executeMrp'\r\n\r\n2022-11-21 17:40:51,150 |OFBiz-JobQueue-0\u00a0\u00a0\u00a0\u00a0 |TransactionUtil\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Transaction rolled back\r\n\r\n2022-11-21 17:40:51,152 |OFBiz-JobQueue-0\u00a0\u00a0\u00a0\u00a0 |TransactionUtil\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |W| Not committing transaction, status is No Transaction (6)\r\n\r\n2022-11-21 17:40:51,153 |OFBiz-JobQueue-0\u00a0\u00a0\u00a0\u00a0 |GenericServiceJob\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |E| Async-Service failed.\r\n\r\norg.apache.ofbiz.service.ServiceAuthException: User authorization is required for this service: executeMrp\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.ServiceDispatcher.runSync(ServiceDispatcher.java:375) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.ServiceDispatcher.runSync(ServiceDispatcher.java:240) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.GenericDispatcherFactory$GenericDispatcher.runSync(GenericDispatcherFactory.java:88) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.job.GenericServiceJob.exec(GenericServiceJob.java:70) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at org.apache.ofbiz.service.job.AbstractJob.run(AbstractJob.java:87) ~[ofbiz.jar:?]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_351]\r\n\r\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_351]\r\n\r\n2022-11-21 17:40:51,153 |OFBiz-JobQueue-0\u00a0\u00a0\u00a0\u00a0 |PersistedServiceJob\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |W| Persisted Job [10018] Failed. Max Retry Hit, not re-scheduling\r\n\r\n2022-11-21 17:41:46,108 |jsse-nio-8443-exec-7 |LoginWorker\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |W| Received a null Security object from HttpServletRequest\r\n\r\n2022-11-21 17:41:46,121 |jsse-nio-8443-exec-7 |ControlServlet\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| [[[FindInventoryEventPlan(Domain:[https://localhost|https://localhost/])] Request Begun, encoding=[UTF-8]- total:0.001,since last(Begin):0.001]]\r\n\r\n2022-11-21 17:41:46,180 |jsse-nio-8443-exec-7 |ConfigXMLReader\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| controller loaded: 0.005s, 149 requests, 66 views in file:/Users/yannonghuang/ofbiz/ofbiz-framework/applications/manufacturing/webapp/manufacturing/WEB-INF/controller.xml\r\n\r\n2022-11-21 17:41:46,196 |jsse-nio-8443-exec-7 |ConfigXMLReader\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| controller loaded: 0.001s, 49 requests, 21 views in file:/Users/yannonghuang/ofbiz/ofbiz-framework/framework/common/webcommon/WEB-INF/common-controller.xml\r\n\r\n2022-11-21 17:41:46,207 |jsse-nio-8443-exec-7 |ConfigXMLReader\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| controller loaded: 0.0s, 0 requests, 0 views in file:/Users/yannonghuang/ofbiz/ofbiz-framework/framework/common/webcommon/WEB-INF/handlers-controller.xml\r\n\r\n2022-11-21 17:41:46,217 |jsse-nio-8443-exec-7 |ConfigXMLReader\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| controller loaded: 0.0s, 4 requests, 0 views in file:/Users/yannonghuang/ofbiz/ofbiz-framework/applications/commonext/webapp/WEB-INF/controller.xml\r\n\r\n2022-11-21 17:41:46,222 |jsse-nio-8443-exec-7 |JWTManager\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Internal single sign on is disabled.\r\n\r\n2022-11-21 17:41:46,237 |jsse-nio-8443-exec-7 |RequestHandler\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |I| Rendering View [FindMrpPlannedEvents].\u00a0 Hidden sessionId by default.\r\n\r\n2022-11-21 17:41:46,250 |jsse-nio-8443-exec-7 |ServiceDispatcher\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |T| Sync service [manufacturing/getUserPreferenceGroup] finished in [4] milliseconds\r\n{noformat}\r\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.0076091052033007145
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008642498403787613
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008219968527555466
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640743e08b22ceafe0d2b484",
        "key": "OPENNLP-1233",
        "id": "13208529",
        "description": "The link \"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\" provided with name \"Penn Treebank tag set\" in sections Tagging and Chunking of manual does not list tags used for chunking. A proper link is needed for anybody to develop applications using openNLP. Found some info on missing tags at \"https://www.clips.uantwerpen.be/pages/mbsp-tags\" but\u00a0 not sure if the link can be used in the manual.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.07340166717767715
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.0077539412304759026
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0047219558618962765
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d6055df4d395ee22215718",
        "key": "HBASE-9077",
        "id": "12660505",
        "description": "Region names and other unusually long strings really make the ui look weird.  We should go with a fluid ui width the minimize the breakage.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.013474530540406704
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.032099299132823944
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0048416838981211185
                }
            }
        },
        "comments": [
            {
                "author_name": "eclark",
                "id": "13732745",
                "body": "Pretty simple patch that should help ease the ui pains when there are long region names"
            },
            {
                "author_name": "hadoopqa",
                "id": "13732834",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12596708/HBASE-9077-0.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 hadoop1.0{color}.  The patch compiles against the hadoop 1.0 profile.\n\n    {color:green}+1 hadoop2.0{color}.  The patch compiles against the hadoop 2.0 profile.\n\n    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 lineLengths{color}.  The patch does not introduce lines longer than 100\n\n  {color:green}+1 site{color}.  The mvn site goal succeeds with this patch.\n\n     {color:red}-1 core tests{color}.  The patch failed these unit tests:\n                       org.apache.hadoop.hbase.TestFullLogReconstruction\n\nTest results: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-prefix-tree.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-client.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-common.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-protocol.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-server.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop1-compat.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-examples.html\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//artifact/trunk/patchprocess/newPatchFindbugsWarningshbase-hadoop-compat.html\nConsole output: https://builds.apache.org/job/PreCommit-HBASE-Build/6640//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "stack",
                "id": "13732878",
                "body": "+1\n\nTest failure is unrelated."
            },
            {
                "author_name": "hudson",
                "id": "13733006",
                "body": "SUCCESS: Integrated in hbase-0.95-on-hadoop2 #223 (See [https://builds.apache.org/job/hbase-0.95-on-hadoop2/223/])\nHBASE-9077 Make Web ui Fluid width (eclark: rev 1511532)\n* /hbase/branches/0.95/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon\n* /hbase/branches/0.95/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/regionserver/RSStatusTmpl.jamon\n* /hbase/branches/0.95/hbase-server/src/main/resources/hbase-webapps/master/table.jsp\n* /hbase/branches/0.95/hbase-server/src/main/resources/hbase-webapps/master/tablesDetailed.jsp\n* /hbase/branches/0.95/hbase-server/src/main/resources/hbase-webapps/master/zk.jsp\n* /hbase/branches/0.95/hbase-server/src/main/resources/hbase-webapps/thrift/thrift.jsp\n"
            },
            {
                "author_name": "hudson",
                "id": "13733041",
                "body": "SUCCESS: Integrated in HBase-TRUNK-on-Hadoop-2.0.0 #656 (See [https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/656/])\nHBASE-9077 Make Web ui Fluid width (eclark: rev 1511533)\n* /hbase/trunk/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon\n* /hbase/trunk/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/regionserver/RSStatusTmpl.jamon\n* /hbase/trunk/hbase-server/src/main/resources/hbase-webapps/master/table.jsp\n* /hbase/trunk/hbase-server/src/main/resources/hbase-webapps/master/tablesDetailed.jsp\n* /hbase/trunk/hbase-server/src/main/resources/hbase-webapps/master/zk.jsp\n* /hbase/trunk/hbase-server/src/main/resources/hbase-webapps/thrift/thrift.jsp\n"
            },
            {
                "author_name": "hudson",
                "id": "13733083",
                "body": "SUCCESS: Integrated in hbase-0.95 #414 (See [https://builds.apache.org/job/hbase-0.95/414/])\nHBASE-9077 Make Web ui Fluid width (eclark: rev 1511532)\n* /hbase/branches/0.95/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon\n* /hbase/branches/0.95/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/regionserver/RSStatusTmpl.jamon\n* /hbase/branches/0.95/hbase-server/src/main/resources/hbase-webapps/master/table.jsp\n* /hbase/branches/0.95/hbase-server/src/main/resources/hbase-webapps/master/tablesDetailed.jsp\n* /hbase/branches/0.95/hbase-server/src/main/resources/hbase-webapps/master/zk.jsp\n* /hbase/branches/0.95/hbase-server/src/main/resources/hbase-webapps/thrift/thrift.jsp\n"
            },
            {
                "author_name": "hudson",
                "id": "13733103",
                "body": "SUCCESS: Integrated in HBase-TRUNK #4353 (See [https://builds.apache.org/job/HBase-TRUNK/4353/])\nHBASE-9077 Make Web ui Fluid width (eclark: rev 1511533)\n* /hbase/trunk/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/master/MasterStatusTmpl.jamon\n* /hbase/trunk/hbase-server/src/main/jamon/org/apache/hadoop/hbase/tmpl/regionserver/RSStatusTmpl.jamon\n* /hbase/trunk/hbase-server/src/main/resources/hbase-webapps/master/table.jsp\n* /hbase/trunk/hbase-server/src/main/resources/hbase-webapps/master/tablesDetailed.jsp\n* /hbase/trunk/hbase-server/src/main/resources/hbase-webapps/master/zk.jsp\n* /hbase/trunk/hbase-server/src/main/resources/hbase-webapps/thrift/thrift.jsp\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5f655f4d395ee221f362b",
        "key": "JCR-4414",
        "id": "13214923",
        "description": "While running this command \"java -jar jackrabbit-standalone-2.18.0.jar --port 8085\" getting HTTP 500 Error and Jack-rabbit log getting \"java.io.FileNotFoundException: jackrabbit-standalone.jar\"\u00a0 Error.\r\n\r\nPlease note: the Same issue has been reported earlier and status is showing closed. But this issue still persists.\r\n\r\nThis same issue is happening for all the jars. Jack-rabbit standalone jar is unable to resolve it automatically. To resolve that issue we need to rename it into \"jackrabbit-standalone.jar\".",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.01536883320659399
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007837417535483837
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004346187226474285
                }
            }
        },
        "comments": [
            {
                "author_name": "reschke",
                "id": "16764797",
                "body": "bq.  the Same issue has been reported earlier and status is showing closed\r\n\r\nand the issue number was?"
            },
            {
                "author_name": "reschke",
                "id": "16765084",
                "body": "I have tried and it works for me, using Java 8, and both with default number and \"\u2013port 8085\".\r\n\r\n\u00a0\r\n\r\nPlease provide additional information (java version, platform, log files, etc)."
            },
            {
                "author_name": "debupaul009",
                "id": "16766062",
                "body": "Issue no was :\u00a0\r\n # JCR-4183"
            },
            {
                "author_name": "reschke",
                "id": "16766142",
                "body": "Please provide additional information (java version, platform, log files, etc)."
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "6407469b2112148e1181db4a",
        "key": "HADOOP-18458",
        "id": "13482259",
        "description": "Recently, our customers raise a requirement: AliyunOSSBlockOutputStream should support heap/off-heap buffer before uploading data to OSS.\r\n\r\nCurrently, AliyunOSSBlockOutputStream buffers data in local directory before uploading to OSS, it is not efficient compared to memory.\r\n\r\nChanges:\r\n # Adds heap/off-heap buffers\r\n # Adds limitation of memory used, and fallback to disk",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.09656401723623276
                },
                "existence": {
                    "prediction": true,
                    "confidence": 0.9867587685585022
                },
                "property": {
                    "prediction": true,
                    "confidence": 0.9750281572341919
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "64074392389f8b79a0d2aa48",
        "key": "LUCENE-5979",
        "id": "12744931",
        "description": "Now that some major filters such as TermsFilter and MultiTermQueryWrapperFilter return DocIdSets that have a better cost, we should switch to the cost API.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.007337319664657116
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.015563104301691055
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.03788459300994873
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d600b0f4d395ee2220b3a6",
        "key": "HIVE-1085",
        "id": "12446366",
        "description": null,
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.008603797294199467
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.013130678795278072
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0040861754678189754
                }
            }
        },
        "comments": [
            {
                "author_name": "nzhang",
                "id": "12803870",
                "body": "To elaborate, currently ColumnarSerDe is used if the hive.default.fileformat is set to RCFile. It should not ColumnarSerDe if the user specify a different storage format in DDL."
            },
            {
                "author_name": "he yongqiang",
                "id": "12803908",
                "body": "hive-1085.2.patch integrates Ning's offline comments. hive-1085.2.patch is more clear for future change. "
            },
            {
                "author_name": "nzhang",
                "id": "12803913",
                "body": "+1\n\nlooks good. Will commit once tests pass."
            },
            {
                "author_name": "nzhang",
                "id": "12803985",
                "body": "Committed. Thanks Yongqiang!"
            },
            {
                "author_name": "he yongqiang",
                "id": "12845701",
                "body": "patch for branch-0.5"
            },
            {
                "author_name": "nzhang",
                "id": "12845718",
                "body": "committed to 0.5. Thanks Yongqiang!"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d759f4d395ee2219884a",
        "key": "THRIFT-2313",
        "id": "12688632",
        "description": "The problem is due to the way Protocols and Transports handle the end of streams.\n\nBasically what happens is that we read a first message correctly, then we try to read another message from the buffer we have no more data\n\nSo, in TBinaryProtocol.readMessageBegin, we starts by reading an Int32 from the streambuffer, but as the buffer is empty, it return undefined, then the rest of the function is complete garbage (but it doesn't crash), so the exception is thrown from the processor. The MultiplexedProcessor see the error (by side effect), and throw a thrift.TException which is not catched by the server.\n\nIt doesn't happens with:\n  - TBufferedTransport because ensureAvailable is called before each reads\n  - TJSONProtocol because we check for the stream length before reading it (borrow + readindex)\n  - Non Multiplexed Protocol: because MultiplexedPrcessor throw its own error (thrift.TException) which is not catched above, however what happens is that a thrift exception is thrown on the wire after *each* requests when using regularprocessor/framedtransport/binaryprotocol\n\nI think that the best way to handle it is to check that there is enough data before extracting it from the buffer in the functions TBinaryProtocol.readInt/String/.... and to throw a underbuffer error if necessary",
        "predictions": {},
        "comments": [
            {
                "author_name": "chubinou",
                "id": "13870203",
                "body": "add patches\n\n0001 -> fix this issue\n0002 -> remove dependency upon Harmony as discussed [here|https://issues.apache.org/jira/browse/THRIFT-2205?focusedCommentId=13867914&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13867914]\n0003 -> split very long lines in nodes tests as suggested [here|https://issues.apache.org/jira/browse/THRIFT-2205?focusedCommentId=13868263&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13868263]\n"
            },
            {
                "author_name": "henrique",
                "id": "13870758",
                "body": "committed!\nthanks for the patches Pierre! I had to change patch 3 a bit to apply it and also removed all the unnecessary tabs.\n\nCheers,\nHenrique"
            },
            {
                "author_name": "chubinou",
                "id": "13870772",
                "body": "hi Henrique,\n\ngreat, thank you.\n\nSorry for the tab, I thought I checked them. In my defense tab/space is quite inconsistent across node implementation (4spaces, 2spaces, tab+ spaces, ...), CRLF LF differences also\n\nPierre"
            },
            {
                "author_name": "hudson",
                "id": "13870811",
                "body": "SUCCESS: Integrated in Thrift #1001 (See [https://builds.apache.org/job/Thrift/1001/])\nTHRIFT-2313 nodejs server crash after processing the first request when using MultiplexedProcessor/FramedBuffer/BinaryProtocol (henrique: rev 216374ec4a72cbabf7c76dd9284362aba4d30f1c)\n* test/nodejs/multiplex_client.js\n* test/nodejs/thrift_test_driver.js\n* test/nodejs/Makefile.am\n* lib/nodejs/lib/thrift/transport.js\n* lib/nodejs/lib/thrift/multiplexed_processor.js\n"
            }
        ],
        "comments_predictions": [
            [
                425153,
                "THRIFT-2313",
                "add patches\n\n0001 -> fix this issue\n0002 -> remove dependency upon Harmony as discussed [here|https://issues.apache.org/jira/browse/THRIFT-2205?focusedCommentId=13867914&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13867914]\n0003 -> split very long lines in nodes tests as suggested [here|https://issues.apache.org/jira/browse/THRIFT-2205?focusedCommentId=13868263&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13868263]\n",
                {
                    "property": {
                        "confidence": 0.004634053912013769,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.31536993384361267,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008009974844753742,
                        "prediction": false
                    }
                }
            ],
            [
                425155,
                "THRIFT-2313",
                "hi Henrique,\n\ngreat, thank you.\n\nSorry for the tab, I thought I checked them. In my defense tab/space is quite inconsistent across node implementation (4spaces, 2spaces, tab+ spaces, ...), CRLF LF differences also\n\nPierre",
                {
                    "property": {
                        "confidence": 0.006088968366384506,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010730813257396221,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008684913627803326,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d61d07f4d395ee2224a19f",
        "key": "CB-10140",
        "id": "12919018",
        "description": "I've been working on a new plugin for Cordova which will allow you to easily deploy different build types in a system lifecycle e.g. alpha, beta and store. This will allow multiple instances of the same app on your device in different states. Currently I've hit a bit of an interesting bug/issue when using this in conjunction with the run command. When the plugin operates it dynamically changes the application id depending on the state so com.test.app becomes com.test.app.alpha and so son. Because of this, when running the app from the CLI it then starts using the incorrect ID (it uses the packageName from the Android Manifest and tries to run nothing or the wrong instance). \n\nEDIT: See the PR for a suggested fix, and if you wish to try and replicate this issue the plugin is now available here: https://github.com/CookieCookson/cordova-plugin-lifecycle",
        "predictions": {},
        "comments": [
            {
                "author_name": "riknoll",
                "id": "15047822",
                "body": "[~Cookie_Cookson] This might be a bit easier to review if you submit it as a PR (just use the JIRA ID in the title and the ASF git bot will comment on this issue)."
            },
            {
                "author_name": "githubbot",
                "id": "15048322",
                "body": "GitHub user CookieCookson opened a pull request:\n\n    https://github.com/apache/cordova-android/pull/244\n\n    CB-10140 Use application id instead of package name when running\n\n    \n\nYou can merge this pull request into a Git repository by running:\n\n    $ git pull https://github.com/CookieCookson/cordova-android applicationid\n\nAlternatively you can review and apply these changes as the patch at:\n\n    https://github.com/apache/cordova-android/pull/244.patch\n\nTo close this pull request, make a commit to your master/trunk branch\nwith (at least) the following in the commit message:\n\n    This closes #244\n    \n----\ncommit 6b0cdfc6b8cba99669ff689316533f6f48ecb110\nAuthor: Christian Cook <christian@elixel.co.uk>\nDate:   2015-12-03T14:00:36Z\n\n    create aapt function to get application id from apk\n\ncommit ea1e09fb85d65248030d406340b3ff49225fdebf\nAuthor: Christian Cook <christian@elixel.co.uk>\nDate:   2015-12-03T14:00:54Z\n\n    use application id in device installs\n\ncommit 1ed0b8547fb4551416c471599c41e085d4a288cd\nAuthor: Christian Cook <christian@elixel.co.uk>\nDate:   2015-12-04T11:04:59Z\n\n    fixes applicationId not being set for uninstall process\n\ncommit dd57d1542ad2a369955a39bffbcd4cdacef0df8c\nAuthor: Christian Cook <christian@elixel.co.uk>\nDate:   2015-12-04T15:53:57Z\n\n    uses application id on emulator install\n\n----\n"
            },
            {
                "author_name": "Cookie_Cookson",
                "id": "15048335",
                "body": "[~riknoll] I've submitted it as a PR and also included a link to the plugin to test with in the description."
            },
            {
                "author_name": "githubbot",
                "id": "15048386",
                "body": "Github user vladimir-kotikov commented on the pull request:\n\n    https://github.com/apache/cordova-android/pull/244#issuecomment-163165235\n  \n    @CookieCookson, LGTM, though I'm not sure about situations when this would be useful.\n    \n    However the problem here is that aapt might be not in the $PATH, so probably you need to check this and set up $PATH correspondingly in [check_reqs](https://github.com/apache/cordova-android/blob/master/bin/lib/check_reqs.js)\n"
            },
            {
                "author_name": "githubbot",
                "id": "15050410",
                "body": "Github user CookieCookson commented on the pull request:\n\n    https://github.com/apache/cordova-android/pull/244#issuecomment-163540285\n  \n    @vladimir-kotikov Thanks for the response! I have created the PR as a fix to an issue with a plugin I am developing. See https://github.com/CookieCookson/cordova-plugin-lifecycle and it should explain its use. \n    \n    I shall investigate check_reqs.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15050617",
                "body": "Github user vladimir-kotikov commented on the pull request:\n\n    https://github.com/apache/cordova-android/pull/244#issuecomment-163582855\n  \n    Thanks for explanation, @CookieCookson\n"
            },
            {
                "author_name": "githubbot",
                "id": "15453449",
                "body": "Github user infil00p commented on the issue:\n\n    https://github.com/apache/cordova-android/pull/244\n  \n    @CookieCookson This seems to have fallen by the wayside for quite a few months.  Are you still looking to add this, or should I close it since it no longer merges cleanly?\n"
            },
            {
                "author_name": "githubbot",
                "id": "15454695",
                "body": "Github user CookieCookson commented on the issue:\n\n    https://github.com/apache/cordova-android/pull/244\n  \n    @infil00p I haven't had the time available to work any more on this, and have got around the issue by other means! I would say close it for now.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15454696",
                "body": "Github user CookieCookson closed the pull request at:\n\n    https://github.com/apache/cordova-android/pull/244\n"
            },
            {
                "author_name": "githubbot",
                "id": "15466348",
                "body": "Github user fredgalvao commented on the issue:\n\n    https://github.com/apache/cordova-android/pull/244\n  \n    @infil00p This issue still exists. For anyone changin applicationId on android, to use flavours or whitelabel-like solutions, running cordova will always try to launch the base package name. It should definitely launch the applicationId instead. I mistakenly created [another issue](https://issues.apache.org/jira/browse/CB-11374) a while ago for this, and I just now discovered this issue because of the mailing list notifications.\n    \n    I'd love to see this topic being fixed/improved. There are a few other comments in [this issue](https://issues.apache.org/jira/browse/CB-11373) as well, regarding this subject.\n"
            },
            {
                "author_name": "githubbot",
                "id": "15467626",
                "body": "Github user infil00p commented on the issue:\n\n    https://github.com/apache/cordova-android/pull/244\n  \n    @fredgalvao The PR was closed, not the issue.  \n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5efb1f4d395ee221e0ee9",
        "key": "MARMOTTA-553",
        "id": "12748567",
        "description": "but is shows the ids or something like that",
        "predictions": {},
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "14173668",
                "body": "Commit a8dc9014d44922c46e5b03cb036ccdd79e8c0d26 in marmotta's branch refs/heads/develop from [~wikier]\n[ https://git-wip-us.apache.org/repos/asf?p=marmotta.git;h=a8dc901 ]\n\nMARMOTTA-553: recovered reasoner justifications\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14173669",
                "body": "Commit 63832d43c828f64721ed5b32945727d18bdc5c7d in marmotta's branch refs/heads/develop from [~wikier]\n[ https://git-wip-us.apache.org/repos/asf?p=marmotta.git;h=63832d4 ]\n\nMARMOTTA-553: cosmetics\n"
            },
            {
                "author_name": "jira-bot",
                "id": "14173670",
                "body": "Commit bac15e8caedaf07550457df337ee00e55ff15d4a in marmotta's branch refs/heads/develop from [~wikier]\n[ https://git-wip-us.apache.org/repos/asf?p=marmotta.git;h=bac15e8 ]\n\nMARMOTTA-553: cleanup\n"
            },
            {
                "author_name": "jakob",
                "id": "14248071",
                "body": "[Apache Marmotta 3.3.0 released|http://s.apache.org/sXH]"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d60bfaf4d395ee2222312a",
        "key": "GEODE-6073",
        "id": "13199202",
        "description": "_As a_ Engineer building on Windows\r\n _I want_ spotless to pass\r\n _So that_ I feel confident in changes I'm going to make\r\n\r\n*Given* I have freshly cloned Geode\r\n *When* I run {{.\\gradlew.bat build}}\r\n *Then* I see a successful build with no Spotless errors\r\n\r\nNotes:\u00a0 This was based on the following conversation in the [dev list|https://markmail.org/message/2jippxjsl6a6r6ae]",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.009108861908316612
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007269301917403936
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.008458774536848068
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "16693767",
                "body": "Commit be99d7be0dd92159fc69856b8d26a046c3989e37 in geode's branch refs/heads/develop from M. Oleske\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=be99d7b ]\n\nGEODE-6073:  All files have lf endings (#2873)\n\n- Spotless no longer uses line endings check as it is not recommened\r\n- https://github.com/diffplug/spotless/tree/master/plugin-gradle#line-endings-and-encodings-invisible-stuff"
            },
            {
                "author_name": "jira-bot",
                "id": "16695384",
                "body": "Commit be99d7be0dd92159fc69856b8d26a046c3989e37 in geode's branch refs/heads/feature/GEODE-6034 from M. Oleske\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=be99d7b ]\n\nGEODE-6073:  All files have lf endings (#2873)\n\n- Spotless no longer uses line endings check as it is not recommened\r\n- https://github.com/diffplug/spotless/tree/master/plugin-gradle#line-endings-and-encodings-invisible-stuff"
            },
            {
                "author_name": "jira-bot",
                "id": "16699359",
                "body": "Commit 184dd3c81b9f23cfef6552b33b083ceaa4c90896 in geode's branch refs/heads/develop from Jacob Barrett\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=184dd3c ]\n\nGEODE-6090: Reverting changes, causes new clones to get modified files.\n\nRevert \"GEODE-6073:  All files have lf endings (#2873)\"\n\nThis reverts commit be99d7be0dd92159fc69856b8d26a046c3989e37.\n"
            },
            {
                "author_name": "jira-bot",
                "id": "16699423",
                "body": "Commit 184dd3c81b9f23cfef6552b33b083ceaa4c90896 in geode's branch refs/heads/GEODE-5547-RegionManagementDUnitTest from Jacob Barrett\n[ https://gitbox.apache.org/repos/asf?p=geode.git;h=184dd3c ]\n\nGEODE-6090: Reverting changes, causes new clones to get modified files.\n\nRevert \"GEODE-6073:  All files have lf endings (#2873)\"\n\nThis reverts commit be99d7be0dd92159fc69856b8d26a046c3989e37.\n"
            },
            {
                "author_name": "moleske",
                "id": "16747550",
                "body": "closing cause it seems I was able to fix this locally without a PR (at least for now) by doing\r\n\r\n{{C:\\Projects\\geode [develop \u2261]> .\\gradlew.bat spotlessApply}}\r\n {{C:\\Projects\\geode [develop \u2261]> git add .}}\r\n\r\nAnd there were no changes to push. So \u00af\\_(\u30c4)_/\u00af"
            }
        ],
        "comments_predictions": [
            [
                2750995,
                "GEODE-6073",
                "closing cause it seems I was able to fix this locally without a PR (at least for now) by doing\r\n\r\n{{C:\\Projects\\geode [develop \u2261]> .\\gradlew.bat spotlessApply}}\r\n {{C:\\Projects\\geode [develop \u2261]> git add .}}\r\n\r\nAnd there were no changes to push. So \u00af\\_(\u30c4)_/\u00af",
                {
                    "property": {
                        "confidence": 0.006268051918596029,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00997241586446762,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007920158095657825,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5d9bbf4d395ee221a3518",
        "key": "SQOOP-3081",
        "id": "13027747",
        "description": "Introduce OracleEscapeUtils.escapeIdentifiers In OracleUpsertOutputFormat to make it consistent with the rest of the code and compatible with SQOOP-3066.\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.03148709610104561
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.007368622813373804
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0036927408073097467
                }
            }
        },
        "comments": [
            {
                "author_name": "jira-bot",
                "id": "15754186",
                "body": "Commit d1e6c5f52f8913a619cfe77c87970d7938c84844 in sqoop's branch refs/heads/trunk from [~maugli]\n[ https://git-wip-us.apache.org/repos/asf?p=sqoop.git;h=d1e6c5f ]\n\nSQOOP-3081: use OracleEscapeUtils.escapeIdentifier\nin OracleUpsertOutputFormat instead of inline\nappending quotes\n\n(Anna Szonyi via Attila Szabo)\n"
            },
            {
                "author_name": "maugli",
                "id": "15754189",
                "body": "Hey [~szonyi],\n\nThanks for spotting this! Made a code easier to maintain!\n\nThanks,\n[~maugli]"
            },
            {
                "author_name": "hudson",
                "id": "15754225",
                "body": "SUCCESS: Integrated in Jenkins build Sqoop-hadoop23 #1283 (See [https://builds.apache.org/job/Sqoop-hadoop23/1283/])\nSQOOP-3081: use OracleEscapeUtils.escapeIdentifier in (maugli: [https://git-wip-us.apache.org/repos/asf?p=sqoop.git&a=commit&h=d1e6c5f52f8913a619cfe77c87970d7938c84844])\n* (edit) src/test/com/cloudera/sqoop/manager/OracleExportTest.java\n* (edit) src/java/org/apache/sqoop/mapreduce/OracleUpsertOutputFormat.java\n"
            },
            {
                "author_name": "hudson",
                "id": "15754275",
                "body": "SUCCESS: Integrated in Jenkins build Sqoop-hadoop100 #1047 (See [https://builds.apache.org/job/Sqoop-hadoop100/1047/])\nSQOOP-3081: use OracleEscapeUtils.escapeIdentifier in (maugli: [https://git-wip-us.apache.org/repos/asf?p=sqoop.git&a=commit&h=d1e6c5f52f8913a619cfe77c87970d7938c84844])\n* (edit) src/java/org/apache/sqoop/mapreduce/OracleUpsertOutputFormat.java\n* (edit) src/test/com/cloudera/sqoop/manager/OracleExportTest.java\n"
            },
            {
                "author_name": "hudson",
                "id": "15754288",
                "body": "SUCCESS: Integrated in Jenkins build Sqoop-hadoop200 #1088 (See [https://builds.apache.org/job/Sqoop-hadoop200/1088/])\nSQOOP-3081: use OracleEscapeUtils.escapeIdentifier in (maugli: [https://git-wip-us.apache.org/repos/asf?p=sqoop.git&a=commit&h=d1e6c5f52f8913a619cfe77c87970d7938c84844])\n* (edit) src/java/org/apache/sqoop/mapreduce/OracleUpsertOutputFormat.java\n* (edit) src/test/com/cloudera/sqoop/manager/OracleExportTest.java\n"
            },
            {
                "author_name": "hudson",
                "id": "15754327",
                "body": "SUCCESS: Integrated in Jenkins build Sqoop-hadoop20 #1082 (See [https://builds.apache.org/job/Sqoop-hadoop20/1082/])\nSQOOP-3081: use OracleEscapeUtils.escapeIdentifier in (maugli: [https://git-wip-us.apache.org/repos/asf?p=sqoop.git&a=commit&h=d1e6c5f52f8913a619cfe77c87970d7938c84844])\n* (edit) src/test/com/cloudera/sqoop/manager/OracleExportTest.java\n* (edit) src/java/org/apache/sqoop/mapreduce/OracleUpsertOutputFormat.java\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "61d5d376f4d395ee22186103",
        "key": "YARN-3071",
        "id": "12768368",
        "description": "copying and pasting conf causes failure on RM startup\n{code}\nCaused by: org.xml.sax.SAXParseException; systemId: file:/home/iwasakims/dist/hadoop-2.6.0/etc/hadoop/fair-scheduler.xml; lineNumber: 18; columnNumber: 5; The content of elements must consist of well-formed character data or markup.\n        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)\n        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)\n        at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:205)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.AllocationFileLoaderService.reloadAllocations(AllocationFileLoaderService.java:250)\n        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.initScheduler(FairScheduler.java:1275)\n        ... 9 more\n{code}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.010093278251588345
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.008346550166606903
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.005663779564201832
                }
            }
        },
        "comments": [
            {
                "author_name": "aajisaka",
                "id": "14282243",
                "body": "Thanks Masatake for the report and the patch. The detail of the issue is the first {{\u2014}} of\n{code}\n  <!\u2014- Queue 'secondary_group_queueue' is a parent queue and may have\n{code}\nis actually a em dash(U+2014)."
            },
            {
                "author_name": "aajisaka",
                "id": "14282249",
                "body": "The fix looks good to me.\nWould you fix {{'secondary_group_queueue'}} to {{'secondary_group_queue'}} also?\n"
            },
            {
                "author_name": "iwasakims",
                "id": "14282311",
                "body": "Thanks for the comment. I attached updated patch."
            },
            {
                "author_name": "aajisaka",
                "id": "14282417",
                "body": "+1 pending Jenkins."
            },
            {
                "author_name": "hadoopqa",
                "id": "14282447",
                "body": "{color:green}+1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12693053/YARN-3071.002.patch\n  against trunk revision 19cbce3.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:green}+0 tests included{color}.  The patch appears to be a documentation patch that doesn't require tests.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in .\n\nTest results: https://builds.apache.org/job/PreCommit-YARN-Build/6358//testReport/\nConsole output: https://builds.apache.org/job/PreCommit-YARN-Build/6358//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "aajisaka",
                "id": "14282452",
                "body": "Committed this to trunk and branch-2. Thanks [~iwasakims] for the contribution."
            },
            {
                "author_name": "hudson",
                "id": "14282465",
                "body": "FAILURE: Integrated in Hadoop-trunk-Commit #6886 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6886/])\nYARN-3071. Remove invalid char from sample conf in doc of FairScheduler. (Contributed by Masatake Iwasaki) (aajisaka: rev 4a5c3a4cfee6b8008a722801821e64850582a985)\n* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm\n* hadoop-yarn-project/CHANGES.txt\n"
            },
            {
                "author_name": "hudson",
                "id": "14282587",
                "body": "FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #79 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/79/])\nYARN-3071. Remove invalid char from sample conf in doc of FairScheduler. (Contributed by Masatake Iwasaki) (aajisaka: rev 4a5c3a4cfee6b8008a722801821e64850582a985)\n* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm\n* hadoop-yarn-project/CHANGES.txt\n"
            },
            {
                "author_name": "hudson",
                "id": "14282603",
                "body": "SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2029 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2029/])\nYARN-3071. Remove invalid char from sample conf in doc of FairScheduler. (Contributed by Masatake Iwasaki) (aajisaka: rev 4a5c3a4cfee6b8008a722801821e64850582a985)\n* hadoop-yarn-project/CHANGES.txt\n* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm\n"
            },
            {
                "author_name": "hudson",
                "id": "14283687",
                "body": "FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #79 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/79/])\nYARN-3071. Remove invalid char from sample conf in doc of FairScheduler. (Contributed by Masatake Iwasaki) (aajisaka: rev 4a5c3a4cfee6b8008a722801821e64850582a985)\n* hadoop-yarn-project/CHANGES.txt\n* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm\n"
            },
            {
                "author_name": "hudson",
                "id": "14283741",
                "body": "FAILURE: Integrated in Hadoop-Yarn-trunk #813 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/813/])\nYARN-3071. Remove invalid char from sample conf in doc of FairScheduler. (Contributed by Masatake Iwasaki) (aajisaka: rev 4a5c3a4cfee6b8008a722801821e64850582a985)\n* hadoop-yarn-project/CHANGES.txt\n* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm\n"
            },
            {
                "author_name": "hudson",
                "id": "14283866",
                "body": "FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #76 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/76/])\nYARN-3071. Remove invalid char from sample conf in doc of FairScheduler. (Contributed by Masatake Iwasaki) (aajisaka: rev 4a5c3a4cfee6b8008a722801821e64850582a985)\n* hadoop-yarn-project/CHANGES.txt\n* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm\n"
            },
            {
                "author_name": "hudson",
                "id": "14283879",
                "body": "SUCCESS: Integrated in Hadoop-Hdfs-trunk #2011 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2011/])\nYARN-3071. Remove invalid char from sample conf in doc of FairScheduler. (Contributed by Masatake Iwasaki) (aajisaka: rev 4a5c3a4cfee6b8008a722801821e64850582a985)\n* hadoop-yarn-project/CHANGES.txt\n* hadoop-yarn-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/FairScheduler.apt.vm\n"
            }
        ],
        "comments_predictions": [
            [
                156013,
                "YARN-3071",
                "Thanks Masatake for the report and the patch. The detail of the issue is the first {{\u2014}} of\n{code}\n  <!\u2014- Queue 'secondary_group_queueue' is a parent queue and may have\n{code}\nis actually a em dash(U+2014).",
                {
                    "property": {
                        "confidence": 0.004149142652750015,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.022795284166932106,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007728769909590483,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "640743e834900d5078d2b1ad",
        "key": "ARROW-6621",
        "id": "13257744",
        "description": "See the CI scripts, we already test the examples for the Arrow sub-crate",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d617d5f4d395ee2223d912",
        "key": "DIRMINA-578",
        "id": "12395056",
        "description": "<dependency>\n\t<groupId>org.apache.mina</groupId>\n\t<version>1.1.7</version>\n\t<artifactId>mina-example</artifactId>\t\t\n</dependency>\nPlayer-1: READY\nPlayer-0: READY\nPlayer-0: RCVD PING (10)\nPlayer-1: SENT PING (10)\nPlayer-1: RCVD PONG (9)\nPlayer-0: SENT PONG (9)\nPlayer-0: RCVD PING (8)\nPlayer-1: SENT PING (8)\nPlayer-1: RCVD PONG (7)\nPlayer-0: SENT PONG (7)\nPlayer-0: RCVD PING (6)\nPlayer-1: SENT PING (6)\nPlayer-0: SENT PONG (5)\nPlayer-1: RCVD PONG (5)\nPlayer-1: SENT PING (4)\nPlayer-0: RCVD PING (4)\nPlayer-1: RCVD PONG (3)\nPlayer-0: SENT PONG (3)\nPlayer-0: RCVD PING (2)\nPlayer-1: SENT PING (2)\nPlayer-1: RCVD PONG (1)\nPlayer-1: LOSE\nPlayer-0: SENT PONG (1)\nPlayer-1: QUIT\nPlayer-0: QUIT\n\n\n\n<dependency>\n  <groupId>org.apache.mina</groupId>\n  <version>2.0.0-M1</version>\n\t<artifactId>mina-example</artifactId>\t\t\n</dependency>\nPlayer-1: READY\nPlayer-0: READY\nPlayer-0: RCVD PING (10)\nPlayer-1: RCVD PONG (9)\nPlayer-0: RCVD PING (8)\nPlayer-1: RCVD PONG (7)\nPlayer-0: RCVD PING (6)\nPlayer-1: RCVD PONG (5)\nPlayer-0: RCVD PING (4)\nPlayer-1: RCVD PONG (3)\nPlayer-0: RCVD PING (2)\nPlayer-1: RCVD PONG (1)\nPlayer-1: LOSE\nPlayer-1: QUIT\nPlayer-0: QUIT\nPlayer-0: SENT PONG (1)\nPlayer-1: SENT PING (2)\nPlayer-0: SENT PONG (3)\nPlayer-1: SENT PING (4)\nPlayer-0: SENT PONG (5)\nPlayer-1: SENT PING (6)\nPlayer-0: SENT PONG (7)\nPlayer-1: SENT PING (8)\nPlayer-0: SENT PONG (9)\nPlayer-1: SENT PING (10)",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.3443767726421356
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.006755283568054438
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006240664981305599
                }
            }
        },
        "comments": [
            {
                "author_name": "trustin",
                "id": "12596633",
                "body": "Should be fixed now.  This issue appears when it runs without an executorfilter.  I queued messageSent event to the internal event queue first, and then flushed the event queue later.  Brevious implementation didn't utilize the event queue but relied on method invocation, which leads to reversed event order."
            }
        ],
        "comments_predictions": [
            [
                3182739,
                "DIRMINA-578",
                "Should be fixed now.  This issue appears when it runs without an executorfilter.  I queued messageSent event to the internal event queue first, and then flushed the event queue later.  Brevious implementation didn't utilize the event queue but relied on method invocation, which leads to reversed event order.",
                {
                    "property": {
                        "confidence": 0.00498900655657053,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006391590926796198,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018537892028689384,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "6407445f029964588d33b277",
        "key": "BEAM-12183",
        "id": "13373606",
        "description": "\n\n ------------------------- 2021-04-19 12:31:36.204466 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-04-26 12:30:20.874702 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-05-03 12:29:16.792222 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-05-10 12:29:29.519031 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-05-17 12:30:00.091114 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-05-24 12:29:54.221799 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-05-31 12:31:24.864242 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-06-08 17:31:17.932924 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-06-14 12:35:03.624310 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-06-21 12:33:39.757352 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-06-28 12:32:46.157093 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-07-05 12:35:40.553152 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-07-19 12:35:08.112477 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-07-26 12:34:45.913171 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-02 12:34:09.284543 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-09 12:42:47.202549 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-16 12:39:14.990443 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-23 12:48:21.027716 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-08-30 12:41:44.104802 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-09-06 12:41:53.790259 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-09-13 12:39:18.423992 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 2.8.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-09-20 12:33:50.564172 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-09-27 12:34:45.155250 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-10-04 12:38:21.107885 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-10-11 12:34:23.153611 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-11-18 05:20:03.483169 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-11-22 12:24:13.776569 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-11-29 12:22:07.919627 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-12-06 12:24:00.628453 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-12-13 12:24:19.936595 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-12-20 12:26:05.237378 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2021-12-27 12:21:49.701133 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-01-03 12:22:35.501114 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-01-10 12:23:28.015491 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-01-17 12:22:54.092125 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.0.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-01-24 12:22:43.428066 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-01-31 12:29:24.327556 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-02-07 15:12:52.898067 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-02-14 12:26:52.676603 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-02-21 18:17:42.502160 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-02-28 12:23:30.580081 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-03-07 12:28:53.894826 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-03-14 12:33:53.315142 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-03-21 12:24:50.411695 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-03-28 12:27:16.893802 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-04-07 16:24:37.701262 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-04-14 16:30:46.491037 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-04-21 16:28:56.906698 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-05-05 16:25:55.883312 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.1.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-05-12 16:25:20.061024 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.2.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-05-19 16:28:15.344134 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.2.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-05-26 16:30:37.780269 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.2.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n\n\n ------------------------- 2022-06-02 16:27:32.795917 -------------------------\n\n        Please consider upgrading the dependency org.apache.kafka:connect-api. \n\n        The current version is 2.5.0. The latest version is 3.2.0 \n\n        cc: \n Please refer to [Beam Dependency Guide |https://beam.apache.org/contribute/dependencies/]for more information. \nDo Not Modify The Description Above. \n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": true,
                    "confidence": 0.6909461617469788
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.011439823545515537
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.010783325880765915
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d62e56f4d395ee2226e9c2",
        "key": "AMBARI-17148",
        "id": "12977346",
        "description": "Ambari sets RMAUDIT and NMAUDIT loggers by default for YARN. \n{code}rm.audit.logger=INFO,RMAUDIT\n..\nnm.audit.logger=INFO,NMAUDIT\n..{code}\n\nThis config leads to log4j errors while running yarn-cli command. \n{code}\n yarn application -list\nlog4j:ERROR setFile(null,true) call failed.\njava.io.FileNotFoundException: /xx/nm-audit.log (No such file or directory)\n\tat java.io.FileOutputStream.open0(Native Method)\n\tat java.io.FileOutputStream.open(FileOutputStream.java:270)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:213)\n\tat java.io.FileOutputStream.<init>(FileOutputStream.java:133)\n\tat org.apache.log4j.FileAppender.setFile(FileAppender.java:294)\n\tat org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165)\n\tat org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:223)\n\tat org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307)\n\tat org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172)\n\tat org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104)\n\tat org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842)\n\tat org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768)\n\tat org.apache.log4j.PropertyConfigurator.parseCatsAndRenderers(PropertyConfigurator.java:672){code}\n\nIn YARN's case, rm.audit.logger should be set when starting RM only and nm.audit.logger when starting NMs only. ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.010282306000590324
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.01564946584403515
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.0038816158194094896
                }
            }
        },
        "comments": [
            {
                "author_name": "hadoopqa",
                "id": "15327528",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12809856/AMBARI-17148.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in ambari-server.\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/7319//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/7319//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "15327562",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12809856/AMBARI-17148.patch\n  against trunk revision .\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in ambari-server.\n\nTest results: https://builds.apache.org/job/Ambari-trunk-test-patch/7320//testReport/\nConsole output: https://builds.apache.org/job/Ambari-trunk-test-patch/7320//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "aonishuk",
                "id": "15327819",
                "body": "Committed to trunk and branch-2.4"
            },
            {
                "author_name": "hudson",
                "id": "15328229",
                "body": "FAILURE: Integrated in Ambari-trunk-Commit #5068 (See [https://builds.apache.org/job/Ambari-trunk-Commit/5068/])\nAMBARI-17148. yarncli throws log4j error \"FileNotFoundException : (aonishuk: [http://git-wip-us.apache.org/repos/asf?p=ambari.git&a=commit&h=fed0aae1495a7a8a445758ae38ad2c77e3881c2f])\n* ambari-server/src/main/resources/stacks/HDP/2.3/services/YARN/configuration/yarn-env.xml\n* ambari-server/src/main/resources/common-services/YARN/2.1.0.2.0/configuration/yarn-env.xml\n* ambari-server/src/main/resources/stacks/HDP/2.1/services/YARN/configuration/yarn-env.xml\n"
            }
        ],
        "comments_predictions": {}
    },
    {
        "_id": "640744b1aa1c3d637833b959",
        "key": "DISPATCH-2325",
        "id": "13426507",
        "description": "{noformat}\r\ntest 68\r\n\u00a0 \u00a0 \u00a0 Start 68: system_tests_routing_protocol68: Test command: /usr/bin/python3 \"/__w/qpid-dispatch/qpid-dispatch/qpid-dispatch/build/tests/run.py\" \"-m\" \"pytest\" \"-vs\" \"--junit-prefix=pytest.system_tests_routing_protocol\" \"--junit-xml=junitxmls/system_tests_routing_protocol.xml\" \"--pyargs\" \"system_tests_routing_protocol\"\r\n37/37 Test #68: system_tests_routing_protocol .....................***Timeout 1200.04 sec {noformat}\r\n\u00a0\r\n\r\nhttps://github.com/apache/qpid-dispatch/runs/5041374330?check_suite_focus=true",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640743bec8b42db502d2adb1",
        "key": "HIVE-19382",
        "id": "13156495",
        "description": "To ensure correctness, in particular for operations that require exclusive ({{INSERT OVERWRITE}}) and semishared ({{UPDATE}}/{{DELETE}}) locks.\r\n\r\nThis is a temporary fix till lock acquisition is moved before analyze in HIVE-18948.\r\n\r\nWith this fix, system proceed as follows. The driver will acquire the snapshot, compile the query wrt that snapshot, and then, it will acquire locks. If snapshot is still valid, it will continue as usual. But if snapshot is not valid anymore, it will recompile the query.\r\n\r\nThis is easier to implement than full solution described in HIVE-18948 because we do not need to move the logic to extract the read/write entities from a query before compilation (actually while parsing).",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.004254360683262348
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.48507529497146606
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.060933977365493774
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "640743ba981a90ab29d2b04c",
        "key": "ARROW-1654",
        "id": "13107401",
        "description": "In [26]: t\nOut[26]: DataType(int64)\n\nIn [25]: pickle.dumps(t)\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-25-f90063f6658b> in <module>()\n----> 1 pickle.dumps(t)\n\n/home/icexelloss/miniconda3/envs/spark-dev/lib/python3.5/site-packages/pyarrow/lib.cpython-35m-x86_64-linux-gnu.so in pyarrow.lib.DataType.__reduce_cython__()\n\nTypeError: no default __reduce__ due to non-trivial __cinit__\n\nThis is discovered when trying to send a pa.DataType along with a udf in pyspark. The workaround is to send pyspark DataType and convert to pa.DataType. It would be nice to able to pickle pa.DataType.",
        "predictions": {},
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d600b0f4d395ee2220a507",
        "key": "HIVE-4844",
        "id": "12657385",
        "description": "Add new varchar data types which have support for more SQL-compliant behavior, such as SQL string comparison semantics, max length, etc.\nChar type will be added as another task.\n",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.3881209194660187
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.15910471975803375
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006599758751690388
                }
            }
        },
        "comments": [
            {
                "author_name": "jdere",
                "id": "13724257",
                "body": "Initial patch of progress, as other folks may be interested in type parameters for HIVE-3976."
            },
            {
                "author_name": "xuefuz",
                "id": "13724626",
                "body": "[~jdere] Thanks for sharing your work. I went thru your patch and had some initial questions. I understand that your patch is still in progress, but I'm wondering what's your thought on how you plan to store the type params. Obviously, type params are metadata of a column, which needs to be stored. I assume that hive schema needs to change to accommodate this.\n\nSecondly, SQL VAR or VARCHAR seems to be special hive string with additional restriction. Your patch seems treating them independently. Do you think if type inheritance works here?\n\nLastly, introducing param types seems non-trivial. Do you think if a design doc or wiki page makes sense?"
            },
            {
                "author_name": "jdere",
                "id": "13724729",
                "body": "Hi Xuefu, \n\n- The patch currently just keeps the params as part of the type string, which means no metastore changes, but could be brittle in other situations. An alternative could be additional columns in the COLUMNS metastore table to hold type qualifiers, similar to what other DB catalogs have, or a separate table of column_id/param_name/param_value. Do you have any suggestions here?\n\n- For inheritance, do you mean for the primitive/writable types? String is a final class, so I don't think it's doable for the primitive. I suppose the writable could derive from Text. \n\n- Sure, a wiki page makes sense.  I'll put one up once I get wiki access."
            },
            {
                "author_name": "xuefuz",
                "id": "13725695",
                "body": "[~jdere]:\n\n1. I'm not sure which way is the better, but I feel that adding additional columns seems cleaner in my opinion.\n\n2. I could be off the topic on inheritance. I guess what I tried to say was some types, for instance, string, CHAR, and VARCHAR are very similar and may share a lot of implementations. This would also apply to DECIMAL and DECIMAL(p,s) also. However, I haven't figured out the implications yet. Please share your insights. "
            },
            {
                "author_name": "appodictic",
                "id": "13725702",
                "body": "Ideally it would be best if by default the field has no parameters to not have to store any additional data in the metastore. "
            },
            {
                "author_name": "jdere",
                "id": "13725983",
                "body": "Added a doc to the wiki at https://cwiki.apache.org/confluence/display/Hive/Type+Qualifiers+in+Hive. \n\nEd, for the metastore changes, would additional columns in the COLUMNS_V2 metastore table be fine, if they are set to NULLs if there are no type qualifiers?\n\nXuefu, yeah for char/varchar I was thinking they could probably share some inheritance, especially since they need to do some length checking, though I hadn't really thought about if they should share with existing String/Text. Well, they can't inherit String as I mentioned before.  For decimal/decimal(p,s), I think the  existing HiveDecimal might be fine, since I think the actual enforcement of precision/scale might happen at the ObjectInspectors/Converters/cast/deserialization. "
            },
            {
                "author_name": "jdere",
                "id": "13740169",
                "body": "Progress patch at https://reviews.facebook.net/D12255"
            },
            {
                "author_name": "xuefuz",
                "id": "13745284",
                "body": "[~jdere] It seems that the patch here and what you posted on fb rb are out of sync. Would you mind updating your patch here? Also, fb rb seems showing diff incorrectly, which is a little bothersome. Thanks."
            },
            {
                "author_name": "jdere",
                "id": "13745319",
                "body": "I'd expect those two patches to be very different as there were a number of changes made between the first patch here and the one on phabricator. What is the issue you see with the diff on phabricator? It was too large to upload using the arc command so I had to use the --less-context option. "
            },
            {
                "author_name": "jdere",
                "id": "13745323",
                "body": "Also note that this has not been re-based in a while - last commit I have in my branch is 9fa33a6d0e7c18d6b94a29e8b6ef928126c9f274 from 2013-07-28."
            },
            {
                "author_name": "jdere",
                "id": "13745327",
                "body": "Patch with changes from https://reviews.facebook.net/D12255. I actually have made a number of changes since then and will upload a new one shortly."
            },
            {
                "author_name": "jdere",
                "id": "13745393",
                "body": "Bit more progress since last phabricator patch. "
            },
            {
                "author_name": "jdere",
                "id": "13745404",
                "body": "Been going over some of these changes with Gunther Hagleitner, and his input was that the metastore changes are not necessary for the varchar/decimal type qualifiers. The type name string is able to hold the whole type description, and in fact the nested types (struct/map/list) are simply represented as strings in the metastore. I'll look into reverting the metastore changes in the patch, and possibly some TypeQualifier-related changes if it makes sense. "
            },
            {
                "author_name": "xuefuz",
                "id": "13745527",
                "body": "{quote}\nWhat is the issue you see with the diff on phabricator? \n{quote}\n\nI don't if this is normal, I attached a screenshot to describe what I saw."
            },
            {
                "author_name": "jdere",
                "id": "13745545",
                "body": "Sorry, still not really sure what the issues is that you're having with the Phabricator diff? But if you are trying to see more of the file through the web page, Phabricator is unable to do so because the diff upload was too large for Phabricator, and so I had to use the --less-context option when I uploaded"
            },
            {
                "author_name": "xuefuz",
                "id": "13745566",
                "body": "I'm sorry that I wasn't clear. Looking at the diff, I assumed that the lines in green are new additions. However, {code}<field name=\"characterMaximumLength\" >{code} is new but is not green, while {code}</embedded>{code} is not new yet is green. It seems to me that the diff is one line off. Or my understanding is off? :)"
            },
            {
                "author_name": "xuefuz",
                "id": "13745576",
                "body": "Re: type name vs additional columns\n\nBy instinct I think latter suggests a cleaner approach while the former seems a little \"hacky\" as we put semantics in the type name, similar to putting a person's name and age in the same column. Having said that, I'm open to that approach. I just wasn't clear about all the benefits of it besides trying to save a schema upgrade."
            },
            {
                "author_name": "jdere",
                "id": "13745674",
                "body": "Yeah, the diff does appear to be a bit off, doesn't look like it's very useful does it?  Might be better off just looking at the diff or applying it to 9fa33a6d0e7c18d6b94a29e8b6ef928126c9f274.  I hope arcanist generated the diff properly.\n\nRemoving the metastore changes does make some things a bit more consistent, since there were times where we were just trying to use the base type name for varchar, but in other instances where it was being used in a nested type we would use the full name.  "
            },
            {
                "author_name": "jdere",
                "id": "13745745",
                "body": "reverted metastore changes"
            },
            {
                "author_name": "jdere",
                "id": "13748095",
                "body": "Attaching HIVE-4844.5.patch:\n- JDBC changes\n- FunctionRegistry.getMethodInternal() should prefer UDF signatures with greater affinity to the argument types passed in (varchar should prefer string, etc)"
            },
            {
                "author_name": "jdere",
                "id": "13748173",
                "body": "Attaching HIVE-4844.6.patch - rebased with trunk"
            },
            {
                "author_name": "jdere",
                "id": "13750812",
                "body": "Apparently the patches I've been attaching (which I downloaded from Phabricator) are not applying correctly.  Attaching char_progress.patch.7.txt which should be the same progress as char_progress.patch.6.txt, but with the patch generated from my git repository."
            },
            {
                "author_name": "jdere",
                "id": "13750815",
                "body": "attached wrong patch .. replacing char_progress.7.patch with HIVE-4844.7.patch."
            },
            {
                "author_name": "xuefuz",
                "id": "13751085",
                "body": "[~jdere] Since this patch is fairly big and progressing over time, I'm wondering if it makes sense to create a few sub tasks and attach smaller patch for each. Especially, you have changes for precision/scale that overlaps with HIVE-3976, and having a stable patch for the common changes makes it easy to create patches on the top of it. What do you think?"
            },
            {
                "author_name": "jdere",
                "id": "13751486",
                "body": "Hi Xuefu, yes this patch has gotten pretty large. I think it's at a point where we can stop the work on this Jira (after I check in some additional tests I have been working on), and additional work can be added as sub tasks, such as support for additional SerDe's. I don't think the current progress can be easily split into smaller patches - perhaps the JDBC changes might be able to pulled out, but everything else needs to go in at the same time to work coherently."
            },
            {
                "author_name": "jdere",
                "id": "13751921",
                "body": "Attaching HIVE-4844.8.patch. This adds more  unit tests, and a few fixes to get the unit tests to pass. Hopefully any further changes to this patch should be changes based on review comments."
            },
            {
                "author_name": "jdere",
                "id": "13752873",
                "body": "attaching HIVE-4844.9.patch, changes per review from hbutani:\n    - descriptive comment about numericTypes map\n    - TypeInfoParser fix and tests for invalid TypeInfo parameter syntax\n    - raise error if Hive tries to instantiate varchar TypeInfo without type params.\n    - fixed typo in constant value in Thrift file\n"
            },
            {
                "author_name": "xuefuz",
                "id": "13753058",
                "body": "Hi Jason,\n\nThanks for your response. I understand it's hard to separate your patch into small patches. On the other hand, I'm wondering if the changes you made dealing with precision/scale is required for char/varchar support. If not, could you spare them from you patch?\n\nThe problem I have is the difficulty to rebase my changes on your patch because of the progressive nature. This might makes easier for both of us to proceed. In the meantime, please feel free to include whatever changes that are needed for both feature. \n\nPlease let me know. Thanks."
            },
            {
                "author_name": "jdere",
                "id": "13753094",
                "body": "Hi Xuefu, sorry about. I did add precision/scale in a few places, let's take a look:\n\n1. JDBC: The precision/scale is also used for returning varchar length, so these changes are necessary.\n2. BaseTypeParams/TypeQualifiers/TTypeQualifiers: These are objects used to hold type qualifier information, and I did add precision/scale fields/setters to these objects. If you'd like them removed I can remove any mention of precision/scale in these objects.\n3. TCLIService.thrift: Add constant string values to represent precision/scale fields. I can also remove those constant definitions if you like.\n\nLet me know if you want me to remove mention of precision/scale from (2) and (3)."
            },
            {
                "author_name": "hiveqa",
                "id": "13753253",
                "body": "\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12600466/HIVE-4844.9.patch\n\n{color:red}ERROR:{color} -1 due to 1 failed/errored test(s), 2918 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hadoop.hive.cli.TestMinimrCliDriver.testCliDriver_bucket_num_reducers\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/553/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/553/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests failed with: TestsFailedException: 1 tests failed\n{noformat}\n\nThis message is automatically generated."
            },
            {
                "author_name": "xuefuz",
                "id": "13753554",
                "body": "[~jdere] for 2 and 3, could you please exclude them? They will not get wasted. (I will eventually include the patch for HIVE-3976.) This will help rebase and review. Thanks a lot."
            },
            {
                "author_name": "jdere",
                "id": "13753887",
                "body": "attaching HIVE-4844.10.patch - remove instances of precision/scale where appropriate per Xuefu's request"
            },
            {
                "author_name": "jdere",
                "id": "13754038",
                "body": "Xuefu, you're going to hate me for this one, but upon review of the code with hbutani, I am planning to remove the ParameterizedPrimitiveTypeInfo/ParameterizedPrimitiveObjectInspector interfaces and just add those methods to the PrimitiveTypeInfo/PrimitiveObjectInspector interfaces. I hope this doesn't cause too many rebase issues with your decimal work."
            },
            {
                "author_name": "hiveqa",
                "id": "13754204",
                "body": "\n\n{color:green}Overall{color}: +1 all checks pass\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12600624/HIVE-4844.10.patch\n\n{color:green}SUCCESS:{color} +1 2918 tests passed\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/561/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/561/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\n{noformat}\n\nThis message is automatically generated."
            },
            {
                "author_name": "jdere",
                "id": "13754289",
                "body": "Attaching HIVE-4844.11.patch, with more changes from hbutani's review - fold ParameterizedPrimitiveTypeInfo into PrimitiveTypeInfo and ParameterizedOI into PrimitiveOI."
            },
            {
                "author_name": "hiveqa",
                "id": "13754496",
                "body": "\n\n{color:red}Overall{color}: -1 at least one tests failed\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12600709/HIVE-4844.11.patch\n\n{color:red}ERROR:{color} -1 due to 3 failed/errored test(s), 2918 tests executed\n*Failed tests:*\n{noformat}\norg.apache.hcatalog.pig.TestHCatStorerMulti.testStoreBasicTable\norg.apache.hadoop.hive.cli.TestNegativeMinimrCliDriver.testNegativeCliDriver_mapreduce_stack_trace_hadoop20\norg.apache.hcatalog.pig.TestHCatLoaderComplexSchema.testSyntheticComplexSchema\n{noformat}\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/569/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/569/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\nTests failed with: TestsFailedException: 3 tests failed\n{noformat}\n\nThis message is automatically generated."
            },
            {
                "author_name": "jdere",
                "id": "13755136",
                "body": "All three failures mentioned above (TestHCatStorerMulti, TestNegativeMinimrCliDriver, TestHCatLoaderComplexSchema) appear to pass when I run these tests myself."
            },
            {
                "author_name": "jdere",
                "id": "13755294",
                "body": "ashutoshc, like Xuefu, has suggested that this patch be split into different subtasks where appropriate, to make review/tracking easier. I'll take a look at what I can do here. At first glance, looks like this can be done as the following set of changes:\n 1. getMethodInternal() should prefer evaluate() signatures with more \"similar\" arguments\n 2. Change getCommonClass/implicitConvertible to use PrimitiveCategory rather than TypeInfo\n 3. Cast operators need to be set with type-specific data prior to initialization\n 4. varchar work (will be done in this Jira)\n 5. Thrift/JDBC changes for varchar"
            },
            {
                "author_name": "phabricator@reviews.facebook.net",
                "id": "13757545",
                "body": "jdere requested code review of \"HIVE-4844 [jira] Add varchar data type\".\n\nReviewers: JIRA\n\nAdd new varchar data types which have support for more SQL-compliant behavior, such as SQL string comparison semantics, max length, etc.\nChar type will be added as another task.\n\nTEST PLAN\n  EMPTY\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12699\n\nAFFECTED FILES\n  common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java\n  common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java\n  common/src/test/org/apache/hadoop/hive/common/type/TestHiveVarchar.java\n  data/files/datatypes.txt\n  data/files/vc1.txt\n  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java\n  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\n  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\n  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java\n  ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcat.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLower.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUpper.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java\n  ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java\n  ql/src/test/queries/clientpositive/alter_varchar1.q\n  ql/src/test/queries/clientpositive/ctas_varchar.q\n  ql/src/test/queries/clientpositive/partition_varchar1.q\n  ql/src/test/queries/clientpositive/varchar_1.q\n  ql/src/test/queries/clientpositive/varchar_2.q\n  ql/src/test/queries/clientpositive/varchar_cast.q\n  ql/src/test/queries/clientpositive/varchar_comparison.q\n  ql/src/test/queries/clientpositive/varchar_join1.q\n  ql/src/test/queries/clientpositive/varchar_nested_types.q\n  ql/src/test/queries/clientpositive/varchar_udf1.q\n  ql/src/test/queries/clientpositive/varchar_union1.q\n  ql/src/test/results/clientpositive/alter_varchar1.q.out\n  ql/src/test/results/clientpositive/ctas_varchar.q.out\n  ql/src/test/results/clientpositive/partition_varchar1.q.out\n  ql/src/test/results/clientpositive/varchar_1.q.out\n  ql/src/test/results/clientpositive/varchar_2.q.out\n  ql/src/test/results/clientpositive/varchar_cast.q.out\n  ql/src/test/results/clientpositive/varchar_comparison.q.out\n  ql/src/test/results/clientpositive/varchar_join1.q.out\n  ql/src/test/results/clientpositive/varchar_nested_types.q.out\n  ql/src/test/results/clientpositive/varchar_udf1.q.out\n  ql/src/test/results/clientpositive/varchar_union1.q.out\n  ql/src/test/results/compiler/plan/groupby2.q.xml\n  ql/src/test/results/compiler/plan/udf6.q.xml\n  serde/if/serde.thrift\n  serde/src/gen/thrift/gen-cpp/serde_constants.cpp\n  serde/src/gen/thrift/gen-cpp/serde_constants.h\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java\n  serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php\n  serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py\n  serde/src/gen/thrift/gen-rb/serde_constants.rb\n  serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java\n  serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java\n  serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java\n  serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java\n  serde/src/test/org/apache/hadoop/hive/serde2/typeinfo/TestTypeInfoUtils.java\n\nMANAGE HERALD RULES\n  https://reviews.facebook.net/herald/view/differential/\n\nWHY DID I GET THIS EMAIL?\n  https://reviews.facebook.net/herald/transcript/30465/\n\nTo: JIRA, jdere\n"
            },
            {
                "author_name": "jdere",
                "id": "13757555",
                "body": "Attaching HIVE-4844.12.patch, which should now be a smaller patch since patch 11 has been broken up into several different subtasks."
            },
            {
                "author_name": "xuefuz",
                "id": "13760721",
                "body": "[~jdere] Looking at your latest patch, I'm wondering if you have given thought on the max on varchar length. Right now you put Integer.MAX_VALUE as the max, but majority of DBs has a smaller limit than that. (Mysql chose 65,535, for instance.) Having a smaller max might leave room for optimization. I understand that there is no standard regarding this, but I'm curious if we made a conscious decision on that."
            },
            {
                "author_name": "jdere",
                "id": "13760823",
                "body": "The max varchar length setting was pretty arbitrary, sure we can have it set to a lower value. Any ideas on what value to initially set? 32,767 (small enough to fit within a short), or maybe something even smaller like 1024, just to make the point that we don't want enormous varchar columns that require checking the string length?"
            },
            {
                "author_name": "xuefuz",
                "id": "13762007",
                "body": "I think people use varchar in Hive probably because of legacy data from DBs. Thus, a number at a scale of major DBs would be good. Yes, it's arbitrary. 64K would be good, but 64M or 64G might not be as good."
            },
            {
                "author_name": "jdere",
                "id": "13763739",
                "body": "Ok, 64K sounds good then. As it turns out there was nothing checking if varchar was defined with too large of a length, so that needed to be added in.  Will post new patch shortly"
            },
            {
                "author_name": "jdere",
                "id": "13763799",
                "body": "HIVE-4844.13.patch:\n- Rebase against trunk\n- Set max varchar length to 64K\n- Fix varchar length when casting constant string values to varchar"
            },
            {
                "author_name": "xuefuz",
                "id": "13763958",
                "body": "Yeah. 64K is good. Just minor thought. Instead of 64K (65556), MYSQL chooses 65535, 1 less than 64K. I don't know if there is any pitfall there. I also saw instead of 256, 255 used for length in other DBs. Anyone has any idea?"
            },
            {
                "author_name": "jdere",
                "id": "13764989",
                "body": "Sure, I'll bump the max down to 65535, though it won't matter much for Hive since a Java short only goes up to 32K, so we need an int to hold the value either way. I need to rebase this patch yet again due to review changes from HIVE-5206, so I'll add this change when I roll a new patch."
            },
            {
                "author_name": "jdere",
                "id": "13765172",
                "body": "new patch HIVE-4844.14.patch:\n- rebase against updated patch of HIVE-5206\n- set max varchar length to 65535\n- remove re-implemented concat/lower/upper GenericUDFs, will added in HIVE-5278"
            },
            {
                "author_name": "ashutoshc",
                "id": "13765858",
                "body": "[~jdere] Left some comments on phabricator."
            },
            {
                "author_name": "ashutoshc",
                "id": "13765866",
                "body": "And few more : )"
            },
            {
                "author_name": "jdere",
                "id": "13766064",
                "body": "upload patch 15, with changes from review comments from ashutosh.\nAlso new review link with this patch at https://reviews.facebook.net/D12891"
            },
            {
                "author_name": "ashutoshc",
                "id": "13766095",
                "body": "+1"
            },
            {
                "author_name": "phabricator@reviews.facebook.net",
                "id": "13766106",
                "body": "ashutoshc has commented on the revision \"HIVE-4844 [jira] Add varchar data type\".\n\n  Mostly looks good. Some comments.\n  I don't see any changes in ColumnarSerde,  LazyBinaryColumnarSede. If they are not supported thats alright. But, if they are can you add tests for RCFile data with these two serdes. Simlarily HBaseSerde and AvroSerde. If you intend to support it will be good to add testcases for those, else support for them can be added later as well.\n\nINLINE COMMENTS\n  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java:629 This method belongs in TypeInfoUtils class.\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:160 Move this method to TypeInfoUtils\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:169 This to ParseUtils\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java:48 Shall we also update this error message saying, first arg must be either string or varchar ?\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java:56 Error message\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java:39-40 You need to mark all these fields as transient.\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java:36 You can add @Description annotation for this which will be useful for end users.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java:401 This for CHAR right, for varchar we need not to do this.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java:474 Can you check the standard here? We may get bitten by backward-compat issues because of this latter.\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12699\n\nTo: JIRA, jdere\nCc: ashutoshc\n"
            },
            {
                "author_name": "phabricator@reviews.facebook.net",
                "id": "13766149",
                "body": "ashutoshc has commented on the revision \"HIVE-4844 [jira] Add varchar data type\".\n\n  Sorry.. missed while previewing earlier.\n\nINLINE COMMENTS\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java:34 You need to add no-arg constructor for Kryo to correctly serialize this.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java:32 Need to add no-arg constructor for Kryo to work correctly.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java:33 no-arg constructor.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java:35 no-arg ctor.\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12699\n\nTo: JIRA, jdere\nCc: ashutoshc\n"
            },
            {
                "author_name": "jdere",
                "id": "13766188",
                "body": "Apparently hadn't completely removed java files for GenericUDFConcat/Upper/Lower - they were still in the patch as empty files. Adding patch v16 which removes those empty files."
            },
            {
                "author_name": "phabricator@reviews.facebook.net",
                "id": "13766216",
                "body": "jdere has commented on the revision \"HIVE-4844 [jira] Add varchar data type\".\n\n  Most of the SerDe support has been broken out into HIVE-5161.  The SerDe's I'm testing there are RegexSerDe, LazyBinarySerDe, LazySimpleSerDe, ColumnarSerDe, LazyBinaryColumnarSerDe, OrcSerDe.  I'll need to take a look again, but if HBase/Avro SerDe's use reflection-based methods to get their Types/ObjectInspectors, then they won't be able to support varchars properly.\n\nINLINE COMMENTS\n  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java:629 will change in the next patch\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:160 will change in next patch\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:169 will change in next patch\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java:48 sure, will change\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java:56 will change this message too\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java:36 whoops forgot to add that .. will do\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java:39-40 Actually, my latest patch did mark these fields as transient .. I'll need to update this review with the updated patch.\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java:34 Do we need to serialize object inspectors? my impression is that should always have been transient, at least when they're used in UDFs since they can be set during initialize().\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java:401 Yeah, this comment is gone in the updated patch.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java:474 2011 SQL Standard (6.13 cast specification) does say that the value should be \"TRUE\"/\"FALSE\". This also matches what we're doing with the string type.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java:33 ok, will change\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java:35 will change\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12699\n\nTo: JIRA, jdere\nCc: ashutoshc\n"
            },
            {
                "author_name": "phabricator@reviews.facebook.net",
                "id": "13766258",
                "body": "jdere requested code review of \"HIVE-4844 [jira] Add varchar data type\".\n\nReviewers: JIRA\n\nChanges to HIVE-4844 per review from ashutosh\n\nAdd new varchar data types which have support for more SQL-compliant behavior, such as SQL string comparison semantics, max length, etc.\nChar type will be added as another task.\n\nTEST PLAN\n  EMPTY\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12891\n\nAFFECTED FILES\n  common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java\n  common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java\n  common/src/test/org/apache/hadoop/hive/common/type/TestHiveVarchar.java\n  data/files/datatypes.txt\n  data/files/vc1.txt\n  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\n  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\n  ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java\n  ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java\n  ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeConstantDesc.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcat.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLower.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUpper.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java\n  ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java\n  ql/src/test/queries/clientnegative/invalid_varchar_length_1.q\n  ql/src/test/queries/clientnegative/invalid_varchar_length_2.q\n  ql/src/test/queries/clientnegative/invalid_varchar_length_3.q\n  ql/src/test/queries/clientpositive/alter_varchar1.q\n  ql/src/test/queries/clientpositive/ctas_varchar.q\n  ql/src/test/queries/clientpositive/partition_varchar1.q\n  ql/src/test/queries/clientpositive/varchar_1.q\n  ql/src/test/queries/clientpositive/varchar_2.q\n  ql/src/test/queries/clientpositive/varchar_cast.q\n  ql/src/test/queries/clientpositive/varchar_comparison.q\n  ql/src/test/queries/clientpositive/varchar_join1.q\n  ql/src/test/queries/clientpositive/varchar_nested_types.q\n  ql/src/test/queries/clientpositive/varchar_udf1.q\n  ql/src/test/queries/clientpositive/varchar_union1.q\n  ql/src/test/results/clientnegative/invalid_varchar_length_1.q.out\n  ql/src/test/results/clientnegative/invalid_varchar_length_2.q.out\n  ql/src/test/results/clientnegative/invalid_varchar_length_3.q.out\n  ql/src/test/results/clientpositive/alter_varchar1.q.out\n  ql/src/test/results/clientpositive/ctas_varchar.q.out\n  ql/src/test/results/clientpositive/partition_varchar1.q.out\n  ql/src/test/results/clientpositive/varchar_1.q.out\n  ql/src/test/results/clientpositive/varchar_2.q.out\n  ql/src/test/results/clientpositive/varchar_cast.q.out\n  ql/src/test/results/clientpositive/varchar_comparison.q.out\n  ql/src/test/results/clientpositive/varchar_join1.q.out\n  ql/src/test/results/clientpositive/varchar_nested_types.q.out\n  ql/src/test/results/clientpositive/varchar_udf1.q.out\n  ql/src/test/results/clientpositive/varchar_union1.q.out\n  serde/if/serde.thrift\n  serde/src/gen/thrift/gen-cpp/serde_constants.cpp\n  serde/src/gen/thrift/gen-cpp/serde_constants.h\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java\n  serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php\n  serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py\n  serde/src/gen/thrift/gen-rb/serde_constants.rb\n  serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java\n  serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java\n  serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java\n  serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java\n  serde/src/test/org/apache/hadoop/hive/serde2/typeinfo/TestTypeInfoUtils.java\n\nMANAGE HERALD RULES\n  https://reviews.facebook.net/herald/view/differential/\n\nWHY DID I GET THIS EMAIL?\n  https://reviews.facebook.net/herald/transcript/30861/\n\nTo: JIRA, jdere\n"
            },
            {
                "author_name": "phabricator@reviews.facebook.net",
                "id": "13766271",
                "body": "ashutoshc has accepted the revision \"HIVE-4844 [jira] Add varchar data type\".\n\n  +1 Thanks, Jason for making changes.\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12891\n\nBRANCH\n  HIVE-4844.2\n\nARCANIST PROJECT\n  hive\n\nTo: JIRA, ashutoshc, jdere\n"
            },
            {
                "author_name": "jdere",
                "id": "13766782",
                "body": "Ran unit test and got a couple failures:\n- varchar_union1.q: looks like this test is not deterministic, need to make sure the query results are sorted\n- udf_reflect2.q: looks like I had a bug in PrimitiveObjectInspectorUtils.getTypeEntryFromTypeSpecs()\nWill update the patch shortly"
            },
            {
                "author_name": "jdere",
                "id": "13766795",
                "body": "patch v17 - fix unit test failures"
            },
            {
                "author_name": "xuefuz",
                "id": "13767064",
                "body": "Thanks for making so much progress in such a short time. I have some comments while reading the patch.\n\n1. TypeInfoUtils.addParamsToTypeName() seems having duplicated code with VarcharTypeParam.toString().I also saw this in FunctionRegistry, which also has some duplicated logic here. It's nice if we can consolidate and have single point of reference for this. \n{code}\n+        String typeName =\n+            PrimitiveObjectInspectorUtils.getTypeEntryFromPrimitiveCategory(typeCategory).typeName\n+            + varcharParams.toString();\n{code}\n\n2. DDLSemanticAnalyzer.getTypeName() tries to get a list of Strings from the ASTNode by using ParseUtils.getCharParams(), in which only a subset of checks are performed. (For instance, it doesn't validate the MAX allowed length.) Instead, I think it's probably better to get VarcharTypeParams instance from the ASTNode and let the instance perform all the checks.\n\nI haven't gone thru the patch yet, but I'd like to share my thoughts.\n"
            },
            {
                "author_name": "xuefuz",
                "id": "13767104",
                "body": "Also in ParseUtils.getCharParams(), checking NumberFormatException and child count is probably not needed. This attributes to the grammar rule.\n\n{code}\n+    | KW_VARCHAR LPAREN length=Number RPAREN      ->    ^(TOK_VARCHAR $length)\n{code}\n\nThis is a minor thing that probably makes the code cleaner."
            },
            {
                "author_name": "hiveqa",
                "id": "13767433",
                "body": "\n\n{color:green}Overall{color}: +1 all checks pass\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12603075/HIVE-4844.17.patch\n\n{color:green}SUCCESS:{color} +1 3124 tests passed\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/727/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/727/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\n{noformat}\n\nThis message is automatically generated."
            },
            {
                "author_name": "jdere",
                "id": "13767520",
                "body": "Adding patch v18, which incorporates Xuefu's comments about consolidating type name generation. No longer catching NumberFormatException, but there still is a try/catch there since the type params validation throws a SerDeException, and I figured it made more sense to return a SemanticException in that context."
            },
            {
                "author_name": "hiveqa",
                "id": "13767534",
                "body": "\n\n{color:green}Overall{color}: +1 all checks pass\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12603075/HIVE-4844.17.patch\n\n{color:green}SUCCESS:{color} +1 3124 tests passed\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/744/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/744/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\n{noformat}\n\nThis message is automatically generated."
            },
            {
                "author_name": "jdere",
                "id": "13767548",
                "body": "Just got the unit test results from v18 and one of the negative tests failed, will need to roll another patch to update the test output."
            },
            {
                "author_name": "jdere",
                "id": "13767565",
                "body": "patch v19 - fixed unit test failure, updated error message"
            },
            {
                "author_name": "hiveqa",
                "id": "13767724",
                "body": "\n\n{color:green}Overall{color}: +1 all checks pass\n\nHere are the results of testing the latest attachment:\nhttps://issues.apache.org/jira/secure/attachment/12603206/HIVE-4844.19.patch\n\n{color:green}SUCCESS:{color} +1 3124 tests passed\n\nTest results: https://builds.apache.org/job/PreCommit-HIVE-Build/751/testReport\nConsole output: https://builds.apache.org/job/PreCommit-HIVE-Build/751/console\n\nMessages:\n{noformat}\nExecuting org.apache.hive.ptest.execution.PrepPhase\nExecuting org.apache.hive.ptest.execution.ExecutionPhase\nExecuting org.apache.hive.ptest.execution.ReportingPhase\n{noformat}\n\nThis message is automatically generated."
            },
            {
                "author_name": "ashutoshc",
                "id": "13767859",
                "body": "Committed to trunk. Thanks, Jason for this useful addition in Hive!"
            },
            {
                "author_name": "hudson",
                "id": "13767918",
                "body": "FAILURE: Integrated in Hive-trunk-h0.21 #2334 (See [https://builds.apache.org/job/Hive-trunk-h0.21/2334/])\nHIVE-4844 : Add varchar data type (Jason Dere via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523463)\n* /hive/trunk/common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java\n* /hive/trunk/common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java\n* /hive/trunk/common/src/test/org/apache/hadoop/hive/common/type\n* /hive/trunk/common/src/test/org/apache/hadoop/hive/common/type/TestHiveVarchar.java\n* /hive/trunk/data/files/datatypes.txt\n* /hive/trunk/data/files/vc1.txt\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeConstantDesc.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java\n* /hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_1.q\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_2.q\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_3.q\n* /hive/trunk/ql/src/test/queries/clientpositive/alter_varchar1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/ctas_varchar.q\n* /hive/trunk/ql/src/test/queries/clientpositive/partition_varchar1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_2.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_cast.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_comparison.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_join1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_nested_types.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_udf1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_union1.q\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_1.q.out\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_2.q.out\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_3.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/alter_varchar1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/ctas_varchar.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/partition_varchar1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_2.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_cast.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_comparison.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_join1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_nested_types.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_udf1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_union1.q.out\n* /hive/trunk/serde/if/serde.thrift\n* /hive/trunk/serde/src/gen/thrift/gen-cpp/serde_constants.cpp\n* /hive/trunk/serde/src/gen/thrift/gen-cpp/serde_constants.h\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java\n* /hive/trunk/serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php\n* /hive/trunk/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py\n* /hive/trunk/serde/src/gen/thrift/gen-rb/serde_constants.rb\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java\n* /hive/trunk/serde/src/test/org/apache/hadoop/hive/serde2/typeinfo\n* /hive/trunk/serde/src/test/org/apache/hadoop/hive/serde2/typeinfo/TestTypeInfoUtils.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13767919",
                "body": "FAILURE: Integrated in Hive-trunk-hadoop2 #431 (See [https://builds.apache.org/job/Hive-trunk-hadoop2/431/])\nHIVE-4844 : Add varchar data type (Jason Dere via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523463)\n* /hive/trunk/common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java\n* /hive/trunk/common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java\n* /hive/trunk/common/src/test/org/apache/hadoop/hive/common/type\n* /hive/trunk/common/src/test/org/apache/hadoop/hive/common/type/TestHiveVarchar.java\n* /hive/trunk/data/files/datatypes.txt\n* /hive/trunk/data/files/vc1.txt\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeConstantDesc.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java\n* /hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_1.q\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_2.q\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_3.q\n* /hive/trunk/ql/src/test/queries/clientpositive/alter_varchar1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/ctas_varchar.q\n* /hive/trunk/ql/src/test/queries/clientpositive/partition_varchar1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_2.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_cast.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_comparison.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_join1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_nested_types.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_udf1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_union1.q\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_1.q.out\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_2.q.out\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_3.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/alter_varchar1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/ctas_varchar.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/partition_varchar1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_2.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_cast.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_comparison.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_join1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_nested_types.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_udf1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_union1.q.out\n* /hive/trunk/serde/if/serde.thrift\n* /hive/trunk/serde/src/gen/thrift/gen-cpp/serde_constants.cpp\n* /hive/trunk/serde/src/gen/thrift/gen-cpp/serde_constants.h\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java\n* /hive/trunk/serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php\n* /hive/trunk/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py\n* /hive/trunk/serde/src/gen/thrift/gen-rb/serde_constants.rb\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java\n* /hive/trunk/serde/src/test/org/apache/hadoop/hive/serde2/typeinfo\n* /hive/trunk/serde/src/test/org/apache/hadoop/hive/serde2/typeinfo/TestTypeInfoUtils.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13767936",
                "body": "FAILURE: Integrated in Hive-trunk-hadoop2-ptest #98 (See [https://builds.apache.org/job/Hive-trunk-hadoop2-ptest/98/])\nHIVE-4844 : Add varchar data type (Jason Dere via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523463)\n* /hive/trunk/common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java\n* /hive/trunk/common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java\n* /hive/trunk/common/src/test/org/apache/hadoop/hive/common/type\n* /hive/trunk/common/src/test/org/apache/hadoop/hive/common/type/TestHiveVarchar.java\n* /hive/trunk/data/files/datatypes.txt\n* /hive/trunk/data/files/vc1.txt\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeConstantDesc.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java\n* /hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_1.q\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_2.q\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_3.q\n* /hive/trunk/ql/src/test/queries/clientpositive/alter_varchar1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/ctas_varchar.q\n* /hive/trunk/ql/src/test/queries/clientpositive/partition_varchar1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_2.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_cast.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_comparison.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_join1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_nested_types.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_udf1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_union1.q\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_1.q.out\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_2.q.out\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_3.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/alter_varchar1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/ctas_varchar.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/partition_varchar1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_2.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_cast.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_comparison.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_join1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_nested_types.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_udf1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_union1.q.out\n* /hive/trunk/serde/if/serde.thrift\n* /hive/trunk/serde/src/gen/thrift/gen-cpp/serde_constants.cpp\n* /hive/trunk/serde/src/gen/thrift/gen-cpp/serde_constants.h\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java\n* /hive/trunk/serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php\n* /hive/trunk/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py\n* /hive/trunk/serde/src/gen/thrift/gen-rb/serde_constants.rb\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java\n* /hive/trunk/serde/src/test/org/apache/hadoop/hive/serde2/typeinfo\n* /hive/trunk/serde/src/test/org/apache/hadoop/hive/serde2/typeinfo/TestTypeInfoUtils.java\n"
            },
            {
                "author_name": "hudson",
                "id": "13767937",
                "body": "FAILURE: Integrated in Hive-trunk-hadoop1-ptest #165 (See [https://builds.apache.org/job/Hive-trunk-hadoop1-ptest/165/])\nHIVE-4844 : Add varchar data type (Jason Dere via Ashutosh Chauhan) (hashutosh: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1523463)\n* /hive/trunk/common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java\n* /hive/trunk/common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java\n* /hive/trunk/common/src/test/org/apache/hadoop/hive/common/type\n* /hive/trunk/common/src/test/org/apache/hadoop/hive/common/type/TestHiveVarchar.java\n* /hive/trunk/data/files/datatypes.txt\n* /hive/trunk/data/files/vc1.txt\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeConstantDesc.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java\n* /hive/trunk/ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java\n* /hive/trunk/ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_1.q\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_2.q\n* /hive/trunk/ql/src/test/queries/clientnegative/invalid_varchar_length_3.q\n* /hive/trunk/ql/src/test/queries/clientpositive/alter_varchar1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/ctas_varchar.q\n* /hive/trunk/ql/src/test/queries/clientpositive/partition_varchar1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_2.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_cast.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_comparison.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_join1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_nested_types.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_udf1.q\n* /hive/trunk/ql/src/test/queries/clientpositive/varchar_union1.q\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_1.q.out\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_2.q.out\n* /hive/trunk/ql/src/test/results/clientnegative/invalid_varchar_length_3.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/alter_varchar1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/ctas_varchar.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/partition_varchar1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_2.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_cast.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_comparison.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_join1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_nested_types.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_udf1.q.out\n* /hive/trunk/ql/src/test/results/clientpositive/varchar_union1.q.out\n* /hive/trunk/serde/if/serde.thrift\n* /hive/trunk/serde/src/gen/thrift/gen-cpp/serde_constants.cpp\n* /hive/trunk/serde/src/gen/thrift/gen-cpp/serde_constants.h\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java\n* /hive/trunk/serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java\n* /hive/trunk/serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php\n* /hive/trunk/serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py\n* /hive/trunk/serde/src/gen/thrift/gen-rb/serde_constants.rb\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java\n* /hive/trunk/serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java\n* /hive/trunk/serde/src/test/org/apache/hadoop/hive/serde2/typeinfo\n* /hive/trunk/serde/src/test/org/apache/hadoop/hive/serde2/typeinfo/TestTypeInfoUtils.java\n"
            },
            {
                "author_name": "jdere",
                "id": "13768867",
                "body": "attaching HIVE-4844.v12.1.patch, for use in 0.12 branch"
            },
            {
                "author_name": "thejas",
                "id": "13769891",
                "body": "Patch committed to 0.12 branch.\n"
            },
            {
                "author_name": "ashutoshc",
                "id": "13795940",
                "body": "This issue has been fixed and released as part of 0.12 release. If you find further issues, please create a new jira and link it to this one."
            },
            {
                "author_name": "rajendragam1986",
                "id": "16593807",
                "body": "Hi,\r\n\r\nI have a question regarding Hive Varchar. I have a few million rows of records in a column.\u00a0\r\n # How I can find out what is the maximum byte used in a row of a column. So that I can optimally allocate length of Varchar column?\r\n\r\n\u00a0"
            },
            {
                "author_name": "gates",
                "id": "16594000",
                "body": "[~rajendragam1986], questions like this should go to the user list rather than be posted on JIRA, where they aren't likely to be seen."
            },
            {
                "author_name": "yucai",
                "id": "16720905",
                "body": "[~jdere], [~ashutoshc], we found\u00a0varchar and string will\u00a0behave\u00a0differently for malformed utf8 characters.\r\n\r\nFor example, the original data is 6130373530633166313366306B35B0A546386A8DAEAB62B4526F273464613936 in hex.\r\n\r\n*B0A5 and*\u00a0*8DAEAB*\u00a0are malformed utf8 characters, they are decoded to\u00a0EFBFBD if the data type is varchar,\u00a0but string will not change it. So:\r\n\r\nVARCHAR in hex shows: 6130373530633166313366306B35EFBFBDEFBFBD46386AEFBFBDEFBFBDEFBFBD62EFBFBD526F273464613936\r\n STRING in hex shows: 6130373530633166313366306B35B0A546386A8DAEAB62B4526F273464613936\r\n\r\nIs it expected?\r\n\r\nMore details @https://issues.apache.org/jira/browse/HIVE-21042"
            }
        ],
        "comments_predictions": [
            [
                2012140,
                "HIVE-4844",
                "[~jdere] Thanks for sharing your work. I went thru your patch and had some initial questions. I understand that your patch is still in progress, but I'm wondering what's your thought on how you plan to store the type params. Obviously, type params are metadata of a column, which needs to be stored. I assume that hive schema needs to change to accommodate this.\n\nSecondly, SQL VAR or VARCHAR seems to be special hive string with additional restriction. Your patch seems treating them independently. Do you think if type inheritance works here?\n\nLastly, introducing param types seems non-trivial. Do you think if a design doc or wiki page makes sense?",
                {
                    "property": {
                        "confidence": 0.007189825642853975,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0033071893267333508,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.09342316538095474,
                        "prediction": false
                    }
                }
            ],
            [
                2012141,
                "HIVE-4844",
                "Hi Xuefu, \n\n- The patch currently just keeps the params as part of the type string, which means no metastore changes, but could be brittle in other situations. An alternative could be additional columns in the COLUMNS metastore table to hold type qualifiers, similar to what other DB catalogs have, or a separate table of column_id/param_name/param_value. Do you have any suggestions here?\n\n- For inheritance, do you mean for the primitive/writable types? String is a final class, so I don't think it's doable for the primitive. I suppose the writable could derive from Text. \n\n- Sure, a wiki page makes sense.  I'll put one up once I get wiki access.",
                {
                    "property": {
                        "confidence": 0.0036105026956647635,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.011196820065379143,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.023384656757116318,
                        "prediction": false
                    }
                }
            ],
            [
                2012142,
                "HIVE-4844",
                "[~jdere]:\n\n1. I'm not sure which way is the better, but I feel that adding additional columns seems cleaner in my opinion.\n\n2. I could be off the topic on inheritance. I guess what I tried to say was some types, for instance, string, CHAR, and VARCHAR are very similar and may share a lot of implementations. This would also apply to DECIMAL and DECIMAL(p,s) also. However, I haven't figured out the implications yet. Please share your insights. ",
                {
                    "property": {
                        "confidence": 0.005604367703199387,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004829664248973131,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02369478903710842,
                        "prediction": false
                    }
                }
            ],
            [
                2012144,
                "HIVE-4844",
                "Added a doc to the wiki at https://cwiki.apache.org/confluence/display/Hive/Type+Qualifiers+in+Hive. \n\nEd, for the metastore changes, would additional columns in the COLUMNS_V2 metastore table be fine, if they are set to NULLs if there are no type qualifiers?\n\nXuefu, yeah for char/varchar I was thinking they could probably share some inheritance, especially since they need to do some length checking, though I hadn't really thought about if they should share with existing String/Text. Well, they can't inherit String as I mentioned before.  For decimal/decimal(p,s), I think the  existing HiveDecimal might be fine, since I think the actual enforcement of precision/scale might happen at the ObjectInspectors/Converters/cast/deserialization. ",
                {
                    "property": {
                        "confidence": 0.004375125281512737,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005140881519764662,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04140234738588333,
                        "prediction": false
                    }
                }
            ],
            [
                2012146,
                "HIVE-4844",
                "[~jdere] It seems that the patch here and what you posted on fb rb are out of sync. Would you mind updating your patch here? Also, fb rb seems showing diff incorrectly, which is a little bothersome. Thanks.",
                {
                    "property": {
                        "confidence": 0.004282653331756592,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01793203502893448,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0077827307395637035,
                        "prediction": false
                    }
                }
            ],
            [
                2012147,
                "HIVE-4844",
                "I'd expect those two patches to be very different as there were a number of changes made between the first patch here and the one on phabricator. What is the issue you see with the diff on phabricator? It was too large to upload using the arc command so I had to use the --less-context option. ",
                {
                    "property": {
                        "confidence": 0.004589750897139311,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007059348747134209,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.017172886058688164,
                        "prediction": false
                    }
                }
            ],
            [
                2012151,
                "HIVE-4844",
                "Been going over some of these changes with Gunther Hagleitner, and his input was that the metastore changes are not necessary for the varchar/decimal type qualifiers. The type name string is able to hold the whole type description, and in fact the nested types (struct/map/list) are simply represented as strings in the metastore. I'll look into reverting the metastore changes in the patch, and possibly some TypeQualifier-related changes if it makes sense. ",
                {
                    "property": {
                        "confidence": 0.0066488366574049,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00370383751578629,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.06362765282392502,
                        "prediction": false
                    }
                }
            ],
            [
                2012153,
                "HIVE-4844",
                "Sorry, still not really sure what the issues is that you're having with the Phabricator diff? But if you are trying to see more of the file through the web page, Phabricator is unable to do so because the diff upload was too large for Phabricator, and so I had to use the --less-context option when I uploaded",
                {
                    "property": {
                        "confidence": 0.004852579440921545,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005091621074825525,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02644725888967514,
                        "prediction": false
                    }
                }
            ],
            [
                2012154,
                "HIVE-4844",
                "I'm sorry that I wasn't clear. Looking at the diff, I assumed that the lines in green are new additions. However, {code}<field name=\"characterMaximumLength\" >{code} is new but is not green, while {code}</embedded>{code} is not new yet is green. It seems to me that the diff is one line off. Or my understanding is off? :)",
                {
                    "property": {
                        "confidence": 0.005801806226372719,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005199384409934282,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016495956107974052,
                        "prediction": false
                    }
                }
            ],
            [
                2012155,
                "HIVE-4844",
                "Re: type name vs additional columns\n\nBy instinct I think latter suggests a cleaner approach while the former seems a little \"hacky\" as we put semantics in the type name, similar to putting a person's name and age in the same column. Having said that, I'm open to that approach. I just wasn't clear about all the benefits of it besides trying to save a schema upgrade.",
                {
                    "property": {
                        "confidence": 0.008864020928740501,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0034634352196007967,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.1805596798658371,
                        "prediction": false
                    }
                }
            ],
            [
                2012156,
                "HIVE-4844",
                "Yeah, the diff does appear to be a bit off, doesn't look like it's very useful does it?  Might be better off just looking at the diff or applying it to 9fa33a6d0e7c18d6b94a29e8b6ef928126c9f274.  I hope arcanist generated the diff properly.\n\nRemoving the metastore changes does make some things a bit more consistent, since there were times where we were just trying to use the base type name for varchar, but in other instances where it was being used in a nested type we would use the full name.  ",
                {
                    "property": {
                        "confidence": 0.005903681740164757,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.004075354430824518,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.036172136664390564,
                        "prediction": false
                    }
                }
            ],
            [
                2012158,
                "HIVE-4844",
                "Attaching HIVE-4844.5.patch:\n- JDBC changes\n- FunctionRegistry.getMethodInternal() should prefer UDF signatures with greater affinity to the argument types passed in (varchar should prefer string, etc)",
                {
                    "property": {
                        "confidence": 0.004586569033563137,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010033742524683475,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011017306707799435,
                        "prediction": false
                    }
                }
            ],
            [
                2012160,
                "HIVE-4844",
                "Apparently the patches I've been attaching (which I downloaded from Phabricator) are not applying correctly.  Attaching char_progress.patch.7.txt which should be the same progress as char_progress.patch.6.txt, but with the patch generated from my git repository.",
                {
                    "property": {
                        "confidence": 0.003876567119732499,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007597545627504587,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.02028438076376915,
                        "prediction": false
                    }
                }
            ],
            [
                2012162,
                "HIVE-4844",
                "[~jdere] Since this patch is fairly big and progressing over time, I'm wondering if it makes sense to create a few sub tasks and attach smaller patch for each. Especially, you have changes for precision/scale that overlaps with HIVE-3976, and having a stable patch for the common changes makes it easy to create patches on the top of it. What do you think?",
                {
                    "property": {
                        "confidence": 0.00544883543625474,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005404805298894644,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.025305185467004776,
                        "prediction": false
                    }
                }
            ],
            [
                2012163,
                "HIVE-4844",
                "Hi Xuefu, yes this patch has gotten pretty large. I think it's at a point where we can stop the work on this Jira (after I check in some additional tests I have been working on), and additional work can be added as sub tasks, such as support for additional SerDe's. I don't think the current progress can be easily split into smaller patches - perhaps the JDBC changes might be able to pulled out, but everything else needs to go in at the same time to work coherently.",
                {
                    "property": {
                        "confidence": 0.006588442251086235,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.007423431146889925,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014795566909015179,
                        "prediction": false
                    }
                }
            ],
            [
                2012165,
                "HIVE-4844",
                "attaching HIVE-4844.9.patch, changes per review from hbutani:\n    - descriptive comment about numericTypes map\n    - TypeInfoParser fix and tests for invalid TypeInfo parameter syntax\n    - raise error if Hive tries to instantiate varchar TypeInfo without type params.\n    - fixed typo in constant value in Thrift file\n",
                {
                    "property": {
                        "confidence": 0.003821570659056306,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00964877288788557,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01470496691763401,
                        "prediction": false
                    }
                }
            ],
            [
                2012166,
                "HIVE-4844",
                "Hi Jason,\n\nThanks for your response. I understand it's hard to separate your patch into small patches. On the other hand, I'm wondering if the changes you made dealing with precision/scale is required for char/varchar support. If not, could you spare them from you patch?\n\nThe problem I have is the difficulty to rebase my changes on your patch because of the progressive nature. This might makes easier for both of us to proceed. In the meantime, please feel free to include whatever changes that are needed for both feature. \n\nPlease let me know. Thanks.",
                {
                    "property": {
                        "confidence": 0.005302086006850004,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.00843567680567503,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014904347248375416,
                        "prediction": false
                    }
                }
            ],
            [
                2012167,
                "HIVE-4844",
                "Hi Xuefu, sorry about. I did add precision/scale in a few places, let's take a look:\n\n1. JDBC: The precision/scale is also used for returning varchar length, so these changes are necessary.\n2. BaseTypeParams/TypeQualifiers/TTypeQualifiers: These are objects used to hold type qualifier information, and I did add precision/scale fields/setters to these objects. If you'd like them removed I can remove any mention of precision/scale in these objects.\n3. TCLIService.thrift: Add constant string values to represent precision/scale fields. I can also remove those constant definitions if you like.\n\nLet me know if you want me to remove mention of precision/scale from (2) and (3).",
                {
                    "property": {
                        "confidence": 0.0033504473976790905,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0131399380043149,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.018645942211151123,
                        "prediction": false
                    }
                }
            ],
            [
                2012171,
                "HIVE-4844",
                "Xuefu, you're going to hate me for this one, but upon review of the code with hbutani, I am planning to remove the ParameterizedPrimitiveTypeInfo/ParameterizedPrimitiveObjectInspector interfaces and just add those methods to the PrimitiveTypeInfo/PrimitiveObjectInspector interfaces. I hope this doesn't cause too many rebase issues with your decimal work.",
                {
                    "property": {
                        "confidence": 0.0043043349869549274,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.028845224529504776,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.007470363285392523,
                        "prediction": false
                    }
                }
            ],
            [
                2012176,
                "HIVE-4844",
                "ashutoshc, like Xuefu, has suggested that this patch be split into different subtasks where appropriate, to make review/tracking easier. I'll take a look at what I can do here. At first glance, looks like this can be done as the following set of changes:\n 1. getMethodInternal() should prefer evaluate() signatures with more \"similar\" arguments\n 2. Change getCommonClass/implicitConvertible to use PrimitiveCategory rather than TypeInfo\n 3. Cast operators need to be set with type-specific data prior to initialization\n 4. varchar work (will be done in this Jira)\n 5. Thrift/JDBC changes for varchar",
                {
                    "property": {
                        "confidence": 0.0033948097843676805,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.03246263414621353,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.05834048613905907,
                        "prediction": false
                    }
                }
            ],
            [
                2012177,
                "HIVE-4844",
                "jdere requested code review of \"HIVE-4844 [jira] Add varchar data type\".\n\nReviewers: JIRA\n\nAdd new varchar data types which have support for more SQL-compliant behavior, such as SQL string comparison semantics, max length, etc.\nChar type will be added as another task.\n\nTEST PLAN\n  EMPTY\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12699\n\nAFFECTED FILES\n  common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java\n  common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java\n  common/src/test/org/apache/hadoop/hive/common/type/TestHiveVarchar.java\n  data/files/datatypes.txt\n  data/files/vc1.txt\n  metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java\n  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\n  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\n  ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java\n  ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcat.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLower.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUpper.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java\n  ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java\n  ql/src/test/queries/clientpositive/alter_varchar1.q\n  ql/src/test/queries/clientpositive/ctas_varchar.q\n  ql/src/test/queries/clientpositive/partition_varchar1.q\n  ql/src/test/queries/clientpositive/varchar_1.q\n  ql/src/test/queries/clientpositive/varchar_2.q\n  ql/src/test/queries/clientpositive/varchar_cast.q\n  ql/src/test/queries/clientpositive/varchar_comparison.q\n  ql/src/test/queries/clientpositive/varchar_join1.q\n  ql/src/test/queries/clientpositive/varchar_nested_types.q\n  ql/src/test/queries/clientpositive/varchar_udf1.q\n  ql/src/test/queries/clientpositive/varchar_union1.q\n  ql/src/test/results/clientpositive/alter_varchar1.q.out\n  ql/src/test/results/clientpositive/ctas_varchar.q.out\n  ql/src/test/results/clientpositive/partition_varchar1.q.out\n  ql/src/test/results/clientpositive/varchar_1.q.out\n  ql/src/test/results/clientpositive/varchar_2.q.out\n  ql/src/test/results/clientpositive/varchar_cast.q.out\n  ql/src/test/results/clientpositive/varchar_comparison.q.out\n  ql/src/test/results/clientpositive/varchar_join1.q.out\n  ql/src/test/results/clientpositive/varchar_nested_types.q.out\n  ql/src/test/results/clientpositive/varchar_udf1.q.out\n  ql/src/test/results/clientpositive/varchar_union1.q.out\n  ql/src/test/results/compiler/plan/groupby2.q.xml\n  ql/src/test/results/compiler/plan/udf6.q.xml\n  serde/if/serde.thrift\n  serde/src/gen/thrift/gen-cpp/serde_constants.cpp\n  serde/src/gen/thrift/gen-cpp/serde_constants.h\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java\n  serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php\n  serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py\n  serde/src/gen/thrift/gen-rb/serde_constants.rb\n  serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java\n  serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java\n  serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java\n  serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java\n  serde/src/test/org/apache/hadoop/hive/serde2/typeinfo/TestTypeInfoUtils.java\n\nMANAGE HERALD RULES\n  https://reviews.facebook.net/herald/view/differential/\n\nWHY DID I GET THIS EMAIL?\n  https://reviews.facebook.net/herald/transcript/30465/\n\nTo: JIRA, jdere\n",
                {
                    "property": {
                        "confidence": 0.005336238071322441,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.050059426575899124,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.07818541675806046,
                        "prediction": false
                    }
                }
            ],
            [
                2012179,
                "HIVE-4844",
                "[~jdere] Looking at your latest patch, I'm wondering if you have given thought on the max on varchar length. Right now you put Integer.MAX_VALUE as the max, but majority of DBs has a smaller limit than that. (Mysql chose 65,535, for instance.) Having a smaller max might leave room for optimization. I understand that there is no standard regarding this, but I'm curious if we made a conscious decision on that.",
                {
                    "property": {
                        "confidence": 0.004778068978339434,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012349476106464863,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008911127224564552,
                        "prediction": false
                    }
                }
            ],
            [
                2012180,
                "HIVE-4844",
                "The max varchar length setting was pretty arbitrary, sure we can have it set to a lower value. Any ideas on what value to initially set? 32,767 (small enough to fit within a short), or maybe something even smaller like 1024, just to make the point that we don't want enormous varchar columns that require checking the string length?",
                {
                    "property": {
                        "confidence": 0.004808705300092697,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009282836690545082,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011385669931769371,
                        "prediction": false
                    }
                }
            ],
            [
                2012181,
                "HIVE-4844",
                "I think people use varchar in Hive probably because of legacy data from DBs. Thus, a number at a scale of major DBs would be good. Yes, it's arbitrary. 64K would be good, but 64M or 64G might not be as good.",
                {
                    "property": {
                        "confidence": 0.004142607096582651,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.1641606241464615,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.015941258519887924,
                        "prediction": false
                    }
                }
            ],
            [
                2012184,
                "HIVE-4844",
                "Yeah. 64K is good. Just minor thought. Instead of 64K (65556), MYSQL chooses 65535, 1 less than 64K. I don't know if there is any pitfall there. I also saw instead of 256, 255 used for length in other DBs. Anyone has any idea?",
                {
                    "property": {
                        "confidence": 0.004381903912872076,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.009193559177219868,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014825636520981789,
                        "prediction": false
                    }
                }
            ],
            [
                2012185,
                "HIVE-4844",
                "Sure, I'll bump the max down to 65535, though it won't matter much for Hive since a Java short only goes up to 32K, so we need an int to hold the value either way. I need to rebase this patch yet again due to review changes from HIVE-5206, so I'll add this change when I roll a new patch.",
                {
                    "property": {
                        "confidence": 0.0050804512575268745,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.5287182927131653,
                        "prediction": true
                    },
                    "existence": {
                        "confidence": 0.012325362302362919,
                        "prediction": false
                    }
                }
            ],
            [
                2012191,
                "HIVE-4844",
                "ashutoshc has commented on the revision \"HIVE-4844 [jira] Add varchar data type\".\n\n  Mostly looks good. Some comments.\n  I don't see any changes in ColumnarSerde,  LazyBinaryColumnarSede. If they are not supported thats alright. But, if they are can you add tests for RCFile data with these two serdes. Simlarily HBaseSerde and AvroSerde. If you intend to support it will be good to add testcases for those, else support for them can be added later as well.\n\nINLINE COMMENTS\n  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java:629 This method belongs in TypeInfoUtils class.\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:160 Move this method to TypeInfoUtils\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:169 This to ParseUtils\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java:48 Shall we also update this error message saying, first arg must be either string or varchar ?\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java:56 Error message\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java:39-40 You need to mark all these fields as transient.\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java:36 You can add @Description annotation for this which will be useful for end users.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java:401 This for CHAR right, for varchar we need not to do this.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java:474 Can you check the standard here? We may get bitten by backward-compat issues because of this latter.\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12699\n\nTo: JIRA, jdere\nCc: ashutoshc\n",
                {
                    "property": {
                        "confidence": 0.0036480107810348272,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.016557106748223305,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.027635864913463593,
                        "prediction": false
                    }
                }
            ],
            [
                2012192,
                "HIVE-4844",
                "ashutoshc has commented on the revision \"HIVE-4844 [jira] Add varchar data type\".\n\n  Sorry.. missed while previewing earlier.\n\nINLINE COMMENTS\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java:34 You need to add no-arg constructor for Kryo to correctly serialize this.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java:32 Need to add no-arg constructor for Kryo to work correctly.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java:33 no-arg constructor.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java:35 no-arg ctor.\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12699\n\nTo: JIRA, jdere\nCc: ashutoshc\n",
                {
                    "property": {
                        "confidence": 0.0032570380717515945,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.016592267900705338,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013299912214279175,
                        "prediction": false
                    }
                }
            ],
            [
                2012194,
                "HIVE-4844",
                "jdere has commented on the revision \"HIVE-4844 [jira] Add varchar data type\".\n\n  Most of the SerDe support has been broken out into HIVE-5161.  The SerDe's I'm testing there are RegexSerDe, LazyBinarySerDe, LazySimpleSerDe, ColumnarSerDe, LazyBinaryColumnarSerDe, OrcSerDe.  I'll need to take a look again, but if HBase/Avro SerDe's use reflection-based methods to get their Types/ObjectInspectors, then they won't be able to support varchars properly.\n\nINLINE COMMENTS\n  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java:629 will change in the next patch\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:160 will change in next patch\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java:169 will change in next patch\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java:48 sure, will change\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java:56 will change this message too\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java:36 whoops forgot to add that .. will do\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java:39-40 Actually, my latest patch did mark these fields as transient .. I'll need to update this review with the updated patch.\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java:34 Do we need to serialize object inspectors? my impression is that should always have been transient, at least when they're used in UDFs since they can be set during initialize().\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java:401 Yeah, this comment is gone in the updated patch.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java:474 2011 SQL Standard (6.13 cast specification) does say that the value should be \"TRUE\"/\"FALSE\". This also matches what we're doing with the string type.\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java:33 ok, will change\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java:35 will change\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12699\n\nTo: JIRA, jdere\nCc: ashutoshc\n",
                {
                    "property": {
                        "confidence": 0.004236432258039713,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.01646173559129238,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.07021799683570862,
                        "prediction": false
                    }
                }
            ],
            [
                2012195,
                "HIVE-4844",
                "jdere requested code review of \"HIVE-4844 [jira] Add varchar data type\".\n\nReviewers: JIRA\n\nChanges to HIVE-4844 per review from ashutosh\n\nAdd new varchar data types which have support for more SQL-compliant behavior, such as SQL string comparison semantics, max length, etc.\nChar type will be added as another task.\n\nTEST PLAN\n  EMPTY\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12891\n\nAFFECTED FILES\n  common/src/java/org/apache/hadoop/hive/common/type/HiveBaseChar.java\n  common/src/java/org/apache/hadoop/hive/common/type/HiveVarchar.java\n  common/src/test/org/apache/hadoop/hive/common/type/TestHiveVarchar.java\n  data/files/datatypes.txt\n  data/files/vc1.txt\n  ql/src/java/org/apache/hadoop/hive/ql/exec/FunctionRegistry.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/BaseSemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveLexer.g\n  ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g\n  ql/src/java/org/apache/hadoop/hive/ql/parse/ParseUtils.java\n  ql/src/java/org/apache/hadoop/hive/ql/parse/TypeCheckProcFactory.java\n  ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java\n  ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeConstantDesc.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/GenericUDFEncode.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/UDFToString.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFBaseCompare.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcat.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFConcatWS.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFLower.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFReflect2.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFStringToMap.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToDate.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToVarchar.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUpper.java\n  ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java\n  ql/src/test/org/apache/hadoop/hive/ql/exec/TestFunctionRegistry.java\n  ql/src/test/queries/clientnegative/invalid_varchar_length_1.q\n  ql/src/test/queries/clientnegative/invalid_varchar_length_2.q\n  ql/src/test/queries/clientnegative/invalid_varchar_length_3.q\n  ql/src/test/queries/clientpositive/alter_varchar1.q\n  ql/src/test/queries/clientpositive/ctas_varchar.q\n  ql/src/test/queries/clientpositive/partition_varchar1.q\n  ql/src/test/queries/clientpositive/varchar_1.q\n  ql/src/test/queries/clientpositive/varchar_2.q\n  ql/src/test/queries/clientpositive/varchar_cast.q\n  ql/src/test/queries/clientpositive/varchar_comparison.q\n  ql/src/test/queries/clientpositive/varchar_join1.q\n  ql/src/test/queries/clientpositive/varchar_nested_types.q\n  ql/src/test/queries/clientpositive/varchar_udf1.q\n  ql/src/test/queries/clientpositive/varchar_union1.q\n  ql/src/test/results/clientnegative/invalid_varchar_length_1.q.out\n  ql/src/test/results/clientnegative/invalid_varchar_length_2.q.out\n  ql/src/test/results/clientnegative/invalid_varchar_length_3.q.out\n  ql/src/test/results/clientpositive/alter_varchar1.q.out\n  ql/src/test/results/clientpositive/ctas_varchar.q.out\n  ql/src/test/results/clientpositive/partition_varchar1.q.out\n  ql/src/test/results/clientpositive/varchar_1.q.out\n  ql/src/test/results/clientpositive/varchar_2.q.out\n  ql/src/test/results/clientpositive/varchar_cast.q.out\n  ql/src/test/results/clientpositive/varchar_comparison.q.out\n  ql/src/test/results/clientpositive/varchar_join1.q.out\n  ql/src/test/results/clientpositive/varchar_nested_types.q.out\n  ql/src/test/results/clientpositive/varchar_udf1.q.out\n  ql/src/test/results/clientpositive/varchar_union1.q.out\n  serde/if/serde.thrift\n  serde/src/gen/thrift/gen-cpp/serde_constants.cpp\n  serde/src/gen/thrift/gen-cpp/serde_constants.h\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/serdeConstants.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde/test/ThriftTestObj.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/Complex.java\n  serde/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/serde2/thrift/test/MegaStruct.java\n  serde/src/gen/thrift/gen-php/org/apache/hadoop/hive/serde/Types.php\n  serde/src/gen/thrift/gen-py/org_apache_hadoop_hive_serde/constants.py\n  serde/src/gen/thrift/gen-rb/serde_constants.rb\n  serde/src/java/org/apache/hadoop/hive/serde2/SerDeUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroObjectInspectorGenerator.java\n  serde/src/java/org/apache/hadoop/hive/serde2/binarysortable/BinarySortableSerDe.java\n  serde/src/java/org/apache/hadoop/hive/serde2/io/DoubleWritable.java\n  serde/src/java/org/apache/hadoop/hive/serde2/io/HiveVarcharWritable.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyHiveVarchar.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/LazyUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazy/objectinspector/primitive/LazyPrimitiveObjectInspectorFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryHiveVarchar.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinarySerDe.java\n  serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/LazyBinaryUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorConverters.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/ObjectInspectorUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/PrimitiveObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/HiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/ParameterizedPrimitiveTypeUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/JavaHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/SettableHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableConstantHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/WritableHiveVarcharObjectInspector.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfo.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoFactory.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java\n  serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/VarcharTypeParams.java\n  serde/src/test/org/apache/hadoop/hive/serde2/typeinfo/TestTypeInfoUtils.java\n\nMANAGE HERALD RULES\n  https://reviews.facebook.net/herald/view/differential/\n\nWHY DID I GET THIS EMAIL?\n  https://reviews.facebook.net/herald/transcript/30861/\n\nTo: JIRA, jdere\n",
                {
                    "property": {
                        "confidence": 0.005043209996074438,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.06795267015695572,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.0687139481306076,
                        "prediction": false
                    }
                }
            ],
            [
                2012196,
                "HIVE-4844",
                "ashutoshc has accepted the revision \"HIVE-4844 [jira] Add varchar data type\".\n\n  +1 Thanks, Jason for making changes.\n\nREVISION DETAIL\n  https://reviews.facebook.net/D12891\n\nBRANCH\n  HIVE-4844.2\n\nARCANIST PROJECT\n  hive\n\nTo: JIRA, ashutoshc, jdere\n",
                {
                    "property": {
                        "confidence": 0.003276021918281913,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.09320933371782303,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.01180401723831892,
                        "prediction": false
                    }
                }
            ],
            [
                2012197,
                "HIVE-4844",
                "Ran unit test and got a couple failures:\n- varchar_union1.q: looks like this test is not deterministic, need to make sure the query results are sorted\n- udf_reflect2.q: looks like I had a bug in PrimitiveObjectInspectorUtils.getTypeEntryFromTypeSpecs()\nWill update the patch shortly",
                {
                    "property": {
                        "confidence": 0.005112414713948965,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.010266460478305817,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.009008859284222126,
                        "prediction": false
                    }
                }
            ],
            [
                2012199,
                "HIVE-4844",
                "Thanks for making so much progress in such a short time. I have some comments while reading the patch.\n\n1. TypeInfoUtils.addParamsToTypeName() seems having duplicated code with VarcharTypeParam.toString().I also saw this in FunctionRegistry, which also has some duplicated logic here. It's nice if we can consolidate and have single point of reference for this. \n{code}\n+        String typeName =\n+            PrimitiveObjectInspectorUtils.getTypeEntryFromPrimitiveCategory(typeCategory).typeName\n+            + varcharParams.toString();\n{code}\n\n2. DDLSemanticAnalyzer.getTypeName() tries to get a list of Strings from the ASTNode by using ParseUtils.getCharParams(), in which only a subset of checks are performed. (For instance, it doesn't validate the MAX allowed length.) Instead, I think it's probably better to get VarcharTypeParams instance from the ASTNode and let the instance perform all the checks.\n\nI haven't gone thru the patch yet, but I'd like to share my thoughts.\n",
                {
                    "property": {
                        "confidence": 0.0077922148630023,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.005544705782085657,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011381720192730427,
                        "prediction": false
                    }
                }
            ],
            [
                2012200,
                "HIVE-4844",
                "Also in ParseUtils.getCharParams(), checking NumberFormatException and child count is probably not needed. This attributes to the grammar rule.\n\n{code}\n+    | KW_VARCHAR LPAREN length=Number RPAREN      ->    ^(TOK_VARCHAR $length)\n{code}\n\nThis is a minor thing that probably makes the code cleaner.",
                {
                    "property": {
                        "confidence": 0.00585850840434432,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0066094412468373775,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.011379683390259743,
                        "prediction": false
                    }
                }
            ],
            [
                2012202,
                "HIVE-4844",
                "Adding patch v18, which incorporates Xuefu's comments about consolidating type name generation. No longer catching NumberFormatException, but there still is a try/catch there since the type params validation throws a SerDeException, and I figured it made more sense to return a SemanticException in that context.",
                {
                    "property": {
                        "confidence": 0.003528484608978033,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.012471322901546955,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013988446444272995,
                        "prediction": false
                    }
                }
            ],
            [
                2012215,
                "HIVE-4844",
                "Hi,\r\n\r\nI have a question regarding Hive Varchar. I have a few million rows of records in a column.\u00a0\r\n # How I can find out what is the maximum byte used in a row of a column. So that I can optimally allocate length of Varchar column?\r\n\r\n\u00a0",
                {
                    "property": {
                        "confidence": 0.004870721139013767,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.016695447266101837,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008541177026927471,
                        "prediction": false
                    }
                }
            ],
            [
                2012217,
                "HIVE-4844",
                "[~jdere], [~ashutoshc], we found\u00a0varchar and string will\u00a0behave\u00a0differently for malformed utf8 characters.\r\n\r\nFor example, the original data is 6130373530633166313366306B35B0A546386A8DAEAB62B4526F273464613936 in hex.\r\n\r\n*B0A5 and*\u00a0*8DAEAB*\u00a0are malformed utf8 characters, they are decoded to\u00a0EFBFBD if the data type is varchar,\u00a0but string will not change it. So:\r\n\r\nVARCHAR in hex shows: 6130373530633166313366306B35EFBFBDEFBFBD46386AEFBFBDEFBFBDEFBFBD62EFBFBD526F273464613936\r\n STRING in hex shows: 6130373530633166313366306B35B0A546386A8DAEAB62B4526F273464613936\r\n\r\nIs it expected?\r\n\r\nMore details @https://issues.apache.org/jira/browse/HIVE-21042",
                {
                    "property": {
                        "confidence": 0.004974286071956158,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006759857293218374,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.014125481247901917,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d5e0ecf4d395ee221b7504",
        "key": "SENTRY-1748",
        "id": "13069261",
        "description": "In order to test Sentry HA, we will need to know which Sentry server a client is connected to so that we can make that server unavailable to the client and cause a failover. Currently the clients will randomly choose which sentry server to connect to. We could like a configuration setting to be available that will cause the client to deterministically choose a configured sentry server, and for the server that is chosen to be available via the CM api. ",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.003010089974850416
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.3347149193286896
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.015021574683487415
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    },
    {
        "_id": "61d608b7f4d395ee2221b8ae",
        "key": "HADOOP-11349",
        "id": "12759248",
        "description": "{{RawLocalFileSystem}} currently implements some file creation operations as a sequence of 2 syscalls: create the file, followed by setting its permissions.  If creation succeeds, but then setting permission causes an exception to be thrown, then there is no attempt to close the previously opened file, resulting in a file descriptor leak.",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.005130819045007229
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.04512076452374458
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.004915566649287939
                }
            }
        },
        "comments": [
            {
                "author_name": "cmccabe",
                "id": "14238816",
                "body": "+1."
            },
            {
                "author_name": "hadoopqa",
                "id": "14238817",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12685906/HADOOP-11349.patch\n  against trunk revision ddffcd8.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 65 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5197//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5197//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5197//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "jira.shegalov",
                "id": "14238900",
                "body": "#  We should consider catching {{Throwable}} to make it more robust. \n# {{out.close}} may throw an exception that will hide the original problem, we probably should just  catch and log it without throwing, to make sure that the original exception is thrown\n\nPlease add a whitespace after {{catch}} "
            },
            {
                "author_name": "varun_saxena",
                "id": "14239049",
                "body": "The findbugs warnings are coming for System.out and System.err being null. Nothing to do with code change.\nHas Jenkins build env changed recently ? Because even in MapReduce, a similar issue was raised - MAPREDUCE-6184"
            },
            {
                "author_name": "varun_saxena",
                "id": "14239069",
                "body": "Findbugs issue seems to be cause by http://sourceforge.net/p/findbugs/bugs/918/ as mentioned in comments section of MAPREDUCE-6184"
            },
            {
                "author_name": "varun_saxena",
                "id": "14239071",
                "body": "Thanks [~jira.shegalov] for the review. \nAttached a new patch addressing these comments.\n\nKindly review [~jira.shegalov] and [~cmccabe]"
            },
            {
                "author_name": "hadoopqa",
                "id": "14239113",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12685949/HADOOP-11349.002.patch\n  against trunk revision db73cc9.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 65 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.\n\n    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5201//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5201//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5201//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "varun_saxena",
                "id": "14239419",
                "body": "Fingbugs issues unrelated to code change"
            },
            {
                "author_name": "varun_saxena",
                "id": "14239421",
                "body": "I meant findbugs."
            },
            {
                "author_name": "cmccabe",
                "id": "14239892",
                "body": "How about using {{IOUtils.cleanup}}?  That's what we use in other places to clean up streams.\n\nthanks"
            },
            {
                "author_name": "varun_saxena",
                "id": "14239942",
                "body": "[~cmccabe], yeah that will be far more cleaner. Uploading a new patch."
            },
            {
                "author_name": "jira.shegalov",
                "id": "14239945",
                "body": "Good idea, [~cmccabe]! It also addresses an additional comment I had for the 002 patch that the exception should be included in the log.\n\nThanks for updating the patch, [~varun_saxena]! \n\nInstead of blindly wrapping the Throwable, you should do it only if it's not {{instanceof IOException}}. Since you have to do this check twice, maybe add a helper method."
            },
            {
                "author_name": "varun_saxena",
                "id": "14239962",
                "body": "[~jira.shegalov], addressed your comment in the new patch. Kindly review."
            },
            {
                "author_name": "cmccabe",
                "id": "14239992",
                "body": "I apologize if it seems like I'm nitpicking here, but I really don't like catching Throwable.\n\nOur usual idiom for this kind of thing is:\n\n{code}\nboolean success = false;\ntry {\n  out = ...\n  success = true;\n} finally {\n  if (!success) {\n    IOUtils.cleanup(out)\n  }\n}\n{code}\n\nThis avoids the need to wrap the exception (or to rethrow the exception at all).\n\nThanks again for taking this one up, and sorry for the nitpick!"
            },
            {
                "author_name": "jira.shegalov",
                "id": "14240008",
                "body": "[~cmccabe], I think it's much better, your suggestion does not qualify as nitpicking :)"
            },
            {
                "author_name": "cnauroth",
                "id": "14240012",
                "body": "+1 for using the success flag idiom.  [~varun_saxena], thank you for picking up this patch."
            },
            {
                "author_name": "varun_saxena",
                "id": "14240023",
                "body": "[~cmccabe] and others, I have updated the patch with the suggested change(using a flag)."
            },
            {
                "author_name": "hadoopqa",
                "id": "14240032",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12686074/HADOOP-11349.003.patch\n  against trunk revision 5776a41.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 111 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5212//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5212//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5212//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hadoopqa",
                "id": "14240092",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12686088/HADOOP-11349.004.patch\n  against trunk revision 5776a41.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 111 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:\n\n                  org.apache.hadoop.ha.TestSshFenceByTcpPort\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5213//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5213//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5213//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "cmccabe",
                "id": "14240102",
                "body": "+1.  Test failure is not related (and findbugs is the upstream issue we know about with migration to new FB)\nWill commit in a few, thanks all"
            },
            {
                "author_name": "hadoopqa",
                "id": "14240186",
                "body": "{color:red}-1 overall{color}.  Here are the results of testing the latest attachment \n  http://issues.apache.org/jira/secure/attachment/12686099/HADOOP-11349.005.patch\n  against trunk revision 1340617.\n\n    {color:green}+1 @author{color}.  The patch does not contain any @author tags.\n\n    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.\n                        Please justify why no new tests are needed for this patch.\n                        Also please list what manual steps were performed to verify this patch.\n\n    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.\n\n    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.\n\n    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.\n\n    {color:red}-1 findbugs{color}.  The patch appears to introduce 111 new Findbugs (version 2.0.3) warnings.\n\n    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.\n\n    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.\n\nTest results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5215//testReport/\nFindbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5215//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html\nConsole output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5215//console\n\nThis message is automatically generated."
            },
            {
                "author_name": "hudson",
                "id": "14240197",
                "body": "FAILURE: Integrated in Hadoop-trunk-Commit #6684 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6684/])\nHADOOP-11349. RawLocalFileSystem leaks file descriptor while creating a file if creat succeeds but chmod fails. (Varun Saxena via Colin P.  McCabe) (cmccabe: rev 03867eb1bb173c66b5eb3bebf2fe03a1188635b5)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n"
            },
            {
                "author_name": "varun_saxena",
                "id": "14240738",
                "body": "Thanks for the review and commit [~cmccabe]"
            },
            {
                "author_name": "hudson",
                "id": "14240894",
                "body": "FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #36 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/36/])\nHADOOP-11349. RawLocalFileSystem leaks file descriptor while creating a file if creat succeeds but chmod fails. (Varun Saxena via Colin P.  McCabe) (cmccabe: rev 03867eb1bb173c66b5eb3bebf2fe03a1188635b5)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n"
            },
            {
                "author_name": "hudson",
                "id": "14240911",
                "body": "FAILURE: Integrated in Hadoop-Yarn-trunk #771 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/771/])\nHADOOP-11349. RawLocalFileSystem leaks file descriptor while creating a file if creat succeeds but chmod fails. (Varun Saxena via Colin P.  McCabe) (cmccabe: rev 03867eb1bb173c66b5eb3bebf2fe03a1188635b5)\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java\n"
            },
            {
                "author_name": "hudson",
                "id": "14241157",
                "body": "FAILURE: Integrated in Hadoop-Hdfs-trunk #1968 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1968/])\nHADOOP-11349. RawLocalFileSystem leaks file descriptor while creating a file if creat succeeds but chmod fails. (Varun Saxena via Colin P.  McCabe) (cmccabe: rev 03867eb1bb173c66b5eb3bebf2fe03a1188635b5)\n* hadoop-common-project/hadoop-common/CHANGES.txt\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java\n"
            },
            {
                "author_name": "hudson",
                "id": "14241186",
                "body": "FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #34 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/34/])\nHADOOP-11349. RawLocalFileSystem leaks file descriptor while creating a file if creat succeeds but chmod fails. (Varun Saxena via Colin P.  McCabe) (cmccabe: rev 03867eb1bb173c66b5eb3bebf2fe03a1188635b5)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n"
            },
            {
                "author_name": "hudson",
                "id": "14241221",
                "body": "FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #38 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/38/])\nHADOOP-11349. RawLocalFileSystem leaks file descriptor while creating a file if creat succeeds but chmod fails. (Varun Saxena via Colin P.  McCabe) (cmccabe: rev 03867eb1bb173c66b5eb3bebf2fe03a1188635b5)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n"
            },
            {
                "author_name": "hudson",
                "id": "14241280",
                "body": "FAILURE: Integrated in Hadoop-Mapreduce-trunk #1988 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1988/])\nHADOOP-11349. RawLocalFileSystem leaks file descriptor while creating a file if creat succeeds but chmod fails. (Varun Saxena via Colin P.  McCabe) (cmccabe: rev 03867eb1bb173c66b5eb3bebf2fe03a1188635b5)\n* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java\n* hadoop-common-project/hadoop-common/CHANGES.txt\n"
            }
        ],
        "comments_predictions": [
            [
                2588743,
                "HADOOP-11349",
                "#  We should consider catching {{Throwable}} to make it more robust. \n# {{out.close}} may throw an exception that will hide the original problem, we probably should just  catch and log it without throwing, to make sure that the original exception is thrown\n\nPlease add a whitespace after {{catch}} ",
                {
                    "property": {
                        "confidence": 0.005331542808562517,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006132509559392929,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.016641465947031975,
                        "prediction": false
                    }
                }
            ],
            [
                2588744,
                "HADOOP-11349",
                "The findbugs warnings are coming for System.out and System.err being null. Nothing to do with code change.\nHas Jenkins build env changed recently ? Because even in MapReduce, a similar issue was raised - MAPREDUCE-6184",
                {
                    "property": {
                        "confidence": 0.006219589151442051,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.008462434634566307,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.008375300094485283,
                        "prediction": false
                    }
                }
            ],
            [
                2588752,
                "HADOOP-11349",
                "Good idea, [~cmccabe]! It also addresses an additional comment I had for the 002 patch that the exception should be included in the log.\n\nThanks for updating the patch, [~varun_saxena]! \n\nInstead of blindly wrapping the Throwable, you should do it only if it's not {{instanceof IOException}}. Since you have to do this check twice, maybe add a helper method.",
                {
                    "property": {
                        "confidence": 0.0049791219644248486,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.006658256985247135,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.013323324732482433,
                        "prediction": false
                    }
                }
            ],
            [
                2588754,
                "HADOOP-11349",
                "I apologize if it seems like I'm nitpicking here, but I really don't like catching Throwable.\n\nOur usual idiom for this kind of thing is:\n\n{code}\nboolean success = false;\ntry {\n  out = ...\n  success = true;\n} finally {\n  if (!success) {\n    IOUtils.cleanup(out)\n  }\n}\n{code}\n\nThis avoids the need to wrap the exception (or to rethrow the exception at all).\n\nThanks again for taking this one up, and sorry for the nitpick!",
                {
                    "property": {
                        "confidence": 0.008067370392382145,
                        "prediction": false
                    },
                    "executive": {
                        "confidence": 0.0029933443292975426,
                        "prediction": false
                    },
                    "existence": {
                        "confidence": 0.04193701967597008,
                        "prediction": false
                    }
                }
            ]
        ]
    },
    {
        "_id": "61d609c4f4d395ee2221f908",
        "key": "GROOVY-4967",
        "id": "12815820",
        "description": "a), b), and c) all work, but d) fails with \"GroovyCastException: Cannot cast object '[x]' with class 'java.util.ArrayList' to class 'java.util.LinkedHashSet'\"\n\na)\n{code}\nList x = []\nHashSet<String> lhs = x\n{code}\n\nb)\n{code}\nList x = ['x']\nHashSet<String> lhs = x\n{code}\n\nc)\n{code}\nList x = []\nLinkedHashSet<String> lhs = x\n{code}\n\nd)\n{code}\nList x = ['x']\nLinkedHashSet<String> lhs = x\n{code}",
        "predictions": {
            "648ee4526b3fde4b1b33e099-648f1f6f6b3fde4b1b3429cf": {
                "executive": {
                    "prediction": false,
                    "confidence": 0.007207999937236309
                },
                "existence": {
                    "prediction": false,
                    "confidence": 0.009845049120485783
                },
                "property": {
                    "prediction": false,
                    "confidence": 0.006558496039360762
                }
            }
        },
        "comments": [],
        "comments_predictions": {}
    }
]